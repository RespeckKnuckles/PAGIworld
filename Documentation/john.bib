%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for John Licato at 2014-09-17 11:27:45 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@book{Dennett1989,
	Author = {Dennett, Daniel},
	Date-Added = {2014-09-17 15:26:02 +0000},
	Date-Modified = {2014-09-17 15:27:45 +0000},
	Publisher = {The MIT Press},
	Title = {The Intentional Stance},
	Year = {1989}}

@article{Siegler1995,
	Annote = {Cited by Wellman 2004 as showing that explaining the reasoning of others' beliefs, inferences, choices, directly enhances learning (related to the self-explanation effect).},
	Author = {Siegler, Robert S.},
	Date-Added = {2014-09-17 13:14:10 +0000},
	Date-Modified = {2014-09-17 13:16:12 +0000},
	Journal = {Cognitive Psychology},
	Number = {3},
	Pages = {225-273},
	Title = {How Does Change Occur: A Microgenetic Study of Number Conservation},
	Volume = {28},
	Year = {1995}}

@article{Chi1989,
	Annote = {Cited by Wellman 2004 as saying that the self-explanation effect also works for adults who explain things to themselves actively.},
	Author = {Chi, Michelene T.H. and Bassok, Miriam and Lewis, Matthew W. and Reimann, Peter and Glaser, Robert},
	Date-Added = {2014-09-17 13:12:08 +0000},
	Date-Modified = {2014-09-17 13:13:12 +0000},
	Journal = {Cognitive Science},
	Number = {2},
	Pages = {145-182},
	Title = {Self-Explanations: How Students Study and Use Examples in Learning to Solve Problems},
	Volume = {13},
	Year = {1989}}

@article{Chi1994,
	Annote = {Cited by Wellman 2004 as example of the self-explanation effect where "when students are trained to provide [explanations of things they read] for themselves, they learn more."},
	Author = {Chi, Michelene T.H. and De Leeuw, Nicholas and Chiu, Mei-Hung and Lavancher, Christian},
	Date-Added = {2014-09-17 13:09:43 +0000},
	Date-Modified = {2014-09-17 13:11:28 +0000},
	Journal = {Cognitive Science},
	Number = {3},
	Pages = {439-477},
	Title = {Eliciting Self-Explanations Improves Understanding},
	Volume = {18},
	Year = {1994}}

@article{Wellman2004,
	Annote = {Chi's self-explanation effect work says "when students are trained to provide [explanations of things they read] for themselves, they learn more." (Chi et al 1994) This also works for adults who actively explain to themselves (Chi et al 1989). 

Explaining the reasoning of others' beliefs, inferences, choices, and statements, also directly enhances learning (Siegler 1995b), Pine and Siegler 2003, suggesting that encouraging development of theory of mind may be helpful in teaching (cite this paper), transition into Rosenbloom

Chi et al., 1994
M.T.H. Chi, N. de Leeuw, M. Chiu, L. LaVancher
Eliciting self-explanations improves understanding

Chi et al., 1989
M.T.H. Chi, M. Bassock, M.W. Lewis, P. Reimanm, R. Glaser
Self explanations: How students study and use examples in learning to solve problems
Cognitive Science, 13 (1989), pp. 145--182

Pine and Siegler, 2003
Pine, K. J., & Siegler, R. S. (2003). The role of explanatory activity in increasing the generality of thinking. Paper presented at the Biennial Meeting of the Society for Research in Child Development, Tampa, FL.

Siegler, 1995b
R.S. Siegler
How does change occur: A microgenetic study of number conservation
Cognitive Development, 28 (1995), pp. 225--273},
	Author = {Wellman, Henry M. and Lagattuta, Kristin H.},
	Date-Added = {2014-09-17 13:07:49 +0000},
	Date-Modified = {2014-09-17 13:09:38 +0000},
	Journal = {Cognitive Development},
	Number = {4},
	Pages = {479-497},
	Title = {Theory of Mind for Learning and Teaching: The Nature and Role of Explanation},
	Volume = {19},
	Year = {2004}}

@incollection{Thagard2012,
	Annote = {Talks about cognitive models of scientific explanation. 
Says there are three major processes involved in explanation:
- providing an explanation from available information
- generating new hypotheses that provide explanations
- evaluating competing explanations

And four major theoretical approaches that have been taken in computational models of it:
- logical: whereby explanations are deductive arguments
- causal schema or analogy
- probabilistic
- using artificial neural networks

PHINEAS (Falkenhainer 1990) uses the analogical tool SME (Falkenhainer et al 1989) to explain scientific phenomena.
The PI system (Thagard 1988) also explains scientific phenomena, using analogy as one of three criteria to select between competing hypotheses.
The ECHO model (Thagard 1989, 1992, 2000) is an artifical neural network-based model that also tries to explain scientific phenomena.
The NEF (neural engineering framework) (Eliasmith and Anderson 2003) uses holographic reduced representations (HRRs) to approximate both distributed representations and operations traditionally defined only over localist representations (like an approximate inverse operation, constructive operations like circular convolution, simple superposition, etc.)},
	Author = {Thagard, Paul and Litt, Abninder},
	Booktitle = {The Cognitive Science of Science},
	Chapter = {3},
	Date-Added = {2014-09-16 19:10:54 +0000},
	Date-Modified = {2014-09-16 19:12:00 +0000},
	Editor = {Thagard, Paul},
	Publisher = {The MIT Press},
	Title = {Models of Scientific Explanation},
	Year = {2012}}

@inproceedings{Pynadath2013,
	Author = {Pynadath, David V and Rosenbloom, Paul and Marsella, Stacy C. and Li, Lingshan},
	Booktitle = {Proceedings of the Sixth Conference on Artificial General Intelligence (AGI-13)},
	Date-Added = {2014-09-15 04:27:08 +0000},
	Date-Modified = {2014-09-15 04:28:47 +0000},
	Title = {Modeling Two-Player Games in the Sigma Graphical Cognitive Architecture},
	Year = {2013}}

@article{Hummel2014,
	Author = {Hummel, John E. and Licato, John and Bringsjord, Selmer},
	Date-Added = {2014-09-15 04:24:48 +0000},
	Date-Modified = {2014-09-15 04:26:34 +0000},
	Journal = {Frontiers in Human Neuroscience},
	Title = {Analogy, Explanation, and Proof},
	Year = {In Press}}

@incollection{Brewer2000,
	Annote = {Nonscientists:
- A study by Brewer and Chinn (1994) supports the idea that nonscientists prefer theories that are consistent rather than inconsistent with the theoretical evidence.
- Chinn and Brewer (1992) and Schank and Ranney (1991) showed undergrads prefer theories that can explain more data, and which have wider empirical scope, respectively.
- Chinn and Brewer (1998) explored how some students might reject anamolous data if it doesn't fit into their theory, and be more willing to accept explanations that dismiss the anomalies.

Scientists:
- Toulmin (1961) argues that the criterias used by scientists to evaluate explanations has changed over time

Children:
- Sumarapungavan (1992) - direct study of some children's evaluations of the quality of explanations.},
	Author = {Brewer, William F. and Chinn, Clark A. and Sumarapungavan, Ala},
	Booktitle = {Explanation and Cognition},
	Date-Added = {2014-09-12 21:08:32 +0000},
	Date-Modified = {2014-09-12 21:09:18 +0000},
	Editor = {Keil, Frank C. and Wilson, Robert A.},
	Publisher = {MIT Press},
	Title = {Explanation in Scientists and Children},
	Year = {2000}}

@incollection{Simon2000,
	Annote = {Didn't read most of it, but he had a small section on analogy where he argued it was a mechanism that plays an important role in theory construction.

},
	Author = {Simon, Herb},
	Booktitle = {Explanation and Cognition},
	Date-Added = {2014-09-12 21:01:15 +0000},
	Date-Modified = {2014-09-12 21:04:43 +0000},
	Editor = {Keil, Frank C. and Wilson, Robert A.},
	Publisher = {MIT Press},
	Title = {Discovering Explanations},
	Year = {2000}}

@incollection{Cummins2000,
	Annote = {He starts by asking why Hempel and Oppenheim's DN model of explanation is still influential, even though it has a poor track record. he says there are two reasons: the hypothetico-deductive model in scientific papers, and the fact that no better theory exists in its place.

When asking why something is the case, a mathematical formula doesn't seem to be sufficiently explanatory. Why? "I think we should take seriously the possibility that it cannot be done because there isn't any difference: No laws are explanatory in the sense required by DN. Laws simply tell us what happens; they do not tell us why or how." (119)

So he argues that DN is a failure

he also argues that psychological explanation, although it can be compelling and informative, is almost always ultimately unsatisfactory as explanation.
Top-down explanations and models are not satisfactory either.},
	Author = {Cummins, Robert},
	Booktitle = {Explanation and Cognition},
	Date-Added = {2014-09-12 15:02:43 +0000},
	Date-Modified = {2014-09-12 15:03:22 +0000},
	Editor = {Keil, Frank C. and Wilson, Robert A.},
	Publisher = {MIT Press},
	Title = {``How Does it Work?" versus ``What are the Laws?": Two Conceptions of Psychological Explanation},
	Year = {2000}}

@incollection{Keil2000,
	Annote = {This is the first chapter in a book which attempts to answer five questions:
1) How do explanatory capacities develop?
- "The ability to provide explanations of any sort does not appear until a child's third year of life, and then only in surprisingly weak and ineffective forms. Ask even a five-year-old how something works, and the most common answer is simply to use the word 'because' followed by a repetition or paraphrase of what the thing does." (3)

2) Are there kinds of explanation?
- "Explanations in terms of more general laws and principles comprise vastly fewer steps and are [yet] cognitively much more challenging. One possible reasoning may have to do with the closeness between explanations of individual histories and our ability to construct and comprehend narratives more generally, one of the earliest human cognitive faculties to emerge (Neisser 1994; Fivush 1997). By contrast, it is a fairly recent development that people have offered explanations of kinds in terms of principles. ... In recognizing the limits of the deductive-nomological model of scientific explanation, to what extent do we close the prima facie gap between scientific explanation and the sorts of intuitive explanations seen in young children?" (5-6)
- "We see here three prima facie distinct kinds of explanation---principle based, narrative based, and goal based". What do they all share? "One common thread may involve a pragmatic, coherence constraint that requires that all causal links be of the same sort and not shift radically from level to level." (6)

3) Do explanations correspond to domains of knowledge?
- Some have proposed that children are endowed with two distinct modes of explanation that shape all other types of explanation they come to accept: an intuitive psychology and an intuitive physical mechanics (Carey 1985).
- "Although, with domains of explanation, we can avoid the conclusion that to know anything we must know everything, we should be wary of thinking of these domains as isolated atoms." (8)

4) Why do we seek explanations and what do they accomplish?

5) How central are causes to explanation?



},
	Author = {Keil, Frank C. and Wilson, Robert A.},
	Booktitle = {Explanation and Cognition},
	Date-Added = {2014-09-12 13:42:57 +0000},
	Date-Modified = {2014-09-12 14:50:19 +0000},
	Editor = {Keil, Frank C. and Wilson, Robert A.},
	Publisher = {MIT Press},
	Title = {Explaining Explanation},
	Year = {2000}}

@article{Thagard1990,
	Annote = {http://www.nbu.bg/cogs/personal/kokinov/COG501/analog.pdf

The paper that should be cited for ARCS, a main competitor to MAC/FAC, and model of analog retrieval.
This paper also introduces the dataset which consists of 100 of aesop's fables encoded in predicate-object form, and 20? of shakespeare's plays. This was used by Pickett2013, and is now available as THNET (THinkNet) at http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/neural/systems/thnet/0.html .},
	Author = {Thagard, Paul and Holyoak, Keith J. and Nelson, G. and Gochfeld, D.},
	Date-Added = {2014-09-05 04:20:05 +0000},
	Date-Modified = {2014-09-05 04:21:18 +0000},
	Journal = {Artificial Intelligence},
	Number = {3},
	Pages = {259-310},
	Title = {Analog Retrieval by Constraint Satisfaction},
	Volume = {46},
	Year = {1993}}

@inproceedings{Law1994,
	Address = {Hillsdale, NJ},
	Annote = {http://groups.psych.northwestern.edu/gentner/papers/LawForbusGentner94.pdf

Provides nice summaries of MAC/FAC and ARCS.

Some major comparisons:
- The most crucial difference [in representations used] is that structure-mapping treats attributes, relations, and functions differently, whereas ARCS does not distinguish them.
- MAC/FAC doesn't take into account pragmatic constraints, but they counter-argue that "the special demands of large memories [in retrieval] argue for simpler algorithms, simply because the cost of false positives is much higher. If retrieval were a one-shot operation, the cost of false negatives would be higher. But in normal situations, retrieval is iterative, interleaved with the construction of the representations being used."},
	Author = {Law, Keith and Forbus, Kenneth D. and Gentner, Dedre},
	Booktitle = {Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society},
	Date-Added = {2014-09-05 04:03:18 +0000},
	Date-Modified = {2014-09-05 04:04:36 +0000},
	Pages = {543-548},
	Publisher = {Lawrence Elrbaum Associates, Inc.},
	Title = {Simulating Simulatiry-Based Retrieval: A Comparison of ARCS and MAC/FAC},
	Year = {1994}}

@article{Nugent2009,
	Annote = {They use two "knowledge-light frameworks for case-based explanation": Explanation oriented retrieval (EOR) and the Knowledge-light explanation framework (KLEF).

Problems with case-based expanations: mostly having to do with determining how appropriate source cases are
Benefits: its "transparency," meaning that you can understand its generated explanations better than you can with neural networks, "simply by showing the retrieved cases to the user."},
	Author = {Nugent, Conor and Doyle, D{\'o}nal and Cunningham, P{\'a}draig},
	Date-Added = {2014-09-01 17:18:10 +0000},
	Date-Modified = {2014-09-01 17:45:53 +0000},
	Journal = {Journal of Intelligent Information Systems},
	Number = {3},
	Pages = {267-295},
	Title = {Gaining Insight Through Case-Based Explanation},
	Volume = {32},
	Year = {2009}}

@article{Dodson2011,
	Annote = {They use a MDP ( markov decision process) to generate an explanation in the domain of academic advising with the intent of convincing college students that a certain selection of course credits is the best for them. The nature of the probabilistic MDP limits the explanations their system generates for users who do not understand or agree with the wisdom behind stochastic planning [p.4]. The explanation, when converted into natural language, may also use an argument by analogy to convince the student of its suggestion; however, as both the source and target of this analogy are in the same domain, and their system does not perform the structural alignment step characteristic of analogical matching, it is better characterized as a case-based reasoning approach.},
	Author = {Dodson, Thomas and Mattei, Nicholas and Goldsmith, Judy},
	Date-Added = {2014-09-01 16:27:34 +0000},
	Date-Modified = {2014-09-01 16:27:34 +0000},
	Journal = {Lecture Notes in Computer Science},
	Pages = {42-55},
	Title = {A Natural Language Argumentation Interface for Explanation Generation in Markov Decision Processes},
	Volume = {6992},
	Year = {2011}}

@book{Hempel1965,
	Address = {New York},
	Author = {Hempel, C.},
	Date-Added = {2014-09-01 16:27:34 +0000},
	Date-Modified = {2014-09-01 16:27:34 +0000},
	Publisher = {Free Press},
	Title = {Aspects of Scientific Explanation and Other Essays in the Philosophy of Science},
	Year = {1965}}

@incollection{Kitcher1989,
	Address = {Minneapolis},
	Author = {Kitcher, P.},
	Booktitle = {Scientific Explanation},
	Date-Added = {2014-09-01 16:27:34 +0000},
	Date-Modified = {2014-09-01 16:27:34 +0000},
	Editor = {Kitcher, P. and Salmon, W.},
	Pages = {410-505},
	Publisher = {University of Minnesota Press},
	Title = {Explanatory Unification and the Causal Structure of the World},
	Year = {1989}}

@inproceedings{Friedman2010,
	Address = {Atlanta, GA},
	Author = {Friedman, Scott E. and Forbus, Ken},
	Booktitle = {Proceedings of the 24th AAAI Conference on Artificial Intelligence},
	Date-Added = {2014-08-26 17:20:30 +0000},
	Date-Modified = {2014-08-26 17:21:26 +0000},
	Title = {An Integrated Systems Approach to Explanation-Based Conceptual Change},
	Year = {2010}}

@phdthesis{Friedman2012,
	Annote = {"In this dissertation, explanations are constructed to promote learning and to answer questions for experimental evaluation, not for inter-agent communication. The problem of constructing explanations for another agent is best addressed elsewhere, since (1) communicating an explanation may have task-specific aspects, and (2) explaining to another person involves knowing what she believes and often including only beliefs and rationale that she lacks."

"Our model differs from Carey's theory on how knowledge is contextualized. Carey (2009) assumes that new conceptual systems are established to store incommensurable categories, and that analogy, abduction, and model-based thought experiments add causal structure to these new conceptual systems. Our model's knowledge is contextualized at the explanation level, so that two phenomena may be explained using mutually incoherent or inconsistent explanations. When our model finds contradictions across preferred explanations, these are resolved locally, to increase the coherence between these explanations. Thus, our model adopts new information and revises its explanations to improve coherence (e.g., by reducing cost, in Chapter 6), but it does not strongly enforce coherence in a discrete conceptual system."

9.3.5: Novel aspects of our model as a theory of conceptual change
- assumes explanations are persistent structures that organize domain knowledge.
- assumes that phenomena are associated with their preferred explanation in memory, for easy retrieval and reuse later

9.4 Future Work
- Simulating over larger timescales
- Improving explanation construction - Instead of constructing multiple explanations and comparing them, it might be more realistic to compute a single one and incrementally elaborate on it.
- Improving explanation evaluation - they penalize for inclusion of things (e.g. contradictions, assumptions) but not for omission of beliefs within an explanation. "This might be simulated by encoding a metaknowledge relation to conceptually associate the belief that the earth has a tilted axis with the belief that the seasons change."
	- Also try to capture other "explanatory virtues" (Lombrozo 2011)
- Other types of agency - cites Dennett and Keil and Lockhart's three types of causality: mechanical, intentional, and teleological/design/function. Adults tend to use the first, children tend to use the latter two.
- Taking analogy further - "While our system uses analogy to retrieve similar examples and infer qualitative proportionalities (Chapter 8), it does not make spontaneous analogies to transfer knowledge across domains."
- Accruing domain knowledge - They used simulations that were hand-coded in chapters 6 and 7.
- Storing explanations - they store preferred explanations and justification structures, but the latter is very large and storing a lot over time may be difficult.
- Clustering explanandums
- Proactivity - the system is very passive and doesn't do things like ask questions, plan, experiment, etc.
- Applying the model of conceptual change - How might the conceptual change model be used in intelligent tutoring systems?
},
	Author = {Friedman, Scott E.},
	Date-Added = {2014-08-26 15:17:22 +0000},
	Date-Modified = {2014-08-26 15:19:00 +0000},
	School = {Northwestern University},
	Title = {Computational Conceptual Change: An Explanation-Based Approach},
	Year = {2012}}

@inproceedings{Friedman2011,
	Annote = {Deals with the self-explanation effect which is well known in psychology of learning, where when children are asked to explain things and create explanations of possibly incomplete data, they end up understanding the thing being taught better.

"domain knowledge is organized in a knowledge-based tiered network as in Friedman and Forbus [2010]. ... The network contains three tiers:"
- concept tier: instructional and intuitive facts from the domain theory. This includes facts about entities, model fragment types, and situations requiring explanation.
- justification structure tier: plots intermediate beliefs as nodes and justifications which associate antecedent and consequent beliefs.
- explanation tier: plots explanations, which represent a set of justifications which provide well-founded support for some situation, s.t. the justification structure is free of cycles and redundancy.

they used metaknowledge that captured epistemic preferences or biases like inconsistency assertions or information source assertions.},
	Author = {Friedman, Scott E. and Forbus, Ken},
	Booktitle = {Proceedings of the 22nd International Joint Conference on Artificial Intelligence},
	Date-Added = {2014-08-24 21:55:01 +0000},
	Date-Modified = {2014-08-26 23:36:02 +0000},
	Title = {Repairing Incorrect Knowledge with Model Formulation and Metareasoning},
	Year = {2011}}

@article{Gentner2010,
	Annote = {Ken said that this paper provides a look at how comparison might play a role in the learning of numbers.

Provides a good, up-to-date summary of work on analogy},
	Author = {Gentner, Dedre},
	Date-Added = {2014-08-20 22:36:01 +0000},
	Date-Modified = {2014-08-21 03:11:14 +0000},
	Journal = {Cognitive Science},
	Pages = {752-775},
	Title = {Bootstrapping the Mind: Analogical Processes and Symbol Systems},
	Volume = {34},
	Year = {2010}}

@incollection{Gentner2003,
	Address = {Cambridge, MA},
	Annote = {the most philosophical of gentner's papers I've seen in a while.

They argue for two possibilities:
- innate processing abilities: larger processing capacity and/or more powerful learning mechanisms than animals
- participation in human language and culture
And not for this possibility:
- Innate domain theories: our starting knowledge state is qualitatively superior to that of other animals

"By "analogical processing" I do not mean only the perception of distant similarity in which only the relations match. Rather, I include the kind of mundane similarity comparisons that involve common entities as well as common relations."

Literal/overall similarity is the combination of object and relational matches. "Literal similarity (overall similarity) comparisons are easy to compute, because the object and relational matches are all mutually supportive. Analogical matches are more difficult, because the relational correspondences are not supported by object matches, and may even be  opposed by them."
"the contrast between analogy and literal similarity is a continuum, not a dichotomy"---from original Gentner 1983 paper

"It is also important that structure-mapping is accomplished with a process that begins blind and local. Achieving a deep structural alignment does not require advance knolwedge to the point of the comparison. (If it did, it would be relatively useless as a developmental learning process.)"},
	Author = {Gentner, Dedre},
	Booktitle = {Language in Mind: Advances in the Study of Language and Thought},
	Date-Added = {2014-08-20 21:28:28 +0000},
	Date-Modified = {2014-08-20 22:19:40 +0000},
	Editor = {Gentner, Dedre and Goldin-Meadow, S.},
	Publisher = {MIT Press},
	Title = {Why We're So Smart},
	Year = {2003}}

@article{Rattermann1998,
	Annote = {Forbus sent this and said it debunks Goswami and Brown (1990).

This paper is largely about the relational shift hypothesis (Gentner 1988) vs the relational primacy hypothesis (Goswami 1996).

Relational Shift Hypothesis - There is a shift from thematic to relational that happens with children as they develop. The mechanism underlying this evolution is epistemological (based on knowledge/expertise in a domain) rather than maturational. "Thus, there is no absolute level of maturity or epxerience that will enable children to process relational similarity; rather, the kind of similarity children can perceive is determined by the nature of their domain representation, and, in particular, by the amount and kind of relational knowledge they possess in the domain". Three predictions:
- young children and adults will initially make many object-similarity responses
- with age/experience, object-similarity responding should decrease, and
- relational responding should increase.
- furthermore, it can occur at different ages in different domains, depending on domain knowledge

Relational Primacy Hypothesis (Goswami 1992,1996) - Object similarity is NOT required for relational similarity, it is merely one of several performance factors that can impede children's ability to perform relationally.
- "The relational shift hypothesis predicts that the younger children should show higher rates of object-similarity errors and lower rates of relational responding than the other children. Thus, mere-appearance responses in particular, and high-similarity errors in general, should diminish and correct relational responding increase as the children gain in age and experience."
- "to the extent that children fail to select the correct relational response, high object-similarity responses should constitute a significant portion of their errors."

EXPERIMENT 1A
- Presented adults with stimuli from Goswami and Brown's second experiment, asked them to judge similarity between C term and each possible choice.
- The MA (mere-appearance) match was not significantly more similar to C than D was.
- "Thus, the conclusion that young children were resistant to object similarity matches is not supported by the data. The children's low level of mere-appearance responding can be accounted for by the low similarity of the intended object similarity choice and by the dilution effect of other competing object matches."

EXPERIMENT 1B
- Used analogies from Goswami and Brown's experiment 2 on 4 and 5 year olds. Two types of task: analogy and causal reasoning control (CRC).
- They used the results from experiment 1A to know what the surface similarity between objects was.
- "Thus, the results show a strong influence of object similarity on the performance on the younger group, as predicted by the relational shift hypothesis."},
	Author = {Rattermann, Mary Jo and Gentner, Dedre},
	Date-Added = {2014-08-20 18:32:40 +0000},
	Date-Modified = {2014-08-20 20:37:17 +0000},
	Journal = {Cognitive Development},
	Pages = {453-478},
	Title = {More Evidence for Relational Shift in the Development of Analogy: Children's Performance on a Causal-Mapping Task},
	Volume = {13},
	Year = {1998}}

@article{Sun2006b,
	Annote = {simulation of two meta-cognitive experiments.

They don't describe much about how the MCS works in low level detail, rather they just say that it was used to select the reasoning process when multiple options were present.},
	Author = {Sun, Ron and Zhang, Xi and Mathews, Robert},
	Date-Added = {2014-08-19 13:33:12 +0000},
	Date-Modified = {2014-08-24 20:53:09 +0000},
	Journal = {Cognitive Systems Research},
	Pages = {327-338},
	Title = {Modeling Meta-Cognition in a Cognitive Architecture},
	Volume = {7},
	Year = {2006}}

@incollection{Sun2005,
	Address = {New York, New York, USA},
	Annote = {http://www.cogsci.rpi.edu/~rsun/folder-files/sun-wgbook2007.pdf

mentions (introduces?) the MS and MCS. 

Meta-Cognitive Subsystem
- one's knowledge concerning one's own cognitive processes and their outcomes
- also includes the active monitoring and consequent regulation and orchestration of these processes, usually in the service of some concrete goal; thus the MCS is closely tied to the MS in CLARION
- Types of metacognitive processes:
	- Behavioral aiming: setting of reinforcement function and setting of goals
	- Information filtering: focusing of input dimensions in the ACS/NACS
	- Information acquisition: selection of learning methods in ACS/NACS
	- Information utilization: selection of reasoning methods in ACS/NACS
	- Outcome selection: selection of output dimensions in ACS/NACS
	- cognitive mode selection: selection of explicit/implicit processing (or combination) in the ACS
	- setting parameters for the ACS/NACS
- Bottom level: split into goal setting network, reinforcement function network, input selection network, etc.
- "inferences were shown to be made based on (1) the lack of knowledge about something, and (2) the importance/significance of that knowledge. In order to make such inferences, meta-cognitive monitoring of one's own reasoning process is necessary." (29)

Sun 2003 - earliest mention of MCS?},
	Author = {Sun, Ron},
	Booktitle = {Modeling Integrated Cognitive Systems},
	Date-Added = {2014-08-19 13:23:44 +0000},
	Date-Modified = {2014-08-19 13:55:17 +0000},
	Editor = {Gray, Wayne},
	Publisher = {Oxford University Press},
	Title = {The Motivational and Metacognitive Control in CLARION},
	Year = {2007}}

@unpublished{Bruce2010,
	Annote = {http://homepages.abdn.ac.uk/f.guerin/pages/teaching/CS4PRO/past_projects/Bruce_David.pdf

},
	Author = {Bruce, David},
	Date-Added = {2014-08-17 16:34:45 +0000},
	Date-Modified = {2014-08-17 16:36:50 +0000},
	Note = {Undergraduate Honours Thesis},
	Title = {Cognitive Architecture and Testbed for a Developmental AI System},
	Year = {2010}}

@article{Ivaldi2014,
	Annote = {The participants were those who worked in University (70%) or do R&D in public (15%) or private (14%) institutes. The vast majority of them (all?) had a robotics-related field as their primary application field.

The most used simulators were Gzebo and ODE (Open Dynamics Engine)

Most important features were: "Stability of Simulation", "Speed", "Precision of Simulation", "Accuracy of Contact Resolution", and "Same interface between real and simulated system", in that order. },
	Author = {Ivaldi, Serena and Padois, Vincent and Nori, Francesco},
	Date-Added = {2014-08-17 15:29:24 +0000},
	Date-Modified = {2014-08-17 15:54:56 +0000},
	Journal = {CoRR},
	Title = {Tools for Dynamics Simulation of Robots: A Survey Based on User Feedback},
	Volume = {abs/1402.7050},
	Year = {2014}}

@inproceedings{Staranowicz2011,
	Annote = {http://delivery.acm.org/10.1145/2150000/2141689/a56-staranowicz.pdf?ip=128.113.243.66&id=2141689&acc=ACTIVE%20SERVICE&key=7777116298C9657D%2EAF047EA360787914%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=397747782&CFTOKEN=42927316&__acm__=1407780892_5a3dc3169989cc5b7e15a466b4efdf2f


Differs from Kramer 2007 because it also compares commercial software. Also is more up-to-date in a fast-moving field.

"Player/Stage (PS)" is free-software, uses TCP/IP sockets for communication, already has communities for it, supports a broad range of robotic platforms and sensors, and is available for Windows, Linux, and Mac OSX.

Programming language - Only Player/Stage supports any, due to tcp/ip sockets
GUI - it seems that both Player/Stage and Gazebo didn't meet the GUI requirement, described as "if it is possible to modify objects and the environment during run-time and/or program functions in a development environment. The graphical user interface does not include windows that open to display the simulation."},
	Author = {Staranowicz, Aaron and Mariottini, Gian Luca},
	Booktitle = {Proceedings of the 4th International Conference on PErvasive Technologies Related to Assistive Environments (PETRA 2011)},
	Date-Added = {2014-08-11 18:07:42 +0000},
	Date-Modified = {2014-08-11 18:08:59 +0000},
	Title = {A Survey and Comparison of Commercial and Open-Source Robotic Simulator Software},
	Year = {2011}}

@article{Drumwright2010,
	Annote = {http://robotics.cs.tamu.edu/dshell/papers/simpar2010ode.pdf},
	Author = {Drumwright, Evan and Hsu, John and Koening, Nathan and Shell, Dylan},
	Date-Added = {2014-08-11 18:06:11 +0000},
	Date-Modified = {2014-08-11 18:07:23 +0000},
	Journal = {Lecture Notes in Computer Science},
	Pages = {38-50},
	Title = {Extending Opern Dynamics Engine for Robotics Simulation},
	Volume = {6472},
	Year = {2010}}

@article{Kramer2007,
	Annote = {they establish a list of evaluation criteria targeted at robotics applications and select and describe nine open source, freely available RDEs (robotic development environments) to review. So Webots, White Box Robotics, and ERSP are excluded as commercial packages.

They review: TeamBots, ARIA, Player/Stage, Pyro, CARMEN, MissionLab, ADE, Miro, MARIE, FlowDesigner, and RobotFlow.

Their criteria for RDEs based on four categories of criteria for comparison:
	F1 - Specification: Formalisms, methodologies, and design tools
		F1.1 Architectural primitives - what primitives are provided
		F1.2 Software engineering - how much support e.g. modularization, code use/reuse
		F1.3 Architecture neutrality - how much it leaves the choice to the designer on which architecture to use
	F2 - Platform Support: related to the hardware and its low-level interface (e.g. OS)
		F2.1 Operating System - OS compatibility
		F2.2 Hardware support - how much sensors, effectors available in an RDE
		F2.3 Simulator - fidelity of the simulator, how many robots can be included in a simulation, physical realism of the world, etc.
		F2.4 Configuration method - how a robot is configured
	F3 - Infrastructure: components and capabilities that are part of the RDE, ut not the "agent architecture proper"
		F3.1 Low-level communication - Is it TCP/IP? What infrastructure does it use?
		F3.2 Logging facilities - how we can write log files and such
		F3.3 Debugging facilities
		F3.4 Distribution mechanisms
		F3.5 Scalability
		F3.6 Component mobility - how well components can be relocated at run-time
		F3.7 System monitor/management - how well you can examine the components of the application
		F3.8 Security - sometimes encryption is needed
		F3.9 Fault-tolerance - Failure detection, recovery, etc.
	F4 - Implementation: aspects of application development (including predefined components used in an agent architecture).
		F4.1 Implementation Characteristics
			F4.1.1 Programming Language - does it provide wrappers or interfaces for multiple languages?
			F4.1.2 High-level language - Should be better than just C or Java.
			F4.1.3 Documentation
			F4.1.4 Real-time operation - how well does it handle real-time constraints
			F4.1.5 Graphical Interface
			F4.1.6 Software integration - can it use external software well?
		F4.2 Predefined components - like software libraries, e.g. for:
			F4.2.1 map-making
			F4.2.2 localization
			F4.2.3 route planning
			F4.2.4 speech recognition
			F4.2.5 speech production
			F4.2.6 vision processing - including blob tracking, edge detection, motion tracking, etc.
			F4.2.7 rule interpreters
			F4.2.8 planners
			F4.2.9 neural networks
			F4.2.10 machine learning
			

They also define usability criteria, which I won't copy here.

They do a systematic calculation in order to determine how the systems compare. },
	Author = {Kramer, James and Scheutz, Matthias},
	Date-Added = {2014-08-11 17:20:35 +0000},
	Date-Modified = {2014-08-11 17:45:31 +0000},
	Journal = {Autonomous Robots},
	Number = {2},
	Pages = {101-132},
	Title = {Development Environments for Autonomous Mobile Robots: A Survey},
	Volume = {22},
	Year = {2007}}

@article{Laird2001,
	Author = {Laird, John and van Lent, Michael},
	Date-Added = {2014-08-11 17:18:59 +0000},
	Date-Modified = {2014-08-11 17:20:03 +0000},
	Journal = {AI Magazine},
	Number = {2},
	Pages = {15-25},
	Title = {Human-Level AI's Killer Application: Interactive Computer Games},
	Volume = {22},
	Year = {2001}}

@inproceedings{Mattingly2012,
	Annote = {They note that "Commercial robotic simulation applications such as V-REF and Webots tend to include an integrated Graphical User Interface (GUI) for robot prototyping and dynamic simulation of robot-environment interaction. To support these functions, they require a basic infrastructure for environment editing, 3D rendering, collision detection, rigid body dynamics, animation, and scripting. Unity includes all of the functions mentioned above in an extremely flexible and easy-to-use editing system."

their robot system supports:
	- robot assembly
	- robot locomotion or animation clip design
	- robot control and simulation

This paper more seems like it describes what unity is capable of, rather than showing a completed product. What they seemed to have done is created a "Robot Design Library" of various assets organized as a set of Unity packages.},
	Author = {Mattingly, William A. and Chang, Dar-Jen and Paris, Richard and Smith, Neil and Blevins, John and Ouyang, Ming},
	Booktitle = {Proceedings of the 17th International Conference on Computer Games (CGAMES 2012)},
	Date-Added = {2014-08-11 17:09:21 +0000},
	Date-Modified = {2014-08-11 17:10:51 +0000},
	Title = {Robot Design Using Unity for Computer Games and Robotic Simulations},
	Year = {2012}}

@inproceedings{Hernandez-Belmonte2011,
	Annote = {They used Unity and its physics engine to model robotics tasks. This paper mostly deals with implementation of sensors.

They use unity because it:
	- Has "an extensive support for multimedia file formats. Unity is multi-platform targeted ... Another interesting feature is the possibility of developing rapidly Web applications. ... Also, the availability of a wider base of support documentation for Unity than for other game engines".},
	Author = {Hernandez-Belmonte, Uriel H. and Ayala-Ramirez, Victor and Sanchez-Yanez, Raul E.},
	Booktitle = {Proceedings of ROSSUM 2011},
	Date-Added = {2014-08-11 16:59:22 +0000},
	Date-Modified = {2014-08-11 17:05:30 +0000},
	Title = {A Mobile Robot Simulator Using a Game Development Engine},
	Year = {2011}}

@article{Asada2009,
	Annote = {Does he mean for "Cognitive Developmental Robotics" to be distinguished from "Developmental Robotics" (Lugarella 2003)?

CDR - "aims to provide new understanding of how human's higher cognitive functions develop by means of a synthetic approach that developmentally constructs cognitive functions. The core idea of CDR is 'physical embodiment' that enables information structuring through interactions with the environment, including other agents."},
	Author = {Asada, Minoru and Hosoda, Koh and Kuniyoshi, Yasuo and Ishiguro, Hiroshi and Inui, Toshio and Yoshikawa, Yuichiro and Ogino, Masaki and Yoshida, Chisato},
	Date-Added = {2014-08-11 14:58:54 +0000},
	Date-Modified = {2014-08-11 15:09:26 +0000},
	Journal = {IEEE Transactions on Autonomous Mental Development},
	Number = {1},
	Pages = {12-34},
	Title = {Cognitive Developmental Robotics: A Survey},
	Volume = {1},
	Year = {2009}}

@article{Lungarella2003,
	Annote = {Developmental robotics - at the intersection of robotics and developmental sciences---in particular developmental psychology and developmental neuroscience.

vs. epigenetic robotics: "While [epigenetic robotics] focuses primarily on cognitive and social development (Zlatev and Balkenius 2001), as well as on sensorimotor environmental interaction (Prince and Demiris 2003), the latter encompasses a broader spectrum of issues, by also investigating the acquisition of motor skills and the role played by morphological development."

In selecting literature to review here, they ruled out those that only used computational simulations; actual robots must have been used.},
	Author = {Lungarella, Max and Metta, Giorgio and Pfeifer, Rolf and Sandini, Giulio},
	Date-Added = {2014-08-11 14:24:40 +0000},
	Date-Modified = {2014-08-11 14:34:00 +0000},
	Journal = {Connection Science},
	Number = {4},
	Pages = {151-190},
	Title = {Developmental Robotics: A Survey},
	Volume = {15},
	Year = {2003}}

@article{Bringsjord2011,
	Author = {Bringsjord, Selmer},
	Date-Added = {2014-08-08 15:45:10 +0000},
	Date-Modified = {2014-08-08 15:46:33 +0000},
	Journal = {Journal of Experimental and Theoretical Artificial Intelligence},
	Number = {3},
	Pages = {271-277},
	Title = {Psychometric Artificial Intelligence},
	Volume = {23},
	Year = {2011}}

@article{Alekhnovich2001,
	Annote = {http://www.math.ucsd.edu/~sbuss/ResearchWeb/kproveApprox/index.html},
	Author = {Alekhnovich, Misha and Buss, Samuel R. and Moran, Shlomo and Pitassi, Toniann},
	Date-Added = {2014-08-06 19:36:00 +0000},
	Date-Modified = {2014-08-06 19:36:54 +0000},
	Journal = {Journal of Symbolic Logic},
	Pages = {171-91},
	Title = {Minimum Propositional Proof Length is NP-Hard to Linearly Approximate},
	Volume = {66},
	Year = {2001}}

@article{Akutsu2013,
	Annote = {http://ac.els-cdn.com/S030439751201047X/1-s2.0-S030439751201047X-main.pdf?_tid=fbc8eb06-1cb5-11e4-b69d-00000aacb362&acdnat=1407253046_c5655cb63b5585ec97ddf73ebc8ef8ed

Provide up-to-date algorithms for the common subtree and tree edit distance problems.

They show that for tree edit distance, even when using unit cost for two trees of height 1 and 2, respectively, is APX-Hard, meaning that no polynomial-time approximation scheme exists if P!=NP. However, they get the theorems:
	Theorem 6.1: The unordered tree edit distance can be approximated within an O(n/log n)-factor under the unit cost model, where n is the size of the larger input tree.
	Theorem 6.4: The unordered tree edit distance can be approximated within a factor of (2h+2) under the unit cost model, where h is the maximum height of two input trees.},
	Author = {Akutsu, Tatsuya and Fukagawa, Daiji and Halld{\'o}rsson, Magn{\'u}s and Takasu, Atsuhiro and Tanaka, Keisuke},
	Date-Added = {2014-08-05 20:19:15 +0000},
	Date-Modified = {2014-08-06 16:38:13 +0000},
	Journal = {Theoretical Computer Science},
	Pages = {10-22},
	Title = {Approximation and Parameterized Algorithms for Common Subtrees and Edit Distance Between Unordered Trees},
	Volume = {470},
	Year = {2013}}

@article{Kilpelainen1995,
	Annote = {The paper that showed that unordered tree edit distance can be solved in polynomial time if the maximum degree is bounded by a constant.},
	Author = {Kilpel{\"a}inen, P. and Mannila, H.},
	Date-Added = {2014-08-05 18:05:48 +0000},
	Date-Modified = {2014-08-05 18:07:34 +0000},
	Journal = {SIAM Journal on Computing},
	Pages = {340-356},
	Title = {Ordered and Unordered Tree Inclusion},
	Volume = {24},
	Year = {1995}}

@article{Zhang1994,
	Annote = {The paper that showed that unordered tree edit distance is MAX SNP-Hard, meaning that it is not polynomial-time approximable unless P=NP.},
	Author = {Zhang, K. and Jiang, T.},
	Date-Added = {2014-08-05 18:04:08 +0000},
	Date-Modified = {2014-08-05 18:05:02 +0000},
	Journal = {Information Processing Letters},
	Pages = {249-254},
	Title = {Some MAX SNP-Hard Results Concerning Unordered Labeled Trees},
	Volume = {49},
	Year = {1994}}

@article{Akutsu2011,
	Annote = {http://www.sciencedirect.com/science/article/pii/S0304397510005463#

Presents a "fixed-parameter algorithm for the tree edit distance problem for unordered trees under the unit cost model that works in O(2.62^k * poly(n)) time and O(n^2) space, where the parameter k is the maximum bound of the edit distance and n is the maximum size of input trees."

"Zhang and Jiang proved that [tree edit distance for unordered trees] is MAX SNP-hard [15], which means that there exists no polynomial-time approximation scheme unless P=NP."
"...it is solved in polynomial time if the maximum degree is bounded by a constant [11]."},
	Author = {Akutsu, Tatsuya and Fukagawa, Daiji and Takasu, Atsuhiro and Tamura, Takeyuki},
	Date-Added = {2014-08-05 17:36:47 +0000},
	Date-Modified = {2014-08-05 17:37:59 +0000},
	Journal = {Theoretical Computer Science},
	Number = {4-5},
	Pages = {352-364},
	Title = {Exact Algorithms for Computing the Tree Edit Distance Between Unordered Trees},
	Volume = {412},
	Year = {2011}}

@article{Ouangraoua2009,
	Annote = {http://www.sciencedirect.com/science/article/pii/S0304397508008621#

They define a formaliation of "semi-ordered trees":
	- "orderd and unorderd trees can [both] be considered as semi-ordered trees using an appropriate definition of the semi-order relations between children of vertices."
	- A semi-order relation on a set V is a reflexive and transitive binary relation on V. 
	- Semi-ordered tree: A pair (T, S_\sqsubseteq) (I'll denote this (T, S&)) where T is a rooted tree and S& = {&_x, x \in T} is a set of total semi-order relations such that for any vertex x of T, &_x is a total semi-order relation on C(x) (C(x) = children of x).

Edit distance defined:
	A *valid mapping* from T1 = (V1,E1) to T2 = (V2,E2) is a set M of ordered pairs of vertices (s, s') with s \in V1 and s' \in V2 s.t. for any pairs (s,s') and (t,t') in M:
		- s=t <--> s'=t' (one-to-one)
		- s<=t <--> s'<=t' (ancestor-descendant preservation)
		- s&t <--> s'&t' (semi-order preservation)
		- for any pair (s,s') \in M, s and s' are called images of each other, denoted M(s) = s' and M(s') = s.
	The cost of M is defined as (here I write 'y' instead of \gamma), where I,J are the subsets of T1 and T2, respectively, which do not appear in M:
		y(M) = \sum_{(s,s') \in M} y(s,s') + \sum_{s \in I} y(s,\lambda) + \sum_{s' \in J} y(\lambda, s').
	Edit distance between T1 and T2 is defined as the minimum cost of a valid mapping from T1 to T2.
	- "Since unordered trees are particular cases of semi-ordered trees, computing the edit distance between two semi-ordered trees is at least as hard as the computation of the edit distance etween unordered trees, which is a MAX-SNP-hard problem" (citation 8 is given). This means that if the unordered tree edit distance problem can be reduced to our problem of finding logico-syntactic similarity, then our problem is at least MAX-SNP hard, but according to wikipedia all such problems have poly-time approximation algorithms! (But Bille2005 says that there "is no absolute approximation algorithm for the unordered less-constrained edit distance problem", so what the hell?)

Constrained mapping:
	A constrained mapping (introduced by [4]) from T1 to T2 is a valid mapping (M,T1,T2) s.t. for any (s,s'),(t,t'),(u,u') \in M:
		(s and t) <= u  <-->  (s' and t') <= u'   (structure preservation)

Algorithm: Based on Zhang[4] they compute the constrained edit distance using a reduction of some subproblems to min-cost max-flow problems. They are able to show, using dynamic programming, a polynomial time algorithm.},
	Author = {Ouangraoua, Aida and Ferrano, Pascal},
	Date-Added = {2014-08-05 15:50:38 +0000},
	Date-Modified = {2014-08-05 15:54:11 +0000},
	Journal = {Theoretical Computer Science},
	Month = {March},
	Number = {8-10},
	Pages = {837-846},
	Title = {A Constrained Edit Distance Between Semi-Ordered Trees},
	Volume = {410},
	Year = {2009}}

@article{Tai1979,
	Annote = {According to Bille2005, this is the paper that introduced tree edit distance.},
	Author = {Tai, Kuo-Chung},
	Date-Added = {2014-08-04 19:30:09 +0000},
	Date-Modified = {2014-08-04 19:31:42 +0000},
	Journal = {Journal of the Association for Computing Machinery (JACM)},
	Pages = {422-433},
	Title = {The Tree-to-Tree Correction Problem},
	Volume = {26},
	Year = {1979}}

@inproceedings{Bello2011,
	Address = {Boston, MA},
	Annote = {http://csjarchive.cogsci.rpi.edu/proceedings/2011/papers/0684/paper0684.pdf

Talks about the 2010 Kovacs experiment in which children have to reason about the beliefs of some other person in order to obey their commands correctly. Paul uses Polyscheme to model this behavior, and shows how it can account for the sort of data seen in that experiment.},
	Author = {Bello, Paul},
	Booktitle = {Proceedings of the 33rd Annual Meeting of the Cognitive Science Society},
	Date-Added = {2014-07-31 20:50:04 +0000},
	Date-Modified = {2014-07-31 20:51:33 +0000},
	Pages = {2997-3002},
	Publisher = {Cognitive Science Society},
	Title = {Shared Representations of Belief and Their Effects on Action Selection: A Preliminary Computational Cognitive Model},
	Year = {2011}}

@article{Bello2012,
	Annote = {http://www.cogsys.org/pdf/paper-3-2-134.pdf

Talks about the need to represent other-world and counterfactual reasoning when kids do things like make a "mud pie." He then models this using Polyscheme. Explains in detail how this modeling is done, too, and how information and beliefs are transferred "between worlds."},
	Author = {Bello, Paul},
	Date-Added = {2014-07-31 20:47:56 +0000},
	Date-Modified = {2014-07-31 20:48:40 +0000},
	Journal = {Advances in Cognitive Systems},
	Pages = {43-58},
	Title = {Pretense and Cognitive Architecture},
	Volume = {2},
	Year = {2012}}

@article{Schmidt2014,
	Annote = {standard reference for HDTP

http://link.springer.com/chapter/10.1007/978-3-642-54516-0_7},
	Author = {Schmidt, Martin and Krumnack, Ulf and Gust, Helmar and K{\"u}hnberger, Kai-uwe},
	Date-Added = {2014-07-03 18:58:44 +0000},
	Date-Modified = {2014-07-03 18:58:44 +0000},
	Journal = {Computational Approaches to Analogical Reasoning: Current Trends. Studies in Computational Intelligence},
	Title = {Heuristic-Driven Theory Projection: An Overview},
	Volume = {548},
	Year = {2014}}

@book{Piaget1980,
	Annote = {Originally published in two volumes as "Recherches sur la contradiction."

From foreword: "According to Piaget, intelligence is synonymous with intention or the ability to adapt thought or action to a goal by recombining the means one has at his disposal. The relationships brought out by these definitions are helpful because by comparing intentional to causal phenomena, Piaget's reasons for attaching so much importance to mental reversibility become apparent." (ix)
In these studies, "Piaget broadens the concept of conradition. Instead of defining it in terms of structures, he defines it in terms of functional disequilibrium. From that perspective, contradiction on the sensorimotor level becomes incomplete compensation between the positive effects of action directed toward some goal and the negative effects produced by the same action or by environmental factors."
"Turning to reversibility, one finds that it, too, is defined in terms of compensating effects. It occurs only when a system is composed in such a way that every possible transformation of the system is coupled to an equal and opposite transformation."
"The upshot of all this is that the reader is left to decide for himself what the relationships between psychogenesis and equilibration is."

From introduction: "The aim of this work is to sek out the relations between contradiction and disequilibriums of action or thought. Is a cognitive disequilibrium simply the result of contradiction, a contradiction of which the subject may or may not be aware, but on which it is possible from the outset to confer a logical form, as if all the definitions and inferences involved had already been given and made explicit, so that the contradiction then consists in a formal error of calculation which is the sole cause of any perturbations or disequilibriums?" Or is it the other way around, where contradictions are a formalization of disequilibrium?

Three manifestations of disequilibrium which are capable of leading to contradictions related to lack of stability:
1) That one and the same action does not always lead to the same result.
2) Insofar as the same action does not always lead to the same result the contrary action will not always cancel out the first. Alternately: two contrary actions to not completely compensate each other. Later: "[this] is the same thing as accepting the existence of a nonzero overlap between a class X and its complementary class non-X." (22)
3) Inferential compositions (coordination of actions or statements) cannot lead to necessary products, but allow indecisions and thus partial incoherences to subsist. Alternately: "the inferential coordinations lack necessity."
Alternately, he later refers to these three as "disequilibriums or 'contradictions' deriving from false identities, incomplete compensations, or incorrectly regulated inferences." (xvi).
But can't you just say all three of these are rooted in logical contradiction? "We think not, since it seems to us that, on the contrary, two fundamental differences exist between the psychogenetic roots of logical contradiction and the characteristics of this type of contradiction. The first is that we are as yet dealing with function only, whereas contradiction proper presupposes structures---either functions or identities, then operations. Functioning precedes and prepares structures, hence the anteriority of disequilibrium in relation to contradictions relative to structures. More importantly...the oppositions arising from disequilibriums are exclusively dependent upon the contents of action or thought. Logical contradiction presupposes a minimum of formalization, in the sense of a construction of statements are logically contradictory or not according to the definitions of the notions employed, whereas oppositions between contents, or the rudimentary functional kind of contradiction, fall into the domain of immediate intuitions, which is to say that of subjective feelings of disequilibriums, or else of not yet conceptualized, or insufficiently conceptualized, actions." (xvi)

Only after the experiments in this book were done did they realize the following explanation: "It is that if a lack of compensation exists between affirmations and negations at elementary levels, this is not by virtue of some kind of primitive state of disorder or chaos ... but for a very much more natural reason: that the spontaneous tendency of every action, perception, or cognition in general is to direct itself toward affirmation and the positive characteristics of reality, while negation, in its necessary forms, is the product of secondary developments only, and, in its contingent forms, of perturbations."

CHAPTERS

"These results show very clearly the difference between logical contradiction---which is necessarily relative to a prviously established system of classes well-defined in comprehension as well as clearly outlined (and therefore clearly quantified) in extension---and prelogical contradiction involving only nonformalized contents. In the latter case, the contradiction consists solely in a disequilibrium between actions, and is relative solely to a more or less realizable coherence between the schemas governing those actions, the sole criterion of which remains the degree of difficulty the conciliatory or equilibrating actions presents, the ultimate limit being presented, of course, by impossibility, though it is a limit that is never reached and, above all, not susceptible of justification." (38)},
	Author = {Piaget, Jean},
	Date-Added = {2014-06-03 16:29:52 +0000},
	Date-Modified = {2014-06-03 20:10:43 +0000},
	Editor = {Coltman, Derek},
	Publisher = {University of Chicago Press},
	Title = {Experiments in Contradiction},
	Year = {1980}}

@article{Le2014,
	Annote = {http://arxiv.org/abs/1405.4053
http://www.reddit.com/r/MachineLearning/comments/26irr0/paragraph_vector_a_step_up_from_word2vec/

instead of using word2vec, they go a step up and create FIXED LENGTH vectors for arbitrarily sized documents, and claim to outperform sentiment analysis algorithms},
	Author = {Le, Quoc V. and Mikolov, Tomas},
	Date-Added = {2014-05-28 02:00:53 +0000},
	Date-Modified = {2014-05-28 02:05:05 +0000},
	Journal = {arXiv.1405.4053},
	Title = {Distributed Representations of Sentences and Documents},
	Year = {2014}}

@book{Piaget1977b,
	Annote = {Equilibration is described as a "fundamental process," which "leads to a state near equilibrium to a qualitatively different state at equilibrium by way of multiple disequilibria and reequilibrations." (3)

"It must be stressed from the start that reequilibration often amounts to nothing more than returning to previous states of equilibrium without creating new equilibrated forms." (3)

EQUILIBRIUM IN COGNITIVE SYSTEMS
- "In reality, cognitive structures most closely resemble biological equilibria [rather than mechanical equilibria], either in their static or homeostatic form or in their dynamic or homeorhetic one." (4)
- Two postulates originally described in "Investigations on Reflective Abstraction":
	1) Every assimilatory scheme tends to incorporate external elements that are compatible with it. This "provides nothing more than an impetus for seeking; it makes activity on the part of the subject necessary."
	2) Every assimilatory scheme has to be accommodated to the elements it assimilates, but the changes made to adapt it to an object's peculiarities must be effected without loss of continuity. i.e. "modifying a scheme must destroy neither its closure as a cycle of interdependent processes nor its previous powers of assimilation."

THE THREE FORMS OF EQUILIBRATION AND THE CORRESPONDENCE BETWEEN AFFIRMATIONS AND NEGATIONS
- There are three types of equilibration.
	1) Between assimilation and accommodation of/to objects.
	2) Between subsystems of a total system. Sometimes subsystems may be constructed at different speeds, leading to phase differences (de'calages).
	3) Between integration an differentiation, or subsystems and their parent system.
- But all three types "involve some sort of correspondence between positive and negative characteristics or between affirmation and negations." He not only needs to determine that certain characteristics match, but also that others do not match (or, constitute "non" matches).
- "But when the subject seeks to regulate the process and to attain coherence and stability, it becomes necessary for him to use exclusions in a systematic way. This is because only exact correspondence between affirmation and negations can ensure equilibrium."

THE REASON FOR DISEQUILIBRIA AND THEIR INITIAL FREQUENCY
- Why do disequilibria appear at all? "Disequilibria alone force the subject to go beyond his current state and strike out in new directions."
- "Disequilibria play only a triggering role. Their fecundity is measured in terms of the possibility of overcoming or escaping from them. It is obvious, therefore, that the real source of progress is reequilibration."
- "Optimizing reequilibration" - The process produced by reequilibration that leads to new forms that are better than previous ones.
- The "proper task" of a theory of equilibration is to explain the transition from disequilibrium to coherence. "To accomplish it, we must go back to the question of why constructing negations is so difficult."
- Negations "arise from constructions whose laboriousness depends on the complexity of the system involved."

REGULATIONS
- In order to actually provide an explanation (as opposed to just a description) of equilibration, Piaget wants to first appeal to processes of regulation.
- "Generally, we speak of regulation when the results of an action, A, modify the repetition of that action, A'. Regulation can therefore take the form either of correcting A (negative feedback) or of reinforcing it (positive feedback)."
- "To explain equilibration, then, we ust indicate why it involves only certain sorts of regulation and not every sort. Then we must make clear how the regulators that accomplish regulation are formed."
- Perturbations - "anything creating obstacles to assimilation or to achieving a goal." Two large classes of them:
	- Perturbations hindering accommodation, e.g. objects' resistance to assimilation.
	- Lacunae that leave needs unsatisfied. "Lacunae become perturbations only in relation to schemes of assimilation that have been activated, and the corresponding regulations therefore constitute positive feedback that prolongs the assimilatory activity of the scheme."
- Every regulation is a reaction to a perturbation, but not every perturbations causes a regulation.
- "If mathematics corresponds to reality, it is because the subject's operations have organic roots. Organisms are physicsl objects, even though they are more active than inanimate objects. That is why their operations can both agree with and go beyond the properties of other objects."
- "Negative feedback, as its name indicates, consists of suppressive correction ... schemeas are modified by eliminating one movement in favor of another, or a movement's force or range is decreased."

COMPENSATIONS
- He wants to explain "the development of cognitive structures in terms of equilibration [that accounts] for the final reversibility of logicomathematical operations (inversion and reciprocity) by invoking mechanisms that do not presuppose it from the start."
- Every compensation acts against obstacles or lacunae.
- Secondly, all cognitive compensations involve an evaluation of success or failure.
- Third, they have a tendency to conserve something during transformations-"for example, to conserve states, sequences, schemes, or subsystems."
- Finally, "If regulations and the compensations they provoke account for the mechanism of equilibration, it is important to stress that these formative processes are already both constructive and conservative."

OPTIMIZING EQUILIBRATION
- Why does cognitive equilibration reach only provisional stopping points?
- In order to express the idea of improvement, he uses "optimizing" equilibrations. "We would even speak of a law of maximization if that word did not have technical meanings that we are not yet able to formulate quantitatively."
- "Optimization is manifested in two ways":
	- when improvement comes "from the success of compensatory regulations and therefore from equilibrium momentarily achieved". E.g. the "enlargement of the differential", like when the subject in the balance beam realizes he has to take into consideration the position as well as the heaviness of the weights.
	- when novelties are drawn by reflective abstractions from the mechanism of the regulations in play.
- "[The] collaboration, if not identity, of regulations and reflective abstraction, both evolving level by level, accounts for the central process of cognitive development, which is to say, for the indefinite formation of operations on operations."

CONCLUSION
- The purpose of constructions is to remedy deficiencies and limitations in previous constructions or to differentiate and integrate existing structures.
- Compensations are necessary because constructions are self-regulating and must make compensatory corrections of the means employed relative to the goal pursued.
- [others] have shown that the most influential factor in acquiring new knowledge structures is perturbation or conflict.
- "Generally speaking, therefore, we can say that the peculiar thing about cognitive equilibria is that not only are contraries attracted to each other, like electric charges of different signs, but they also engender one another."

=============================
CHAPTER 2: THE FUNCTIONING OF EQUILIBRATION AND THE STAGES OF COMPENSATION
=============================

OBSERVABLES AND COORDINATIONS
- "An observable is anything that can be established by immediate experience of the facts themselves." Later, he replaces this with: "We shall define [observables] in terms of what the subject believes he has observed and not just in terms of what is observable. This definition reflects the fact that a finding is never independent of the mental tools the subject uses to determine it. In other words, observations are never independent of assimilations, because the mental tools used to make observations are not purely perceptual." So observations are NOT the same as the lowest-level sensory input!
- Action observables (OBS S) are to be distinguished from Object observables (OBJ O). When rolling a ball of clay into a sausage, he says one OBJ S is the act of rolling something out, and an OBJ O is elongation (? isn't this an action as well?).
- "[C]oordinations involve inferences and go beyond what is observable. ... [but] Implicit inferences play as great a role as those made partially explicit, if not a greater one. ... Coordinations are inferences, implicit or explicit, that the subject considers or utilizes as if they were imposed on him. The convinction that an inference is necessary may vary from some vague awareness to a feeling of logical necesssity. The criterion used to determine the presence of necessary or pseudonecessary inferences is that something more than inductive generalizations is involved. In other words, there must be something more than simply an extensional transition from "some" to "all" as far as observable relationships are concerned. Coordinations, in fact, involve constructing new relationships that go beyond what can be observed. For example, the expectation that when a ball, A, hits another ball, B, B will move cannot be called a 'coordination.' One can, however, apply that term to the hypothesis that some 'spirit' or 'force' is transmitted from A to B. This is because transmission of movement is never itself observable." So coordinations are (1) unobservable, (2) a type of inference, and (3) postulate the existence of something unobservable.
- Why shouldn't we consider observations as inferences or coordinations? Because erroneous coordinations can lead to incorrect observations, and likewise from incorrect inferences, but they are not the same.
- Distinguish between three types of coordinations:
	- coordinations of a subject's actions in the form of preoperations, e.g. the transitivity of relationships set up by the subject.
	- operations from coordinations of objects' actions, e.g. causal models.
	- coordinating properties that the subject momentarily introduces into objects, e.g. "arrang[ing] counters in one-to-one correspondence. This produces equivalence between two rows. In such situations it is obvious that actions or operations of the subject are being coordinated, not actions of objects."

TYPE I INTERACTIONS
- How are action-observables put into relation to object-observables? 
- He wants to show, among other things, how "observables that arise from the properties of action are subordinated to observables that arise from the properties of objects." 
- "We shall call this elementary interaction type I", of which he distinguishes two types, "on the basis of what has just been said[?] about differences between causal and logicomathematical actions.:
- IA: observables arise within a context of causal action. Specific to cases having to do with the subject's actions.
- IB: observables arise within a context of logicomathematical action. They "relate action-observables of logicomathematical form", where "kinematic or dynamic elements are not taken into account."
- see image I drew in notebook (call these "Interaction Diagrams")
- both IA and IB involve some sort of resistance---in IA it is the physical resistance as in force preventing movement, and IB it is the difficulty in getting the objects into the form wanted, which is entirely mental. 
- a and b are facts of a relational nature. "In other words, they put observables in direct and perceptually verifible relationships that are covariational in form." They are functions because they "are oriented and express dependencies." But "functions and not implications are involved, the arrows simply indicating the directions of the functions." 
- So it works as follows:
	- The subject performs the action Ms.
	- The subject notices the 'pushing' feelings/observables Ps, and connects it as the action Ms->Ps
	- The subject notices his action (Ms->Ps) is regulated by the object's resistance Ro, and the movement acquired by the object Mo reciprocally depends on that action.
	- The subject "may deduce, either by representative inference or in certain cases even by preinferences based on perceptual or motoric regulations, that something is transmitted between his hand and the object."
- So in what sense can a model like IA be said to demonstrate equilibration? Exactly what is being equilibrated?
	- "type I interactions manifest the simples form of equilibration (symbolized by the double arrow, <->). This is the equilibration that occurs between assimilation by means of a scheme (Ms + Ps or As + Fs) and accommodation to objects (Ro + Mo)."
	- Equilibration, in a sense, is present in every single arrow in each model. Whenever one set of observations or coordinations affects another, it is equilibration that determines how the affecting is to be manifested. e.g. how the 'perturbation' is to be reacted to.
	- I think then, that the most important thing for a model of Piagetian Equilibration to focus on, are the perturbation-correction interactions, namely, how a system reacts to internally- and externally-caused perturbations. I think that this can be captured in a sufficiently powerful model of analogical matching.

TYPE IIA INTERACTIONS
- OBS S - "observables relative to the subject's action." (uniting of the observables Ms, Ps, Fs from Type I)
- OBS O - "observables relative to objects." (uniting of the observables Ro, Mo)
- COORD S - "inferential coordinations of the subject's actions or operations ... what is contributed by necessary inferences and what thus goes beyond the observable presupposes the use of compositions of the sort we call COORD S." He much later says that these are "regulations involved in logicomathematical coordinations" (134).
- COORD O - "inferential coordinations among objects" (of a kinematic or dynamic, and therefore causal, nature). These are rooted in objects, physical content (directly observable at first and later "imagined within or among observables", which I take to mean higher level abstractions of physical properties), and causality.

(see notebook for notes in this area)

THE STAGES OF COMPENSATION
- In mechanics, equilibrium is "framed in terms of the complete compensation of all the changes it is possible for a system to undergo." So either the system knows how to compensate for perturbations, or it doesn't. 
- There are three principal forms of reaction:
	- Alpha. A few fact enters the system and produces a perturbation. Alpha reactions are when the system is not moved far from equilibrium (simple modifications made to compensate for the perturbation), or the perturbation is stronger "or is implicitly judged so by the subject." The subject responds by ignoring or removing what bothers him. "It is obvious, then, that type alpha reactions are only partially compensatory, and consequently that the equilibria that result from them remain very unstable."
	- Beta. The perturbating element is integrated into the system. The structure is changed, called "displacement of equilibrium," until the new fact is assimilable. "The point is that, by integrating or internalizing perturbations into the cognitive system in play, type Beta reactions transform them into internal variations. These may be capable only of partial compensations, but they still produce compensations superior to the compensations produced by type Alpha reactions."
	- Gamma. Anticipating possible variations; this is "possible in all logicomathematical situations and in certain highly elaborated causal explanations." Thus the perturbations are not seen as such, and rather become "potential transformations of the system." So there is transformation of the system, unlike type Alpha, but the transformation is expected by the system.
	- These are phases which appear in this order and are "quite regularly found according to the area studied," but are NOT general stages. "[F]or cognitive systems, ... the modes of compensatory reaction differ markedly from one level to another and that subjects conceive perturbations quite differently according to the degree to which the perturbation in question is integrated into the system."
- "It is legitimate, therefore, to consider reversibility, as we have always done, as a result of equilibration where equilibration is a complex process embracing the psychogenetic variations of compensatory reactions and the modes of apprehending or assimilating perturbations. Reversibility is not an independent process invoked to explain equilibrium."

OTHER POSSIBLE MODELS OF EQUILIBRATION
- rest of the chapter is spent talking about alternate models; for example another analogy can be drawn from mechanical equilibrium where we consider concepts of "potential energy" or "lowest possible energy states". We can also alternatively use game theory and cost/gain measures. 

=============================
CHAPTER 3: THE DEVELOPMENT OF PERCEPTUAL AND SPATIAL SENSORIMOTOR STRUCTURES
=============================

CONSTRUCTIONS, REGULATIONS, AND COMPENSATIONS
- "[T]he solution we have sought in al our works and that we hope have come close to in this book appeals not to predetermined forms of equilibrium, but to successive "optimizing" equilibrations interrupted by disequilibria." This separates his view of equilibria from the Gestalt view, in which "the structure of the Gestalt remains the same throughout all developmental levels."
- "Construction plays, from the beginning, a compensatory role vis-'a-vis certain perturbations. ... In other words, the general process that is always found to be involved begins with the use of an assimilatory scheme whose functioning is sooner or later impeded by perturbations. The compensations that result are manifested in the form of new construction. The regulations characterizing the various phases of that construction have two characteristics. They are compensatory with regard to the perturbation, implying, at least potentitally, the formation of negations; and they are formative with regard to the construction of a new equilibrated structure."
- "As for the assimilatory with which the whole sequence [of construction] began, either it was acquired, and therefore itself proceeded from similar developmental processes, or it was innate. In the latter case it would be the product of regulations or compensations of an organic nature."
- "The interpretation we favor connects all cognitive construction with external perturbations by means of the resulting compensatory reactions. ... [I]nterest is the motivational or evaluative aspect of every assimilatory scheme. An object is of interest to a scheme to the degree that it nourishes (*alimente*) the scheme. ... Second, need is the expression of the momentary nonfunctioning of a scheme. From the cognitive point of view, this corresponds to a lacuna or deficit, that is, to the negative aspect of perturbations."

SENSORIMOTOR REGULATIONS
- "[T]he assimilatory schemes a subject starts with are innate, few in number, and very general in terms of what they can assimilate. [So they are very flexible in what they allow as a match.] Sucking (a scheme that quickly extends beyond nursing), looking, listening, and touching (which begins with the palmar reflex and subsequently extends into intentional prehension) are all examples."
- "[I]t is found that during the first stages, precisely when perturbations are primitive, object-observables, OBS O, and action-observables, OBS S, remain essentially undifferentiated. For example, before the nursling considers his hands to be organs dependent upon himself or his intentions and part of the well-delimited system that is his body, he regards them as foreign tableaux traversing his visual field. He may even be frightened if such uncontroled objects happen to touch his face. ... In sum, he does not conceive himself to be a subject any more than he conceives objects to be permanent or localizable."
- After the regulations that are formed over the level of innate schemes: "The principal problem brought up by the next level is the problem of coordination among schemes. The most precocious forms of such coordinations are those that connect vision with hearing so that the baby looks in the direction of a sound in order to see the corresponding visual picture."
- We see "a beginning of negations constructed by the subject" in "a baby's taking away a pillow hindering the movement of his hand in order to reach an object. ... The permanence of object is acquired shortly after behaviors of this sort appear".
- "In sum, reexamination of sensorimotor regulations appears to provide a first justification for our general hypothesis that the hierarchical construction of new behavioral schemes involves compensatory mechanisms."

PERCEPTUAL REGULATIONS
- He lists examples which show "to what extent perceptual regulations and compensations, though analogous in form to intelligent regulations of preoperatory or even operatory levels---for example, object permanence or conservations---remain inadequate for accurately ascertaining observables. While it is obvious that the conceptualization of observables cannot be drawn from perception alone, it is less obvious that there are numerous cases where it is the conceptualization itself that orients perceptual activities and causes the subject to perceive things he would not have seen without it. In this way, conceptualization compensates distortions inherent in undirected perception." - this is a good counter to those who think Bayesianism or pure probabilistic models are good enough to explain all of cognition!

REGULATIONS OF SPATIAL REPRESENTATION
- What are the "specific characteristics of space that must be conceptualized before the construction of representative space can begin?"
- Proximity might come from ordering: "given an order ABCD..., the term B, neighbors both A and C while A does not neighbor C, and so forth. Therefore, when the young child trys[sic] to reproduce an ordered series of objects, he starts off making mistakes because of the primacy of positive proximities. For example, he forms the series DCB because C belongs between D and B, but he soon corrects this to BCD because, with DCB, B would no longer be next to A. Only after numerous corrections (compensatory regulations) will he be able to conserve a given order or the same orientation of the series from beginning to end"
- The conception of straight lines, so fundamental to Euclidian geometry, is constructed from "terms of conserving direction. The idea of direction derives from the idea of order."
- Measurement develops, and from generalizing measurement to 2 or 3 dimensions and adding the notions of fixed reference points and compensations, a coordinate system develops.

=============================
CHAPTER 4: LOGICOMATHEMATICAL STRUCTURES
=============================

THE CONSERVATION OF QUANTITIES
- Says the way notions of conservation are equilibrated were "treated too summarily in our essay of 1957 (*Logique et 'equilibre*), as if it were only a matter of probabilities of encounter between the subject and properties of the object. In reality, compensatory regulations are involved that have the effect of putting the positive aspects of transformations into correspondence with their negative aspects."
- Revertibility, or as this book prefers to translate it, Empirical Reversibility (original french renversabilit'e): Not full reversibility, but involves the subject's anticipation of the possibility of an empirical return to the starting point. E.g., that a ball of clay rolled out might possibly be returned to a ball of clay.
- "[I]nferential necessity is an index of the closure of an operatory structure. [T]he first such structures are the *groupements*. It will also be helpful to recall that conservation of the whole is the thing all *groupement* structures have in common and that the operations essential to such structures specifically include identity and reversibility. In other words, groupements involve complete compensation of affirmations by negations. If that is true, the commutability, substitution, and compensation of positive and negative relations, all of which are derivatives or expressions of groupement structure, do not constitute first facts. Rather, they are results of the regulatory mechanisms that produce such structures."
- "It should be noted, however, that the correspondence of negations and affirmations associated with type gamma reactions is achieved only after a long equilibration ending in reversibility; reversibility does not come before and cause equilibration."

CLASSIFICATIONS AND THE QUANTIFICATION OF INCLUSION
- The youngest children (Piaget draws from stages discussed in "The Early Growth of Logic in the Child"), when asked to "Put everything that is alike together," create pairwise similarities rather than overall categorizations. But the youngest subjects look "exclusively for similarities and pays no attention to differences." The ability to pay attention to differences seems to emerge later; older subjects say things like "Do not put together things that are not alike," which logically follows from the command given by the researcher. Piaget interprets this as evidence that "it is possible to consider differences between elements as perturbations. At level I these are canceled out or ignored according to the rules of type alpha reactions."
- Next, differences are noticed, but still "lacking is a total or superordinate class that would include such collections as subclasses with their particular characteristics subordinated to qualities they all have in common."
- At level III, "equilibrium of similarities and differences is attained. This is possible because the regulations leading from level II to level III compensate the differences that exist between the little collections of level II and at the same time identify properties they have in common so that they may be brought together as parts of a larger class." This gives the "false impression" of operatory classification, but is not so!
- At level III differences are not seen as negations. "The systems of level III so completely lack any abstraction of negations that it might even be said that none are included. In effect, given a class A included in a class B, the level III subject sees quite well that while all the As are Bs, there are also A's that are Bs but are "different" from A. He will also undoubtedly say that A's are not As, but that statement is only verbal. As far as operations go, he understands the relationships among classes and subclasses so poorly that he cannot manage to find any evidence for the conclusion that there are necessarily more elements in the superordinate class B than there are in the subclass A. ... When he is asked to compare A and B, he can do no more than compare A with A'.
- "At level IV, differences and similarities are finally equilibrated completely. This means that differences are understood as partial negations."

SERIATION AND TRANSITIVITY
- Again says "seriation was inadequately analyzed in our essay on cognitive equilibrium published in 1957". 
- discusses the stick sorting experiment that he seems so fond of
- At level IV, they display reversible operations, which, among other things, "indicates that similarities and differences have become relationships that can be quantified in positive and negative terms." e.g. we see the realization that "smaller than" = "not as big as", and the number of sticks bigger than the smallest equals the number of sticks smaller than the biggest.

=============================
CHAPTER 5: THE EQUILIBRATION OF OBSERVABLES AND COORDINATIONS
=============================

REGULATIONS CONCERNING OBJECT-OBSERVABLES (OBS O)
- An observable, as discussed earlier, means an "establishable fact." But "everyone agrees that a fact goes beyond what is perceptually given. ... Ascertaining a fact always involves a conceptualization biased toward some interpretation. That is why we said earlier that the observables we are concerned with are all conceptualized at the levels under consideration."
- [I]t is clear that, virtually from the start, conceptualizing an observable quickly comes to depend on relating it to other observables. 
- "Constructions are continually threatened by contradictions, and contradictions between facts or ideas always involve incomplete compensations. ... That said, let us attempt to understand the relation between constructions and compensations as they concern observables. We shall do so by distinguishing different kinds of regulations and spelling out the functions each fulfills."
- "the most elementary regulations are those that consist in adjusting the conceptual form of an observable to its perceptual content. [Two forms:] One case is where the perceptual content has to do with an external object, the other is where it has to do with action itself, in which case it becomes part of the conceptualization constituting the 'taking of consciousness.'"
- "When a quality lent to an object is illusory and deforming, what is generally responsible for the false OBS O is erroneous or incomplete coordinations. For example, movement is attributed to immobile bodies transmitting force because transmission of movement is thought to involve external or semi-external motion. Sometimes however, deformation results from omission of an observable or, in other words, from inadequately analyzing perceptual data." So for Piaget, the source cases are at least partially stored in COORDs.
- The equilibrium here is between the 'perceptible content' and the 'conceptualized form'. 

REGULATIONS CONCERNING ACTION-OBSERVABLES (OBS S) AND HOW CONSCIOUSNESS IS TAKEN
- "taking consciousness consists in representing sensorimotor actions symbolically [which] involves conceptualization. The problem is therefore analogous to the problem of the relation between form [the system of concepts the subject uses to take consciousness of the action or, in other words, to conceptualize its motor content] and content."
- In the early stages, children can do tasks without explaining how; "Such solution of concrete operational problems posed in terms of success rather than in terms of explanation is often designated practical intelligence."
- Regarding things a child knows how to do but doesn't know how to explain, "it is clear that elements are not neglected simply because the child cannot pay attention to everything at once. [Rather,] The missing facts have been set aside because they contradict the child's habitual way of conceptualizing some part of the situation." So for example tossing something into a box, he can't say it's throwing because "throwing something into a box implies aiming perpendicularly at it."
- ADR's hypothetico-deduction doesn't always happen: "it must be pointed out that the elements left out when consciousness is taken are subject to a kind of cognitive repression. This does not mean that the subject begins by consciously making a hypothesis ..., then reflects upon his hypothesis and sets it aside as contradictory. It seems more reasonable to suppose that he does not make hypotheses of this sort because he simply cannot understand that they are possibilities. If that is so, what appears to be a contradiction is really a failure of assimilation."
- On the other hand: "With taking consciousness of his own action, however, this does not seem to be what happens.  In such situations the subject has, in fact, understood something of the idea that he refuses to accept in his conceptualization, but his understanding has been achieved in terms of action. In other words, it proceeds from a sensorimotor scheme and not from an idea. We are obliged to conclude, therefore, that the scheme, whose existence as a scheme of action is undeniable, is eliminated from the conscious conceptualization by a sort of active rejection or repression because it is incompatible with other concepts the subject believes in."
- In distinguishing sensorimotor content from the conceptual form required to take consciousness of it, two types of equilibrium are involved:
	- "the form assimilates certain elements of the content, in which case there is equilibrium based on mutual support or adaptive compensation [footnote: they call this "compensation by reciprocity."]. In other words, to every assimilatory concept there corresponds an accommodation imposed by the content assimilated, and form and content are equilibrated through reciprocal adjustments."
	- "the form rejects certain elements of the content, in which case a force belonging to the rejected content opposes the force exerted by the form. ... in this second and unstable form the conceptualization resists and the content applies pressure against the resistance."
- "potential observables tending to force entry into the conceptualization constitute perturbations. Because of that, compensation initially consists in canceling them out or in denying them entry"

REGULATIONS CONCERNING RELATIONSHIPS AMONG OBSERVABLES
- "real progress is evident when a conceptualization is itself conceptualized. That is what happens when similarities and differences are conceived as variables, that is, when gradations like 'large,' 'slightly large,' or 'very large' come into play."
- "compensating a perturbation has as its first effect either assimilation, in which case a similarity is established, or failed assimilation followed by assimilation to some other scheme, in which case a difference is established."
- "In conclusion, examining regulations affecting relationships among observables shows that in these cases, just as much as in the initial conceptualizations of observables discussed [earlier], the constructions necessary to the transition from one developmental level to another move in the direction of compensation."

REGULATIONS OF COORDINATIONS: CAUSALITY
- Next he examines "coordinations themselves---the inferential mechanisms of general cognitive structures. Is equilibration through progressive regulation only a secondary corrective mechanism, or is it generative?"
- "Causality begins at the sensorimotor level. Among its elementary forms, the tactilokinesthetic ones in particular, it is possible to distinguish the following types: (1) regulations bearing on unconceptualized observables that are directly perceived and, with repetition, schematized; and (2) regulations bearing on coordinations in the sense of compositions that go beyond what can be observed."
- "The coordinations that result from [type IIA interactions] are responsible for causal connections among observables. By themselves, observables and their regulations provide nothing but regular successions having no necessity."
- "Already at the sensorimotor level, inferential or preinferential compositions are found, and the regulations inherent in the sensorimotor or perceptual schemes ensuring such compositions are already compensatory."
- "In short, causality involves compensations at all levels from elementary regulations up to higher-level deductive models. This is because causal regulations, like causal deductions, always bear on material transformations of the object while themselves stemming from the subject's activities."

REGULATIONS OF COORDINATIONS: LOGICOMATHEMATICAL COORDINATIONS AND THE FORM OF REGULATIONS
- "Now for the subject's coordinations that lead to logicomathematical operations. In their final operatory form, such structures attain complete compensation. This is evident from their reversibility and from the fact that any operation always enjoys involutive relationships of inversion, of reciprocity, or correlativity (duality) with certain other operations. Because of this, we have for a long time held reversibility to be the product of step-by-step equilibration during the formative stages and have conceived the operation as a 'perfect' regulation in the sense that it anticipates all transformations and precorrects errors."
- "insofar as the connections [COORD O processes] establish are attributed to objects, insofar as they specifically become causal, it is because they tend to connect material transformations of objects. They are consequently based on a physical content, at first observable, then imagined within or among observables."
- By contrast, the regulations involved in logicomathematical coordinations (COORD S) lead to compensations that have to do with form alone, such as inverse operations or reciprocities.
- The form all regulations share "consists precisely in being able to act on any sort of content in terms of symmetries relative to activities that are already quantified in an elementary way. These elementary quantifications include reinforcement or weakening, increasing or decreasing, choosing one direction or another. In brief, they take the form of positive or negative modifications, each of which compensates the other."
- In a causal system, regulation can be modified with actions (you can push harder to move an object), but in a logicomathematical system "regulation modifies the form of its content only by using other forms belonging to the regulation."
- "Regulation, therefore, is uniform, since its mechanisms remain the same in every area and are always of a logicomathematical nature in the sense that they are based on more and less, on symmetries, and so forth. This means that even at level where there are only regulations, all physical knowledge in the process of formation includes a logicomathematical contribution. That contribution, if one may so speak, is one that the regulation itself attributes to its object, even though the object is of a material nature and external to it. In other words, from the moment the subject increases or decreases a push of his own or a push between two objects, the increase or decrease is already of a logicomathematical nature, but applied and immediately attributed to the material push itself. From this it follows that, at every level, physical knowledge is indissociably physical and logicomathematical. Logicomathematical knowledge, on the other hand, can be dissociated from physical knowledge and sooner or later reach a "pure" state." (136)
- "operations do not derive from the effective compensations to which regulations in every case lead. Instead, they are derived from the internal processes regulations employ in order to arrive at such compensations. This is because those processes already have a logicomathematical form."
- "equilibration does not constitute some superfluous characteristic tacked onto the general construction of cognitive structures. From the moment observables begin to be conceptualized up to the time deductive forms are composed, equilibration is indissociable from construction. From the psychogenetic point of view, it is the motivating force behind cognitive construction because it constantly brings about the construction of new forms and at the same time explains the accession of higher-level operatory structures, first to unexpected and finally to necessary status. From the logical point of view, it is evident in the reversibility and constructive symmetries of those structures."

CONCLUSION
- Why are there equilibrations that are "optimizing from the point of view both of construction and of increased coherence"? Because: "The constructive part consists in elaborating operations on operations, relations of relations, regulations of regulations, and so forth. In short, it has to do with building new forms that bear on previous forms and include them as contents. ... Improvement in equilibrium results, therefore, from the fact that the higher system is the seat of new regulations."
- But why do new constructions occur? "new possibilities are opened up by creating structure. ... Our hypothesis is therefore that operations bearing on preexisting operations owe their genesis to just such situations [where perturbations caused by new structures can be compensated by coherent incorporations into the system through type beta and gamma reactions]."
- "If a new construction is suggested by things previously accomplished, is it not a matter of simple predetermination? the answer to this is that the world of possibilities is never finished, nor, consequently, is it given in advance. ... every time something is accomplished, it opens up new possibilities that do not exist on previous levels."
- "There are three distinct varieties of equilibration, reflecting different relationships between the subject and objects or between the subject's schemes, but all three share a common form in their structural mechanism---al require increasingly complete and detailed compensations between positive properties or affirmations and the corresponding negations."
- regarding the aspects of cognitive development: "the general features of the process involve relatively few interactions. These are expressed in the idea of optimizing equilibration, but only on two conditions. The first is that optimizing equilibration is not reduced to a march toward static equilibrium. The second is that it is not conceived in terms of a pure evolutionism leading into a radical becoming that forgets the mechanisms of transmission and the fact that every improvement is oriented in the direction of coherence or more developed forms of internal necessity."

=============================
APPENDIX 1: RESPONSE TO OBJECTIONS
=============================
- responding to objections that the concept of regulation and compensation is too general, he says if we analyze its elementary components: two processes acting in opposite directions and a notion of balance between them, this allows us to formalize the concept. Without this, "it would be difficult to see how regulations could improve actions."
- to those saying he only gives descriptions, not explanations. Piaget says explanations begin once you start giving reasons for those general facts. He sees little benefit in insisting on the functional reasons, and gives seven "structural" (causal-related) mechanisms:
	1. the components of every assimilatory system is cyclic and interdependent. 
	2. "the fundamental factor in a cognitive equilibrium is the conservative action that systems, like totalities of any rank, exercise over their parts. ... This is because it results from previous assimilatory functioning and because conservation of the total cycle, and therefore subordination of parts, is an absolutely essential condition for such functioning to continue."
	3. Anticipations give birth to "reflectings", which is the source of new levels on which actions or operations employed as instruments in the previous structure can become thematized objects of thought. "The whole history of mathematics stems from this process of reflective abstraction, which explains the formation of new structures starting with existing ones, a phenomenon observed from the beginning of psychogenesis."
	4. Reflective abstraction explains the formation of regulations of regulations, not in terms of some new factor externally imposed, but in terms of differentiation of a single mechanism.
	5. Every structure is based on the structures that follow it in the sense that the latter realize possibilities opened up by the preceding structure.
	6. Optimizing equilibration is a process that leads to better equilibrium rather than simply returning to more stable forms of a former equilibrium. 
	7. The construction by internalization is accompanied by externalizations in the form of attributions to objects. "That is the source of the successive levels of causal explanation and the functional interactions of logicomathematical and physical thought."},
	Author = {Piaget, Jean},
	Date-Added = {2014-05-14 01:07:13 +0000},
	Date-Modified = {2014-05-27 18:06:05 +0000},
	Editor = {Brown, Terrance and Thampy, Kinshore Julian},
	Publisher = {University of Chicago Press},
	Title = {The Equilibration of Cognitive Structures: The Central Problem of Intellectual Development},
	Year = {1985}}

@book{Piaget1970,
	Annote = {Originally published in French as Le Structuralisme by Presses Universitaires de France, Paris, 1968.

"In psucyology, structuralism has long combatted the atomistic tendency to reduce wholes to their prior elements." (4)
- So, it doesn't want to say that the whole can be explained by its individual parts, but rather emphasize the totality. E.g. "1+1=2" is more than the combination of its parts.

First definition of structure: "a system of transformations which involve laws, which never yield results external to the system nor employ the external elements." (5)

Structure is consists of "three key ideas":
- wholeness; structures are wholes, as opposed to aggregates independent of the complexes into which they enter. For example, "the integers do not exist in isolation from one another, nor were they discovered one by one in some accidental sequence and then, finally, united into a whole. They do not come upon the scene except as ordered, and this order of the integers is associated with *structural* properties (of groups, fields, rings, and the like)..." (7).
- transformation; it is a system of transformation and not a mere collection of elements and their properties. The transformations contain laws: the structure is preserved or enriched by the interplay of its transformation laws.
- self-regulation. This entails "self-maintenance and closure" (14). where the 3 basic mechanisms are rhythm, regulation, and operation.
- NOT formalization. Formalization is "always the creature of the theoretician, whereas structure itself exists apart from him. Formalization sometimes proceeds by direct translation into logical or mathematical equations ... But, it is worth repeating, the mode of existence of the structure he earlier discovered must be determined separately for each particular area of investigation." (5) 

structures have a duality: they are always simultaneously structured and structuring (10).

"Operational structuralism" exists between atomism and Gestalt, emergent totalities (8). It's "neither the elements nor a whole that comes about in a manner one knows not how, but the relations among elements that count [and are primary]" (8-9).

Self-regulation - 

Groups - Piaget believed the day would come when mathematical groups would become important in biology as they are in algebra, and that we should look to them for a foundation of structures.

"It is because the group concept combines transformation and conservation that it has become the basic constructivist tool. Groups are systems of transformations; but more important, groups are so defined that transformation can, so to say, be administered in small doses, for any group can be divided into subgroups and the avenues of approach from any one to any other can be marked out." (21)

He cites Felix Klein's famous Erlanger Program as a "prime example of the scientific fruitfulness of structuralism." (22)

Cites work of the Bourbaki and how their general "mother structures" might "correspond to coordinations that are necessary to all intellectual activity" (27).

Talks about Godel and implications for the axiomatic method and formalizing knowledge (32-33) and expressivity (34).

Not everything is structure: "though it is true that everything can become structured, the difference in modality is all-important. Structure in the technical sense of a self-regulating system of transformations is not coincident with form: even a stack of pebbles can be said to have *form* (there are "bad" as well as "good" forms; see Section 11), but this mere heap cannot become a *structure* unless we place it in the context of a sophisticated theory by intercalating the system of all its "virtual" movements." (36)

He refers to the logical positivists many times in this book, how could he be unaware of Wittgenstein?

"In sum, there are physical structures which, though independent of us, correspond to our operational structures, especially in sharing the quasi-intellectual trait of covering the possible and locating the real within a system of virtuals. This kinship between causal and operational structures is quite what one would expect so long as explanation involves models (which are at least in part artificial constructs)" (43-44).

"[A]ction in this sense is the source of operations as well. Not that it "contains" them *ab inito*, it does not, just as it does not "contain" the whole of causality, but that its general coordinations involve certain elementary structures sufficient to serve as point of departure for reflectie abstraction and, eventually, more complex constructions." (44)

As for biological structures, "to note the existence of wholes at different levels and to remark that at a given moment the higher 'emerges' from the lower is to locate a problem, not to solve it." (46) Piaget wants the mode of operation to also be specified, which is where transformations play a part.

I don't quite understand his discussion on structure in Biology. It sounds like he wants to argue against Chomsky and Fodor's innate concepts.

"it is undoubtedly the field concept that must be blamed for the Gestald theorists' slighting of all functional and psychogenetic considerations and ultimately, of the agency of the subject." (55)

"it is equilibration which makes Gestalt reenter the domain of structure...[because it] involves the idea of transformation within a system and the idea of self-regulation. Gestalt psychology is therefore a structuralist theory more on account of its use of equilibration principles than because of the laws of wholeness it proposes." (57)

Piaget argues that since perception can be trained, and the "anti-functionalism" of field effects makes Gestalt doubtful.

How does knowledge come about? Piaget argues there are only 3 ways:
1) Innatism/predetermined biological structures
2) Contingent emergence
3) Constructivism

p. 61-62: To be taught about logico-mathematical structures, the child "must already be in possession of certain minimal instruments of assimilation, which themselves partake of such structures ... or else he "constructs" them---but he is by no means free to draw them up at his pleasure (like the rules of a game or the figures in a picture), so the question of how and why this construction yields *necessary* results remains. Why does it look "as if" the results were "predetermined"? Now observation and experiment show as clearly as can be that logical structures *are* constructed, and that it takes a good dozen years before they are fully elaborated; further, that this construction is governed by special laws, laws which do not apply to any and every sort of learning. Through the interplay of reflective abstraction, which furnishes increasingly complex "materials" for construction, and of equilibration (self-regulation) mechanisms, which make for internal reversibility, structures---*in being constructed*---give rise to that necessity whcih a priorist theories have always thought it necessary to posit at the outself. Necessity, instead of being the prior *condition* for learning, is its *outcome*.
Of course, human structures do not arise out of nothing. If it be true that all structures are generated, it is just as true that generation is always a passing from a simpler to a more complex structure, this process, according to the present state of our knowledge, being endless. So there are certain givens from which the construction of logical structures takes off, but these "data" are not primordial in any absolute sense, being merely the starting point for our analysis, nor do they "contain" what is, in the course of construction, "derived" from and "based" on them. We called these initial structures behind which we cannot go "general coordinations of actions," meaning to refer to the connections that are common to all sensori-motor coordinations.  ... [p.63] The functional factors are *assimilation* ... and *accommodation*... The structural elements are, essentially, certain *order* relations (the order of movements in a reflex act, in a habitual act, in the suiting of means to end), *subordination schemes* (the subordination of a relatively more simple schema like grasping to a relatively more complex one like pulling) and *correspondences* (such as are involved in what we have elsewhere called "recognitory assimilation")."

"[W]e conclude that there is room for an alternative that falls between absolute preformation of logical structures on the one hand and their free or contingent invention on the other." (67)

Against Platonism: "[A]s soon as [the Platonist] breaks beyond the confines of his expertise and tries to develop an epistemology, he will have to ask himself where, exactly, this region of the virtual is to be located. To call on essences to furnish the virtual with its underpinnings is to beg the question. Nor can the physical world provide its habituation. It makes far better sense to assign the virtual a place in organic life, though obviously only on condition that it be clearly understood that general algebra is not "contained" in the behavior of bacteria or viruses. So what remains is, again, the constructivist hypothesis, and is it not quite plausible to think of the nature that underlies physical reality as constantly in process of construction rather than as a heap of finished structures?" (67-68)

On AI: "[O]ne of the most instructive methods for analyzing its actions is to construct, by means of machines or equations, models of "artificial intelligence" for which a cybernetic theory can then furnish the necessary and sufficient conditions; what is being modeled in this way is not its structure in the abstract (algebra would suffice for this), but its effective realization and operation. It is from this point of view that structures are inseperable from performance, from functions in the biological sense of the world." (69)

We can't say everything is structure, "*structure* must be defined more narrowly than *form*. How is this to be done? Let us note first of all that, even though on the present theory everything can *become* structured, structures are, nevertheless, only one kind of "forms of forms," namely, such as are governed by the several extremely comprehensive limiting conditions we explained in our opening chapter: only self-regulating transformational systems are structures." (113)

How do forms become structures? (113)
- For logico-mathematics it is derived from forms through reflective abstraction. "But there must also be a general formative process in *nature*, leading from forms to structures and establishing the self-regulation constitutive of the latter." (113) So Piaget sees equilibration as a natural process, rather than one that is exclusively psychological.

"From this perspective, there is nolonger any need to choose between the primary of the social or that of the intellect; the collective intellect is the social equilibrium resulting from the interplay of the operations that enter into all cooperation." (114)

On education: "If the concept of self-regulation or equilibrium has any sense at all, the logic or pre-logic of the members of a given society cannot be adequately gauged by already crystallized cultural products; the real problem is to make out how the ensemble of these collective instruments is utilized in the everyday reasoning of each individual." (117)},
	Author = {Piaget, Jean},
	Date-Added = {2014-05-13 02:52:47 +0000},
	Date-Modified = {2014-05-13 03:10:19 +0000},
	Publisher = {Basic Books, Inc},
	Title = {Structuralism},
	Year = {1970}}

@incollection{Piaget1979b,
	Annote = {On possibility: he wants to distinguish between two conceptions of possibility. The first is a mathematical one which defines "all possible things", whereas a second conception is a more guided search process that depends on the current schema of the reasoner. He wants to go with the latter.

Three types of schemata to distinguish:
1) Presentative - Derives from permanent characteristics of objects, superclass of representational concepts.
2) Procedural - Goal-oriented, sequences of actions
3) Operational - like procedural, but more of a mix of the two types

Distinguishes between two systems:
1) System I: Aims at understanding of all physical and logico-mathematical realities. Made of schemas 1 and 3.
2) System II: Tries to bring successes in every area from sensorimotor stage to advanced reasoning. Made of schemas 2 and 3.

System II is more exploratory, doing things system I would see as errors. This is where new possibilities come from.

4 kinds of possibilities: hypothetical, actualizable, deducible, and available (when the subject thinks he can and should generalize a structure without yet knowing how to do so procedurally).

Closes by talking about necessity, and where it comes from. },
	Author = {Piaget, Jean and Voyat, Gilbert},
	Booktitle = {The Impact of Piagetian Theory},
	Chapter = {2},
	Date-Added = {2014-04-21 19:52:33 +0000},
	Date-Modified = {2014-04-23 07:53:46 +0000},
	Editor = {Murray, Frank B.},
	Publisher = {University Park Press},
	Title = {The Possible, the Impossible, and the Necessary},
	Year = {1979}}

@incollection{Piaget1979a,
	Annote = {Two hypotheses Piaget says guided him:
- knowledge comes from action and not simply from perception
- certain of these schemes of action can be interiorized and transformed into operations, the operations being, for example, the operations of ordering, reuniting, reversing actions, etc. 

Central hypothesis: "knowledge is based essentially on systems of transformation. To know is to transform objects, or rather it is to transform groups of objects to make them assimilable to our structures."

"A correspondence is not a transformation. A correspondence is simply a comparison, such as when the child places 10 red tokens in correspondence with 10 blue tokens ... The child does not transform the tokens, he simply compares them, and there is no transformation."

- On the sensorimotor level the assimilations to schemes of action are already correspondences. After a child has by chance touched a suspended object and has seen that he can make it swing, he will, everytime he sees a hanging object, tap it to make it swing. He has made a correspondence between the new situation and the situations that he already knew."
- "Our general hypothesis is that there are three distinguishable stages in the relationships between correspondences and transformations."
	- "At first, correspondences pave the way for the transformations, since there are no transformations that the child discovers without first having made certain correspondences."
	- "The second stage is where the transformations and the correspondences are in interaction, that is to say, render each other mutual services."
	- "At a third stage, new correspondences, such as the correspondence between direct operations and inverse operations, result from the construction of operational structures themselves. This time they are necessary correspondences that can be drawn deductively from the structure, whereas the initial correspondences, those that prepare the transformations, were only empirical correspondences that are based simply on the perception of observables."

- "For a long time transformationseemed to us sufficient for explaining cognitive development and sufficient for practical action, because a practical action always consists in modifying reality. ... But the study of correspondences and of morphisms has shown us that comparisons are also quite necessary. These correspondences are not transformations, but may accompany transformations. Even though as comparisons they transform nothing by themselves, these comparisons are necessary for the discovery of transformations, because in order to discover transformations it is necessary to know the data and in order to know the data it is necessary to begin with the systems of comparison." },
	Author = {Piaget, Jean},
	Booktitle = {The Impact of Piagetian Theory},
	Chapter = {2},
	Date-Added = {2014-04-21 19:24:25 +0000},
	Date-Modified = {2014-04-21 19:25:58 +0000},
	Editor = {Murray, Frank B.},
	Publisher = {University Park Press},
	Title = {Correspondences and Transformations},
	Year = {1979}}

@incollection{Gallagher1978,
	Annote = {summary of some of LPT's views, but her full book is a bettery guide. As for the meaning of activity:

- "The search for the meaning of activity has lead us to the sources of contradiction. A major source is the request for the child to anticipate the outcome of the event. There is no disturbance if the discrepancy is ignored."
- If the discrepancy is ephasized, however, then we get projection to a new level of understanding, reordering, or re-equilibration.
- "Activity in the Piagetian sense is essentially tied to an awareness of the coordinates or inferences between the subject and object. To repeat, activity is not manipulation of objects. Neither is it simply a mental reordering. These inferences or `goings beyond,' as was noted, may be sparked by discrepancies between what was anticipated and the real events."},
	Author = {Gallagher, Jeanette McCarthy},
	Booktitle = {Knowledge and Development},
	Date-Added = {2014-04-20 02:10:34 +0000},
	Date-Modified = {2014-04-20 03:19:55 +0000},
	Editor = {Gallagher, Jeanette McCarthy and Easley Jr., J. A.},
	Publisher = {Plenum Press},
	Title = {Reflexive Abstraction and Education: The Meaning of Activity in Piaget's Theory},
	Volume = {2},
	Year = {1978}}

@article{Murawski1998,
	Annote = {http://www.staff.amu.edu.pl/~rmur/hpl1.ps

Conclusions: Tarski claims his final results were obtained independently. Godel was aware that provability did not equal truth in 1931, and this led him to discover incompleteness. Godel only didn't publish first because he "feared that work assuming such a concept would be rejected by foundational establishment [whereas] Tarski was free of such limitations."},
	Author = {Murawski, Roman},
	Date-Added = {2014-04-17 16:41:13 +0000},
	Date-Modified = {2014-04-17 17:26:57 +0000},
	Journal = {History and Philosophy of Logic},
	Pages = {153-160},
	Title = {The Problem of the Priority: Tarski vs. G{\"o}del},
	Volume = {19},
	Year = {1998}}

@incollection{Inhelder1990,
	Annote = {http://books.google.com/books?hl=en&lr=&id=Y2gTxnlDY20C&oi=fnd&pg=PA33&ots=upf6SoJCCy&sig=7LgqwtIqkt638yOUvNzYcV8xEfU#v=onepage&q&f=false

Inhelder talks about what structures meant to late Piagetian thought, and what they were.

"Piaget did not regard structuralism as a doctrine and certainly not as a philosophical theory; he valued it as a method and shared this view with a number of other proponents of structuralism, including Levi-Strauss. ... [He] pointed out that it cannot be an exclusive method. ... Piaget argued for a synthesis of static structural descriptions and a more dynamic genetic approach."

He described structures as "totalities that include their own transformational rules bearing on relations rather than on elements".

It has often been said that Piaget's structures were "devoit of content, that they were immutable, and that the resulting view of intellectual development was an abstract, predetermined hierarchy of structures." However, all that is wrong.

His work on possibility and necessity (Piaget 1987a and b) also contradicted earlier findings: "Previously it was thought that the understanding of necessity and possibility occurred at the end of cognitive development ... The new approach brought to light the early appearance in the child of the understanding of certain forms of possibility and necessity, which were thought of as depending on what Piaget called `necessitating' processes and on processes involving the creation of new possibilities."

From Inhelder and Piaget (1980)'s paper called "Procedures and Structures": "The essential difference that distinguishes procedures and structures is ... although both procedures and structures are based on transformations, procedures carry out, or make use of, transformations, in order to attain a great variety of specific goals. Procedures are thus fundamentally temporal processes. Structures, however, link transformations one to another and extract connections to form atemporal systems. ... [O]nce a structure has been discovered or elaborated, it loses its telenomic dimension. ... Once established, the structure becomes atemporally stable."

Piaget 1987a,b - about possibility and necessity:
	- Possibility and necessity, vol.1 and 2: The role of possibility in cognitive development.
Piaget 1980b - about contradiction. Les formes elementaires de la dialectique [The elementary forms of dialectics]
},
	Author = {Inhelder, Barbel and de Caprona, Denys},
	Booktitle = {Reasoning, Necessity, and Logic: Developmental Perspectives},
	Date-Added = {2014-04-14 19:42:10 +0000},
	Date-Modified = {2014-04-15 16:37:18 +0000},
	Publisher = {Psychology Press},
	Title = {The Role and Meaning of Structures in Genetic Epistemology},
	Year = {1990}}

@article{Sun2012,
	Annote = {Ron sent this to me as a possible basis for the "proto-concepts" in my cogsci paper. 

Describes CLARION (in detail, down to the Heidegerrian basis), and then talks about different ways in which symbol extraction and generation is theoretically explained in CLARION.},
	Author = {Sun, Ron},
	Date-Added = {2014-04-14 05:13:40 +0000},
	Date-Modified = {2014-04-14 05:14:53 +0000},
	Journal = {Philosophical Psychology},
	Title = {Autonomous Generation of Symbolic Representations Through Subsymbolic Activities},
	Year = {2012}}

@inproceedings{Raad2014,
	Address = {Republic of Korea},
	Annote = {http://hal.archives-ouvertes.fr/docs/00/96/77/38/PDF/Is_Ontology_Alignment_like_Analogy_-_Raad_Evermann.pdf

They do some experiments, find that LISA does better than many current ontology matchers out there.},
	Author = {Raad, Elie and Evermann, Joerg},
	Booktitle = {Symposium On Applied Computing (SAC)},
	Date-Added = {2014-04-14 02:31:40 +0000},
	Date-Modified = {2014-04-14 02:32:53 +0000},
	Title = {Is Ontology Alignment like Analogy? Knowledge Integration with LISA},
	Year = {2014}}

@article{Piaget2006,
	Annote = {http://www.sciencedirect.com.libproxy.rpi.edu/science/article/pii/S0732118X06000080?np=y

Translation of Piaget's final three papers, which were unfinished. Translation done by Leslie Smith.

Guiding hypothesis: "There are implications between actions or operations as such; these implications both lie beneath and precede implications between statements (propositions); and they constitute the essential driving force of cognitive, and in particular dialectical, constructions."

"[N]ecessities are not observables. Rather, necessities intervening in reasons are formative with their links leading to that reconstitution of the object or event to be understood. 'Reason' consists in this."},
	Author = {Piaget, Jean},
	Date-Added = {2014-04-13 20:30:31 +0000},
	Date-Modified = {2014-04-13 20:34:05 +0000},
	Journal = {New Ideas in Psychology},
	Number = {1},
	Title = {Reason},
	Volume = {24},
	Year = {2006}}

@misc{Voyat1980,
	Annote = {http://www.fondationjeanpiaget.ch/fjp/site/textes/VE/JP80_Voyat_interview.pdf

From an interview with piaget shortly before his death.

- Equilibration is an active process, not a state! "For example, when you ask me a question while I was thinking of something else, that creates a disequilibrium, that is to say a new need to be satisfied, this need being to make a suitable reply to the question that you asked me."

- On innateness: "I don't believe in complete innateness. ... The nervous system is clearly innate. That is not something constructed by the individual."

- On structures:
	- Inhelder asks Piaget to elaborate on his belief that structures are somewhere between the nervous system and conscious thought. Piaget agrees with inhelder that structures are "what the child knows how to do, not what the child thinks."},
	Author = {Voyat, Gilbert},
	Date-Added = {2014-04-13 19:16:00 +0000},
	Date-Modified = {2014-04-13 19:28:31 +0000},
	Howpublished = {Interview},
	Title = {Interview with Piaget}}

@article{Wavering2011,
	Annote = {http://onlinelibrary.wiley.com/doi/10.1111/j.1949-8594.2011.00083.x/abstract

Very short paper, talks about how Piaget's logic of meanings can be used to symbolize some basic thought patterns used by children in school.},
	Author = {Wavering, Michael James},
	Date-Added = {2014-04-13 18:53:15 +0000},
	Date-Modified = {2014-04-13 18:54:55 +0000},
	Journal = {School Science and Mathematics},
	Number = {5},
	Pages = {249-252},
	Title = {Piaget's Logic of Meanings: Still Relevant Today},
	Volume = {111},
	Year = {2011}}

@incollection{vonGlasersfeld1991,
	Address = {New York, New York, USA},
	Annote = {http://www.vonglasersfeld.com/130

connects late Piagetian thought to more traditional philosophy (John Locke), shows how Piaget was more in line with Locke than the empiricists who followed Locke were.

Offers an interpretation of Piaget's abstractions:

Empirical abstraction: Concerns observables, the sources of which are exogenous

Reflective abstraction: Concerns coordinations, the sources of which are endogenous. von Glasersfeld points out that this can be (and was in fact, by Piaget) subdivided into two types (or more accurately, two *components* of reflective abstraction):
	Reflective type - Reflechissement; when an activity or mental operation (not a static combination of sensory elements) developed on one level is abstracted and applied to a higher level. 
	Revlexive type - Reflexion; a cognitive reconstruction or reorganization of what has been transferred; a process of construction. 
	The confusion from the above seems to have to do with confusions in translations, and perhaps Piaget's own interchanging of the terms at times (11-12).

Pseudo-Empirical: combination},
	Author = {von Glasersfeld, Ernst},
	Booktitle = {Epistemological Foundations of Mathematical Experience},
	Date-Added = {2014-04-13 18:25:19 +0000},
	Date-Modified = {2014-04-13 18:28:33 +0000},
	Editor = {Steffe, L. P.},
	Pages = {45-67},
	Publisher = {Springer},
	Title = {Abstraction, Re-Presentation, and Reflection: An Interpretation of Experience and of Piaget's Approach},
	Year = {1991}}

@inproceedings{Licato2014b,
	Author = {Licato, John and Sun, Ron and Bringsjord, Selmer},
	Booktitle = {Proceedings of CogSci 2014},
	Date-Added = {2014-04-04 01:13:49 +0000},
	Date-Modified = {2014-04-04 01:15:53 +0000},
	Title = {{Using a Hybrid Cognitive Architecture to Model Children's Errors in an Analogy Task}},
	Year = {2014}}

@book{Piaget2001b,
	Annote = {Reflective abstraction, with its two components of ``reflechissement'' and ``reflexion'', can be observed at all stages: from the sensory-motor levels on, the infant is able, in order to solve a new problem, to borrow certain coordinations from already constructed structures and to reorganize them in function of new givens. We do not know, in these cases whether the subject becomes aware of any part of this. (Piaget et al., 1977, Vol.I; p.6).},
	Author = {Piaget, Jean and Montangero, Jacques and Billeter, J.B.},
	Date-Added = {2014-04-02 06:54:48 +0000},
	Date-Modified = {2014-04-02 06:55:34 +0000},
	Editor = {Campbell, Robert},
	Publisher = {Psychology Press},
	Title = {Studies in Reflecting Abstraction},
	Year = {2001}}

@book{Montangero1997,
	Annote = {p. 62 onwards has a good description of the history of Piaget's development of abstractions. 

Says that in the "last period of Piaget's work, the notion of reflective abstraction is made more specific and enriched." (63)

- Says that equilibriation and reflective abstraction are the same thing! (63)


Divides the periods of Piaget's thought:
Origins
- the similarity between biological processes and psychological processes of knowing influenced him

1920s - early 1930s: The Child's Mentality and the Gradual Socialization of Thought
- focus on what the child couldn't do in terms of reasoning ability
- egocentrism
- discussion of structures already, but they are not precisely defined
- says these early books on children's thinking had an almost immediate worldwide impact, as they signified the emergence of a new and innovative thinker.

to 1945: The beginnings of knowledge and the parallel between intelectual development and biological adaptation
- we first see the use of the concept of biological adaptation to explain the development of knowledge: "intellectual development consists of an adaptation that prolongs biological adaptation while transcending it. The relation between thinking and things (and, before the appearance of thought, between action and things) is the basis of knowledge."
- Piaget became "resolutely functionalist" and we see careful definitions of assimilation, accommodation, and equilibrium.
- Almost entirely focused on the sensorimotor stage, with the exception of "Play, Dreams, and Imitation in the Child"
- "He considered object permanence as the first manifestation of invariance principles; simple actions of infants (shaking, rolling, etc.) were considered to be `practical concepts' and the possibility of making a detour as isomorphous to a mathematical structure."

to late 1950s: Structural analysis used to study the formation of the 'categories' of thought
- equilibrium is defined using terms borrowed from logico-mathematics
- structures, operations, and the relations between them are explored
- INRC group and reversibility
- vertical and horizontal decalage are described
- The growth of logical thinking published in this period
- "The principal limitations of the works of this period stem from the difficulty of operationalizing the concept of structure, and from the fact that no analysis is proposed of how mental structures are actually constructed."

to late 1960s: Transitional period between the primary of operatory structures and an interest in developmental mechanisms
- No new model or explanatory concept dominated, as in the previous periods. Instead, this period is described as containing "the essential theoretical reference" from the third period, but also it "foreshadowed that of the fourth and last period."
- We see the "first new model" of the equilibration process as the endogenous process by which logical development tends toward equilibrium.
- He writes "Structuralism" where structures are defined as self-regulating centers of functioning, and "his first conclusion was that the study of structures must not exclude any other aspects of research.

1970s: Multiple ways of explaining cognitive progress
- Reflective and empirical abstraction
- On contradictions: "Piaget concluded [in "Experiments in Contradiction"] that the contradictions of natural thought are disequilibrium that can be considered to be incomplete compensations. They are not logical contradictions---they are signs of disequilibrium, not the cause of it. If contradictions are so common in preoperational children, it is due to the primacy of positive aspects over negative ones. ... As far as the development of knowledge is concerned, contradictions are considered as positive phenomena and not as something to be regretted. Instead, the need to overcome them makes them an integral part of the equilibration process."
- "For the first time in his life, Piaget repudiated one of his ideas", saying that his previous model on equilibration was unsatisfactory. Instead it became more interactive and dialectic. "The process cannot be reduced to compensations of external perturbations, precisely because of [the complex] interaction between schemes.
- He seemed to eventually lose interest in equilibration and instead "went on to explain progress from other points of view, in particular that of reflective abstraction."
- "Piaget himself was convinced that reflective abstraction and equilibration were two different ways of describing the same process; dialectics is the `inferential aspect of equilibration' (Les formes elementaires de la dialectique, 1980, p.10); generalization is very close to abstraction. Unfortunately, Piaget did not bother to state clearly why it is necessary to describe the same process in all these different ways. In addition, he provided little information on the relations (resemblances, differences, intersections) between the different concepts."



The rest of the book has a bunch of definitions and quotes, this is uploaded to google drive as "piaget definitions".},
	Author = {Montangero, Jacques and Maurice-Naville, Danielle},
	Date-Added = {2014-04-02 04:45:24 +0000},
	Date-Modified = {2014-04-20 08:33:22 +0000},
	Publisher = {Lawrence Elrbaum Associates, Inc.},
	Title = {Piaget or the Advance of Knowledge: An Overview and Glossary},
	Year = {1997}}

@book{Gallagher2002,
	Annote = {Source of the confusion between reflexive and reflective abstraction:

"In some English translations, the French term refle'chissante was expressed as reflective. The preferred term is reflexive to avoid confusion with reflected, which refers to the level of abstraction characteristic of adolescent thinking (see Chapter Six)." (footnote on p.29)

Six principles of learning derived from genetic epistemology (p.11):
- Learning is an internal process of construction; children's own activities determine their reactions ot environmental stimulation.
- Learning is subordinated to development, that is, competence is a precondition for learning.
- Children learn not only by observing objects but also by reorganizing on a higher mental level what they learn from coordinating their activities.
- Growth in knowledge is often sparked by a feedback process that proceeds from questions, contradictions, and consequent mental reorganization.
- Questions, contradictions, and the consequent reorganization of thought are often stimulated by social interaction.
- since awareness (conscious realization) is a process of reconstruction rather than sudden insight, understanding lags behind action

She claims that information-processing theorists writing computer programs used concepts "traditionally associated with genetic epistemology", such as structure, assimilation, and accommodation (Tulving and Donaldson 1972, Anderson, Spiro and Montague 1977).

"Equilibration is the third element in development, besides environment and heredity, and it embodies Piaget's middle-ground position, or third possibility." (23)

How do children achieve higher understanding in the marble task? "[C]hildren need to reorganize their own thinking. This reorganization is what we call regulation and represents the basic meaning of equilibration." (25)
The analogy between biological phenocopy and cognitive phenocopy rests on the notion of the need for regulation: an orderly reorganization that leads to a new way of functioning. This reorganization is not imposed from the outside [as in Lamarckian evolution], nor is it 'given'; it is self-regulated. All other Piagetian concepts and all other sections of this book build on equilibration: children grow in knowledge by constructing their own understandings, which are not imposed from the outside but are reached through an internal process of reorganization." (25-26)

Her descriptions of abstractions:
Empirical abstraction - "Draws its information from objects; is based on observables (exogenous source). Important: Empirical abstraction does not intervene by itself at any level of knowing; it is made possible by previous reflexive abstractions through activities of the person."
Reflexible abstraction: "Is based on coordination of actions or operations (endogenous source) and is, therefore, constructive. Two fundamental characteristics:
- Projection: The raising (or projecting) to a higher level of what is borrowed from a lower level of understanding.
- Reflection, or mental reorganization: need to reconstruct what was abstracted from the lower level."
Pseudoempirical abstraction: "(a form of reflexive abstraction): the object is modified by the person's actions and enriched by properties drawn from the coordination of the actions." (28)

A structure is "self-regulating, or governed from within. Here is the notion of construction, the building up of understandings by the child. ... A structure is not observable. This is why constructivist empistemology is not well accepted by empiricists, who place heavy emphasis on observed behavior. Furthermore, children, as well as adults, may be not aware of the mental structures that underlie their thinking. Through questions and careful analysis of both behavior and verbal answers as the child interacts with the environment, we are able to infer structure....in sum, a technical explanation is not a prerequesite for the presence of a structure. Another method of determining whether a structure is present is to give additional problems that are logically related to the first one." (32)

"A simple way to express the meaning of a structure is to say that it is an organization of these interactions [between a child and the objects with which he plays]. For example, when a little girl stacks blocks in a seriated fashion, she is demonstrating a mental structure of seriation at a very action-oriented level." (33)

Difference between structures, action schemas, and actions: "[Some] actions are really simple structures labeled schemes (or action schemes) in Piagetian theory. Schemes, however, are really broaders than the simple actions, for the term is used to emphasize what in an action can be repeated and generalized." (33) When the actions become internalized, represented in thought, and reversible, they become operations (34).

Imagine a child who sees a purple triangle for the first time. She has never seen one in this color, so "the child is faced with a contradiction" (48). She has a couple of ways to react:
1) Alpha behavior - She either ignores the contradiction and calls it a square, or she creates a new group in her mind of just this new object. 
2) Beta behavior - Child attempts to integrate the new object into her existing categories, by accommodating the categories (placing them with purple squares or black triangles).
3) Gamma behavior - she already anticipated that the objects can be grouped by color, and so the assimilation is done easily.

Contradiction, then, is simply a failed assimilation.

The Five Models of Equilibration: each of these are one type of interaction between observables and coordinations (the inferences the child might derive from his or her own actions or the actions of objects on each other to unify the elements of such actions). In all of these, reflexive and empirical abstraction interact. (50-52)
1a) Child observes results of actions on objects, which leads to equilibration.
1b) Child applies logico-mathematical knowledge to objects (as in ordering, sorting, etc)
2a) Like 1a, but they also conceptualize by verifying hypotheses.
2b) Like 1b, but it incolves coordinations of inferences.
2c) Objects act on each other, and children only observe.

Three types of equilibration (54-56):
- Between assimilation and accommodation
- Between subsystems (structures related to different domains)
- Between parts and the whole of a structure

"[I]t is necessary to stress that, even though language is not present, it is during this time (from birth to approximately 18 months) that infants construct all the cognitive substructures that represent the foundation for later perceptual and intellectual development." (64)

"Although Piaget has argued that equilibration constitutes the central concept of his theory ... As Gallagher (1977) notes in her description ... North-Americans have tended to ignore equilibration (dismissing it as "frustrating," "useless," and "misleading") and to emphasize instead the concept of stages. What these psychologists failed to grasp is that equilibration "is not a cumbersome fourth factor [of development] but *the* regulator or prime instrument without which knowledge acquisition is impossible" (p.29; italics in original)."(177)},
	Author = {Gallagher, Jeanette McCarthy and Reid, D. Kim},
	Date-Added = {2014-04-02 04:07:26 +0000},
	Date-Modified = {2014-05-13 22:39:27 +0000},
	Publisher = {iUniverse},
	Title = {The Learning Theory of Piaget and Inhelder},
	Year = {2002}}

@book{Arnon2013,
	Author = {Arnon, Ilana and Cottril, Jim and Dubinsky, Ed and Okta{\c c}, Asuman and Fuentes, Solange Roa and Trigueros, Maria and Weller, Kirk},
	Date-Added = {2014-04-02 01:48:04 +0000},
	Date-Modified = {2014-04-02 01:49:55 +0000},
	Publisher = {Springer},
	Title = {APOS Theory : A Framework for Research and Curriculum Development in Mathematics Education},
	Year = {2013}}

@inproceedings{Besold2013,
	Author = {Besold, Tarek Richard},
	Booktitle = {Proceedings of the 6th International Conference on Artificial General Intelligence},
	Date-Added = {2014-04-01 22:59:44 +0000},
	Date-Modified = {2014-04-02 02:54:15 +0000},
	Title = {Human-Level Artificial Intelligence Must Be a Science},
	Year = {2013}}

@book{Piaget1974,
	Address = {New York, New York, USA},
	Annote = {
"[T]he operations transform the real and thus correspond to what the subject can do to the objects in his deductive or deductible manipulations, which are at first material but susceptible of progressively formal refinement. Causality, on the other hand, expresses what the objects do as they act on one another and on the subject. There must, therefore, be an intimate relationship between these two kinds of actions; otherwise the logico-mathematical constructions of the subject would never meet with reality, while reality would modify the subject's operations without his knowing it." (1-2)

So what is the relationship between causality and operations (which I take to mean the transformations encoded by action schemas)? Piaget sees three possibilities:


   * the logico-mathematical operations of the subject develop on their own (independently of the development of causality) by reflective abstractions starting with the general coordinations of his actions. Piaget sees this as unlikely. 
   * Causality precedes the operation or the preoperational actions, and the development of those operations constitutes are reflection, first internalized and then formalized, of the causal notions successively imposed on the subject by reality. ... The main difficulty is that, ... it is necessary to interpret causality as being due to either the experience of objects or to the actions themselves, but only as physical experiences rooted in the interactions between the organism and the objects. "[E]xplaining causality independently of operations amounts to considering causal relationships as data directly observable in the immediate experience of the objects or of the actions, and capable of being deduced from them by simple or physical abstraction, as opposed to reflexive or logico-mathematical abstraction, without recourse to either a construction or a composition." (7)
   * The hypothesis they go along with is "that at every level the development of the understanding of causality proceeds by interacting with the development of the operations, which amounts to saying that each of these two developments helps the other, following conflicts as well as convergences, so that we can never speak of a one-way action except on special and momentary occasions and in alternating successions." (8)

They have an underlying link: "The element common to operational transitivity and causal transmission, while both are still in the process of being understood, is a function of totalization or of interlocking that tends to go beyond the starting point in order to take into account the system as a whole. ... In short, the exchange between causality and operation, in this case, would consist of an action of the (causal) contents on a cognitive functioning, which would favor the construction of an operational form reacting in turn on the contents. In other words, the reflexive abstraction that has permitted the construction of transitivity, in which the subject attributes to the object mediate causal transmissions, would have been more easily arrived at through knowledge of a few causal facts such as immediate successive transmissions, the knowledge of these facts having ben acquired by physical abstractions, yet reinforcing the need for the closure of the operational structure in the process of formation." (17-18)

He describes an example from calculus's invention: "[I]t was on the way to being developed as soon as Descartes' synthesis of algebra (finite) and of geometry (finite) into analytic geometry was effected. All that remained was to extend it into an algebra of the infinite and into a theory of limits. But to take this double step, which could have come from direct generalizations through purely reflexive abstractions, Newton and Leibniz needed the incentive of physical problems, in other words, the suggestion implicit in the contents borrowed from dynamics. Calculus of the infinite, which grew out of this process, does not thereby constitute a product of experience or of simple abstractions drawn from the object alone. Simple abstractions, however, accelerated the process by virtue of their generalizing function, even though this function then returned to the mathematics on which the construction in question was based. ... In general, it cannot be denied that the problems of physical causality have frequently given rise to mathematical inventions by, not a copy of the real, but a kind of operational reconstruction of a phenomenon the knowledge of which was previously dictated by experience." (18-19)


What about "immediate" inferences?


   * Example: "A baby at the breast who shows impatience at feeding time calms down as soon as he sees his mother appear, which in verbal terms would be translated as "Mother, therefore nursing."" (20) This is a causal connection.
   * Not all "the intermediate inference of the preoperational levels have a causal content. They can serve as classifiers. For example, pipe implies Father, even though in the majority of cases what interests the subject in the objects is what he can produce ... But in the realm of the causal, it goes without saying that the functioning of intelligence, in its efforts to anticipate or comprehend, is all the more stimulated and developed when the problems posed by the real are more varied and more interesting. As a result, we have a permanent functional stimulation that reinforces the development of schemes in their totality ... but naturally especially in those that may be structurally analogous to the relationships involved in the causal problem under consideration." (20)

Summary points from the conclusion:


  1. ``Every sensori-motor action is causal in its psychophysiological mechanism {\ldots} However, none of these particular actions remains exclusively causal [since they are] dominated by the requirements of a general coordination [which is constantly trying to generalize them, connect them to others, etc.]''
  2. There is an undifferentiation between causality and the preoperational structures, and Piaget considers this a very important point. ``In short, the hypothesis is that the causal and logical structures of stage I would both feel the slowing-down effects of a relative undifferentiation, whereas a coordination due to a sufficient differentiation would be profitable for them.''
  3. ``{\ldots}the relative undifferentiation between causal or pre causal and logical or pre logical connections entails continuous interactions, at the core of which it is possible to discern influences in both directions. It would therefore be somewhat artificial to expect to find [at level I] operations `applied' or `attributed' to the object, first because there do not yet exist operational forms distinct from direct connections between contents, and therefore no operations{\ldots}''
  4. This differentiation starts at stage II, ``but it is still limited {\ldots} the operations called `concrete' are only partially dissociated from their content and consist of successive structurings of different contents, with systematic, horizontal lags [d{\'e}calages].'' Familiarity with a domain involves an analogical mapping that relies less on semantic connections at the object level. ``We might assume that the step-by-step compositions that limit the mobility of the operational structures of stage II are really due to the delaying influences of causality on operations, that delay being the result of lack of sufficient differentiation and therefore of sufficient coordination.
  5. At stage III ``the differentiation of causality and operations is sufficient to permit both the free progress of the operations and of the rather rich attributions ensuring the equally remarkable development of causality at this level.''
  6. So ``causality and operations have a common origin in the actions of the subject, with the only difference being that the first depends more on particular actions and the second on their coordinations,'' but ``of what does this differentiation [between the two] consist, and how does it proceed? The problem of going from cognitive structures initially undifferentiated, and thus sources of internal oppositions, to structures both differentiated and coordinated in a coherent way dominates, in reality, the whole mental development in its fundamental processes of progressive equilibration, of periodic disequilibriations and consent reequilabriations. The question of relations between logico-mathematical operations and causality thus constitutes only a particular case, although an especially important one by reason of the great dychotomy[sic] that it represents.'' Attributions start out as absolute: ``for young subjects an object cannot be both bigger than another and smaller than a third, because it cannot be both `big' and little''', but later ``the attributes `big' and `little' become related" (122). ``[The] progressive overtaking [depassement] of contradictions, which constitutes the formative process of differentiations as well as of coordinations, is fundamental when it comes to relations between operations and causality. To raise contradictions is, in effect, to construct a new operational structure'' (122).

  7. 
    1. The problem reduces to this: ``What steps in the thinking of the subject can be taken to go from a situation in which almost everything remains successive and causal to a situation permitting the selection of extemporaneous connections between forms that are stable or capable of being reestablished?''
    2. The first process which answers this question is: ``the effort of visualize total simultaneous representations of past, present, and future events, remaining successive on the level of perceptive observations.''
    3. Second is ``the intervention of self-regulations, introducing in these systems a mobile equilibrium in such a way that the coordinations can be effected in both directions {\ldots} and thus be transformed into reversible operations.''
    4. But this isn't enough for Piaget, he wants to express the differentiation in terms of the realization of the possible. In stages I and II, ``The physical notion of the virtual bears on the possibilities the compensations of which can be simultaneous, but the realizations of which are only consecutive {\ldots} By nature, hypothetico-deductive [stage III] reasoning goes directly from the possible to the necessary by connecting the possible without the intermediary of reality. Besides, it is by this criterion that we can recognize the appearance of formal thought.'' (125)
    5. ``The fact that the possible and the real are opposites explains, in the final analysis, the multiple differences between operations and causality, which are so evident that there is no need to insist on them''
  8. ``Briefly, the differentiation between the operation and the causal depends on the progressive construction of its extemporaneous forms. But three questions remain:''
  9. 
    1. ``Why this study of the extemporaneous?'' Because it relies on something important: the need for thought to escape from ``the contradictions inherent in the successive events and, in time, to oppose some stability to the [pantasie] of the real."
    2. ``How does it result in the constitution of `forms'?'' ``[O]nce we admit that action itself is initially both causal and coordinating, the passage from the action to the operation is made by a gradual elimination of the dynamic and kinematic factors that include the intervention of duration. What remains, then, is a whole set of realities that must be called `forms' since they are no longer physical. Their nature can be accurately defined, at the risk of the most serious misunderstandings, only by determining in a systematic way in what respects they are richer or poorer than the causal transformations to which they correspond. [very pragmatic!]
    3. What is their relationship with the forms of objects in causality between objects as opposed to that of the action itself? First, ``we cannot consider even the most general of these forms, namely, those of logic, as the residue of properties common to all the objects once the kinematic and dynamic factors are removed. {\ldots} [Secondly,] to the degree that there is correspondence between the causal transformations of objects and the operational transformations of the subject, it means neither that the latter are derived from the former {\ldots} nor the converse. {\ldots} The problem, then, is one of relationships between the two types of abstractions that these two kinds of activities presuppose.'' Is this where low-level analogical predicate transfer comes in?
  10. ``Two fundamental data dominate the problems of physical knowledge and consequently the relationships between the operations of the subject and the causality of objects. {\ldots} [First,] that the reading of an experiment requires the use of instruments of assimilation to make this reading possible {\ldots} [Second, that causal connections], while relying partially on information obtained through simple abstractions, inevitably go beyond the realm of the observable, even when it concerns the action itself, because then the movements of the subject, the resistance he succeeds in overcoming, etc., are for him observables that, like the others, are objective.
  11. He talks about the relationship between `legality' and causality, which I don't quite understand. Then, ``the second general result of our studies, namely, the interpretation of causality as operational structures attributed to the object. {\ldots} The nature of causality thus always includes a system of transformations that cannot be reduced to a simple relationship of cause and effect presupposed by common sense. Even in cases where such a relationship seems to exist, as in the example of a push, there intervenes in reality an elementary structure, that is, compensations between losses and gains, composition of transformations and conservations, etc., not to mention directions---in other words, a deductive system.'' (134) However: ``the deductive system on which the causal explanation is based does not consist of a simple arrangement of laws or their contents, fitting into each other [embo{\^\i}tement] by a syllogistic chain of reasoning [encha{\^\i}nment] {\ldots} It really consists of a composition of applied operations themselves arrived at by means of general procedures of coordination and of operational transformations {\ldots} It is, indeed, these general forms of operational organization that constitute structures, to the extent that its internal compositions close in on themselves when necessary.''
  12. ``On the whole, operations constitute, so to speak, a causality applicable to extra temporal forms and physical causality, a system of operations brought about by the material objects. {\ldots} But then why does the subject not know, through the medium of his organism, the totality of causes and effects that are centered in him, or at least the totality of those that rule his interactions with the environment? It is because knowledge is not a reflection but an activity, and because our knowledge of causality is something other than causality and proceeds by various laborious approximations. These begin only with actions, that is, with higher forms of the interactions between the organism and the objects external to it.''


Part 2 of book: By Garcia and Piaget


Garcia goes through an interesting historical discussion that talks about how Huygens and Leibnitz tried to challenge Newton's approach to physics, and how Descartes similarly tried to challenge Newton on these lines by creating a purely geometric physics. Riemann's conception of non-Euclidian geometry (of course later resurrected by Einstein) is characterized as a resurrection of the Cartesian approach. Einstein is quoted as saying: ``How is it possible that mathematics, which is the product of human thought and independent of all experience, can adapt itself so admirably to the objects of reality?'' Einstein's work was initially hailed as achieving Descartes' dream of a purely geometric physics, but Garcia disagrees: ``It is not that the theory of gravity was geometrized, it is that geometry became the expression of the gravitational field'' (182).

I think discussion is trying to head towards alternate mathematics, or more specifically alternate physics, which is entirely plausible in light of this historical evidence and with our understanding now of how physical causality develops in the constructivist theory. As Garcia's part of the book opens, ``The ambition of genetic epistemology has always been to link the problems that arise at the most elementary levels of knowledge to those raised by the theory of scientific thought itself.''},
	Author = {Piaget, Jean and Garcia, Rolando},
	Date-Added = {2014-03-29 02:35:08 +0000},
	Date-Modified = {2014-04-01 17:38:28 +0000},
	Editor = {Miles, Donald and Miles, Marguerite},
	Publisher = {W.W. Norton and Company, Inc.},
	Title = {Understanding Causality},
	Year = {1974}}

@article{Cohen2006,
	Author = {Cohen, Paul R.},
	Date-Added = {2014-03-22 00:48:28 -0400},
	Date-Modified = {2014-03-22 00:49:15 -0400},
	Journal = {AI Magazine},
	Number = {4},
	Title = {If Not Turing's Test, Then What?},
	Volume = {26},
	Year = {2006}}

@inproceedings{Levesque2012,
	Annote = {https://cs.nyu.edu/davise/papers/WSKR2012.pdf

Also provides corpus of Winograd schemas. More at http://www.cs.nyu.edu/faculty/davise/papers/WS.html. 


},
	Author = {Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
	Booktitle = {Proceedings of the Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},
	Date-Added = {2014-03-21 23:48:18 -0400},
	Date-Modified = {2014-03-22 00:49:54 -0400},
	Title = {The Winograd Schema Challenge},
	Year = {2012}}

@inproceedings{Jurgens2012,
	Address = {Montreal, Canada},
	Annote = {http://aclweb.org/anthology//S/S12/S12-1047.pdf

Citation for the popular SemEval-2012 Task 2 test, being used by many vector-based approaches to analogy and relational detection.

},
	Author = {Jurgens, David A. and Mohammad, Saif M. and Turney, Peter D. and Holyoak, Keith J.},
	Booktitle = {Proceedings of the First Joint Conference on Lexical and Computational Semantics (*SEM)},
	Date-Added = {2014-03-18 15:02:03 -0400},
	Date-Modified = {2014-03-18 15:04:13 -0400},
	Organization = {Association for Computational Linguistics},
	Pages = {356-364},
	Title = {SemEval-2012 Task 2: Measuring Degrees of Relational Similarity},
	Year = {2012}}

@article{Turney2013,
	Annote = {http://arxiv.org/pdf/1310.5042v1.pdf

Presents "SuperSim", a unified approach to analogy (relational similarity) and paraphrase (compositional similarity). SuperSim treats them both as problems of supervised tuple classification, using a standard SVM as the supervised learning algorithm. 

"SuperSim matches the state of the art on SAT analogy questions and substantially advances the state of the art on the SemEval 2012 Task 2 challenge, and the noun-modifier paraphrase questions."},
	Author = {Turney, Peter D.},
	Date-Added = {2014-03-18 14:54:12 -0400},
	Date-Modified = {2014-03-18 15:01:49 -0400},
	Journal = {Transactions of the ASsociation for Computational Linguistics (TACL)},
	Pages = {353-366},
	Title = {Distributional Semantics Beyond Words: Supervised Learning of Analogy and Paraphrase},
	Volume = {1},
	Year = {2013}}

@inproceedings{Zhila2013,
	Annote = {http://www.aclweb.org/anthology/N/N13/N13-1120.pdf

They have a system that "combines heterogeneous models based on different information sources for measuring relational similarity." They achieve a new state-of-the-art on the SemEval-2012 task 2 test set.},
	Author = {Zhila, Alisa and Yih, Wen-tau and Meek, Christopher and Zweig, Geoffrey and Mikolov, Tomas},
	Booktitle = {Proceedings of NAACL-HLT},
	Date-Added = {2014-03-18 14:50:43 -0400},
	Date-Modified = {2014-03-18 14:52:28 -0400},
	Pages = {1000-1009},
	Title = {Combining Heterogeneous Models for Measuring Relational Similarity},
	Year = {2013}}

@incollection{Dubinsky2002,
	Annote = {http://www.math.kent.edu/~edd/ICMIPaper.pdf

Not the original citation for APOS, but it has a good up to date summary. Annotated bibliography included that shows work with APOS theory, but I don't see any computational implementations.},
	Author = {Dubinsky, Ed and Mcdonald, Michael A.},
	Booktitle = {The Teaching and Learning of Mathematics at University Level},
	Date-Added = {2014-03-18 12:06:04 -0400},
	Date-Modified = {2014-03-18 12:09:26 -0400},
	Editor = {Artigue, Mich{\`e}le and Kirchgr{\"a}ber, Urs and Hillel, Joel and Niss, Mogens and Schoenfeld, Alan},
	Pages = {275-282},
	Publisher = {Kluwer Academic Publishers},
	Series = {New ICMI Study Series},
	Title = {APOS: A Constructivist Theory of Learning in Undergraduate Mathematics Education Research},
	Volume = {7},
	Year = {2002}}

@inproceedings{Socher2010,
	Annote = {http://nlp.stanford.edu/pubs/2010SocherManningNg.pdf

Using deep learning. They represent each leaf node as an n-dimensional vector representation of words, and incrementally combine two vectors at a time to produce a tree structure. They were able to then find similarities between phrases based on the vectors, even with previously unseen words and phrases, e.g. "To decline to comment" is close to "to not disclose", and "a spokesman declined to elaborate" was close to "spokesman [who] refused to identify".},
	Author = {Socher, Richard and Manning, Christopher D. and Ng, Andrew Y.},
	Booktitle = {Proceedings of the NIPS-2010 Deep Learning and Unsupervised Learning Workshop},
	Date-Added = {2014-03-13 11:32:54 -0400},
	Date-Modified = {2014-03-13 11:34:21 -0400},
	Title = {Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks},
	Year = {2010}}

@inproceedings{Socher2011,
	Annote = {http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Socher_125.pdf

Paper where they describe their deep learning work that builds representations of scenes from the ground up. They also apply it to natural language sentences.},
	Author = {Socher, Richard and Lin, Cliff Chiung-Yu and Ng, Andrew Y. and Manning, Christopher D.},
	Booktitle = {Proceedings of the 28th International Conference on Machine Learning},
	Date-Added = {2014-03-13 11:30:44 -0400},
	Date-Modified = {2014-03-13 11:31:47 -0400},
	Title = {Parsing Natural Scenes and Natural Language with Recursive Neural Networks},
	Year = {2011}}

@article{Guerin2011,
	Annote = {http://journals.cambridge.org/action/displayFulltext?type=1&fid=8274016&jid=KER&volumeId=26&issueId=02&aid=8274014

Good summary of work on the early developmental approach to AI, or the development of commonsense knowledge in an individual.

Some things he says is missing from Developmental AI:

   * The type of stage transition has not been captured which both:
      * Doesn't simply learn skills at one level and then moving it to a higher level where they can be used as macro actions. Rather, the existing skills take on a new character, being used in a new way, leading to the emergence of more new skills.
      * Allows the new stage of behavior to happen because the level of development at the old stage enables the infant to notice some new relationship in the world, rather than simply having the agent decide that some skill level has reached a threshold.
      * We need to focus on "developing detailed physical world knowledge rather than attempting to build systems which display some of the abstract hallmarks of stage transition."
   * Microworlds used are insufficient to:
      * Provide enough source analogies to bootstrap understanding of concepts like (inside/outside), (large/strong), force dynamics, etc.
      * Allow systems to create and maintain knowledge that it can verify itself (Sutton's 'Verification Principle').
      * Model the acquisition of spatial knowledge, which is one of the foundational domains as noted by Kupiers et al., Piaget, and Brunschvicg.
      * Object knowledge and recognition should involve the learning of "complex and subtle concepts".
   * Lack of analogy:
      * There is a "lack of techniques for analogy finding and pattern matching. ... [W]hen something happens as the result of an action, it is necessary to recognize which of the existing schemas it is analogous to."
      * "Analogical reasoning also seems to be essential for building models of the world, and indeed one could say that intelligence is all about building models of the world ... The existing works have perhaps not yet found the need for analogical reasoning, as they have not yet got as far as building elaborate models of the world; existing models are restricted to some correlation among a limited number of sensorimotor schemas".
   * There is a lack of comparison between the systems because "all the works carry out their experiments in completely different worlds. If the community could agree on some standard benchmark simulation worlds, then it would be possible to compare all the techniques".

},
	Author = {Guerin, Frank},
	Date-Added = {2014-03-12 14:23:16 -0400},
	Date-Modified = {2014-03-12 15:14:04 -0400},
	Journal = {The Knowledge Engineering Review},
	Number = {2},
	Pages = {209-236},
	Title = {Learning Like a Baby: A Survey of Artificial Intelligence Approaches},
	Volume = {26},
	Year = {2011}}

@article{Heider1944,
	Author = {Heider, Fritz and Simmel, Mary-Ann},
	Date-Added = {2014-03-12 12:45:50 -0400},
	Date-Modified = {2014-03-12 12:46:59 -0400},
	Journal = {American Journal of Psychology},
	Title = {An Experimental Study of Apparent Behavior},
	Volume = {13},
	Year = {1944}}

@inproceedings{Bringsjord2003b,
	Author = {Bringsjord, Selmer and Schimanski, Bettina},
	Booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI)},
	Date-Added = {2014-03-12 11:55:20 -0400},
	Date-Modified = {2014-03-12 11:56:21 -0400},
	Title = {What is Artificial Intelligence? Psychometric AI as an Answer},
	Year = {2003}}

@article{Turing1950,
	Author = {Turing, Alan M.},
	Date-Added = {2014-03-12 11:11:23 -0400},
	Date-Modified = {2014-03-12 11:12:02 -0400},
	Journal = {Mind},
	Pages = {433-460},
	Title = {Computing Machinery and Intelligence},
	Year = {1950}}

@article{Bringsjord2001b,
	Author = {Bringsjord, Selmer and Bello, Paul and Ferrucci, David},
	Date-Added = {2014-03-12 11:07:53 -0400},
	Date-Modified = {2014-03-12 11:09:50 -0400},
	Journal = {Minds and Machines},
	Pages = {3-27},
	Title = {Creativity, the Turing Test, and the (Better) Lovelace Test},
	Volume = {11},
	Year = {2001}}

@article{Pegg2005,
	Annote = {http://homepages.warwick.ac.uk/staff/David.Tall/pdfs/dot2005h-zdm-pegg-tall.pdf

Good summary of the development of mathematical ability and schemas. "Particular reference is given to the shifting of attention from step-by-step procedures that are performed in time, to symbolism that can be manipulated as mental entities on paper and in the mind." They also describe their own SOLO model. It's not clear whether it is a computational model or not.

The SOLO model has "modes," the first four of which roughly correspond to the PIagetian stages: Sensorimotor, Ikonic, Concrete symbolic, Formal, and Post Formal. Each mode is nested within the next rather than being replaced by it. They model how a subject can start from the action schema of counting numbers to reasoning symbolically about them.

Talks about the shift in focus from *actions* on already-known objects to thinking of those actions as manipulable mental objects. This is Piaget's notion of reflective abstraction, "in which actions on existing or known objects become interiorized as processes and then encapsulated as mental objects of thought." Dubinsky's action-process-object, Sfard's interiorization-condensation-reification, etc. describe this same thing. 

In Dubinsky's APOS theory:
- actions become interiorised as processes (AP)
- which then become objects in a wider schema (OS)

"It is not claimed that this is the *only* way in which concepts grow. ...there are different ways in which concepts can be constructed, including constructions from *perceptions* of objects, *actions* on objects and *properties* of objects."

"In all of these 'topics' there is an underlying local cycle of concept construction from action-schema to mental object."},
	Author = {Pegg, John and Tall, David},
	Date-Added = {2014-03-11 11:37:01 -0400},
	Date-Modified = {2014-03-11 11:38:49 -0400},
	Journal = {International Reviews on Mathematical Education (Zentralblatt f{\"u}r Didaktik der Mathematik)},
	Number = {6},
	Pages = {468-475},
	Title = {The Fundamental Cycle of Concept Construction Underlying Various Theoretical Frameworks},
	Volume = {37},
	Year = {2005}}

@inproceedings{Aksoy2013,
	Annote = {They show how an extension of their semantic event chain, called the extended SEC, can achieve tasks like assimilation, accomodation, etc. They are able to compare actions at different levels of semantic depth; here they use cutting and chopping.

Semantic Event Chain (SEC) - A possible descriptor for manipulation actions. Analyzes the sequence of changes of the *relations* between the objects being manipulated by a human or robot. SECs are invariant to the particular objects used. They are analogical!},
	Author = {Aksoy, E. E. and Tamosiunaite, M. and Vuga, R. and Ude, R. and Geib, C. and Steedman, M. and W{\"o}rg{\"o}tter, F.},
	Booktitle = {Proceedings from the Third IEEE International Conference on Development and Learning and on Epigenetic Robotics},
	Date-Added = {2014-03-10 13:42:54 -0400},
	Date-Modified = {2014-03-10 13:59:12 -0400},
	Title = {Structural Bootstrapping at the Sensorimotor Level for the Fast Acquisition of Action Knowledge for Cognitive Robots},
	Year = {2013}}

@inproceedings{Cohen2007,
	Annote = {http://yuhanchang.com/papers/ijcai07.pdf

They have a robot model named "Jean" that executes and learns action schemas and "gists". They define an Experimental State Splitting algorithm which iteratively refines/splits state descriptions to make the transitions between states more predictable.

"This paper demonstrates that the schemas learned by Jean can be trasnferred between situations, as any Piagetian schema should be."

Action schema - "comprises a controller, a representation of the dynamics of executing the controller, and one or more criteria for stopping executing the controller." They draw parallels between nondeterministic FSMs and action schemas, but also note differences.

Gists - compositions of action schemas for common tasks.},
	Author = {Cohen, Paul R. and Chang, Yu-Han and Morrison, Clayton T.},
	Booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence},
	Date-Added = {2014-03-10 12:49:27 -0400},
	Date-Modified = {2014-03-10 12:51:27 -0400},
	Pages = {720-725},
	Title = {Learning and Transferring Action Schemas},
	Year = {2007}}

@inproceedings{Platt2006,
	Annote = {http://www.cs.ou.edu/~fagg%20/papers/2006/platt_etal_icdl_2006.pdf

The use action schemas for a robot grasping task. They define an algorithm called "schema structured learning" that "repeatedly executes variations of the generalized solution in search of instantiations that satisfy action schema objectives."

Action schemas - consists of: a one-to-one mapping between an abstract state and action space, which is matched with an underlying state and action space. The underlying space is assumed to represent the system's state and action with the finest granularity available to the robot. There is also an abstract transition function that defines desired transition behavior in the underlying space. The action schema's abstract policy is translated into a number of policy instantiations that define a set of potential solutions.

So if S' x A' is the abstract state-action state defined by the action schema, and S x A is the underlying state-action space that can represent possible behavior, the abstract policy is:

pi' : S' -> A'

mapping internal representations of states (binary codes) to abstract actions that should be taken.

f : S -> S'
g : A -> A'

are state and action functions which uniquely assign each underlying state and action to an abstract state and action.},
	Author = {Platt, Robert and Grupen, Roderic A. and Fagg, Andrew H.},
	Booktitle = {Proceedings of the Fifth International Conference on Development and Learning},
	Date-Added = {2014-03-10 12:23:51 -0400},
	Date-Modified = {2014-03-10 12:26:27 -0400},
	Title = {Improving Grasp Skills Using Schema Structured Learning},
	Year = {2006}}

@article{Sun1995,
	Annote = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.31.9790&rep=rep1&type=pdf

Describes an organization that allows for the implementation of schemas and logics in connectionist models.

Describes "different forms of schemas". Since there are so many different forms of representation, he concludes that implementing schemas should be done incrementally: start with something simple, and add more complexity as needed.

This paper also introduces the DN formalism, which allows for a lot of the things I wanted to do! It allows for free variables, variable binding, unification, etc.},
	Author = {Sun, Ron},
	Date-Added = {2014-03-10 12:08:14 -0400},
	Date-Modified = {2014-03-10 12:09:29 -0400},
	Journal = {Applied Intelligence},
	Pages = {83-102},
	Title = {Schemas, Logics, and Neural Assemblies},
	Volume = {5.2},
	Year = {1995}}

@article{Arbib1992,
	Annote = {http://geza.kzoo.edu/~erdi/cns/schema.pdf

Anticipatory schemas - Plans for perceptual action as well as readiness for particular kinds of sensory structure (Nessier 1976). 

Schema - "What is learned about some aspect of the world, combining knowledge with the processes for applying it" (4)

Schema instance - An active deployment of the processes used for applying a schema. Each has an "activity level" which indicates its current salience for the ongoing computation.

Perceptual schema - Determines not only whether a given "domain of interaction" (an action-oriented generalization of the notion of object) is present in the environment is present in the environment, but can also provide parameters concerning the current relationship of the organism with that domain. May require several schema instances, each suitably tuned, to subserve our perception of several instances of its domain.

Motor schema - Provides control systems which can be coordinated to effect a wide variety of actions. Whereas activity level of perceptual schemas represents salience or plausibility of the hypothesis the schema represents, for motor schemas it may signal the "degree of readiness" to control some course of action.

Schema assemblages - A combination of schema instances.

Coordinated control program - schema assemblage which processes input via perceptual schemas and delivers its output via motor schemas.},
	Author = {Arbib, Michael A.},
	Date-Added = {2014-03-10 11:30:37 -0400},
	Date-Modified = {2014-03-10 11:32:22 -0400},
	Journal = {Encyclopedia of Artificial Intelligence 2},
	Title = {Schema Theory},
	Year = {1992}}

@book{Piaget1991,
	Annote = {A translation "from the original french version published by Murionde Geneve in 1987."

"The two general goals of this book are to find where one must start to construct a logic of meanings and to show that such a logic is based upon implications and other relations among actions and operations. In no way can a logic of meanings be limited to a logic of true or false statements. It must pertain to the referents of statements, and therefore to objects themselves" (p.63-64)

"The data gathered in this project delineate the elementary ontogenetic forms leading to the construction of operations, and to structures that result from their necessary compositions. Each chapter has shown these developmental roots to be meanings and implications among meanings, starting with action implications that are initially implicit before being consciously grasped and finally being formulated verbally." (119)

Chapter 5 shows instances of children excluding or including objects because they "can" or "cannot" be used for certain tasks. This shows an action-centered understanding of objects, as opposed to a truth-value-centered understanding (though the statement CanBeUsedFor(x,y) clearly can be expressed in a truth-functional logic, the point is that the children first enrich their understandings with permissible and nonpermissible actions primarily).

He also tries to show that the connectives used in the early developmental stages reflect those seen in the formal operations stages. e.g. "To sum up, our subjects employ connectives that are isomorphic to 10 of the 16 future binary operations. ... The 10 that are used are all connectives between meanings that do not depend on an extensional truth table." (p.66)

Piaget tries to show how the higher-level reasoning processes, based on truth values, can emerge from action implications. But does he also believe that understanding of objects come from action implications as well? Answer is yes: "It follows that an object is a set of conjoined predicates and its meaning amounts to 'what can be done' with it, and is thus an assimilation to an action scheme" (119)

"From a general standpoint, the two meanings of an object are, subjectively, what can be done with it and, objectively, what it is made of or how it is composed. The former cannot be separated from the meaning of actions...The latter meaning raises the problem of whether objects are composed from a set of observable properties, or require establishing relations, reconstitutions, and so forth" (p.57, TaLoM)

"We must therefore make a distinction between two kinds of action or meaning implication: Local implications which pertain to a single relation ...; and systemic implications which untie the local relations into a consistent whole and provide "reasons" for it. ... At level II [in this particular experiment,] the first systemic implications appear in comparison of patterns, or judgments about what is possible or impossible on the looms. As already pointed out, however, the inferences do not reach necessary "reasons," since the only reasons consist in claiming that certain relations are "always" or "never" found in the cases observed, which indicates a confounding of necessity with generality. Even so, such reactions demonstrate that there is now a "system" for the subject, instead of merely a collection of local regularities. It is only at level III that systemic implications prevail to such a point that Xys, for instance, is able to deduce all the other possibilities from a single pair of magnets, which indicates the victory of the "necessary" over the "general."" (p.89, TaLoM)

"we can distinguish three kinds of predicate meanings:
(1) "Coupled predicates" which are indissociably linked, such as the size of an element and its position in a seriation---as if changing an element's position entailed simultaneously changing its size
(2) A more refined linkage is to think that putting a large element next to some small ones, or vice versa, modifies the size of elements that have become neighbors, through a kind of contagion.
(3) The predicates are eventually relativized: The terms "big" and "small" are meaningful insofar as they relate to reference frames and are thus essentially relative: Big means "bigger than x" and small means "smaller than x." This evolution in the meaning of predicates cannot be separated from a transformation in the mode of coordination, which starts as a mere figural arrangement and ends as a composition of relations proper, the latter indexing the arrival of concrete operations. In other words, the evolution of meanings corresponds with a development of action implications, which do not constitute pure "forms" but depend directly on the nature of their contents." (p.94-95, TaLoM)

"The general law that seems to arise...is that comprehensive classes are initially lacking and instead there is a progressive transition from 'paired predicates' and simple changes to increasingly encompassing and hierachized classifications. In other words, after an initial period characterized by alternating and local centrations on resemblances or differences, progress in all situations consists in synthesizing both these relations, and this synthesis compels the formation of structured wholes. The simples of these is seriation, which is an equivalence of the successive differences between each element and its successor. Reciprocally, classifications include a difference between equivalences: Sub-classes of the same rank express an equivalence relation, whereas the hierarchical ordering of classes expresses a difference relation (the less numerous classes being the most encompassing ones, and the more numerous classes being the less encompassing ones). Thus, both seriation and classification require a synthesis of resemblances and differences, and there is a reciprocity between their respective structures. No wonder then that such syntheses develop slowly [...] The tools for constructing these syntheses are obviously the action implications that gradually replace the initial paired predicates." (106-108, TaLoM)

"In addition to these kinds of structures [seriations and classifications], there is a preoperation that is rather frequent at all ages and which is often combined with the operations of these two groupings, although it is not their source. This preoperation is the construction of symmetries. For any given order of resemblances or differences, to construct a symmetry is to find the corresponding order through a reversal or inversion around a separating axis." (111, TaLoM).

"Seriations consist in similarities between differences ... and classifications are differences between similarities ... [S]imilarities and differences involved in classifications and seriations are concerned only with contents, irrespective of positions. We may then define symmetry as an inverse correspondence---a similarity in contents with a reversal of positions. [In other words, the contents of A and B are compared to produce the relationship R, and then B and A are compared to produce R', and R and R' are compared.]" (118?, TaLoM)

From Piaget's "Conclusions" chapter:
"As a conclusion, we shall classify the various forms of meanings and meaning implications."
- The meanings of predicates: The simplest. Defined as the "similarities and differences between one property observed in an object and other predicates that are recorded simultaneously or already known. Predicates are connected through conjunction-like preoperations which may be either 'constrained' (i.e., necessary, hence involving a mutual implication, as in the co-occurrence of shape and size), or 'free' (and therefore contingent, as between a shape and a color). In between these two types, we have observed in younger subjects what we have called 'coupled predicates.' These are linked through 'pseudo-constrained' conjunctions; for instance, the expectation that the size ofthe middle element in a seriation can change through a mere change in its position."
- It follows that an object is a set of conjoined predicates and its meaning amounts to 'what can be done' with it, and is thus an assimilation to an action scheme (whether the action is overt or mental). 
- As for actions themselves, their meaning is defined by 'what they lead to' according to the transformation they produce in the object or in the situations to which they are applied. Whether we are dealing with predicates, objects, or actions, their meanings always implicate the subject's activities, which interact either with an external physical reality, or with elements that were previously generated by the subject, such as logico-mathematical entities.

There are various degrees in meanings:
- Local: relates to limited data and to particular contexts. The meaning of actions are determined by the observed outcomes. Implications are data- and context-bound.
- Systemic: Laying the groundwork for structures. Implications are inserted in a system of relations which are established through step-by-step understanding. Possibility and impossibility appear. These inferences, however, do not suffice to reach necessary "reasons."
- Structural: Pertaining to the internal compositions of already constituted structures. There is an endogenous understanding of the "reason" for the observed general facts.

"If all truth is based on meanings, and if all forms of meanings consist in attributions of schemes to either predicates, objects, or actions, then clearly there could be no such thing as an isolated scheme or meaning. Rather, there are always multiple relations among them. This means that at all developmental levels, no matter how primitive, all knowledge has an inferential nature, however implicit and elementary it may be. To put it another way, using a meaning always presupposes and entails using some implications."

Action implications, just as implications between statements, may take three forms:
- A proactive form (which Pierce called "predictive"), where case A->B means that B is a new consequence derived from A.
- A retroactive form (which Pierce called "retrodictive"), where case A->B means B implies A as a preliminary condition.
- A justifying form, which relates the above two through necessary connections that thus attain the status of "reasons." However, we must recall that the reason Ri of a necessary truth can never be isolated. Sooner or later, it brings up the problem of the reason Rj for reason Ri, and so on, through a dialectical spiral that is superimposed on the interconnections between implications of type 1 and 2.

From Garcia's portion of the book:

Piaget's approach to logic originates in epistemology. "His psychological research---the psychogenesis of concept formation---is meant to provide *tools* to understand how knowledge evolves."
"Piaget's logical theory has two purposes that need to be very carefully distinguished:
a) To explain how logical relations and logical structures are developed by the subject (the *knowing* subject!) until they reach the level of what is called the natural logic of a human adult.
b) To show how logical relations and logical structures play the fundamental role of assimilatory instruments that allow the knowing subject to apprehend and organize the objects of knowledge, thus being the necessary conditions for *any* kind of knowledge.
Both processes go together and they interact in accordance with the well known formula: The subject structures the world as he structures his own structuring instruments, i.e., his logic."

There are three important steps in the evolution of logico-arithmetic links, which correspond to pre-operatory thought, concrete operations, and hypothetico-deductive reasoning. These correspond to intra-operatory, inter-operatory, and trans-operatory links. Piaget seemed to agree that the latter terms are better.
Intra-Operatory links:

   * Intra-Operatory Links:

      * Refer to internal articulations. 
      * Lack reversibility.
      * Two main types:

         * Comparisons and correspondences - Formed in the step preceding the constitution of functions. Within this class we find identities (not in any way a simple kind of relation) as well as correspondences that result from repetitions, similarities and equivalences. Functions also, but only insofar as they do not imply transformations and their variants.
         * Transforming actions:

            * Collections of objects divided in sub-collections (without understanding of quantification attached to the inclusion relation)
            * Seriation of objects of various different sizes (only when it comes from empirical verifications not involving transitivity)
            * Natural numbers (without conservation of quantity)
   * Inter-operatory links

      * Involve elementary operations w/compositions among operations, leading to the first rational logico-arithmetic structures, e.g.

         * reversibility
         * recursivity
         * transitivity
         * commutability (and its linear form: commutativity)
         * limited associativity
         * reciprocity
      * The groupings, although quite consistent and highly general, are still very poor and have important limitations:

         * It performs its function by expressing qualitative properties of certain exogenous contents, and as such is always subordinated to contents that are given. So their consistency is theoretically formalizable.
         * No composition except between neighboring elements or subsets. To combine any two elements or subsets requires extensional generalizations not yet developed by the child.
         * There are difficulties in conceiving class intersections
         * There is an impossibility of deducing the properties of a subsystem starting with the properties of the total system. "This is the essential reason to consider the grouping as a weak structure."
   * Trans-operatory links

      * Not yet thematized, and characterize only a "know-how" of the subject as opposed to an understanding of the structures, but has structures which result from a very constructive process that applies operations on operations. E.g.:

         * Permutations - a seriation of all seriations.
         * Combinations - classifications of all classifications. 
         * Set of subsets - comes from combinations by adding a new factor: vicariance / substitution. 
         * INRC group, which includes both inversions and reciprocities. This kind of group appears (only instrumentally and not yet thematized) each time that two different systems are composed into a single totality. The two-valued prepositional logic is also an example of such a group.
   * "Each stage cannot be conceived as simply a natural *growth* of the preceding one; each stage *re-organizes the whole of the instruments already used by the subject.* Piaget took exception to the idea of deducing *a priori* what such a development must be from its most humble beginning to its 'final' state by means of an essentially algebraic structural analysis, when he said "It could possibly lead to some generalizations that would be interesting from a formal viewpoint, but that might have no genetic significance."
"The transition from one stage to the next will not be depicted as some sort of 'addition' of new elements to the existing ones. Each transition means a complete *re-organization* of the previous 'stage.' This, in turn, means that the former dynamic equilibrium has been destroyed. ... Cognitive development is thus characterized by structural discontinuity and functional continuity."


"Within the theory of genetic epistemology, the re-organization process is conceived of as taking place through the utilization of some specific *cognitive* instruments. The central role is played here by what Piaget has called 'reflective abstraction.' The very way in which it enters the process of constructing new structural relations prevents any idea of a continuous line of development or growth.

Chapter 11

LR - logic of relevance
LO - operatory logic
LE - logic of entailment
They want to find a convergence between LR and LO on three fundamental points:
a) Logic starts from inferences, and inferences are primarily implications between meanings
b) Logical connectives in propositional logic are introduced *via* inferences (i.e. implications)
c) Truth-functional logic is just one special case among a large variety of possible links among propositions

Inference is to be the starting process to building up a logic. "[L]ogic starts at the moment a child is able to anticipate a relation between actions...Anticipation of actions means *inference*. Piaget's dictum---'at all levels, even the most elementary ones, any form of knowledge includes an inferential aspect, however implicit or elementary it may be'---is an essential founding block of his epistemological theory. Let us insist...that this is an *epistemological* assertion based on the *empirical* findings of genetic *psychology*. It was therefore clear that, from the developmental point of view, logic starts long before propositions, that logical relations are not based on linguistic relations, and that the propositional calculus could not claim to be necessarily the first chapter of a book of logic."

Chapter 12 - General Conclusions

"The central thesis put forward by Piaget is that, even at the most elementary levels, knowledge always involves some inferential dimension. The problem was to find out what this inferential dimension consists of. The answer may be stated very briefly: at the most elementary levels, inferences are just implications between meanings (which are attributed to properties, to objects, and to the actions themselves)." This thesis is later reformulated to: "There is a logic of meaning preceding the formal logic of statements; such a logic of meanings is based on implications between meanings or, what amounts to the same thing, implications between actions."
1) Meanings result from an attribution of assimilation schemes to objects, the properties of which are not "pure" observables but always involve an *interpretation* of the "data". The meaning of an object is "what can be done" with the object, and this definition applies not only to the sensorimotor level but to the pre-operatory level starting with the semiotic function. However, meanings are also what can be said of objects, i.e., descriptions, as well as what can be thought of them, when classifying or relating them and so on. As for actions themselves, their meaning is "what they lead to" according to the transformations they produce in the objects or situations on which they bear.
2) Elementary actions as well as higher-order actions could not exist nor function without links relating theme. 
3) The most characteristic feature of the logical links elaborated by the children already at the level of actions, but later on among statements, is that these elaborations take place *on the basis of meaning implications*.
4) Another way of describing the proactive-retroactive-justifying division is: amplification which bears on consequences, conditioning which bears on preliminary conditions, and deepening which brings out the reasons.

"If we relate to the main claim of this book, according to which the psychogenetic roots of logic are found in meanings and in implications between them, an important consequence arises: as an object of knowledge, an object is nothing but a set of conjoined predicates, and its meaning amounts to 'what can be done with it,' i.e. to the assimilation to an action scheme (whether the action is a material one or a mental one)."

"a) The main purpose of this book was to show how the construction of a logic of actions is prepared in childhood as a necessary substratum for operatory logic. In order to do that it was necessary to make a close analysis of meaning implications, especially those which consist of implications among actions or among operations. The concept of an action implication is the most original notion introduced in the book. To further analyze this form of implication one must go back as far as possible in psychogenetic evolution at the level of actions and the most elementary inferences.
b) The second objective of the research has been clearly attained. The aim was to show that at a very early stage, at the level of actions, one observes the early formation of operations each of which, when considered separately and *in its context of meanings*, is isomorphic with respect to one of the 16 binary operations of propositional logic.
c) The third objective was not only to show that logical connectives start long before the 'operatory' stages, but rather than logical relations are constructed by fragments that gradually merge into logical structures."

"As a final remark, let us recall, once more, the central thesis of genetic epistemology that forms the basis of the research reported in this book. The knowing subjects, including the norms they themselves are always elaborating (without needing philosophers or psychologists to prescribe them), cannot be objectively understood at the beginning , at the end, nor at any stage in their history or formation because they are never completed systems. The subject's true nature lies in being a self-organizing process. This process is a continuous one and its general vection( s) alone has (have) an epistemological significance. The major problem is to reconstitute such vections, although they are never completed and can be grasped through reconstitution only, and never through a priori deduction. No amount of philosophical speculation, nor of rigorous logical analyses, may substitute for it."
},
	Author = {Piaget, Jean and Garcia, Rolando and Davidson, Philip},
	Date-Added = {2014-02-24 12:46:47 -0500},
	Date-Modified = {2014-02-26 10:56:13 -0500},
	Editor = {Davidson, Philip M. and Easley, Jack},
	Publisher = {Lawrence Elrbaum Associates, Inc.},
	Title = {Toward a Logic of Meanings},
	Year = {1991}}

@inproceedings{Ovchinnikova2013,
	Address = {Trento, Italy},
	Annote = {discusses work on determing what the probability of an abducted hypothesis is.

They represent knowledge with a formalization that allows for all possible hypotheses to be drawn as AODAGs (And/Or directed acyclic graphs). The calculation of the "likelihood of abductive hypotheses relevant for discourse interpretation" is based on what information is contained in this graph.

"However, the problem remains how to set prior values for costs and weights before starting the learning. Furthermore, it is impossible to interpret learned values, which results in the choice of the best hypothesis being unpredictable."

This framework is not yet implemented (as of this paper's publication).},
	Author = {Ovchinnikova, Ekaterina and Gordon, Andrew S. and Hobbs, Jerry},
	Booktitle = {Proceedings of the Joint Symposium on Semantic Processing (JSSP2013)},
	Date-Added = {2014-02-21 19:31:51 +0000},
	Date-Modified = {2014-02-21 19:57:46 +0000},
	Title = {Abduction for Discourse Interpretation: A Probabilistic Framework},
	Year = {2013}}

@inproceedings{Roemmele2014,
	Annote = {This paper focuses on their game Triangle charades - Players create motion trajectories for actions by animating a triangle to depict those actions. Other players guess the action depicted, choosing from 6 options.

Their goal is to automatically establish social information (actions) from motion. No mention in this paper on whether they will make the data available anytime soon.

},
	Author = {Roemmele, Melissa and Archer-McClellan, Haley and Gordon, Andrew S.},
	Booktitle = {IUI '14: Proceedings of the 19th International Conference on Intelligent User Interfaces},
	Date-Added = {2014-02-21 19:08:45 +0000},
	Date-Modified = {2014-02-21 19:11:12 +0000},
	Pages = {209-214},
	Title = {Triangle Charades: A Data-collection Game for Recognizing Actions in Motion Trajectories},
	Year = {2014}}

@article{Weinland2011,
	Annote = {Action label - "a name, such that an average human agent can understand and perform the named action."
Feature extraction
Action learning and classification
Action segmentation - necessary to cut streams of motions into single action instances that are consistent to the set of initial training sequences used to learn the models.

They use a classification of techniques based on how they represent the spatial and temporal structure of actions.

SPATIAL ACTION REPRESENTATIONS
	Body models - They represent the spatial structure of actions with reference to the human body.
		Recognition by reconstruction - two separate stages: motion capture of 3d models, and action recognition
		Direct recognition - 2d representations used
	"finding body parts and estimating parametric body models from images remains an unsolved problem, independent of the model used (2D or 3D)."
	Image models - aka holistic representations, which use global, image-based representations of actions. Regions of interest (ROIs) are identified. There are many classes of such models, which use:
		Silhouettes and contours of an agent performing an action
		Dense optical flow extracted from consecutive images - focus on motion blobs
		Gradient fields in XYT directions, each frame represented through histograms over those gradients
		HMAX - neuroscientifically inspired, 
	Spatial statistics - decompose images/video into smaller regions, recognizing actions based on statistics of local features from all regions rather than body parts or image coordinates.
		Space-time interest points
		Bag-of-features (BOF)
		Spatial BOF

TEMPORAL ACTION REPRESENTATIONS
	Action Grammars - represent actions as a sequence of moments, each with their own appearance and dynamics
		HMM - the most prominent of the versatile probabilistic grammars used
		Dynamic Bayesian networks (DBN)
		Conditional Random Fields (CRF) - discriminative markov models which can use non-independent features and observations over time
		Other dynamic models:
			Auto regressive models
			Time-delayed neural networks
			Context-free grammars
			Feature-structure grammars
	Action Templates - instead of representing features/dynamics explicitly and separately, these learn temporal blocks of features (templates). Typically computed over long sequences of frames. Templates are usually fixed-size vector representations.
	Temporal statistics - try not to build a model of action dynamics, rather build statistical models of the appearance of actions.
		Keyframe method - learns appearance models from single-characteristic keyframes
		Temporal bag of features
		

ACTION SEGMENTATION - how do we split up actions in the first place?
	Boundary detection - looks for pauses, local minimas, etc.
	Sliding windows - performs classification on all the overlapping segments and keeps the ones with the best scores
	Grammar concatenation - concatenates grammars to model the transitions BETWEEN actions as well

VIEW-INDEPENDENT ACTION RECOGNITION - work on how to normalize views

DATASETS
	KTH - contains 2391 sequences of 6 actions done by 25 subjects in 4 scenarios. Has most samples per class. Best recognition rates are around 90-94%.
	Weizmann - Background-subtracted silhouette appraoches already reach 100% accuracy.
	INRIA XMAS (IXMAS) - Best recognition rates 98.78%. Approaches using only a single camera at 82%.
	Other less-used datasets: CMU MoBo, HUMAN-EVA, HOHA},
	Author = {Weinland, Daniel and Ronfard, Remi and Boyer, Edmond},
	Date-Added = {2014-02-18 04:27:24 +0000},
	Date-Modified = {2014-02-21 18:12:45 +0000},
	Journal = {Computer Vision and Image Understanding},
	Pages = {224-241},
	Title = {A Survey of Vision-Based Methods for Action Representation, Segmentation and Recognition},
	Volume = {115},
	Year = {2011}}

@article{Marshall2006,
	Annote = {Main citation for Metacat.

It extends Copycat by adding mechanisms to make sure it doesn't make the same mistakes twice.},
	Author = {Marshall, James B.},
	Date-Added = {2014-02-15 21:16:54 +0000},
	Date-Modified = {2014-02-15 21:17:47 +0000},
	Journal = {Journal of Experimental and Theoretical Artificial Intelligence},
	Number = {3},
	Pages = {267-307},
	Title = {A Self-Watching Model of Analogy-Making and Perception},
	Volume = {18},
	Year = {2006}}

@article{Doumas2013,
	Annote = {tests some of DORA's predictions that comparison triggers the processes that discover new relations.

"In both experiments, participants who successfully mapped exemplars from the same category onto one another learned a novel, category-defining higher-order relation between their elements and no participant who failed to map correctly succeeded in learning the relation. Indeed, categorization performance of the latter group never got above chance."},
	Author = {Doumas, Leonidas A. and Hummel, John E.},
	Date-Added = {2014-02-15 21:11:23 +0000},
	Date-Modified = {2014-02-15 21:14:44 +0000},
	Journal = {{PLoS ONE}},
	Number = {6},
	Title = {Comparison and Mapping Facilitate Relation Discovery and Predication},
	Volume = {8},
	Year = {2013}}

@article{Morrison2010,
	Annote = {Shows that Hong Kong children can perform better on some analogical reasoning systems, the authors suspect this is because there are cultural differences that emphasize relations with HK children. "Specifically, we demonstrated that a knowledge representation change from two, 2-place predicates into one, 3-place predicate reduces the demands of processing a '2-relation' scene analogy problem in LISA." I need to cite this for the cogsci 2014 paper!

They also present "simulations in LISA that support the hypothesis that maturation of inhibitory control in working memory is critical for the development of adult-like analogical reasoning."},
	Author = {Morrison, Robert G. and Doumas, Leonidas A. and Richland, Lindsey E.},
	Date-Added = {2014-02-15 21:04:36 +0000},
	Date-Modified = {2014-02-15 21:06:31 +0000},
	Journal = {Developmental Science},
	Pages = {1-14},
	Title = {A Computational Account of Children's Analogical Reasoning: Balancing Inhibitory Control in Working Memory and Relational Representation},
	Year = {2010}}

@inproceedings{Klein2003,
	Annote = {Seems to be the primary, oldest citation for the stanford parser.

http://www.cs.berkeley.edu/~klein/papers/unlexicalized-parsing.pdf

"In this paper, we show that the parsing performance that can be achieved by an unlexicalized PCFG [probabilistic context-free grammar] is far higher than has previously been demonstrated".},
	Author = {Klein, Dan and Manning, Christopher D.},
	Booktitle = {Proceedings of the 41st meeting of the association for computational linguistics},
	Date-Added = {2014-02-12 15:48:39 -0500},
	Date-Modified = {2014-02-12 15:49:39 -0500},
	Title = {{Accurate Unlexicalized Parsing}},
	Year = {2003}}

@inproceedings{Socher2013,
	Annote = {Citation for the "new compositional grammar" stanford parser.
We can cite this as an example of NLP guys finally realizing the benefit of dual representation (localist and distributed simultaneously) models, e.g. on p.5 he describes his representation as both discrete and continuous.

http://nlp.stanford.edu/pubs/SocherBauerManningNg_ACL2013.pdf

They use a representation that keeps both parse structure (with nodes as discrete categories) and vector representation.

"Similar to [Collins 2003], we use the idea of letting discrete categories reduce the search space during inference."
They also use untying, which "has also been successfully used in deep learning applied to vision [Le et al., 2010]". In a tied network, the same weight matrix is used to compute all non-leaf node representation vectors, given the vectors of its children as parameters. In a syntactically untied RNN, the function to compute a parent vector depends on the syntactic categories of its children. (see figures 2 and 3).

The third major idea here is the combination with a PCFG.


Starts by creating a vector for every word in the sentence. The starting representation is an ordered list of (word,vector) pairs.},
	Author = {Socher, Richard and Bauer, John and Manning, Christopher D. and Ng, Andrew Y.},
	Booktitle = {Proceedings of ACL 2013},
	Date-Added = {2014-02-12 14:32:52 -0500},
	Date-Modified = {2014-02-12 16:51:07 -0500},
	Title = {{Parsing With Compositional Vector Grammars}},
	Year = {2013}}

@inproceedings{Marneffe2006,
	Annote = {http://t3-1.yum2.net/index/nlp.stanford.edu/manning/papers/LREC_2.pdf

Stanford Parser publication. (also see Socher2013 for more updated citation, Klein and Manning, 2003 for the older citation)

phrase structure parse - represents nesting of multi-word constituents
dependency parse - represents dependencies between individual words. A TYPED dependency parse labels dependencies with grammatical relations, such as *subject* or *indirect object*.

"Our technique for producing typed dependencies is essentially based on rules --- or patterns --- applied on phrase structure trees."
Two phases:
Phase 1: Dependency Extraction
	- sentence is parsed with a phrase structure grammar parser
	- identifies the head of each portion of the sentence, "using rules akin to the Collins head rules, but modified to retrieve the semantic head of the constituent rather than the syntactic head."

Phase 2: Dependency Typing
	- label each of the extracted dependencies with a grammatical relation that is as specific as possible:
		- for each grammatical relation, the tree-expression syntax provided by tregex is used to define one or more patterns over the phrase structure parse tree
		- each pattern is matched against every tree node, the matching pattern with the most specific grammatical relation is chosen for that dependency
	- then some extra processing is done for special cases},
	Author = {de Marneffe, Marie-Catherine and McCartney, Bill and Manning, Christopher D.},
	Booktitle = {Proceedings of the IEEE / ACL 2006 Workshop on Spoken Language Technology},
	Date-Added = {2014-02-12 14:29:04 -0500},
	Date-Modified = {2014-02-12 15:29:24 -0500},
	Title = {{Generating Typed Dependency Parses from Phrase Structure Parses}},
	Year = {2006}}

@article{Shultz2012,
	Annote = {Good explanation of how cascade-correlation works, and how the qualitative change model compares to static models of neural networks. Goes through a few piagetian tasks that have been modeled by CC.},
	Author = {Shultz, Thomas R.},
	Date-Added = {2014-02-02 23:47:41 +0000},
	Date-Modified = {2014-02-02 23:49:24 +0000},
	Journal = {Cognitive Development},
	Pages = {383-400},
	Title = {{A Constructive Neural-Network Approach to Modeling Psychological Development}},
	Volume = {27},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QSC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEtczIuMC1TMDg4NTIwMTQxMjAwMDQ3MC1tYWluLnBkZtIXCxgZV05TLmRhdGFPEQH+AAAAAAH+AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfMS1zMi4wLVMwODg1MjAxNDEyMDAjMzAxQkU0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAb5M8UOAgAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM8UflgAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMS1zMi4wLVMwODg1MjAxNDEyMDAjMzAxQkU0LnBkZgAOAEQAIQAxAC0AcwAyAC4AMAAtAFMAMAA4ADgANQAyADAAMQA0ADEAMgAwADAAMAA0ADcAMAAtAG0AYQBpAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAE1Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEtczIuMC1TMDg4NTIwMTQxMjAwMDQ3MC1tYWluLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDZAN4A5gLoAuoC7wL6AwMDEQMVAxwDJQMqAzcDOgNMA08DVAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANW}}

@article{Frye1995,
	Annote = {several experiments with 3-4 year olds showing cognitive development testing rule following and physical causation understanding.},
	Author = {Frye, Douglas and Zelazo, Phillip David and Palfai, Tibor},
	Date-Added = {2014-01-29 00:17:02 +0000},
	Date-Modified = {2014-01-29 00:17:55 +0000},
	Journal = {Cognitive Development},
	Pages = {483-527},
	Title = {{Theory of Mind and Rule-Based Reasoning}},
	Volume = {10},
	Year = {1995}}

@article{DasGupta1989,
	Annote = {Cited by Goswami and Brown as saying that the ability for children to reason about the physical causes used in their analogy problems develops dramatically between ages 3 and 4. },
	Author = {Das Gupta, P. and Bryant, P.E.},
	Date-Added = {2014-01-26 17:17:04 -0500},
	Date-Modified = {2014-01-26 17:19:12 -0500},
	Journal = {Child Development},
	Month = {October},
	Number = {5},
	Pages = {1138-1146},
	Title = {{Young Children's Causal Inferences}},
	Volume = {60},
	Year = {1989}}

@book{Beth1966,
	Annote = {Contains writings from Piaget on Reflective Abstraction. Might be the original source of the term 'reflective abstraction'. Piaget's part of this book is "a major source for the foundation of APOS Theory" according to Arnon et al.

- "reflective abstraction is not a discovery, because the structure or the "reflected" entity are not the same as those from which they are derived." (206)
- "when the child discovers by experience the result of an action, for example, that the result of an addition is independent of the order followed {\ldots}, reflective abstraction consists of translating a succession of material actions into a system of interiorised operations, the laws of which are simultaneously implied in an act." (206)

- "If is then necessary to suppose that abstraction starting from actions and operations -- which we shall call "reflective abstraction" -- differs from abstraction from perceived objects -- which we shall call "empirical abstraction" (assuming the hypothesis that non-perceptible objects are the product of operations) -- in the sense that reflective abstraction is necessarily constructive. In fact, as opposed to empirical abstraction, which consists merely of deriving the common characteristics from a class of objects (by a combination of abstraction and simple generalisation), reflective abstraction consists in deriving from a system of actions or operations at a lower level, certain charactersitics whose reflection (in the quasi-physical sense of the term) upon actions or operations of a higher level it guarantees; for it is only possible to be conscious of the processes of an earlier construction through a reconstruction on a new plane. {\ldots} In short, reflective abstraction proceeds by reconstructions which transcend, whilst integrating, previous constructions." (188-189)
- "[T]he "reflective abstractions" by means of which the elements of a higher structure are derived from a lower structure, do not involve an absolute starting point; and that the sensory-motor structures {\ldots} are themselves derived from more elementary structures by a process analogous to reflective abstraction." (204)


From dubinsky:
- Piaget observed that reflective abstraction has no absolute beginning but is present at the very earliest ages in the coordination of sensorimotor structure (Beth & Piaget pp. 203-208)
- Empirical abstraction derives knowledge from the properties of objects (pp. 188-189)
- New mathematical constructions proceed by reflective abstraction (p.205)
- Godel's incompleteness theorem is an example (p. 275)


206},
	Author = {Beth, Evert W. and Piaget, Jean},
	Date-Added = {2014-01-26 18:09:23 +0000},
	Date-Modified = {2014-04-02 01:45:05 +0000},
	Editor = {Davidson, Donald and Hintikka, Jaakko and Nuchelmans, Gabri\"{e}l and Salmon, Wesley C.},
	Publisher = {D. Reidel Publishing Company / Gordon and Breach Science Publishers, Inc.},
	Title = {Mathematical Epistemology and Psychology},
	Year = {1966}}

@incollection{Dubinsky1991,
	Annote = {Tries to show that the late Piagetian concept of reflective abstraction can be "a powerful tool in the study of advanced mathematical thinking". 

Has a good discussion on what reflective, pseudo-empirical, and empirical abstraction are.

- "Reflective abstraction is a concept introduced by Piaget to describe the construction of logico-mathematical structures by an individual during the course of cognitive development." (95)
- "We interpret [Empirical abstraction] to mean that it has to do with experiences that appear to the subject to be external. The knowledge of these properties is, however, internal and is the result of constructions made internally by the subject." (97)
- Pseudo-empirical abstraction is intermediate and teases out properties that the actions of th esubject have introduced into objects. E.g. the observation of a 1-1 correspondence between two sets of objects which the subject has placed in alignment. Understanding that there is a 1-1 relation between the sets is the result of internal constructions made by the subject.
- Reflective abstraction has the subject as its source and it is completely internal. 
- "The actions that lead to pseudo-empirical and reflective abstraction are performed on objects whose properties the subject only comes to know through empirical abstraction. On the other hand, empirical abstraction is only made possible through assimilation schemas which were constructed by reflective abstraction (Piaget, 1985, pp. 18-19). Consider, for example a physics experiment which may hve the purpose of making an empirical abstraction to obtain factual data about a certain object. The experiment presupposes, however, an enormous range of logico-mathematical preliminaries -- in deciding how to pose the question, in the construction of apparatus for "indirect observations" (e.g., triangulation to obtain distances between stars), in the use of particular forms of measurement, and finally, in setting out the results in logico-mathematical language. All of these are concepts that must have been constructed using reflective abstraction. (Piaget, 1980, p. 91)" (98)
- Empirical and pseudo-empirical abstraction draws knowledge from objects by performing (or imagining) actions on them. Reflective abstraction interiorizes and coordinates these actions to form new actions and, ultimately new objects (which may no longer be physical but rather mathematical such as a function or a group). Empirical abstraction then extracts data from these new objects through mental actions on them, and so on." (98)
- "The point, rather, is that when properly understood, reflective abstraction appears as a description of the mechanism of the development of intellectual thought. It is important for Piaget's theory that this same process that describes advanced mathematical thinking appears in cognitive development throughout life from the child's very first coordinations that lead to concepts such as number, measurement, multiplication, and proportion (Piaget, 1972, pp. 70-71) An important ingredient of Piaget's general theory ... is the idea that reflective abstraction is one isolated case of certain very general processes that are found throughout living creation (Piaget, 1971, p. 331)." (99)},
	Author = {Dubinsky, Ed},
	Booktitle = {Advanced Mathematical Thinking},
	Chapter = {7},
	Date-Added = {2014-01-26 18:04:22 +0000},
	Date-Modified = {2014-01-26 18:07:07 +0000},
	Editor = {Tall, David},
	Publisher = {Kluwer Academic Publishers},
	Title = {{Reflective Abstraction in Advanced Mathematical Thinking}},
	Year = {1991}}

@inproceedings{Licato2014a,
	Author = {Licato, John and Sun, Ron and Bringsjord, Selmer},
	Booktitle = {Proceedings of the 2014 International Joint Conference on Neural Networks (IJCNN)},
	Date-Added = {2014-01-26 04:15:38 +0000},
	Date-Modified = {2014-04-03 23:23:45 +0000},
	Title = {{Structural Representation and Reasoning in a Hybrid Cognitive Architecture}},
	Year = {2014}}

@article{Goldman1982,
	Annote = {Cited by Goswami and Brown (1990) as providing further evidence to the claim that children could only reason through association, not analogy. Supports hypothesis in Sternberg and Nigro (1980).},
	Author = {Goldman, S.R. and Pellegrino, J.W. and Parseghian, P.E. and Sallis, R.},
	Date-Added = {2014-01-24 21:37:05 +0000},
	Date-Modified = {2014-01-24 21:38:58 +0000},
	Journal = {Child Development},
	Pages = {550-559},
	Title = {{Developmental and Individual Differences in Verbal Analogical Reasoning}},
	Volume = {53},
	Year = {1982}}

@article{Sternberg1980,
	Annote = {Cited by Goswami and Brown 1990 as the claim and evidence for children being unable to reason through analogy except through association.},
	Author = {Sternberg, Robert J. and Nigro, Georgia},
	Date-Added = {2014-01-24 21:33:27 +0000},
	Date-Modified = {2014-01-24 21:39:11 +0000},
	Journal = {Child Development},
	Number = {1},
	Title = {{Developmental Patterns in the Solution of Verbal Analogies}},
	Volume = {51},
	Year = {1980}}

@techreport{Shastri1990,
	Author = {Shastri, Lokendra and Ajjanagadde, Venkat},
	Date-Added = {2014-01-20 21:44:12 +0000},
	Date-Modified = {2014-01-20 21:45:28 +0000},
	Institution = {University of Pennsylvania},
	Title = {{From Simple Associations to Systemic Reasoning: A Connectionist Representation of Rules, Variables and Dynamic Bindings}},
	Year = {1990}}

@article{Garcez2006,
	Author = {Garcez, Artur S. d'Avila and Lamb, L.C.},
	Date-Added = {2014-01-20 21:40:36 +0000},
	Date-Modified = {2014-01-20 21:41:58 +0000},
	Journal = {Neural Computation},
	Number = {7},
	Pages = {1711-1738},
	Title = {{A Connectionist Model for Epistemic and Temporal Reasoning}},
	Volume = {18},
	Year = {2006}}

@book{Stanovich1999,
	Address = {Mahwah, NJ},
	Annote = {Cited as the source of the "system 1" vs "system 2" distinction.},
	Author = {Stanovich, Keith E.},
	Date-Added = {2014-01-17 16:26:36 +0000},
	Date-Modified = {2014-01-17 16:27:51 +0000},
	Publisher = {Lawrence Elrbaum Associates.},
	Title = {Who is Rational? Studies of Individual Differences in Reasoning},
	Year = {1999}}

@article{Tversky1977,
	Annote = {cited by Sun2004a as the source of the measure of similarity used in the NACS.

A. Tversky, (1977). Features of similarity. Psychological Review, 84(4), 327-352.},
	Author = {Tversky, A.},
	Date-Added = {2014-01-10 18:08:51 +0000},
	Date-Modified = {2014-01-17 17:27:25 +0000},
	Journal = {Psychological Review},
	Number = {4},
	Pages = {327-352},
	Title = {{Features of Similarity}},
	Volume = {84},
	Year = {1977}}

@article{Shelley2002b,
	Annote = {Argues that dissimilarity is different from disanalogy.

"In the logic literature, analogies are equated with similarities and, consequently, disanalogies are equated with dissimilarities."

His problems with this:
- Analogies are based on shared relational structures rather than shared attributes.
- Disanalogies are viewed not as inferences but as factors that subtract from the likelihood of preexisting, analogical inferences. So I think he equates "analogy" with "analogical inference" and thus "disanalogy" is a counter to an existing analogical inference, whereas "dissimilarity" is a lack of aligning attributes.
- "The leading role played by causally relevant relations in [some disanalogies] suggests that the usual analogical mechanisms are at work here, rather than any mechanism tied especially to dissimilarities."
- "[D]issimilarities do not necessarily ential disanalogies." (p.3)

Spends the rest of the paper discussing examples from classical debates on God as a designer, rebuttals by Hume, etc.},
	Author = {Shelley, Cameron},
	Date-Added = {2013-12-13 01:27:06 +0000},
	Date-Modified = {2013-12-13 19:25:37 +0000},
	Journal = {Metaphor and Symbol},
	Number = {2},
	Pages = {81-97},
	Title = {The Analogy Theory of Disanalogy: When Conclusions Collide},
	Volume = {17},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzY1OTAzNzgucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rws2NTkwMzc4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjyZzs/MhgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAztAS1gAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgA2NTkwMzc4LnBkZgAOABgACwA2ADUAOQAwADMANwA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy82NTkwMzc4LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@article{Shelley2002,
	Annote = {Distinguishes between four types of counterarguments to analogies, and argues that they "*do* address the acceptability of analogical hypotheses, indicating that analogies can confer acceptability, confirmation notwithstanding", which challenges the logical empiricst view that analogy does not confer acceptability.

Four types of counterargument to analogy. Two dimensions: orientation (whether it accepts that the analogy produces the proposed conclusion) and effect (whether it offers a better, alternative conclusion or is simply destructive).
Disanalogies - Initially accepts the model conclusion, but shows that the same or similar analogies lead to irreconcilable conclusions.
Misanalogies - Tries to correct some mistake lurking in the analogical model. Rejects the model conclusion because of the mistake, but offers a new model.
Counteranalogies - Alternative hypothesis that happens to be analogical. An analogical explanation that shares the explanandum of its model but employs a different source analog. Accepts that the analogy given leads to the conclusion, but says that a better analogy exists that leads to a different conclusion.
False Analogies - Claiming no analogy exists at all. Both rejects the original conclusion and doesn't offer an alternative.

Thagard's "Analogical Abduction" (1988, p. 60-3) is a novel explanation construted by borrowing the structure of an already-accepted explanation.

Ultimately, this paper argues that if analogy had no ability to lend support to conclusions, then what are all the anti-analogy arguments attacking? "So, we should conclude that there is a logic of analogical inference after all and that analogy counterarguments depend upo it and elucidate it."},
	Author = {Shelley, Cameron},
	Date-Added = {2013-12-10 21:05:07 +0000},
	Date-Modified = {2013-12-11 04:01:03 +0000},
	Journal = {British Journal for the Philosophy of Science},
	Pages = {477-496},
	Title = {Analogy Counterarguments and the Acceptability of Analogical Hypotheses},
	Volume = {53},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1NoZWxsZXkyLnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMU2hlbGxleTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SUc7M7WIAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM7NM7IAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAU2hlbGxleTIucGRmAAAOABoADABTAGgAZQBsAGwAZQB5ADIALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1NoZWxsZXkyLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=}}

@inproceedings{Forbus2007,
	Annote = {http://www.qrg.northwestern.edu/papers/Files/QRG_Dist_Files/QRG_2007/AAAI11ForbusK_footer.pdf

Describes architecture of their "Learning Reader" system, which:
- starts with knowledge extracted from ResearchCyc
- primary goal is to "identify quickly and accurately what pre-existing knowledge an input text is referring to, creating new knowledge only when none can be found."
- uses Martin and Risebeck (1986)'s DMAP model of natural language parsing (Direct Memory Access Parsing) which, "unlike traditional syntactic parsers, [is] tightly integrated with the knowledge base. Every component of DMAP interacts with the KB." Even syntactic patterns, or "phrasal patterns", are presumably stored in the DB. DMAP treats NLP as a stream of references, so as far as I can tell it takes access to memory as the primarily important process rather than syntactic processing.
- Uses their FIRE reasoning engine, which solves scalability by restricting the set of axioms used (and other strategies).
- "Our goal is that trainers should never know the underlying representations that Learning Reader is creating."
- "We know of no other system that integrates analogical processing into the understanding process."},
	Author = {Forbus, Kenneth D. and Riesbeck, Christopher K. and Birnbaum, Lawrence and Livingston, Kevin and Sharma, Abhishek and Ureel, Leo},
	Booktitle = {Proceedings of AAAI-07: Twenty-Second Conference on Artificial Intelligence},
	Date-Added = {2013-11-03 01:17:37 -0400},
	Date-Modified = {2013-11-03 01:19:21 -0400},
	Title = {Integrating Natural Language, Knowledge Representation and Reasoning, and Analogical Processing to Learn by Reading},
	Year = {2007}}

@article{Gentner1997b,
	Annote = {http://www.qrg.northwestern.edu/papers/files/Gentner_Markman_AmPsy_Jan97.pdf

"[T]he authors suggest that both similarity and analogy involve a process of structural alignment and mapping, that is, that similarity is like analogy." (abstract)
"Th[e] contrast between analogy and literal similarity is in fact a continuum, not a dichotomy." (48)

"There is, in general, an indefinite number of possible relations that an analogy could pick out (Goodman, 1972), and most of these are ignored." (46) 

"we must have a representational system that is:"
- "sufficiently explicit about relational structure to express the causal dependencies that match across the domains."
- "a representational scheme capable of expressing not only objects but the relationships and bindings that hold between them, including higher order relations such as causal relations."

"To discuss alignment processes, we need to take representation seriously, but this should not be taken to imply a commitment to any particular representation as the best or only possible representation of a situation." (47)

Three psychological constraints on analogy (which is alignment):
1) Structurally consistent: observes parallel connectivity (argument alignment) and one-to-one correspondence
2) Relational focus: "analogies must involve common relations but need not involve common object descriptions"
3) Systematicity: "Analogies tend to match connected systems of relations"

},
	Author = {Gentner, Dedre and Markman, Arthur B.},
	Date-Added = {2013-11-03 00:53:12 -0400},
	Date-Modified = {2013-11-03 01:02:33 -0400},
	Journal = {American Psychologist},
	Number = {1},
	Pages = {45-56},
	Title = {Structure Mapping in Analogy and Similarity},
	Volume = {52},
	Year = {1997}}

@article{Macagno2009,
	Annote = {http://www.dougwalton.ca/papers%20in%20pdf/09Analogy.pdf

Gives a review of current literature out there that attempts to formalize argument by analogy.

- "Whately, Perelman and Olbrechts-Tyteca, Copi and Jackson, and Weitzenfeld take into consideration the relation between the terms in analogy. In particular, Copi and Jackson focus on the causal relation between the terms, whereas Weitzenfeld shows how the terms must be isomorphic, that is, share some nonaccidental features, in order for the relation of analogy to hold. On the other hand, the theories developed by Govier, Waller, and Guarini take into consideration the logical form of analogy. This approach reflects the crucial theme developed in law and inquires into this topic from a logical perspective. Trudy Govier refuses to reduce analogy to a deductive inference."

"Even though the analogy in the *a priori* scheme is grounded upon an implied universal principle, it does not proceed from this principle. The implicit claim is not often known and hard to formulate {\ldots}; it can be retrieved only after reflection and is not immediately available to the interlocutor." (170)

Waller distinguishes between two main patterns:
Deductive (Govier's a priori) Analogy: Essentially tries to form a general principle from the source case, and argues that it applies to the target case.
Inductive Analogy: The argument of shared characteristics, a transferred characteristic from src to tgt, and some notion of relevance.
Waller seems to think that the second pattern implicitly also relies on a general principle (if I understand correctly), and Guarini criticizes this. Guarini says that we don't always know the general principle right away; there is something else going on!

"Contrasting argument from example against argument by analogy clarifies the distinction between the two through classification under a genus and semantic categories."
- In argument from example:
	- "The conclusion is drawn by reasoning from a case characterized by certain factors to another case involving the same factors."
	- Argument based on genus; i.e. 'the target case and the source case are of the same genetic type'
- In argument from analogy:
	- "in an analogy the general rule is not presupposed, known, nor recalled by means of an example"
	- e.g., "as a place without a harbour cannot be safe for ships, so a mind without integrity cannot be trustworthy for a man's friends."
	- "the second predicate is attributed to the second subject according to the same relation of the first predication. Here no general rule is either drawn or presupposed. Instead, the two relations are compared."},
	Author = {Macagno, Fabrizio and Walton, Douglas},
	Date-Added = {2013-10-16 13:40:03 -0400},
	Date-Modified = {2013-10-16 14:27:13 -0400},
	Journal = {Philosophy and Rhetoric},
	Number = {2},
	Title = {Argument from Analow in Law, the Classical Tradition, and Recent Theories},
	Volume = {42},
	Year = {2009}}

@article{Governati2008,
	Annote = {"We argue, in particular, that the introduction of obligations can provide a new reading of the concepts of intention and intentionality. {\ldots} We show that the notion of social agent [whose obligations prevail over intentions] either requires more complex computations or has some philosophical drawbacks."

BDI architecture - belief-desire-intention are taken as mental attitude primitives.

DL - Defeasible logic; a simple, efficient but flexible non-monotonic formalism able to deal with many different intuitions of non-monotonic reasoning and recently applied in many fields.

The aim of the article is to address these tow issues:

1) To devise an extension of DL able to cover a number of different agent types, but which, despite its expressiveness, is computationally feasible. They prove it is possible to complete the complete set of consequences of a given theory in linear time (!).
- Knowledge is represented in two ways: facts and rules
- Rules come in three types: strict (->), defeasible (=>), and defeaters (~>). These are rules that are interpreted as: always implies, can imply, and should never be followed by, respectively.

2) On the other hand, they argue the notion of agent type can be problematic. They discuss the notion of a "social agent" (norm-complying).},
	Author = {Governati, Guido and Rotolo, Antonino},
	Date-Added = {2013-10-04 07:38:16 -0400},
	Date-Modified = {2013-10-04 10:32:34 -0400},
	Journal = {Autonomous Agents and Multi-Agent Systems},
	Number = {1},
	Pages = {36-69},
	Title = {BIO Logical Agents: Norms, Beliefs, Intentions in Defeasible Logic},
	Volume = {17},
	Year = {2008}}

@article{Dietrich2010,
	Annote = {http://philpapers.org/rec/DIEAIT

Presents two kinds of analogical representational change, both of which occur early in the analogy-making process. Three key claims:
1) A certain type of rapid representational abstraction is crucial to making the relevant analogies
2) Rapid abstractions are induced by retrieval across large psychological distances
3) Both categorizations and analogies supply understandings of perceptual input via *construing*, which is a proposed type of categorization

"one main these of this paper [is] that analogy and categorization are deeply similar. A proposed approach to unifying the two will be presented here."

"{\ldots}the kind of representational changes proposed here are not incremental and do not involve building representations up over time. This is not to deny that incremental, representation construction occurs in analogical reasoning, the evidence for such construction is strong {\ldots} rather, to suggest that (at least) two other kinds of change are also present; indeed, required. These changes occur not in the reasoning phase, but right at the time the analogy is made." These are:
1) A quite rapid species of abstraction (called "rapid abstraction")
	- This "could be modeled within some well-known analogical retrieval engines such as MAC/FAC by adding the relevant representational change algorithms."
	- Happens BEFORE the analogy is made, not as a result of an analogy
	- STRANG: computer model that implements this sort of representational change. It "builds structured representations by parsing input strings according to the fixed grammar". Appears to use a copycat-like domain of strings.
	- They cite work by Liberman and Trope which says that "the further away something is from the self's here and now, the more abstractly it is represented".
2) A much milder sort of change forming the basis of unifying analogy and categorization, called "construing"
	- This is supposed to be the main contribution of this paper, advocating construing as part of the analogy-making process.
	- "The goal of *construing theory* is to explain how cognitive agents construct meaningful *understandings* of objects in their environments even though they begin with meaningless, semantic-free perceptual representations of those objects (i.e., perceptual input)."
	- Construal-based categorization consists of these steps:
		1) Create a non-semantic, initial stimulus representation through low-level processing
		2) Generate a summary description based on a non-semantic process of high-level visual object recognition.
		3) Retrieve the category designated by the summary description.
		4) Integrate, via mapping, the initial visual stimulus description and the generic category knowledge to produce a construal.

He's not so much interested in representational change that happens after analogies are already found in order to make the mappings better, but rather representational changes that are "produced by forging the analogy in the first place." Also, SMT "as well as many other analogy theories are committed to the view that almost all of the structural representational changes occur *because* of the analogy. The Low Probability Argument suggests this is very unlikely: some representational changes are crucial to *making* the analogy."

Low Probability Argument - Dietrich's argument that the probability of finding relevant analogs is too low to explain the abundance of spontaneous analogical remindings humans find.

UNIFYING ANALOGY AND CATEGORIZATION VIA CONSTRUING
- Construal-based analogy
- He combines the construal-based categorization above with liberman-trope theory's concept of psychological distance
- "this type of analogy produces a *product*; it is not just a mapping between two mental representations in memory."
- Very much looks like the work I'm doing, except, "STRANG only models the rapid abstraction part."

READ: Gentner and Wolff 2000 : provides an extensive catalogue of representational changes that work within SMT.
},
	Author = {Dietrich, Eric},
	Date-Added = {2013-09-30 17:28:23 -0400},
	Date-Modified = {2013-10-01 00:33:33 -0400},
	Journal = {Cognitive Processing},
	Number = {4},
	Title = {Analogical Insight: Toward Unifying Categorization and Analogy},
	Volume = {11},
	Year = {2010}}

@incollection{Feteris2011,
	Annote = {http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2283092

Starts by examining the three "dominant traditions in legal argumentation-theory: the logical, the rhetorical and the dialogical approach."

THE LOGICAL APPROACH
- Evaluating arguments require that the premises are acceptable, and the argumentation is formally correct / logically valid.

THE RHETORICAL APPROACH
- emphasizes the content of arguments and the context-dependent aspects of acceptability, which are dependent on the effectiveness of the argumentation for the audience to which it is addressed
- Three main authors: Perelman (new rhetoric), Toulmin (argumentation model), and Viehweg (topical approach).
- "As a theory about *legal* argumentation, Perelman's work is the most sophisticated rhetorical approach."
- "According to Perelman, the justification of a decision in law is not formal proof." Rather, he must show his interpretation of a law as it applies to a particular case is correct by various means.

THE DIALOGICAL APPROACH
- can be seen as an extension of the logical approach, where "various authors extend logical systems to make them more suitable for legal argumentation."
- "In this approach, legal argumentation is considered from the perspective of a discussion procedure. The rationality of the argument depends on whether the procedure meets certain formal and material standards of acceptability."
- Three aspects of justification:
	Formal - This is an internal justification
	Material - An external justification: Can the facts and the legal rule or norm used be considered acceptable?
	Procedural - For a legal discussion to be acceptable, it is important that the participants observe certain rules (having to do with acceptable discourse)
- Discusses such rules that must be obeyed in the dialogical approach, e.g. doesn't contradict rules of law, it's supported by legal principles or by close analogy with established laws, and is supported by an argument about the consequences of the decision in relation to the relevant legal values.
- Robert Alexy's work: "a normative statement is true or acceptable if the judgement could be the result of procedures followed in the process of justification."

TWO OTHER RECENT DEVELOPMENTS
- AI and Law approach, which puts forth "proposals for the reconstruction of legal reasoning as a process of weighing reasons for and against a conclusion in the context of a dialogue."
- Pragma-dialectical approach, which sees legal argumentation "as part of a rational discussion in which a protagonist defends a standpoint against the anticipated or actual reactions of a critical antagonist."},
	Author = {Feteris, Eveline T. and Kloosterhuis, Harm},
	Booktitle = {Law and Method: Interdisciplinary Research into Law},
	Date-Added = {2013-09-30 02:58:55 -0400},
	Date-Modified = {2013-09-30 15:38:08 -0400},
	Editor = {van Klink, B. and Taekema, S.},
	Pages = {253-273},
	Publisher = {Mohr Siebeck},
	Title = {Law and Argumentation Theory: Theoretical Approaches to Legal Justification},
	Year = {2011}}

@article{Guarini2004,
	Annote = {http://scholar.uwindsor.ca/cgi/viewcontent.cgi?article=1014&context=philosophypub

Tries to show that a deductive schema of analogical arguments in law and other fields created by Bruce Waller doesn't capture some analogical arguments.

"[Waller] is surely correct that we need to distinguish between analogies that are used to argue for a claim and analogies that are used to illutrate or explain. Failure to make this distinction may lead interpreters to attribute wildly implausible arguments where arguments were not being offered to begin with."

- Waller seems to present an argument based on label transfer, where the deductive argument is essentially, if the transferred label implies X, then because the transferred label also applies to the target domain, then X is implied there as well.
- Marcello brings up an example where the label transfer occurs, but is overshadowed by a counterargument. In other words, the arguer admits that the label is transferred, but doesn't accept X is implied for other reasons.
- Another problem comes from (Crenshaw 1998). 
- Finally, the objection he thinks is the most serious. "Argument reconstructions are interpretations, and these interpretations are used to understand and evaluate arguments. If the reconstruction of an argument fails to capture a feature essential for evaluation, then that reconstruction fails. I will argue that analogical arguments come in various degrees of strength, and that the schema presented in [Waller] cannot capture the required degrees of strength."

He proposes an alternate form "as the core of the kinds of analogical arguments we have considered thus far.":
1) a has features f1, {\ldots}, fn
2) b has features f1, {\ldots}, fn
3) a and b should be treated or classified in the same way with respect to f_n+1

He notes that "the first two claims do not entail the third. Even if the premises are taken as initially establishing the conclusion, there is room to argue for one or more differences that may weaken or even defeat the conclusion." Also, he takes f1 - fn to be *relevant similarities*. Yet, even this "would not make the core of the reconstruction a deductive entailment (since there may be relevant dissimilarities that could defeat the conclusion.)"},
	Author = {Guarini, Marcello},
	Date-Added = {2013-09-30 01:52:32 -0400},
	Date-Modified = {2013-09-30 02:31:36 -0400},
	Journal = {Informal Logic},
	Number = {2},
	Pages = {153-168},
	Title = {A Defence of Non-Deductive Reconstructions of Analogical Arguments},
	Volume = {24},
	Year = {2004}}

@article{Franklin2012,
	Annote = {http://lpr.oxfordjournals.org/content/11/2-3/225.full.pdf+html

"This article surveys what has been learned about the obstacles to formalization [of reasoning] from five decades of experience. It will concentrate on representation more than on inference, since the main problems arise there. It will use mostly legal examples, though in general the difficult problems for legal reasoning have proved to be essentially the same as those of commonsense reasoning."

PROBLEMS FOR FORMALIZATION

1) The open-textured or fuzzy nature of language / legal concepts
- Example: X is quite tall. 
- In the rule "No vehicles allowed in the park", do roller skates apply? They are not normally vehicles, but they might be considered vehicles for purposes of this rule.

2) Degrees of similarity and analogy
- Popov v. Hayashi: Popov almost caught baseball, but it slid out of his mitt and was caught by Hayashi. "The question is, how is a formalization of legal reasoning to recognize and represent these cases concerning wildlife [he describes cases where a group hunts foxes, almost kills them, then they are killed by another group] as relevantly similar to the case involving a baseball?"
- He cites a form of analogy given by Guarini!
- Mentions the problem of 'relevant similarity'; which features determine membership in a category in such a way that they justify label transfer?

3) Representation of context
- 'context' - loosely defined, outside information that has to be imported to a text to help in interpreting it
- in a narrower sense we also speak of 'different contexts.'
- "The jury is still out on whether any AI system will be able to equal the performance of the reasonable man, whose role as a repository of commonsense facts is an essential resource of the law. If so, it will not be soon."

4) Symbol grounding problem
- In the case of words: "we cannot just define words by other words, for the same reason that we cannot learn the meaning of Chinese words using only a Chinese-Chinese dictionary. Somewhere, our use of the word 'cat' has to attach to, be learned from and be triggered by our experiences of cats (and only cats)."
- In legal language, the technical terms like 'possession' or 'probable cause' are difficult to understand without grounding.

5) Representation of causation, conditionals and counterfactuals
- cites a study by Knobe and Fraser (2009) where a professor takes one of a receptionist's pens, and later assistants take the remaining pens. Later the receptionist wants to take a message, but there are no pens. Who's responsible, the professor or the assistants? More people say the assistants.

6) Balancing of reasons
- Juror says "this argument is good, but not enough to counter the other argument{\ldots}" How does he balance the weights of the arguments?
- old legal maxim goes, "Arguments are to be weighed, not counted"
- this is called 'Judicial Balancing'

7) Probabilistic, Default, or Non-monotonic reasoning (including problems of priors, the weight of evidence and reference classes)
- Author thinks that Bayesian and probabilistic approaches to balancing reasons actually has been very successful as a formalism. But there are problems with it.
- Priors is the biggest of these problems.
- In reference class problems, like United States v. Shonubi. 
- Another example: Valuing a house for sale involves estimating its price from the sale records for 'similar' houses. How is this determined?
- This is called the 'reference class problem', introduced by Venn and named by Reichenbach. "Plainly, the problem will appear in any case wehre there may be doubt as to what class containing an instance is most relevant to determining its probability of having some attribute. {\ldots} There is some consensus in philosophy that [this] is inherently unsolvable, that 'there is no principled way to establish the relevance of a reference class'."

8) Issues of the discrete vs. the continuous
huh

9) Understanding
- "After 50 years of experience, it is time to face the possibility that understanding is essentially quite unlike rule-following. {\ldots} the more experience we have, the more unique human understanding looks."
- Example he gives from mathematics: why is 2 x 3 = 3 x 2? Answer: Because two rows of three things are exactly the same things as three columns of two. "The prospects for putting genuine understanding of that kind into software or hardware are as close to zero as they were in 1950."


CASE STUDY
- They examine "one state-of-the-art example of such work [to formalize legal reasoning]", Henry Prakken's 2008 formalization of the reasoning in a routine Dutch case of disputed possession.
- He is unable to formalize the part where the testimony of one party adds to the perceived sincerity of another (and the perceived sincerity of that party is critical to the decision)

CONCLUSION
- legal argumentation does not contain a discrete structure which formal methods can usefully represent, order, and display. "This conclusion thus supports the use of diagrammatic methods to organize evidence and legal reasoning, as they allow the discrete structure of propositions and their relations to be displayed in ways easy for humans to grasp." But why can't the diagrammatic methods then be formalized? I don't understand this.
- The intuitive judgments of degree based on genuine understanding required in this sort of reasoning are, "on present evidence, beyond the methods of AI."},
	Author = {Franklin, James},
	Date-Added = {2013-09-29 22:06:19 -0400},
	Date-Modified = {2013-09-29 22:07:25 -0400},
	Journal = {Law, Probability and Risk},
	Month = {June-September},
	Number = {2-3},
	Pages = {225-245},
	Title = {Discussion paper: How Much of Commonsense and Legal Reasoning is Formalizable? A Review of Conceptual Obstacles},
	Volume = {11},
	Year = {2012}}

@article{Dimiskovska2013,
	Annote = {http://revus.revues.org/2463

She uses the DiaLaw model of dialogical legal reasoning to analyze a case (which takes place in the mediterranean), though she follows "the spirit rather than the letter of the model."

Three approaches to justifying legal decisions: (according to Feteris)
- Logical - put into logical form and show soundness
- Rhetorical - Treats justification as audience-relative, "meaning that the measure of the acceptability of the justification is its effectiveness for the audience."
- Dialogical - treats it as part of a larger dialogue about a particular standpoint, and allows the back-and-forth discussion to be modeled. 

She chooses the dialogical view, because "this approach seems the most suitable conceptual tool for the analysis of controversies since it represents legal justification as a regulated exchange of theses and arguments between a proponent and an opponent", and they "allow for the use of formal dialogical models in which the oridinary logical operations of deduction are presented in a purely dialogical form." Finally, because you can model the rules of discussion (what they are allowed to say and when, I assume) you can treat it as a sort of 'logical game'.

REASON-BASED LOGIC
- tries to capture the specific features of reasoning with rules and principles, which systematically includes balancing the reasons for and against the particular conclusions
- rules are treated as 'logical individuals' which have conditions and conclusions.

There is one instance of analogy in the reasoning here:
"{\ldots}the dissenting opinions oppose the use of the argument by analogy concerning the criterion of age as a basis for retirement. The reason for this is that the situation of the judges of regular courts [the source analog], who are elected without any limitation on the duration of judicial function, is essentially different from that of members of the State Judicial Council since the duration of their function is already explicitly limited by the Constitution to six years, with only one possible re-election."},
	Author = {Dimi{\v s}kovska, Ana},
	Date-Added = {2013-09-28 23:48:05 -0400},
	Date-Modified = {2013-09-29 00:02:30 -0400},
	Journal = {Revus},
	Title = {(Dia)logical Reconstruction of Legal Justification},
	Volume = {19},
	Year = {2013}}

@article{Schlimm2008,
	Annote = {Argues that structure mapping theory doesn't work in all cases, particularly domains that are object-rich like mathematical domains. 
Also describes the "axiomatic" approach to analogies as a way of explaining analogies of this type.

"A domain consists of a class of elements, referred to as *objects*, and a number of *relations* that hold between them." 

What he calls the 'axiomatic' approach "considers two domains as analogous if they satisfy the same laws or axioms (i.e., if they are models of the same set of axioms)." This is an extension of a distinction made by George Polya. 

Relation-rich vs. Object-rich domains : distinction based on "the ratio between the number of objects and the number of relations in the domain." He says that when a domain is given, the relevant relations and objects are explicitly given as well, so if you question this then this distinction becomes less clear.
- mathematics are typically object-rich (with sometimes infinite objects); the ones studied so far in analogy are usually relation-rich
- He gives the example of a domain that is similar to the example Owen gave in his book, where a triangle might be analogous to a square, even though there's no one-to-one mapping between their angles or sides. So the mapping has to be done at the axiomatic level, or at a level of description that is more general (which Owen already suggested).

Hesse argued that analogies cannot be formal, where all similarities (positive analogies) between the analogous domains are expressed by a formal system.

More advantages of axiomatic approach over structural:
- Variants of SMT don't account for the negative analogy except as the absence of a mapping
- 'Determining an axiomatic characterization of what two domains have in common is a procedure that can be applied incrementally, that is, the analogy can be *deepend* in the course of the investigation{\ldots}' whereas a similar process in SMT would require that previous mappings are discarded.
- some arguments he makes are really over the benefits of using a *representation* that is axiomatic rather than object-rich, instead of talking about the process of analogy-finding itself.},
	Author = {Schlimm, Dirk},
	Date-Added = {2013-09-28 01:29:10 -0400},
	Date-Modified = {2013-09-28 20:11:37 -0400},
	Journal = {Philosophy of Science},
	Pages = {178-200},
	Title = {Two Ways of Analogy: Extending the Study of Analogies to Mathematical Domains},
	Volume = {75},
	Year = {2008}}

@techreport{Burstyn2013,
	Author = {Burstyn, Igor},
	Date-Added = {2013-09-17 12:05:45 -0400},
	Date-Modified = {2013-09-17 12:09:26 -0400},
	Institution = {Drexel University},
	Title = {Peering Through the Mist: What Does the Chemistry of Contaminants in Electronic Cigarettes Tell Us About Health Risks?},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QLy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL21zMDgucGRm0hcLGBlXTlMuZGF0YU8RAZwAAAAAAZwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwhtczA4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxDhzl319wAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzl4uNwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEdNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBtczA4LnBkZgAADgASAAgAbQBzADAAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIANFVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvbXMwOC5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDAAMUAzQJtAm8CdAJ/AogClgKaAqECqgKvArwCvwLRAtQC2QAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALb}}

@article{Markman1993,
	Annote = {Draws on Tversky's (1977) contrast model, which says the psychological similarity of objects depends on its commonalities:differences ratio. Other aspects of his theory were used, like how commonalities are more important to perceived similarity than differences (523).

"The results [of experiment 1] supported the view that similarity comparison is fundamentally a process of finding aligned systems of commonalities, and that differences related to those common systems (alignable differences) are psychologically distinct from unrelated differences (nonalignable differences)."

"If items are represented as collections of independent features [as opposed to linked by relations like in SMT], similar pairs should have many commonalities and few differences, while dissimilar pairs should have few commonalities and many differences. Further, since this view makes no distinction between alignable and nonalignable differences, there is no basis for predicting the patterns of correlation found here. Finally, on this accont, we would not expect to find relationships between commonalities and differences." (529)

},
	Author = {Markman, A.B. and Gentner, D.},
	Date-Added = {2013-09-09 12:22:49 -0400},
	Date-Modified = {2013-09-09 21:42:13 -0400},
	Journal = {Journal of Memory and Language},
	Pages = {517-535},
	Title = {{Splitting the Differences: A Structural Alignment View of Similarity}},
	Volume = {32},
	Year = {1993},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL01hcmttYW5HZW50bmVyOTNiLnBkZtIXCxgZV05TLmRhdGFPEQHQAAAAAAHQAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcVTWFya21hbkdlbnRuZXI5M2IucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8QuM5TbsAAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM5TpwAAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBUTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoATWFya21hbkdlbnRuZXI5M2IucGRmAA4ALAAVAE0AYQByAGsAbQBhAG4ARwBlAG4AdABuAGUAcgA5ADMAYgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQVVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvTWFya21hbkdlbnRuZXI5M2IucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAM0A0gDaAq4CsAK1AsACyQLXAtsC4gLrAvAC/QMAAxIDFQMaAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAxw=}}

@article{Klenk2011,
	Annote = {"The solution we propose is to use analogy to solve the everyday breadth problem and assist with the domain breadth problem. We do not mean cross-domain analogies, {\ldots} Instead, we focus here on within-domain analogies, where a new situation is understood in terms of a prior example".

Analogical model formulation - Using an analogy with a prior example to construct a model. They claim this is more general than the hand-coded rule approach of HALO (Barker et al. 2004).

"this article describes how a combination of three ideas enables companions to perform well on a subset of the BMCT. The first idea of course is analogical model formulation. The second idea is *sketch annotations*, which introduce visual quantities into a sketch in a manner that can be used in causal theories and applied via analogy. The third idea is analogical reference frames, for solving DQA problems like the one above. Using analogical reference frames significantly extends the scope of comparative analysis over the traditional perturbed-system model (Weld 1988)." (302)

RESULTS: p.319-320},
	Author = {Klenk, Matthew and Forbus, Ken and Tomai, Emmett and Kim, Hyeonkyeong},
	Date-Added = {2013-09-08 18:18:13 -0400},
	Date-Modified = {2013-09-11 20:38:16 -0400},
	Journal = {Journal of Experimental and Theoretical Artificial Intelligence},
	Month = {September},
	Number = {3},
	Pages = {299-327},
	Title = {Using Analogical Model Formulation with Sketches to Solve Bennett Mechanical Comprehension Test Problems},
	Volume = {23},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzYzMDAwMDI3LnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMNjMwMDAwMjcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48ls5SU2IAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM5Si6IAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoANjMwMDAwMjcucGRmAAAOABoADAA2ADMAMAAwADAAMAAyADcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzYzMDAwMDI3LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=}}

@article{Chapin2011,
	Annote = {"The present article explains how gaps in a top-down logicist approach to SA [story arrangement] can apparently be addressed by a bottom-up approach focussed (sic) on what we refer to as *change analysis*."

They colored images to make them easier to process. Then they calculated things like 'center of mass' for each object in the image, and distance metrics, etc. Then they were ordered using a greedy algorithm, but I don't see what exactly the algorithm evaluated (except possibly trying to put a simple ordering that makes sense of the changes of the metrics).},
	Author = {Chapin, Nate and Szymanski, Boleslaw and Bringsjord, Selmer and Schimanski, Bettina},
	Date-Added = {2013-09-08 17:38:57 -0400},
	Date-Modified = {2013-09-08 18:20:04 -0400},
	Journal = {Journal of Experimental and Theoretical Artificial Intelligence},
	Month = {September},
	Number = {3},
	Pages = {329-341},
	Title = {A Bottom-Up Complement to the Logic-Based Top-Down Approach to the Story Arrangement Task},
	Volume = {23},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzYzMDAwMDI2LnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMNjMwMDAwMjYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48lM5SU0YAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM5Si4YAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoANjMwMDAwMjYucGRmAAAOABoADAA2ADMAMAAwADAAMAAyADYALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzYzMDAwMDI2LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=}}

@article{Turney2011,
	Annote = {PairClass - their algorithm for analogy perception that recognises lexical proportional analogies using representations that are automatically generated from a large corpus of raw textual data.

High level perception - "The process of forming high-level conceptual representations from raw data (without hand-coding)." (2), attributed to Chalmers et al. 1992.

- Vectors in PairClass represent relations between two words.
- "Thus, our approach to analogy perception is to frame it as a problem of classification of word pairs (hence the name PairClass)".
- "In this article, we frame the task of recognising lexical analogies as a problem of classifying word pairs (Table 1). {\ldots} Each word pair is represented as a vector in feature space and a supervised learning algorithm is used to classify the feature vectors."
- "For the five experiments for which there are previous results, PairClass is not the best, but it performs competitively."

The seven tests they use are listed on p.345.

Steps:
- check word copuses for phrases that look like they might express relations between words
- "generate patterns from all of the phrases that were found for all of the input word pairs [by replacing] the given word pairs with variables, X and Y, and we replace the remaining words witha wild card symbol (an asterisk) or leave them as they are." Feature selection is used to reduce the number of patterns considered since it is exponential in the number of words.
- Generate feature vectors for each word pair where each feature is a pattern template.
- Apply standard supervised learning algorithms (type of SVM used here) to these feature vectors.

Results:
SAT: 52.1%; best known is 56.1% (Turney 2005), average senior in high school is 57%.
{\ldots}rest are listed there

to check out:
"Turney (2008a) introduced the [LRME], which {\ldots} is able to construct mappings without hand-coded high-level representations."
"The ACL Wiki lists 12 previously published results with the 374 SAT analogy questions [footnote 5]" {\ldots} footnote 6 has TOEFL synonym questions:
- http://aclweb.org/aclwiki},
	Author = {Turney, Peter D.},
	Date-Added = {2013-09-08 16:37:42 -0400},
	Date-Modified = {2013-09-08 16:39:30 -0400},
	Journal = {Journal of Experimental and Theoretical Artificial Intelligence},
	Month = {September},
	Number = {3},
	Pages = {343-362},
	Title = {Analogy Perception Applied to Seven Tests of Word Comprehension},
	Volume = {23},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzYzMDAwMDIzLnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMNjMwMDAwMjMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48ks5SUxsAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM5Si1sAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoANjMwMDAwMjMucGRmAAAOABoADAA2ADMAMAAwADAAMAAyADMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzYzMDAwMDIzLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=}}

@inproceedings{Kunda2010,
	Address = {Portland},
	Annote = {http://csjarchive.cogsci.rpi.edu/Proceedings/2010/papers/0431/paper0431.pdf

They want to find strategies that will solve Raven's without translating them into propositions first, like everyone else does.
"In this paper, we provide evidence from two different methods that Raven's problems can be solved visually, without first converting problem inputs into propositional descriptions."

Hunt (1974) identified a "Gestalt" strategy which uses visual representations and perceptual operations like continuation and superposition (in contrast to propositional, or "Analytic" approaches), but never actually implemented an algorithm.

They have two algorithms, both of which use image transformations without converting the images into propositions:
Affine method - restricts dilation (scaling) to 1 (meaning no scaling)
Fractal method - uses a short sequence of progressively smaller dilation values
They say there's evidence that humans can perform some of these basic image transformations.

They were generally able to produce results of an average 10 1/2 year old.},
	Author = {Kunda, Maithilee and McGreggor, Keith and Goel, Ashok},
	Booktitle = {Proceedings of the 32nd Annual Meeting of the Cognitive Science Society},
	Date-Added = {2013-09-04 22:17:27 -0400},
	Date-Modified = {2013-09-04 22:35:00 -0400},
	Month = {August},
	Title = {Taking a Look (Literally!) at the Raven's Intelligence Test: Two Visual Solution Strategies},
	Year = {2010}}

@article{Dowe2012,
	Annote = {Tries to ask what the 'right' intelligence tests for machines are.

Detterman's 2011 challenge to Watson: "I, the editorial board of Intelligence, and members of the International Society for Intelligence Research will develop a unique battery of intelligence tests that would be administered to that computer and would result in an actual IQ score."

"Summing up, there are IQ tests no machine can pass nowadays, but a selction of the 'machine-unfriendly' IQ tests would have no particular relation with their ability to measure intelligence well in humans, but rather just their ability to discriminate between humans and state-of-the-art machines, as CAPTCHAs do."

Their dismissal of current psychometrics for AI systems is based on their opinion that "the experiment with this small program in Perl has already shown that IQ tests have become specialised for humans, and many difficulties may arise if these tests are used to measure intelligence outside this 'normative' population. {\ldots} human IQ tests are not for machines. The reason is that, in our opinion, many things are taken for granted in IQ tests which cannot be assumed for machines. Current IQ tests are *anthropocentric*."

Regarding Bringsjord and Schimanski, "their impact has been very limited since only AI systems which are specialised to the particular test interface and choice of symbolic representation can be evaluated."

"A convenient theoretical, a priori approach to constructing intelligence tests can be based on formal computational definition of the cognitive abilities involved, and likewise a mathematical, intrinsic, derivation of task complexity."},
	Author = {Dowe, David L. and Hernandez-Orallo, Jose},
	Date-Added = {2013-09-04 21:49:15 -0400},
	Date-Modified = {2013-09-04 21:51:04 -0400},
	Journal = {Intelligence},
	Pages = {77-81},
	Title = {IQ Tests Are Not for Machines, Yet},
	Volume = {40},
	Year = {2012}}

@article{Forbus1998,
	Annote = {Summarize Hofstadter's claims as follows:
"[They claim] analogy should be viewed as a form of *high level perception* that encompasses both representation building and mapping as indivisible operations within a single model." They also criticize SME "on the grounds that it is modular". 

Their responses:

(1) Most of their arguments regarding SME and copycat are incorrect.
	- "The omission of Phineas from CFH's discussion of analogy {\ldots} is striking, since it provides strong evidence gainst their position." (But a footnote says that this was actually corrected.  (10)
	- The newer systems use a new version of SME called ISME which "allows incremental extension of the descriptions used as base and target [, which] greatly extends SME's representation-building capabilities." (12)

(2) The claim that analogy is high-level perception, while in some ways an attractive metaphor, is too vague to be useful as a technical proposal.
	- The view that you can't separate models of construction and matching, they are "less enthusiastic about its merits as a technical proposal, especially the claim of the inseperability of the processes."


"We do not assume that the representations given to SME contain all logically possible (or even relevant) information about a situation." (7)

There are five issues they see as central to respond to the claims:

- How does perception relate to analogy?
	- "Since Copycat's mapping process is inextricably mixed with its (high-level) perceptual representation-building processes, there is no way to model being reminded and pulling a representation from memory. Yet work on [CBR in AI] suggests that previous examples play a central role in the representation and understanding of new situations and in the solution of new problems." (14)
	- "Copycat has no way to store an analogical inference, nor to derive an abstract schema that represents the common system {\ldots} " In other words, the way in which analogy is used to learn. Forbus says there are at least three ways: "schema abstraction, inference projection, and re-representation. The fluid and incremental view of representation embodied in Copycat cannot capture analogy's role in learning" (15). 

- How does flexibility arise in analogical processing?
	- SME allows for different interpretations of the matches
	- In Copycat the weights on predicate pairs and the conceptual depths of individual predicates are hand-coded, and "This is not flexibility: it is hand-tailoring of inputs to achieve particular results, in exactly the fashion that CFH decry." (19)
	- Copycat's "operation is entirely domain-specific. This, to us, is the ultimate inflexibility." (22)

- Is analogy a domain-general process?
	- "A consequence of CFH's argument that perception cannot be split from comparison is that one should not be able to make domain-independent theories of analogical processing." (Is this right? I assume he means because the knowledge construction part is so domain-dependent.)
	- He argues against the "dangers" of domain-specific models

- How should microworlds be used in the study of analogy?
	- They argue that Copycat deserves the "toy domain" label much more than SME+PHINEAS

- How should the psychological plausibility of a model of analogy be assessed?
	- Forbus thinks you have to develop your models as you test their predictions with people, in accordance with a "more-or-less standard cognitive science paradigm". Hofstadter, however, criticizes the approach that tries to match the average performance of humans---I assume Hofstadter means that we don't want to model the mean performance, but rather capture the diversity of performances; but Forbus replies as if he doesn't really understand this point. He says "The trouble with this method of assessment is that it is hard to find out when one is wrong." (28)},
	Author = {Forbus, Kenneth D. and Gentner, Dedre and Markman, A.B. and Ferguson, R.W.},
	Date-Added = {2013-08-13 19:54:50 +0200},
	Date-Modified = {2013-08-13 22:01:36 +0200},
	Journal = {Journal of Experimental and Theoretical Artificial Intelligence (JETI)},
	Pages = {231-257},
	Title = {Analogy Just Looks Like High Level Perception: Why a Domain-General Approach to Analogical Mapping is Right},
	Volume = {10},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Rvd25sb2FkLnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMZG93bmxvYWQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8OAM4v69QAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM4wJBQAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAZG93bmxvYWQucGRmAAAOABoADABkAG8AdwBuAGwAbwBhAGQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Rvd25sb2FkLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=}}

@techreport{Hofstadter1984,
	Annote = {Again, Mitchel 1993 (book) is probably the best resource for copycat, but this might help.

They DO have a measure of how abstract something is: "The Slipnet's topography is defined by our attaching to each node a "semanticity", roughly defining its degree of abstractness. The reason for our equating abstractness with importance is our belief that the degree of depth and power of an analogy is proportional to the degree of abstractness" (4).

"the central problem is how to formulate a theory that will allow a machine to achieve a graceful compromise between forces pushing for literal translation and forces pushing for very abstract, metaphorical connections." (4)

"We have formulated what we believe to be the most fundamental semantic concepts in the alphabetic micro-world (and psychological research by Restle has confirmed our intuitions). They are as follows:" (5)
- C-group (copy-group) : AAA, KK, PQPQPQ, M
- S-group (successor-group) : ABC, XYZ, FG, T <---note that the alphabets and concepts of succession are among the "Platonic" concepts
- P-group (predecessor-group) : simply reverse of S-group

Other notions:
Salience - How distinguished an element is. "[I]f a B occurs in a structure, it may be better to view that letter as an instance of "successor-of-A", rather than as a mere B."
Symmetry - ABA (syntactic symmetry at letter level, meaning knowledge of the semantics is not necessary to see symmetry), ABCTTTABC (syntactic symmetry at group level), ABCXYZ (semantic symmetry at letter level), ABCZYX (semantic symmetry at group level) etc.

Jumbo - Program that takes a certain number of letters and tries to make english words out of them. They want to explore how people "fuss around" with ideas. Differs from copycat in two important ways: copycat is ordered so the problem becomes "where to draw boundaries, what kinds of categories to see structures in terms of, what kinds of cross-compartmental connections to draw, and so on." Secondly, copycat has a richer category system.

The Slipnet - The source of Fluidity in Copycat
- Each node has a degree of activation starting at zero, representing the system's "interest" in the node
- Activation doesn't spread uniformly; some links are "greased" and spreading is probabilistic (in the long run this spread becomes more continuous)
- "In effect, slippage means deformation of one descriptive structure into another." (20)
- Intensional slippage - yields a synonymous though superficially different structure. e.g. converting AAB into either A folllowed by AB; or AA followed by B.
- Extensional slippage - yields a structure whose meaning is truly different. e.g., converting one of these rules to the other: (1) Replace the rightmost letter by its successor (2) Replace the leftmost letter by its predecessor
- Semanticity - Number that tries to estimate how useful a given concept is in making characterizations of an object.},
	Author = {Hofstadter, Douglas R.},
	Date-Added = {2013-08-12 16:25:06 +0200},
	Date-Modified = {2013-08-13 08:28:46 +0200},
	Institution = {Massachusetts Institute of Technology},
	Title = {The Copycat Project: An Experiment in Nondeterminism and Creative Analogies},
	Year = {1984},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Rvd25sb2FkICgxKS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGRvd25sb2FkICgxKS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDdrOLmhoAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADOLqCoAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGRvd25sb2FkICgxKS5wZGYAAA4AIgAQAGQAbwB3AG4AbABvAGEAZAAgACgAMQApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9kb3dubG9hZCAoMSkucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@book{Weinreb2005,
	Annote = {Argues against those who think analogy is not used often, or doesn't belong in, law. Mostly does this by showing examples that require analogy, and shows how seeing legal reasoning as possible independent of analogical reasoning doesn't work.

(rest of my notes in kindle bookmarks and highlights)},
	Author = {Weinreb, Lloyd L.},
	Date-Added = {2013-08-10 20:23:23 +0800},
	Date-Modified = {2013-08-10 21:10:46 +0800},
	Publisher = {Cambridge University Press},
	Title = {Legal Reason : The Use of Analogy in Legal Argument},
	Year = {2005}}

@inproceedings{Pickett2013,
	Annote = {Addresses "how anaogies can be isolated from large domains and spontaneously retrieved from long term-memory, a process we call *spontaneous analogy*".
- represents relational structures as "feature bags" s.t. their surface similarity corresponds to the structural similarity
- automatically generates an ontoogy of relational structures, to efficiently retrieve analogs from LTM
- claim to yield "significant time-savings over linear analog retrieval at a small accuracy cost."

Spontaneous analogy - The process of efficiently retrieving an analog from long-term memory given an unsegmented source domain such that part of the source shares structural similarity with the analogy, though they might not share surface similarity.

Spontol - their algorithm that "solves the problem of spontaneous analogy: efficient parsing, storage, and retrieval of analogs from long-term memory. {\ldots} We know of no prior work that scales to this task when the number of narratives and statements per narrative are both in the hundreds."

OTHER WORK:
COWARD - performs isomorphic subgraph search
SUBDUE - breaks up large graphs into repeated subgraphs
Nauty - uses a bunch of heuristics, but source and target must be provided
MAC (from MAC/FAC) - uses vectors of content like # of nodes
ARCS - also assumes analogs have been clearly delineated
SEQL - generalizes relational concepts, but doesn't "build a hierarchical ontology of analogical schemas."
Holographic reduced representations - also tries to represent structures as vectors, but can't "exploit partial analogical schemas."
Ontol / "The Chunker" - this paper's algorithm is based on this one; it searches for large, frequently occurring sets of features. Searches for intersections among existing feature bags and proposes these as candidates for new concepts, based on how well it would compress the ontology. Contains top-down and bottom-up features.

"Although the parsing problem is NP-complete, a single bottom-up pass can be performed in logarithmic time" (3231)

DATASET: "a database of 126 stories provided by Thagard et al. (1990)" (3233) They were able to produce an ontology of stories

"Whereas MAC/FAC returns entire stories, Spontol-Retrieve returns analogical *schemas* (just as a visual system would return a generic "pterodactoyl" concept rather than specific instances of pterodactoyls)." They actually compared this to MAC/FAC! How did they get the implementation?
NOTE: I emailed the author and he said they had to create their own implementation.

"Though [systems like LISA] fail to address how relational structures can be efficiently retrieved from long-term memory, we hypothesize that a working-memory system, such as LISA, is necessary for the "chaining" process on which our system relies."
},
	Author = {Pickett, Marc and Aha, David W.},
	Booktitle = {Proceedings of the 35th Annual Meeting of the Cognitive Science Society (COGSCI 2013)},
	Date-Added = {2013-08-07 10:26:44 +0800},
	Date-Modified = {2013-09-04 21:46:43 -0400},
	Title = {Spontaneous Analogy by Piggybacking on a Perceptual System},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhcGVyMDU3NS5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDXBhcGVyMDU3NS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEPfOJyiyAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADOJ2DyAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHBhcGVyMDU3NS5wZGYADgAcAA0AcABhAHAAZQByADAANQA3ADUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhcGVyMDU3NS5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==}}

@inproceedings{Trench2013,
	Annote = {Performs psychological studies on retrieval. 

Regarding analogical retrieval:
- Do other activities different from problem solving automatically elicit a search for analogical sources, and
- Can strategic search overcome the superficial bias observed in classical experiments?

MAC/FAC - divides retrieval into two phases:
- MAC - fast superficial filter, generates content vectors and essentially ranks them based on superficial concept overlap
- FAC - structural matcher that filters the results from MAC

Both LISA and MAC/FAC are "ambiguous as to whether the models account for spontaneous remindings, voluntary remindings, or both. {\ldots} the first objective of the present study is thus to investigate to what extent the search for BAs [Base analogs] in LTM is automatically triggered by the processing of the TAs [Target Analogs]".

- Studies showed "that when being asked to generate analogies to convince somebody of performing an action, people easily retrieve BAs from their autobiographical memory." (48)},
	Author = {Trench, Maximo and Olguin, Valeria and Margni, Adrian and Minervino, Ricardo A.},
	Booktitle = {Proceedings of the 35th Annual Meeting of the Cognitive Science Society (COGSCI 2013)},
	Date-Added = {2013-08-05 16:20:16 +0800},
	Date-Modified = {2013-08-07 10:20:29 +0800},
	Title = {Automatic and Strategic Search During Analogical Retrieval},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhcGVyMDI3OC5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDXBhcGVyMDI3OC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEPXOJNiIAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADOJRDIAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHBhcGVyMDI3OC5wZGYADgAcAA0AcABhAHAAZQByADAAMgA3ADgALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhcGVyMDI3OC5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==}}

@inproceedings{Foster2013,
	Annote = {Propose a "computational synergy between analogy and RL, in which analogical comparison provides the RL learning algorithm with a measure of relational similarity, and RL provides feedback signals that can drive analogical learning."

- Human conceptual knowledge representation should be represented not just as distributions of features but as relational structures (Sloman et al. 1998, Jones and Love 2007)
- Parallel connectivity - "whenever two relations are mapped to each other, the objects filling their respective role-fillers are also mapped together." (448)
- "One potential shortcoming of the basic theory of analogy reviewed here is that is it [sic] essentially unsupervised. In this framework, the quality of an analogy depends only on how welll the two systems can be structurally aligned, and not on how useful or predictive the shared structure might be." (449) "For example, one could list many relational patterns that arise in chess games but that are not especially useful for choosing a move or for predicting the course of the game. {\ldots} An alternative [model] would involve feedback from the environment, so that the value of an analogy or schema is judged partially by how well it improves predictions of reward or other important environmental variables."
- Works as follows:
	- the model maintains a set of exemplars E, each with learned value v(E)
	- the state s is compared to all exemplars using structural alignment
	- estimated value of the state V~(s) is a similarity-weighted average of v(E)
	- after an action is taken and the reward and next state are observed, standard RL provides error computations
	- exemplar values updated
- They tested the program on its ability to learn tic-tac-toe.},
	Author = {Foster, James M. and Jones, Matt},
	Booktitle = {Proceedings of the 35th Annual Meeting of the Cognitive Science Society (COGSCI 2013)},
	Date-Added = {2013-08-05 15:56:20 +0800},
	Date-Modified = {2013-08-05 15:58:00 +0800},
	Title = {Analogical Reinforcement Learning},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhcGVyMDEwNS5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDXBhcGVyMDEwNS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEPPOJNLsAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADOJQssAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHBhcGVyMDEwNS5wZGYADgAcAA0AcABhAHAAZQByADAAMQAwADUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhcGVyMDEwNS5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==}}

@inproceedings{Vattam2013,
	Annote = {Focus on "situated analogy", where "source analogues are obtained through interactions with an external environment rather than being recalled from internal long-term memory."
More specifically:
IAR - Interactive Analogical Rerieval, where interaction with "online information evironments" are used to obtain source analogues.
Even more specifically:
They focus on IAR in the domain of "biologically inspired design".

"Our model builds on two existing theories: Analogical Retrieval by Constraint Satisfaction (ARCS) and Information Foraging Theory (IFT) {\ldots} [which is] itself a biologically inspired theory of online information seeking behavior."

They wanted to build on ARCS specifically because it matches their observations, and it has semantic, structural, and pragmatic similarity. But although "on one hand, ARCS explains how source analogues are retrieved from the long-term memory but is silent about analogies situated in external information environments."

Their model - PRISM (PRessurized Information Scent foraging Model)

"they are presented with snippets of information, called *proximal cues*, which the analogy seeker uses to perceive the information scent of the digital information patches."},
	Author = {Vattam, Swaroop S. and Goel, Ashok K.},
	Booktitle = {Proceedings of the 35th Annual Meeting of the Cognitive Science Society (COGSCI 2013)},
	Date-Added = {2013-08-02 11:47:41 +0800},
	Date-Modified = {2013-08-05 12:21:10 +0800},
	Title = {An Information Foraging Model of Interactive Analogical Retrieval},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhcGVyMDY0Ny5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDXBhcGVyMDY0Ny5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEPnOIKRqAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADOINyqAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHBhcGVyMDY0Ny5wZGYADgAcAA0AcABhAHAAZQByADAANgA0ADcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhcGVyMDY0Ny5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==}}

@inproceedings{Licato2013b,
	Address = {Beijing, China},
	Author = {Licato, John and Bringsjord, Selmer and Govindarajulu, Naveen S.},
	Booktitle = {Proceedings of the IJCAI 2013 Workshop on Computational Creativity, Concept Invention, and General Intelligence},
	Date-Added = {2013-08-01 21:38:42 +0800},
	Date-Modified = {2013-11-12 13:03:14 -0500},
	Editor = {Besold, Tarek Richard and K{\"u}hnberger, Kai-uwe and Schorlemmer, Marco and Smaill, Alan},
	Title = {{How Models of Creativity and Analogy Need to Answer the Tailorability Concern}},
	Year = {2013}}

@book{Marcus2009,
	Annote = {Talks about how the human body is so flawed due to evolution, and in a similar way so is the mind.
- discusses the difference between quantifiers and "generics": (loc. 1673)
- discussion of optimality in human reasoning (loc. 1701)},
	Author = {Marcus, Gary},
	Date-Added = {2013-07-24 12:25:38 +0200},
	Date-Modified = {2013-07-24 12:28:48 +0200},
	Publisher = {Mariner Books},
	Title = {Kluge: The Haphazard Evolution of the Human Mind},
	Year = {2009}}

@book{Hofstadter2013,
	Annote = {The main thesis of the book: "---that analogy-making and categorization are just two names of the same phenomenon."(loc. 2839)

- "The point is, we're constantly noticing odd, random resemblances around us because our brains are always on the lookout for insights into reality, always using the past to try to make sense of the present, always making spontaneous connections, always throwing bottle after bottle overboard in the faint hope that one of them might reach land." (loc. 7912)
- On the "source-target paradigm" that dominates analogy research:
	- (loc. 9401): "Unfortunately, the source-target paradigm has a serious defect that undermines the generality of the conclusions that experiments based upon it produce. This defect stems from the fact that the knowledge acquired about the source situation during the twenty minutes or so of a typical experiment is perforce very limited -- often consisting merely in the application of a completely unfamiliar formula to a word problem. By contrast, when in real life we are faced with a new situation and have to decide what to do, the source situations we retrieve spontaneously and effortlessly from our memories are, in general, extremely familiar. We all depend implicitly on knowledge deeply rooted in our experiences over a lifetime, and this knowledge {\ldots} has also been generalized over time, allowing it to be carried over fluidly to all sorts of new situations. It is very rare that in real life we rely on an analogy to a situation with which we are barely familiar at all."
	- He is arguing that source analogies are located using familiarity, rather than surface features. The only reason that surface features are used so heavily in experiments is because they are forced to do it: "What [the experiments] show is that when people learn something superficially, they wind up making superficial analogies to it." (loc. 9409)
	- "Are we poor human beings really so constantly gulled by surface appearances?" (loc. 9414)
	- So I think insofar as people turning to surface features first, the authors would say it's only if they're dealing with domains with which they are unfamiliar. This can be tested: have a bunch of pro basketball players and use the source analogies from basketball, for example.
	- "A superficial features is an aspect of a situation that can be modified without touching the core of that situation." (loc. 9422) "Color is quite obviously a surface-level feature for the category *gearshift*." But note, under this definition, color would not be a surface level for a photorealistic painting, since changing the color of the painting would make it no longer photorealistic!
	- "In short, what we use to guide our retrieval of memories when we are in an unfamiliar situation is not what is most *superficial*, but what is most *salient* to us. {\ldots} the features that guide our retrieval of a specific memory are chosen not because they reside on the surface, but because - quite to the contrary - among all the potential retrieval cues to which we have access, they are they *deepest* ones. For different people, the salience of a given feature depends on their expertise in the given domain." (loc.9465)
	

- "The fact that [two proverbs can] assert contradictory things shows that what counts is not a proverb's truth, but its ability to cast light on a situation, allowing it to be seen as more than simply a recitation of events." (2916)
- "To be sure, we don't want to suggest that an event has just *one* abstract structure. Speaking, *a posteriori*, of "the" abstract structure of an event gives the impression that there was and is only one correct way to perceive it and to have a memory of it get triggered, which is not the case, which is not the case; any of various distinct conceptual skeletons might get attached to a given situation, depending on the frame of mind one is in when it is encountered." (4621)
- "Our view is very different from one in which logic is seen as central. Indeed, as we stressed in Chapter 4, expertise builds up as categories are acquired and organized. Rather than depending on formal perceptions of situations, people have the ability to treat novel situations as if they were familiar, thanks to categorization. {\ldots} Analogical thinking is the key to understanding new situations and to building up new concepts, and this holds at all levels, ranging from the shakiest beginer to the most fluent expert. The difference between these two is not their style of thinking - logical for the expert and analogical for the beginner - but the repertoire of categories that they have at their disposition, and the way those categories are organized." (10853)
- "{\ldots}even in a bare-bones mathematical situation, people are very seldom able to ignore all of its superficial, concrete aspects and to home in on just its abstract formal structure. For better or for worse, people are influenced by how situations are concretely described, by their familiarity with similar situations, and by the naiive analogies that these situations evoke naturally." (11871)
- He objects to the distinguishing between categorization and analogy because "as research in psychology has shown, {\ldots} the vision *categorization = placing things in their natural boxes* is highly misleading, for categorization is every bit as subjective, blurry, and uncertain as is analogy-making. A categorization can be outright wrong, can be partially correct, can be profoundly influenced by the knowledge, prior, experiences, {\ldots} [etc] of the person who makes it, and can depend on the local contextor the global culture in which it is made." (12001)
- discussion on how perception of mathematical truths affected the field, even though mathematics is supposed to be unchanging (12115)
- discussion on how Einstein used analogy, or specifically category extension/blending (13419)},
	Author = {Hofstadter, Douglas R. and Sander, Emmanuel},
	Date-Added = {2013-07-17 14:42:32 +0200},
	Date-Modified = {2013-07-24 12:20:09 +0200},
	Publisher = {Basic Books, Inc},
	Title = {Surfaces and Essences: Analogy as the Fuel and Fire of Thinking},
	Year = {2013}}

@book{Ashley1990,
	Annote = {Main citation for HYPO and Ashley's approach.},
	Author = {Ashley, Kevin D.},
	Date-Added = {2013-07-11 01:28:48 +0200},
	Date-Modified = {2013-07-11 01:29:41 +0200},
	Publisher = {MIT Press},
	Title = {Modeling Legal Argument - Reasoning with Cases and Hypotheticals},
	Year = {1990}}

@article{Ashley1988,
	Annote = {Hypo ", a computer program that performs case-based reasoning in the legal domain, helps attorneys analyze and make arguments about new fact situations in terms of the most relevant precedent cases. {\ldots} Hypo must make factual comparisons of cases relative to the problem situation and determine the legal significance of comparisons in terms of arguments about the problem situation."

Hypo uses two kinds of domain knowledge to construct "claim lattices":
1) CKB containing actual legal cases, and
2) the library of dimensions - these "capture the legal relevance of a fact cluster to a claim's merits".

},
	Author = {Ashley, Kevin D. and Rissland, Edwina L.},
	Date-Added = {2013-07-10 22:41:16 +0200},
	Date-Modified = {2013-07-11 01:27:31 +0200},
	Journal = {IEEE Expert},
	Month = {Fall},
	Title = {A Case-Based Approach to Modeling Legal Expertise},
	Year = {1988},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FzaGxleS1yaXNzbGFuZC04OC5wZGbSFwsYGVdOUy5kYXRhTxEB1AAAAAAB1AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHFmFzaGxleS1yaXNzbGFuZC04OC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPM7OAz9xAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADOA3exAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAVU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGFzaGxleS1yaXNzbGFuZC04OC5wZGYAAA4ALgAWAGEAcwBoAGwAZQB5AC0AcgBpAHMAcwBsAGEAbgBkAC0AOAA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hc2hsZXktcmlzc2xhbmQtODgucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AzgDTANsCswK1AroCxQLOAtwC4ALnAvAC9QMCAwUDFwMaAx8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADIQ==}}

@article{Ashley2010,
	Annote = {Three emerging techniques:
1) Machine learning to extend and apply users' hypotheses (theories) of document relevance
2) Hypothesis ontology to generalize user modeling regarding relevance theories
3) Social network analysis to supplement and apply user modeling regarding relevance theories

Relevance hypothesis - aka theory of relevance; is abstract description of subject matter that, if found in a document, would make that document relevant (Hogan et al., 2009). E.g., "There are documents showing that the VP knew that cigarette ads were targeted to children by 1989".

"Ashley and Bridewell (2007) proposed a hypothesis-based, legal information retrieval approach for e-Discovery that lets litigators express their criteria of document relevance in terms of hypotheses about who communicated what to whom, when, and to the extent possible, why." (2)

Uses examples from "TREC Legal Track" materials.

Technique 1: Machine learning
- theory of relevance is tested and can be trained with help of supervised learning but "the authors do not elaborate on the particular machine learning techniques applied" (5).
- SMILE+IBP (Brueninghaus and Ashley,2005) used ML techniques

Technique 2: Hypothesis ontology to generalize relevance theories
- Hypothesis ontology: "a vocabulary of objects (agents) and processes," associated with recurrent areas of interest in e-Discovery such as knowledge transmission in corporate or commercial settings and define[s] the relationships in which these entities can participate.
- "The ontology and framework could also support reasoning about communications and documents, especially if supplemented with information about the social network".

Technique 3: Social network analysis to apply relevance theories
- "Since senders, recipients, and owners of documents identify themselves through email records and the contents of their workspaces, one conceivably can build a model of the network of knowledge and, from that structure, infer something about the likely content and target of the communications {\ldots} map the general flow of knowledge and infer something about the relevance of the content of documents based on who has them, who sent them, and who likely read them." (6)},
	Author = {Ashley, Kevin D. and Bridewell, Will},
	Date-Added = {2013-07-10 22:08:21 +0200},
	Date-Modified = {2013-07-10 22:18:43 +0200},
	Journal = {Journal of Artificial Intelligence and Law, Special Issue on e-Discovery},
	Number = {2},
	Pages = {311-320},
	Title = {Emerging AI and Law Approaches to Automating Analysis and Retreival of Electronically Stored Information in Discovery Proceedings},
	Volume = {18},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0RFU0lfSUlJLktBc2hsZXkucGRm0hcLGBlXTlMuZGF0YU8RAcwAAAAAAcwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxRERVNJX0lJSS5LQXNobGV5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw2yzgM5SwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzgNxiwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFNNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBERVNJX0lJSS5LQXNobGV5LnBkZgAADgAqABQARABFAFMASQBfAEkASQBJAC4ASwBBAHMAaABsAGUAeQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQFVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvREVTSV9JSUkuS0FzaGxleS5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDMANEA2QKpAqsCsAK7AsQC0gLWAt0C5gLrAvgC+wMNAxADFQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMX}}

@inproceedings{Bench-Capon2009,
	Annote = {"{\ldots}studies the use of hypothetical and value-based reasoning in cases concerning the US 4th amendment. {\ldots} semi-formal reconstruction is given of parts of the *Carney* case, which has been studied previously in AI and law research on CBR." For example, Rissland (1989) and Ashley (2008), which are both compared here.

Carney case involved whether a mobile home was subject to the "automobile exception".

"{\ldots}what we have not modelled is references to precedents and heuristics for modifying tests or for generating hypotheticals, which we leave for future work." (10)},
	Author = {Bench-Capon, Trevor and Prakken, Henry},
	Booktitle = {Legal Knowledge and Information Systems. JURIX 2009: The Twenty-Second Annual Conference},
	Date-Added = {2013-07-10 21:35:43 +0200},
	Date-Modified = {2013-07-10 21:37:18 +0200},
	Editor = {Governatori, G.},
	Pages = {11-20},
	Publisher = {IOS Press},
	Title = {A Case Study of Hypothetical and Value-based Reasoning in US Supreme Court Cases},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2p1cml4MDkucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwtqdXJpeDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxCBzgMvwwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzgNoAwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBqdXJpeDA5LnBkZgAOABgACwBqAHUAcgBpAHgAMAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9qdXJpeDA5LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@inproceedings{Prakken2012b,
	Annote = {Shows how ASPIC+ can be used.

"{\ldots}a case study in which an opinion of a legal scholar on a legislative proposal is formally reconstructed in the ASPIC+ framework for argumentation-based inference."

- Carneades [7] is another argumentation-based framework

AF - Abstract Argumentation Framework:
<Args, Def>
Args - set of arguments
Def - subset of Args x Args, shows which args defeat other args
Labellings : Args -> {in,out}
},
	Author = {Prakken, Henry},
	Booktitle = {Legal Knowledge and Information Systems. JURIX 2012: The Twenty-fifth Annual Conference},
	Date-Added = {2013-07-10 21:08:36 +0200},
	Date-Modified = {2013-07-10 21:12:23 +0200},
	Editor = {Schafer, B.},
	Pages = {119-128},
	Publisher = {IOS Press},
	Title = {Formalising a Legal Opinion on a Legislative Proposal in the ASPIC+ Framework},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2p1cml4MTIucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwtqdXJpeDEyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxCDzgMqPQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzgNifQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBqdXJpeDEyLnBkZgAOABgACwBqAHUAcgBpAHgAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9qdXJpeDEyLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@incollection{Alberti2012,
	Annote = {Introduces Deon+, a language where the two basic deontic operators of obligation and prohibition are enriched with quantification over time using ALP (abductive logic programming) and CLP (constraint logic programming).

ALP - a set of programming languages deriving from Logic programming. A distinguished set of predicates called abducibles, do not have definitions but have truth values that can be assumed. ICs (integrity constraints) restrict the set of hypotheses that can be made. They support hypotheticals and have been applied to the event calculus! (12)

CLP - a class of programming languages that allows use, inside a program, of atoms and terms interpreted in a theory external to the program. Many abductive proof procedures are integrated with CLP since "researchers found that CLP was able both to extend the expressivity of ALP in practical applications, and that it helped reducing the search space." (312)


12 - use of ALP with event calculus to show one can solve planning problems simply!
13,19 - "various abductive proof-procedures have been proposed in the past, and they have recently gained significant efficiency."
17 - IFF abductive proof-procedure whose basic transitions are used by Deon+.
7 - the /S/CIFF proof procedures?},
	Author = {Alberti, Marco and Gavanelli, Marco and Lamma, Evelina},
	Booktitle = {Logic Programs, Norms and Action: Essays in Honor of Marek J. Sergot on the Occasion of His 60th Birthday},
	Date-Added = {2013-07-09 22:27:40 +0200},
	Date-Modified = {2013-07-09 22:28:20 +0200},
	Editor = {Artikis, Alexander and Craven, Robert and {\c C}i{\c c}ekli, Nihan Kesim and Sadighi, Babak and Stathis, Kostas},
	Publisher = {Springer},
	Title = {Deon+: Abduction and Constraints for Normative Reasoning},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEwMDdfOTc4LTMtNjQyLTI5NDE0LTMucGRm0hcLGBlXTlMuZGF0YU8RAfAAAAAAAfAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx0xMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjxzzgGSNQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzgHKdQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFxNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgAxMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAOADwAHQAxADAALgAxADAAMAA3AF8AOQA3ADgALQAzAC0ANgA0ADIALQAyADkANAAxADQALQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBJVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy8xMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDVANoA4gLWAtgC3QLoAvEC/wMDAwoDEwMYAyUDKAM6Az0DQgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANE}}

@incollection{Prakken2012,
	Annote = {two recent developments:
- work on preference-based abstract argumentation - he argues these cannot leave the structure of argument and the nature of attack and defeat unspecified.
	- this is based on this formulation of acceptable arguments: "An argument A is acceptable with respect to a set of arguments S if all B defeating A are defeated by a C in S."
	- "{\ldots}in general the choice of preference to resolve an attack depends on the structural nature of the attack, and the problem with PAFs is that they cannot model the structural nature of attacks. Note that the same observations hold for value-based argumentation frameworks and any similar abstract framework for preference-based argumentation." (260)
- work on classical (deductive) argumentation - he argues that these cannot model certain common forms of defeasible reasoning in a natural way.
	- John Pollock, "one of the fathers of our field," gave the negative answer to the question of whether classical / deductive logic could sufficiently define the inference rules with which arguments can be constructed. It is "logically impossible to reason successfully about the world around us using only deductive reasoning."
- His claim is that the ASPIC+ framework does not suffer from these limitations.

"Historically, the formal study of argumentation-based inference mainly originated from research on nonmonotonic logic and logic programming, while it was also influenced by research in AI and Law." (250)
- Defeasible reasoning - unsound reasoning from a certain basis. E.g., quakers are normally pacifists, republicans are normally not, and nixon was a quaker and a republican. A defeasible reasoner is interested in what can be concluded about whether Nixon was a pacifist. Note no inconsistencies, because "normally" is not logically binding!

"[T]he study of argumentation in AI is nowadays very popular, which is good, since our field has a lot of intellectual and application potential {\ldots} However, I feat that if the characteristics of actual argumentation are ignored and the historic roots of our field are forgotten, this potential may not be realised." (267)

63-65: work on deontic logic he's "still proud of"},
	Author = {Prakken, Henry},
	Booktitle = {Logic Programs, Norms and Action: Essays in Honor of Marek J. Sergot on the Occasion of His 60th Birthday},
	Date-Added = {2013-07-09 20:49:49 +0200},
	Date-Modified = {2013-07-09 20:50:28 +0200},
	Editor = {Artikis, Alexander and Craven, Robert and {\c C}i{\c c}ekli, Nihan Kesim and Sadighi, Babak and Stathis, Kostas},
	Publisher = {Springer},
	Title = {Some Reflections on Two Current Trends in Formal Argumentation},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEwMDdfOTc4LTMtNjQyLTI5NDE0LTMucGRm0hcLGBlXTlMuZGF0YU8RAfAAAAAAAfAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx0xMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjxzzgGSNQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzgHKdQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFxNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgAxMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAOADwAHQAxADAALgAxADAAMAA3AF8AOQA3ADgALQAzAC0ANgA0ADIALQAyADkANAAxADQALQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBJVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy8xMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDVANoA4gLWAtgC3QLoAvEC/wMDAwoDEwMYAyUDKAM6Az0DQgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANE}}

@incollection{Dunne2012,
	Annote = {Aims to consider "some aspects relating to computational modelling of persuasive argumentation specifically concerned with emotive techniques" (235)

- one can identify many cases where a combination of devices is used to reinforce particular forms of persuasive argument. 
- "It may be noted that in order for irrational methods to be effective there is a presumption that the audience addressed (or at the very lease some influential sub group within it) is, in fact, actually *susceptible* to such influence." (237)
- Is it desireable to exploit irrational argumentation? 
- Conclusion: "While there is a significant basis for studying computational realisations of such approaches from classical texts on rhetoric through cognitive sciences and aesthetic theories, formal computational treatments of this same issue remain to be fully advanced."},
	Author = {Dunne, Paul E.},
	Booktitle = {Logic Programs, Norms and Action: Essays in Honor of Marek J. Sergot on the Occasion of His 60th Birthday},
	Date-Added = {2013-07-09 19:23:07 +0200},
	Date-Modified = {2013-07-09 20:39:47 +0200},
	Editor = {Artikis, Alexander and Craven, Robert and {\c C}i{\c c}ekli, Nihan Kesim and Sadighi, Babak and Stathis, Kostas},
	Publisher = {Springer},
	Title = {Irrationality in Persuasive Argumentation},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEwMDdfOTc4LTMtNjQyLTI5NDE0LTMucGRm0hcLGBlXTlMuZGF0YU8RAfAAAAAAAfAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx0xMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjxzzgGSNQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzgHKdQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFxNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgAxMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAOADwAHQAxADAALgAxADAAMAA3AF8AOQA3ADgALQAzAC0ANgA0ADIALQAyADkANAAxADQALQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBJVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy8xMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDVANoA4gLWAtgC3QLoAvEC/wMDAwoDEwMYAyUDKAM6Az0DQgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANE}}

@incollection{Bench-Capon2012,
	Annote = {- Often vague terms whose application is not fixed in advance of their use, called 'open textured'.
- Their paper [8] said that in programming open textured terms with logic, approximation (fuzzy logic and probabilities) was not good, rather the adversarial nature of these should be embraced by having competing arguments compared.
- Prakken [39] used argumentation to resolve conflicts between norms in the European Civil Law tradition. Here three ways to evaluate arguments:
	- Prefer the one citing the more specific law
	- Prefer the more recent law
	- Prefer the more authoritative law
- Which argument is more persuasive may not be the same for different people. One approach [16,19] allows values (social purposes) to be ranked, and this ranking allowed for audience modeling.
- VAFs (Value-Based Argumentatino Frameworks)
- EAFs (Extended Argumentation Frameworks) generalize VAFs and allow attacks on attacks.
- Two issues in what make arguments persuasive looked at: Accural, and Degrees of Promotion
- Accrual: Abstract args have attack but no relations of support. One can say that in logic, "supporting" arguments and their support strengths are unnecessary. Alternately, one can create "super-arguments" consisting of all smaller supporting arguments. EAFs allow preferences to accrue. "How to treat accrual remains an importan open issue in computational argumentation, and one which is considerable significance for AI and Law." (229)
- Degrees of promotion: How to measure the amount some value is promoted. Taxation for the greater good vs. individual freedom.
- Conclusion: more work is needed.

51 - cited for definition of term open-textured. Waismann, F.: The Principles of Linguistic Philosophy. St. Martins Press, NY (1965)

35 - citation for EAFs. Modgil, S.: Reasoning about preferences in argumentation frameworks. Artif. In-
tell. 173(9-10), 901--934 (2009)

23 - citation for the "spirit of abstract frameworks", which current attempts to model notions of support in abstract arguments diverges from. Dung, P.M.: On the acceptability of arguments and its fundamental role in non- monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2), 321--358 (1995)},
	Author = {Bench-Capon, Trevor},
	Booktitle = {Logic Programs, Norms and Action: Essays in Honor of Marek J. Sergot on the Occasion of His 60th Birthday},
	Date-Added = {2013-07-09 16:13:06 +0200},
	Date-Modified = {2013-07-09 17:25:45 +0200},
	Editor = {Artikis, Alexander and Craven, Robert and {\c C}i{\c c}ekli, Nihan Kesim and Sadighi, Babak and Stathis, Kostas},
	Publisher = {Springer},
	Title = {Open Texture and Argumentation: What Makes an Argument Persuasive?},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEwMDdfOTc4LTMtNjQyLTI5NDE0LTMucGRm0hcLGBlXTlMuZGF0YU8RAfAAAAAAAfAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx0xMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjxzzgGSNQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzgHKdQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFxNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgAxMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAOADwAHQAxADAALgAxADAAMAA3AF8AOQA3ADgALQAzAC0ANgA0ADIALQAyADkANAAxADQALQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBJVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy8xMC4xMDA3Xzk3OC0zLTY0Mi0yOTQxNC0zLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDVANoA4gLWAtgC3QLoAvEC/wMDAwoDEwMYAyUDKAM6Az0DQgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANE}}

@inproceedings{Indurkhya1997,
	Annote = {Tries to focus on how new "interpretations" are generated to make two legal cases seem analogous.

"{\ldots}our previous work on creative analogies and metaphors, where it is proposed that a new perspective on some object or situation (a *case* for a legal-reasoning system) can result from applying the higher-level description of one object to the low-level description of another object, and the underlying process is that of change of representation." (180)

- He first notes that sometimes new categories are created in order to show that cases are similar or dissimilar. A structured representation is created for the new case, and a precedent is used to support an argument if it is similar *with respect to* this structured representation. (181)
- Sometimes novel ways to categorize are used---existing categories are applied to members which normally aren't seen as belonging to that category.
- Types of mechanisms used:
	- specialization
	- generalization (complement of specialization)
	- split
	- make quantitative into qualitative
	- restructure
	- redefine
- Key features of their model:
	- multi-layered representation for each precedent: bottom is facts, middle-layer contains connective concepts, highest level is ratio decidendi
	- most knowledge is encoded as rules
	- rule can connect concepts on multiple levels (or within levels)
	- generating an argument = coming up with a representation
	- rules intra-level can work forward and backward.
- "We should note that our approach to precedent retrieval is perhaps less efficient than a dimension-based approach [like Ashley 1990's HYPO]. However, we feel that this is the cost one must pay for being able to model creative arguments." (184)

- Previous systems:
	- Cabaret (Rissland and Skalak 1991) and BankXX (Rissland, Skalak, and Friedman 1996)
	- HYPO (Ashley 1990)
	- some others (see sec. 7)
},
	Author = {Indurkhya, Bipin},
	Booktitle = {Proceedings of the Sixth International Conference on Artificial Intelligence and Law},
	Date-Added = {2013-07-08 12:05:13 +0200},
	Date-Modified = {2013-07-08 12:11:27 +0200},
	Title = {On Modeling Creativity in Legal Reasoning},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QUy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0luZHVya2h5YV9MZWdhbF9Jc3N1ZXNfQW5hbG9neV9vcHRpbWl6ZWQucGRm0hcLGBlXTlMuZGF0YU8RAh4AAAAAAh4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx9JbmR1cmtoeWFfTGVnYWxfSXNzdWUjRjEwN0EucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxB6zgAHbgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzgA/rgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAF5NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBJbmR1cmtoeWFfTGVnYWxfSXNzdWUjRjEwN0EucGRmAA4AWgAsAEkAbgBkAHUAcgBrAGgAeQBhAF8ATABlAGcAYQBsAF8ASQBzAHMAdQBlAHMAXwBBAG4AYQBsAG8AZwB5AF8AbwBwAHQAaQBtAGkAegBlAGQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0luZHVya2h5YV9MZWdhbF9Jc3N1ZXNfQW5hbG9neV9vcHRpbWl6ZWQucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A5ADpAPEDEwMVAxoDJQMuAzwDQANHA1ADVQNiA2UDdwN6A38AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADgQ==}}

@article{Schauer2008,
	Annote = {He argues that analogy is different from precedence. It seems he thinks that analogy itself is justification, which as we now know through Bartha, is not the case.

p.11 - "Does the reasoner feel bound to make what he feels is the wrong decision? This is precedence in the legal world, not analogy" [huh?] I think he's saying the ultimate justification of a precedence-based argument comes not from the strength of an analogy, but elsewhere. This I can accept, because I agree with Bartha's model, under whose this author's argument (summarized on p.13) doesn't make sense, because an analogical argument is in fact weakened by contradictory circumstances.

But his argument that an argument by analogy is structured in a way "very different" from one by precedence, p.15, is overstated. But again, he wants to say above all that reasoning by analogy and precedence are not the same, which is fine; precedence is however a justification that depends intimately on analogy.},
	Author = {Schauer, Frederick},
	Date-Added = {2013-07-07 15:45:16 +0200},
	Date-Modified = {2013-07-07 15:47:25 +0200},
	Journal = {Perspectives on Psychological Science},
	Number = {6},
	Pages = {454-460},
	Title = {Why Precedent in Law (and Elsewhere) is Not Totally (or Even Substantially) About Analogy},
	Volume = {3},
	Year = {2008}}

@inproceedings{Schwering2007,
	Annote = {Compares SMT and HDTP

Summarizes their core assumptions / guiding phiosophies as well, e.g. hdtp is mathematically sound, and "we think that the optimal solution for analogy matching is a trade-off between efficiency and expressivity."},
	Author = {Schwering, Angela and Krumnack, Ulf and K{\"u}hnberger, Kai-uwe and Gust, Helmar},
	Booktitle = {2nd European Cognitive Science Conference (EuroCogSci07)},
	Date-Added = {2013-07-07 14:18:26 +0200},
	Date-Modified = {2013-07-07 14:20:23 +0200},
	Pages = {652-657},
	Title = {Analogical Reasoning with SMT and HDTP},
	Year = {2007}}

@inproceedings{Robere2012,
	Annote = {Types of anti-unification and their complexities are on page 6
Notes that the analogical matcher is separate from the re-representation of theories using FOL and deduction},
	Author = {Robere, Robert and Besold, Tarek Richard},
	Booktitle = {AI'12: Proceedings of the 25th Australasian Joint Conference on Advances in Artificial Intelligence},
	Date-Added = {2013-07-07 14:14:15 +0200},
	Date-Modified = {2013-07-07 14:16:41 +0200},
	Title = {Complex Analogies: Remarks on the Complexity of HDTP},
	Year = {2012}}

@inproceedings{Sun1991,
	Author = {Sun, Ron},
	Booktitle = {Proceedings of the 13th Cognitive Science Society Conference},
	Date-Added = {2013-06-15 09:51:23 -0400},
	Date-Modified = {2013-06-15 09:52:38 -0400},
	Pages = {437-442},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Connectionist Models of Rule-Based Reasoning},
	Year = {1991},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4zMS44NTMxICgxKS5wZGbSFwsYGVdOUy5kYXRhTxEB1AAAAAAB1AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHFjEwLjEuMS4zMS44NTMxICgxKS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPGDN4enYAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADN4iIYAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAVU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6ADEwLjEuMS4zMS44NTMxICgxKS5wZGYAAA4ALgAWADEAMAAuADEALgAxAC4AMwAxAC4AOAA1ADMAMQAgACgAMQApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy8xMC4xLjEuMzEuODUzMSAoMSkucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AzgDTANsCswK1AroCxQLOAtwC4ALnAvAC9QMCAwUDFwMaAx8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADIQ==}}

@inproceedings{Sun1995b,
	Author = {Sun, Ron},
	Booktitle = {Proceedings of the International Conference on Artificial Intelligence (IJCAI-95)},
	Date-Added = {2013-06-15 09:48:52 -0400},
	Date-Modified = {2014-01-17 17:23:27 +0000},
	Pages = {424-430},
	Publisher = {Morgan Kaufmann},
	Title = {{A Microfeature Based Approach Toward Metaphor Interpretation}},
	Year = {1995},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS40MS42OTQxLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjQxLjY5NDEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48Zs3h6YYAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM3iIcYAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjQxLjY5NDEucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADQAMQAuADYAOQA0ADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS40MS42OTQxLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@inproceedings{Sammoud2005,
	Annote = {"At each cycle, each ant constructs a matching {\ldots} by iteratively adding couples of vertices {\ldots} the choice of the next couple to be added to m is done with respect to a probability that depends on pheromone and heuristic factors." (sec. 3.3)},
	Author = {Sammoud, Olfa and Solnon, Christine and Gh{\'e}dira, Khaled},
	Booktitle = {5th European Conference on Evolutionary Computation in Combinatorial Optimization (EvoCOP 2005)},
	Date-Added = {2013-06-06 23:35:00 -0400},
	Date-Modified = {2014-01-17 17:23:10 +0000},
	Publisher = {Springer},
	Title = {{An Ant Algorithm for the Graph Matching Problem}},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS43Ny40MTEyLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjc3LjQxMTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48b83WzRwAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM3XBVwAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjc3LjQxMTIucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADcANwAuADQAMQAxADIALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS43Ny40MTEyLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@article{Cunningham2009,
	Annote = {The entire taxonomy:
	Direct Metrics - can be applied to feature-vector representations, dominant strategy
		Overlap
		Minkowski
		Euclidean
		Manhattan
		Value Difference
		KL-Divergence
	Transformation-Based
		Edit distance
		Gene Alignment measures
		Adaption-Guided Retrieval
		Earth Mover distance
		Graph Edit distance
	Information-theoretic
		Compression-based
		GenCompress
	Emergent
		Web-based kernel
		Random forests
		Cluster Kernels

- "The standard methodology in CBR is to represent a case as a feature vector and then to assess similarity based on this"

Three types of representations for cases:
	Feature-value representations - can be intensional (concepts broken down in terms of attributes) or extensional (concepts described in terms of instances, e.g. countries would be: Belgium, Italy, Peru). 
	Structural representations -
		Hierarchical - uses only one link type, the part-of link
		Network (typically a semantic one) - uses multiple link types
		Flow structure - introduces a temporal dimension
	String and sequence representations - data stored as strings (e.g., frequently asked questions, informational websites)

- Li et. al's compression idea says that if two documents "are very similar then the compressed size of the two documents concatenated together will not be much greater than the compressed size of a single document".},
	Author = {Cunningham, Padraig},
	Date-Added = {2013-06-06 23:07:02 -0400},
	Date-Modified = {2013-06-06 23:09:12 -0400},
	Journal = {IEEE Transactions on Knowledge and Data Engineering},
	Number = {11},
	Title = {A Taxonomy of Similarity Mechanisms for Case-Based Reasoning},
	Volume = {21},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3VjZC1jc2ktMjAwOC0xLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSdWNkLWNzaS0yMDA4LTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Spc3WxukAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM3W/ykAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAdWNkLWNzaS0yMDA4LTEucGRmAAAOACYAEgB1AGMAZAAtAGMAcwBpAC0AMgAwADAAOAAtADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3VjZC1jc2ktMjAwOC0xLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@article{Gobet2001,
	Annote = {"This article summarizes the major sources of evidence for chunking within humans, and illustrates how chunking has been incorporated into computational models of human learning."

Two broad areas of literature:
	Goal-oriented chunking: assumes a deliberate, conscious control of chunking process
	Perceptual chunking: assumes a more automatic, continuous process of chunking during perception

A chunk defined: "{\ldots}a collection of elements having strong associations with one another, but weak associations within other chunks."},
	Author = {Gobet, Fernand and Lane, Peter C.R. and Croker, Steve and Cheng, Peter C-H. and Jones, Gary and Oliver, Iain and Pine, Julian M.},
	Date-Added = {2013-06-06 20:45:35 -0400},
	Date-Modified = {2013-06-06 21:01:12 -0400},
	Journal = {TRENDS in Cognitive Sciences},
	Number = {6},
	Title = {Chunking Mechanisms in Human Learning},
	Volume = {5},
	Year = {2001}}

@article{Dorigo2005,
	Author = {Dorigo, Marco and Blum, Christian},
	Date-Added = {2013-05-30 15:06:14 -0400},
	Date-Modified = {2014-01-17 17:21:57 +0000},
	Journal = {Theoretical Computer Science},
	Number = {2-3},
	Pages = {243-278},
	Title = {{Ant Colony Optimization Theory: A Survey}},
	Volume = {344},
	Year = {2005}}

@book{Kulkarni2012,
	Annote = {============================================================
CHAPTER 3: REINFORCEMENT LEARNING
============================================================

Active reinforcement learning - An active agent must decide which action to take
Passive reinforcement learning - There is a fixed policy

Markov property - If the environment at state corresponding to time t+1 only depends on the state and action representation at time t, then the state signal has the Markov property (69)

Model - Represents the knowledge about state transition that can be represented in mathematical form (70)
Model-Free Policies - A controller learns without learning the model
Model-Based Policies - Model is learned and used to derive a controller

Adaptive Dynamic Programming - Combines Dynamic Programming and Reinforcement Learning. 

Q-learning (74):
- Does not estimate a system model, estimates the real-valued function Q:SxA->R of state and actions: Q(x,a)=expected sum of discounted reward for performing action a in state x.

Q(x,a) = E{r_k + \gamma max_b Q(x_{k+1},b) | x_k = x, a_k = a}


============================================================
CHAPTER 7: MULTIPERSPECTIVE AND WHOLE-SYSTEM LEARNING
============================================================
},
	Author = {Kulkarni, Parag},
	Date-Added = {2013-05-29 14:34:06 -0400},
	Date-Modified = {2013-05-29 14:38:27 -0400},
	Publisher = {Oxford : Wiley-Blackwell},
	Title = {Reinforcement and Systemic Machine Learning for Decision Making},
	Year = {2012}}

@article{Boden1995,
	Annote = {http://www.stanford.edu/group/SHR/4-2/text/boden.html

"A scientific account of creativity is possible only if the ideas conveyed metaphorically in Section II can be clearly expressed. Conceptual spaces would have to be precisely identified and mapped, and ways of exploring and changing them (some general, some domain-specific) would need to be explicitly defined.

(In addition, we would need a clear theory of analogical thinking. Analogy plays a large part in "combinatorial" creativity and sometimes, as in the case of Kekul&eacu;, contributes to "impossibilistic" creativity too. Some promising suggestions about how analogies can be recognized, and how they can inform our perception so that we come to see things in a new way, have been offered by Douglas Hofstadter and colleagues.7)"},
	Author = {Boden, Margaret A.},
	Date-Added = {2013-05-26 21:00:56 -0400},
	Date-Modified = {2013-05-26 21:02:03 -0400},
	Journal = {Stanford Humanities Review},
	Number = {2},
	Pages = {123-139},
	Title = {Creativity and Unpredictability},
	Volume = {4},
	Year = {1995}}

@article{Boden2009,
	Annote = {http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/2254

Some dismiss even "apparently creative performance" as a possibility in computers.

P-creative idea: A psychological novelty, that is new *to the person who generated it*.
H-creative: One that is P-creative that hasn't occurred in history before.

"Novel ideas may be produced by combination, by exploration, or by transformation (Boden 2004)".

Combinational - makes associations between ideas that were previously only indirectly linked. "Analogy is a form of combinational creativity that exploits shared conceptual structure and is widely used in science as well as art. {\ldots} combinationlal creativity that is usually mentioned in definitions of 'creativity' and that (almost always) is studied by experimental psychologists specializing in creativity."
Exploratory - Rests on some culturally accepted style of thinking, or "conceptual space"; person moves through the space.
Transformational creativity - The space itself is transformed by "altering (or dropping) one or more of its defining dimensions. As a result, ideas can now be generated that simply *could not* have been generated before the change."

"[T]he vast majority of what H-creative professional artists and scientists do involves exploratory, not transformational, creativity."

"[T]he creativity that's most difficult for AI to model is the combinational type." {\ldots} "But the making os associations doesn't have to be learned: it's a natural feature of associative memory. That's why combinational creativity is the easiest of the three types for human beings to achieve."},
	Author = {Boden, Margaret A.},
	Date-Added = {2013-05-26 20:39:33 -0400},
	Date-Modified = {2013-05-26 20:42:04 -0400},
	Journal = {AI Magazine},
	Number = {3},
	Title = {Computer Models of Creativity},
	Volume = {30},
	Year = {2009}}

@article{Mantaras2005,
	Annote = {Offers perspective on the cog sci foundations of CBR and its relationship to analogical reasoning. 

ON ANALOGY VS CBR:
- "Analogical reasoning research focuses on basic mechanisms such as matching and retrieval, and how those mechanisms are used in other cognitive processes, including reasoning and learning."
- "The centrality of relational information in human similarity judgments is now reasonably well established{\ldots}but it also suggests that CBR and machine learning systems that use feature vectors are unlikely to be good models of human cognition."
- "One of the major differences in approach between CBR and analogy research is their focus on generality." Analogy research considers matching and retrieval to be broadly general cognitive processes, CBR "focuses on creating a system to perform a specific task well on existing computing hardware, and generality is often traded off for efficiency or other performance measures, with an emphasis on *content theories* that reflect the knowledge required for particular task domains." For example, "If the MAC/FAC model is correct, then CBR index-based retrieval schemes would best be viewed as good engineering tools, rather than as cognitive models. This is still an open question."
- Adaptation is a major issue for CBR (but they don't say how analogy treats adaption, presumably they mean to imply that analogical models don't deal with this that much).

},
	Author = {Mantaras, Ramon Lopez de and Mcsherry, David and Bridge, Derek and Leake, David and Smyth, Barry and Craw, Susan and Faltings, Boi and Maher, Mary Lou and Cox, Michael T. and Forbus, Kenneth and Keane, Mark and Aamodt, Agnar and Watson, Ian},
	Date-Added = {2013-05-25 18:29:54 -0400},
	Date-Modified = {2013-05-25 18:44:11 -0400},
	Journal = {The Knowledge Engineering Review},
	Number = {3},
	Pages = {215-240},
	Title = {Retrieval, Reuse, Revision and Retention in Case-based Reasoning},
	Volume = {20},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1MwMjY5ODg4OTA2MDAwNjQ2YS5wZGbSFwsYGVdOUy5kYXRhTxEB1AAAAAAB1AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHFlMwMjY5ODg4OTA2MDAwNjQ2YS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEfbNxrOVAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADNxuvVAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAVU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AFMwMjY5ODg4OTA2MDAwNjQ2YS5wZGYAAA4ALgAWAFMAMAAyADYAOQA4ADgAOAA5ADAANgAwADAAMAA2ADQANgBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9TMDI2OTg4ODkwNjAwMDY0NmEucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AzgDTANsCswK1AroCxQLOAtwC4ALnAvAC9QMCAwUDFwMaAx8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADIQ==}}

@inproceedings{Burstein1989,
	Address = {Pensacola Beach, Florida},
	Annote = {Traditionally analogy was done using the A:B::C:D format

"Analogy has been differentiated from *similarity* along the dimension of type of shared content, by the considering the proportion of shared attributes vs. abstract relational structure in the compared systems {\ldots} This is accentuated when analogies are restricted to "between-domains" analogies, although studies of analogical problem solving in AI have often focused much attention on "within-domain" analogies, much like examples in case-based reasoning."

DIFFERENCES:
- analogy tends to be between-domains, cbr typically within-domain
- "An exact match to a prior situation is treated as the limit of a "good prior case" for a case-based reasoner, and this is not considered to be an analogy at all." (133)
- Some cbr systems require the prior cases be "specific examples of situations, as opposed to generalized concepts or domain principles {\ldots} analogies are often used to map general principles to domains where they were not known to apply previously."
- Kolodner writes that an important distinction is in the strong pragmatic, problem-solving orientation of CBR, as opposed to the broader role of reasoning by analogy in learning and generalization.},
	Author = {Burstein, Mark H.},
	Booktitle = {Proceedings from the Case-based Reasoning Workshop},
	Date-Added = {2013-05-25 18:14:52 -0400},
	Date-Modified = {2013-05-25 18:17:08 -0400},
	Pages = {133-136},
	Title = {Analogy vs CBR: The Purpose of Mapping},
	Year = {1989},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0J1cnN0ZWluLUNCUjg5LnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSQnVyc3RlaW4tQ0JSODkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4+3c3GsIAAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM3G6MAAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAQnVyc3RlaW4tQ0JSODkucGRmAAAOACYAEgBCAHUAcgBzAHQAZQBpAG4ALQBDAEIAUgA4ADkALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0J1cnN0ZWluLUNCUjg5LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@article{Aamodt1994,
	Annote = {gives an "overview of the foundational issues related to case-based reasoning".

"What is case-based reasoning? Basically: To solve a new problem by remembering a previous similar situation and by reusing information and knowledge of that situation." (2)

"Case-based reasoning and analogy are sometimes used as synonyms (e.g. by Carbonell). Case-based reasoning can be considered a form of *intra-domain analogy*. However, as will be discussed later, the main body of analogical research {\ldots} have a different focus, namely analogies across domains." (3)

"Other trails into the CBR field has come from the study of analogical reasoning [Gentner-83]" (4).

Further clarification in types of reasoning (p.6):
- Exemplar-based reasoning - Concepts are defined *extensionally*, as the set of its exemplars. 
- Instance-based reasoning - highly *syntactic* CBR-approach. Representations are usually very simple (e.g. feature vectors), since a major focus is to study automated learning with no user in the loop. "Basically, this is a non-generalization approach to the concept learnin problem".
- Memory-based reasoning - emphasizes collection of large numbers of cases, and reasoning as a process of accessing and searching in this memory.
- Case-based reasoning - general term, but *typical* cbr methods usually have cases with a certain degree of information richness and complexity of organization. They are also usually able to modify a retrieved solution. Also, they typically utilize general background knowledge.
- Analogy-based reasoning - Sometimes a synonym of CBR, but "it is also often used to characterize methods that solve new problems based on past cases from a *different domain*, while typical case-based methods focus on indexing and matching strategies for single-domain cases. {\ldots} The major focus of study has been on the *reuse* of a past case, what is called the mapping problem: Finding a way to transfer, or map, the solution of an identified analogue (called source or base) to the present problem (called target)."

"The representation problem in CBR is primarily the problem of deciding what to store in a case, finding an appropriate structure for describing case contents, and deciding how the case memory should be organized and indexed for effective retrieval and reuse." (11)},
	Author = {Aamodt, Agnar and Plaza, Enric},
	Date-Added = {2013-05-25 16:58:47 -0400},
	Date-Modified = {2013-05-25 17:00:21 -0400},
	Journal = {AI Communications},
	Number = {1},
	Pages = {39-59},
	Title = {Case-based Reasoning: Foundational Issues, Methodological Variations, and System Approaches},
	Volume = {7},
	Year = {1994},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xNS45MDkzLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjE1LjkwOTMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48Wc3Gno8AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM3G1s8AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjE1LjkwOTMucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADEANQAuADkAMAA5ADMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xNS45MDkzLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@article{Watson1994,
	Abstract = {http://www.ai-cbr.org/classroom/cbr-review.html

CBR does not address certain problems directly:
	- it doesn't require an explicit domain model, and so elicitation becomes a task of gathering case histories
	- implementation is reduced to identifying significant features that describe a case, an easier task than creating an explicit model,
	- by applying database techniques largely volumes of information can be managed, and
	- CBR systems can learn by acquiring new knowledge as cases thus making maintenance easier. 

"The work Schank and Abelson in 1977 is widely held to be the origins of CBR. They proposed that our general knowledge about situations is recorded as *scripts* that allow us to set up expectations and perform inferences. {\ldots} [Simultaneously, Gentner] was developing a theoretical framework for analogy which also has relevance to CBR."

CBR Cycle:
	- Retrieve most similar cases
	- Reuse the cases to attempt to solve
	- Revise the proposed solution if necessary, and
	- Retain the new solution as part of a new case.

THE CASE FOR CASE-BASED REASONING
"In *second generation* systems [Clancey 1985] a *deep* underlying causal model exists that enables the system to reason from first principles in its application domain. {\ldots} However, as identified in section 1 there are five major problems with this approach:
- knowledge elicitation is difficult
- KBS [knowledge base systems?] can be very complex and can take many man years to develop,
- KBS are frequently slow,
- KBS are often poor at managing large volumes of information, and
- Once developed they are difficult to maintain."


"CBR systems can be built where a model does not exist, this is also well demonstrated by the CLAVIER system."
Clavier system was the first commercially fielded CBR application, out of Lockheed, Palo Alto. "{\ldots}the autoclave's heating characteristics are not fully understood (i.e., there is no model that operators can draw upon)." This is what the authors mean by CLAVIER being able to apply CBR when there isn't a model, rather than meaning that there is no idea how to represent the knowledge in a way that removes structure-matching.

"{\ldots}there are also sensitive problems that face CBR including:
- how cases should be represented,
- how indices should be chosen for organizing memory efficiently,
- how to structure relationships between cases and parts of different cases,
- how to handle cases containing multimedia,
- how to handle massive case-bases, and
- how to develop general adaptation heuristics for modifying previous cases or their solutions to fit new cases."},
	Author = {Watson, Ian and Marir, Farhi},
	Date-Added = {2013-05-24 23:28:38 -0400},
	Date-Modified = {2013-05-25 16:42:42 -0400},
	Journal = {The Knowledge Engineering Review},
	Number = {4},
	Pages = {327-354},
	Title = {Case-based Reasoning: A Review},
	Volume = {9},
	Year = {1994}}

@book{Riesbeck1989,
	Annote = {9-14 was given as an example of how the field of CBR already has explored the tailorability concern in depth

- "We retrieve a prior case from memory, attempt to determine its relevance, and decide what to do, based upon what happened in that case. That is what I have called case-based reasoning." (11)
- "If a system knows only one case, it is more likely to come up with something new than if it has had many experiences and has generalized them. In a sense, you can only be creative if you know very little. {\ldots} While it seems clear that to a large extent people do become les creative the more they do the same thing in the same way, it also seems quite clear that there are experts in the world who have had many experiences and are still quite capable of new insights about those experiences. The claim is that those people depend upon stories." (13)
- "To put this another way, creativity depends upon our ability to analyze incoming stories effectively. The more content, the more varied the possible analyses and the more possible it is to find germane indexes" (14).

- "The basic idea in case-based reasoning is simple: A case-based reasoner solves new problems by adapting solutions that were used to solve old problems. {\ldots} A case-based reasoner:
- finds those cases in memory that solved problems similar to the current problem, and
- adapts the previous solution or solutions to fit the current problem, taking into account any difference between the current and previous situations.
Finding relevant cases involves
- characterizing the input problem, by assigning the appropriate features to it,
- retrieving the cases from memory with those features,
- picking the case or cases that match the input best." (25)

- "Creativity does not arise during normal planning. When first solving a problem, the average planner does not look for the most optimal, cleverest solution. The planner instead adapts an old solution that was used for a problem most like the current one. One cannot afford to be clever all the time. It makes sense to wait until it is apparent that cleverness is *required*. It is during *replanning* that creativity is most called for, and it is in this stage that we would expect to see novel plans invented.
{\ldots}
The *hard* part of fixing problems is knowing where the problems lie. This is why it makes more sense for a planner to wait until they show up, and apply his knowledge of how to fix them at that point, than to try to employ that knowledge in the first place, with the aim of preventing any problem that could in principle be avoided given his current knowledge." (290)

The book seems to make no mention of analogy, forbus, gentner, hofstadter, anything. It was published in 1989 though.},
	Author = {Riesbeck, Christopher K. and Schank, Roger C.},
	Date-Added = {2013-05-24 11:00:46 -0400},
	Date-Modified = {2013-05-24 11:25:46 -0400},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Inside Case-based Reasoning},
	Year = {1989}}

@incollection{Bringsjord2003,
	Annote = {CRA - chinese room argument

"In this chapter we attempt some philosophical jujitsu against those who think real robots spell trouble for CRA: we show how real robots can be used to *strengthen* CRA."
- They aim to show first that the current version of the robot reply stands, and current robots have only created zombie animals (zombanimals).
- They also build the "missing thought experiment" Searle looked for that was a version of the CRA immune from the original robot and system replies.

CC - Necessarily, if x is a system of suitably configured computation, then x has genuine mental states, which include phenomenal consciousness.
TT - turing test

if CRA is sound, then (not CC) and (not TT)	

S - entire system
O - observers on the outside
P - person inside

A robot is engineered to see "Smuddas". They argue that Harnad's argument fails, because there is still a jump from "seeing" one level of description (the squiggles that are output by the transducers) and "understanding" what they picture (the smudda).

},
	Author = {Bringsjord, Selmer and Noel, Ron},
	Booktitle = {Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence},
	Date-Added = {2013-05-23 22:33:44 -0400},
	Date-Modified = {2013-05-23 22:38:29 -0400},
	Editor = {Preston, John M. and Bishop, Michael A.},
	Publisher = {Oxford University Press},
	Title = {Real Robots and the Missing Thought-experiment in the Chinese Room Dialectic},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4zMi4zNzc3LnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjMyLjM3NzcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48Ys3ESe0AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM3Egi0AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjMyLjM3NzcucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADMAMgAuADMANwA3ADcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4zMi4zNzc3LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@article{Sun2012b,
	Annote = {Mentions episodic memory

"[A] non-memory-centered way of looking at memory is needed to better understand it from the standpoint of cognitive agents' essential activities" (227). "We cannot simply study memory by exhaustively testing what it is capable of" (228). He wants to view memory systems as functional modules and go from there.

Briefly argues that memory's properties will likely exist only if it contributes to an agent's essential activities, and the variety of agent activities suggests there may be many types of memory with corresponding properties.

"[D]eclarative (non-action-centered) memory may be further partitioned into semantic memory and episodic memory {\ldots} Semantic memory is used for storing general (non-action-centered) knowledge that is not tied to specific experiences, while episodic memory is for storing experience-specific information." (230)

In figure 2, the outside world cannot directly write to the NACS, this is done thorugh the ACS. Also, there doesn't seem to be anything connected to episodic memory (this might just be a limitation of the graphic though).

Evidence in support of hypothesis that declarative memory is divided into semantic and episodic:
	- There are clear functional differences between them (235).
	- The rest he cites other papers
	- Regarding the distinction between episodic top and bottom levels:
		- Explicit episodic memory is "relatively speaking, well established {\ldots} includes spatial and temporal information about events and activities [and] constitutes an explicit personal memory (or "self-referential memory")" (235)
		- Implicit episodic memory "may be used for keeping statistics extracted from actual experiences {\ldots} [and] is formed through transforming available information in a way that enables rabid[sic] supply of needed information {\ldots}" (235)
		- Derived memory (which is the type of memory the implicit episodic memory is) is formed on the basis of:
			a) predictability - it should lead to successful anticipation of likely future use of information
			b) importance - the cost of the derived memory should be justified by the value of the prediction
			c) urgency - the information may need to be accessed in a rapid fashion
			d) economy - the number of judgements supported by the derived memory should be large enough compared with the size of the memory

Accounting for synergy between implicit and explicit declarative memory:
	- Artificial grammar learning studies may be evidence of this (Sun and Matthews 2005)
	- SBR and RBR


Sun and Matthews 2005 - example of learning using NACS and grammar experiment. Does it mention episodic memory? No, it doesn't.
Exploring the interaction of implicit and explicit processes to facilitate individual skill learning.},
	Author = {Sun, Ron},
	Date-Added = {2013-05-20 21:58:29 -0400},
	Date-Modified = {2013-05-20 22:17:23 -0400},
	Journal = {New Ideas in Psychology},
	Pages = {227-240},
	Title = {Memory Systems within a Cognitive Architecture},
	Volume = {30},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1MwNzMyMTE4WDExMDAwNzI5Lmh0bWzSFwsYGVdOUy5kYXRhTxEB1AAAAAAB1AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHFlMwNzMyMTE4WDExMDAwNzI5Lmh0bWwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEfrNwEtOAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADNwIOOAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAVU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AFMwNzMyMTE4WDExMDAwNzI5Lmh0bWwAAA4ALgAWAFMAMAA3ADMAMgAxADEAOABYADEAMQAwADAAMAA3ADIAOQAuAGgAdABtAGwADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9TMDczMjExOFgxMTAwMDcyOS5odG1sABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AzgDTANsCswK1AroCxQLOAtwC4ALnAvAC9QMCAwUDFwMaAx8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADIQ==}}

@incollection{Hofstadter1995,
	Annote = {Good description of the copycat project, but the fuller citation is Mitchell 1993.

Copycat has the ability to change how it "views" objects, so it might see the string "abcc" as a string of four letters, or as two letters followed by a group, or as a single group, etc. 

Three major components of Copycat's architecture
(1) Slipnet - the "site of all permanent Platonic concepts", its LTM that contains only concept TYPES and no TOKENS. Concepts can undergo slippage to go from one to another. 
	- Each concept has an explicit core, which "is a crucial element of the architecture." (215) So his concepts lie somewhere between those in localist (single node) and connectionist architectures.
	- Concept halos change "in response to a temporary context, and when that context is removed, the Slipnet tends to revert to its "normal" state." (216) 
	- The slipnet does not retain changes from run to run or create new permanent concepts. "Thus Copycat does not model learning in the usual sense [, unless] that term is taken to include the notion of adaptation of one's concepts to novel contexts." (216)
(2) Workspace - the "locus of perceptual activity" containing instances of concepts from the Slipnet combined into temporary perceptual structures.
	- When a set of objects has common fabric/bond type, it might be "chunked" into a higher-order object called a group (218). The groups themselves get properties just like objects, and even higher-level chunking can happen. This is how structure is found.
(3) Coderack - like a waiting room in which experts that carry out tasks in the workspace can be called, but they are done so stochastically only.
	- contains codelets, which is a tiny part of a run. Every one of the actions that operate on the other components are effector codelets. Scout codelets "looks at a potential action and tries to estimate its promise" (221). There are bottom-up and top-down ones.
	- pressures determine the speeds of rival processes
	- codelets are constantly removed and replaced on to the coderack

- "One of the central goals of the Copycat architecture is to allow many pressures to simultaneously coexist, competing and cooperating with one another to drive the system in different directions." (224)
- There is a measure of "temperature" that allows the system to start out not caring which order codelets are run in, and over time becoming more "closed-minded". The degree of randomness in decision making is controlled by this temperature variable(s). (228) It can also be sort of a measure of the final analogy's quality (236).
- Randomness vs fluidity: 
	- He argues that the mind effectively carries out asynchronous computing; the different codelets operate in "entirely random [order] relative to one another" (232).
	- "Fluidity is an emergent quality, and to simulate it accurately requires an underlying randomness." (233)},
	Author = {Hofstadter, Douglas R. and Mitchell, Melanie},
	Booktitle = {Fluid concepts and creative analogies: computer models of the fundamental mechanisms of thought},
	Date-Added = {2013-05-19 00:55:20 -0400},
	Date-Modified = {2013-05-19 04:14:27 -0400},
	Editor = {Hofstadter, Douglas R. and the Fluid Analogies Research Group},
	Publisher = {Basic Books, Inc},
	Title = {The Copycat Project: A Model of Mental Fluidity and Analogy-making},
	Year = {1995}}

@incollection{Dehghani2011,
	Annote = {- Their system MoralDM combines utilitarian and deontological moral decision-making
- Uses natural language understanding system to "semi-automatically" (explained on p.426) create representations (422) and reduce tailorability
- Combines first-principles and analogical reasoning
- Sacred/protected values block utilitarian motives (423)
- Uses FIRE for reasoning and Cyc as knowledge base, EANLU for NLP
- Simple method of combining decisions of different modules (426)
- The entire freaking article reads like alphabet soup; there are so many subsystems and initialisms
- They were able to successfully replicate some answers in human experiments
- I think the most relevant contribution here is the ADR-like combination of first-principle and analogical reasoning in a module-like way that I wanted to do as well (and came up with before I read this paper). Our system will have a wider variety of reasoning types than this one.},
	Author = {Dehghani, Morteza and Forbus, Ken and Tomai, Emmett and Klenk, Matthew},
	Booktitle = {Machine Ethics},
	Chapter = {18},
	Date-Added = {2013-05-18 01:51:05 -0400},
	Date-Modified = {2013-05-18 01:55:45 -0400},
	Editor = {Anderson, Michael and Anderson, Susan Leigh},
	Publisher = {Cambridge University Press},
	Title = {An Integrated Reasoning Approach to Moral Decision Making},
	Year = {2011}}

@incollection{Bringsjord2011b,
	Annote = {- "[T]he approach is to engineer ethically correct robots by giving them the capacity to reason *over*, rather than merely *in*, logical systems {\ldots} by taking seriously Piaget's position that sophisticated human thinking exceeds even abstract processes carried out in a logical system, and by exploiting category theory{\ldots}" (361)
- Danger "{\ldots}if a lethal agent is unable to engage in at least something close to sophisticated human-level ethical reasoning and decision making and instead can only operate at Piaget's fourth stage {\ldots} [things will] go horribly awry" (366)
- "The approach that *won't* get us killed {\ldots} is to control robot behavior by operations over an ensemble of suitably stacked logical systems{\ldots}" (366)
- Category theory can reason over logics (it treats them as categories) so it's a useful formalism towards this goal.},
	Author = {Bringsjord, Selmer and Taylor, Joshua and van Heuveln, Bram and Arkoudas, Konstantine and Clark, Micah and Wojtowicz, Ralph},
	Booktitle = {Machine Ethics},
	Chapter = {20},
	Date-Added = {2013-05-18 01:46:15 -0400},
	Date-Modified = {2013-05-18 01:48:55 -0400},
	Editor = {Anderson, Michael and Anderson, Susan Leigh},
	Publisher = {Cambridge University Press},
	Title = {Piagetian Roboethics via Category Theory : Moving beyond Mere Formal Operations to Engineer Robots Whose Decisions Are Guaranteed to be Ethically Correct},
	Year = {2011}}

@incollection{Guarini2011,
	Annote = {Two possible reasons for modeling ethics computationally: (1) human interaction purposes and (2) to better understand ethics, this paper focuses on the second reason.
Generalists - Tend to stress importance of rules, principles, standards
Particularists - stress individual cases instead
- they disagree about whether moral rules or individual cases are "normatively prior" (for purposes of justification of moral actions)
- Guarini wants to walk the line in between the two
- Pre-reflective processes are by dedinition non-inferential, at least not explicitly or consciously. Initial classification is pre-reflective (330).
- "It could very well be that sometimes we are inferring principles from an examination of cases, and sometimes we are inferring cases from an examination of principles" (331)
- He separates the pre-reflective (quick, non-inferential) classification processes from the reflective (inferential, explicit) ones, but emphasizes the need to study their interaction (333)},
	Author = {Guarini, Marcello},
	Booktitle = {Machine Ethics},
	Chapter = {18},
	Date-Added = {2013-05-16 15:07:04 -0400},
	Date-Modified = {2013-05-16 15:09:18 -0400},
	Editor = {Anderson, Michael and Anderson, Susan Leigh},
	Publisher = {Cambridge University Press},
	Title = {Computational Neural Modeling and the Philosophy of Ethics: Reflections on the Particularism-Generalism Debate},
	Year = {2011}}

@incollection{McLaren2011,
	Annote = {http://www.cs.cmu.edu/~bmclaren/pubs/McLaren-CompModelsEthicalReasoning-MachEthics2011.pdf

Review of computational models of ethical reasoning

"[E]thical reasoning is based on abstract principles that cannot be easily applied in formal, deductive fashion. Thus the favorite tools of logicians and mathematicians, such as first-order logic, are not applicable." (297)

Systems described here:

Ethos System - one of the earliest, designed to help students work through ethics problems (Searing 1998)

Dax Cowart Program - like Ethos system in purpose, but multimedia, and focuses only on the 'Dax Cowart' case.

Jeremy - (anderson et al. 2005a) based on Bentham's Hedonistic Act Utilitarianism, calculates "total net pleasure".

W.D. - newer version of jeremy, based on W.D. Ross's philosophy

MedEthEx - Similar to W.D. except it uses medical ethics

HYPO - (Ashley 1990)

PETE - (Goldin et al. 2001) Software tutor that leads students step-by-step to prepare cases for class discussion

TruthTeller (author's own)
	- Designed to accept a pair of ethical dilemmas, outputs the similarities and differences between them from ethical and pragmatic perspectives.
	- Seems to use something like case-based reasoning, but he says it's based on 'Casuistry'
	- Uses questions and dilemmas based on the game of Scruples
	- Process involves 'alignment' which looks like structural alignment, and then identifies important parts of the argument, presenting these results using some natural language generation.

SIROCCO (second program by the author)
	- Accepts one ethical dilemma, returns other cases and ethical principles that may be relevant to the current case
	- provides the basic information "with which a human reasoner {\ldots} could answer an ethical question and then build an argument or rationale for that conclusion"
	- Input is in a standardized language called Engineering Transcription Language (ETL)  http://www.cs.cmu.edu/~bmclaren/ethics/


- "The view that runs throughout the author's work is that reaching an ethical conclusion is, in the end, the obligation of a *human* decision maker. {\ldots} In other words, the programs are intended to stimulate the "moral imagination"".
- "Both the Truth-Teller and SIROCCO projects are focused and rely heavily on a [heavily standardized] knowledge representation of ethics, in contrast to, for instance, the programs of Anderson et al., which have little reliance on representation."},
	Author = {McLaren, Bruce M.},
	Booktitle = {Machine Ethics},
	Chapter = {17},
	Date-Added = {2013-05-10 02:28:44 -0400},
	Date-Modified = {2013-05-10 04:43:20 -0400},
	Editor = {Anderson, Michael and Anderson, Susan Leigh},
	Pages = {297-315},
	Publisher = {Cambridge University Press},
	Title = {Computational Models of Ethical Reasoning: Challenges, Initial Steps, and Future Directions},
	Year = {2011}}

@inproceedings{Colhoun2009,
	Address = {Sofia, Bulgaria},
	Annote = {Response to Lee2008.

Reminds us that whereas a lineup with generative causal relationships increases the perceived likelihood of the analogically transferred effect being true, Lee and Holyoak showed that preventative causal relations *decrease* the strength of an effect inference.

Whereas Lee and Holyoak want to incorporate the causal model as part of the analogical one, Lee and Gentner disagree and say that the causal model is used to separately "reason through the (newly imported) causal relations in the target domain and to evaluate the analogical inferences after the mapping is completed." (3) They want this evaluation to be a separate step, and the SME model presented in this paper demonstrates it's possible for the causally-motivated inference evaluation to be outsourced to a post-analogical process.

"Our assertion is that analogy does not explain everything, or should it. If other reasoning processes explain causal inferences adequately, even when reasoning from causal analogies, there's no parsimonious reason to suppose that analogical processing models should be adapted to do their job. In sum, analogy is important for learning about novel causal systems, but models of analogy need not subsume causal inferencing processes." (13 / 94)},
	Author = {Colhoun, Julie and Gentner, Dedre},
	Booktitle = {Proceedings of the Second International Conference on Analogy},
	Date-Added = {2013-05-10 01:23:42 -0400},
	Date-Modified = {2013-05-10 01:30:09 -0400},
	Editor = {Kokinov, Boicho N. and Holyoak, Keith J. and Gentner, Dedre},
	Title = {Inference Processes in Causal Analogies},
	Year = {2009}}

@inproceedings{Lee2009,
	Address = {Sofia, Bulgaria},
	Annote = {http://www.academia.edu/188824/Integrating_analogical_inference_with_Bayesian_causal_models

Talks about assigning "meaning" to the causal relations in models of analogy, rather than treating them as just additional higher-order relations. This model integrates "analogical reasoning with probabilistic inference, deriving probabilities for analogical inferences."},
	Author = {Lee, Hee Seung and Holyoak, Keith J. and Lu, Hongjing},
	Booktitle = {New Frontiers in Analogy Research: Proceedings of the Second International Conference on Analogy},
	Date-Added = {2013-05-10 00:52:44 -0400},
	Date-Modified = {2013-05-10 00:54:15 -0400},
	Title = {Integrating Analogical Inference with Bayesian Casual Models},
	Year = {2009}}

@inproceedings{Lee2008,
	Address = {Austin, TX},
	Annote = {http://csjarchive.cogsci.rpi.edu/proceedings/2008/pdfs/p297.pdf
http://www.academia.edu/188822/Absence_makes_the_thought_grow_stronger_Reducing_structural_overlap_can_increase_inductive_strength

Cited by Bartha as saying why increased systematicity doesn't always translate into greater inductive strength, directly attacking Gentner's theory (if we believe inductive strength , or potential for generalization, is necessary for analogy)
This paper has a response by Colhoun and Getner (2009?).

Experiment 1 shows that "reducing analogical overlap by eliminating a higher-order causal relation {\ldots} from the target *increased* inductive strength even though it *decreased* similarity of the analogs." They "confirm that people do not simply focus on the number of correspondences between a source and target; rather, they consider the *meaning* of causal relations, and in particular whether causes are generative or preventative."

Experiment 2 extends these to cross-domain analogical inferences

"Analogical inference appears to be mediated by building and then `running' a causal model"

"Recently, Lee and Holyoak (2007) examined the role of causal models in analogical inference by testing a hypothesis proposed by Bartha [, who] distinguished between *contributing* causes (generative) and *counteracting* causes (preventative) in evaluating the strength of analogical arguments. He pointed out that eliminating from the target a counteracting cause present in the source might actually strengthen an argument from analogy."

},
	Author = {Lee, Hee Seung and Holyoak, Keith J.},
	Booktitle = {Proceedings of the Thirtieth Annual Conference of the Cognitive Science Society},
	Date-Added = {2013-05-09 23:48:37 -0400},
	Date-Modified = {2013-05-10 00:39:02 -0400},
	Editor = {Sloutsky, V. and Love, B. and McRae, K.},
	Organization = {Cognitive Science Society},
	Title = {Absence Makes the Thought Grow Stronger: Reducing Structural Overlap Can Increase Inductive Strength},
	Year = {2008}}

@article{Bringsjord2008c,
	Annote = {==========================
Section 1 / 2 : Background
==========================

- "Let's all face up to the reality that the logic-based approach {\ldots} to building artificial counter parts to you and me is self-sustaining, self-contained, and too-long trammeled by unstructured, sub-symbolic approaches that now need to simply be left to fend for themselves."
- LAI is distinguished by three hallmarks:
	Ambitious - it wants to build artificial persons
	Logical Systems - It is based on the formalization of people as bearers of propositional attitudes (believes, knows, etc) and reasoning over that, achieved using logical systems. Logical systems consist of 6 elements:
		(1) an alphabet A, invariant across the logical system for any application area (can consist of predicate symbols, etc)
		(2) grammar G defined over A
		(3) Argument theory, or proof theory if reasoning is deductive in nature
		(4) Argument semantics specifying the meaning of inferences from (3)
		(5) Formula semantics, assigns meaning to symbols
		(6) Metatheory defining attributes over the previous 5 things (e.g. soundness, decidability{\ldots})
	Top-down - doesn't focus on physical stuff or "stage-one" transduction (note: in direct disagreement with Brooks), to the exclusion of lower-level processes and formalisms. It starts by immediately tackling that which is distinctive of persons (e.g. propositional attitudes) without wasting dwelling on the adventitious embodiment of cognition in particular physical stuff, i.e. stage-one transduction.
- "[L]ogic is the science of rigorous reasoning, and that reasoning comes in the following additional modes, at the very least: inductive, abductive, defeasible, analogical, and visual. AI work that leverages or at least takes profitable account of all these and other modes is most appropriate for supporting my manifesto. {\ldots} Logic-based AI, as I define and defend it herein, takes account of *all* logic."
- LAI can be seen as the field devoted to capturing seven capacities simultaneously in a computationally implemented logical system: (1) to will, choose, plan, etc. autonomously; (2) to have subjective consciousness; (3) to have self-consciousness; (4) to communicate through language; (5) to know, and have beliefs that are first, second, third order and so on; (6) to desire objects, events, and changes in its own character; and (7) to reason (p.3)
- "{\ldots}some today use the term `reasoning' in heterodox fashion, using such phrases as "Bayesian reasoning" to refer to probabilistic *calculation*. Calculation is not surveyable reasoning." Surveyable reasoning is that in which each inference can be independently inspected and certified (footnote, p.10)
- There is a "three-part cycle" that goes: updating of the (agent's understanding of the) environment, reasoning, and actions (which might change the environment)
- Two categories of logical systems: mathematical logic (those used for formalizing purely mathematical stuff) and philosophical logic (which has psychological dimensions).

==========================
Section 3: Factors Supporting LAI as an Independent Field
==========================

- Five arguments: 
- History supports the divorce. Reasoning gave birth to computation, and "there is no information processing-based aspect of personhood beyond the reach of logic to simulate, and hence no need of non-logic to capture intelligence" ? this is where I think Selmer ignores the issue of practicality, which is a major driving factor in so many technological advances.
- The advent of the web. It is increasingly representing knowledge in logical systems.
- The remarkable effectiveness of logic. For rigorousness, effectiveness, clarity, etc., logic is unbeatable
- Logic Top to Bottom Now Possible. "We are now beginning to see that logic can be all-encompassing. Even dynamic perception and action can be systematically logic-based. Of course, this is simply an assertion, and the proof, I admit, is in the pudding."
- Learning and Denial. "What has been called `learning' in AI simply isn't." He argues that extracting mathematical functions (as machine learning does) isn't learning; we use logic-based formalisms and careful reasoning over the representations in them in learning.
- Logic is an antidote to "cheating" in AI. Cheating happens when their systems don't create argument-based justifications, including justifications that are full-blown proofs. 
- Logic is our only hope against the dark AI future. Similar to previous point; but focuses more on how logic-based AI can create ethical robots.

==========================
Section 4: Objections; Rebuttals
==========================

- Logic is already treated as separate, so this paper is superfluous, or LAI doesn't need to be separate. Selmer responds that splits often take place "because of a difference in methodologies and formalisms, and having an objective in common failed to keep the marriage intact." He similarly replies that these splits are often not collapsible (consider psychology and philosophy).
- You're neglecting probabilistic AI. 
	- He acknowledges Bayesian nets may allow for some more efficient calculations, but he asks what does this have to do with his call for logicist independence? Claims that probabilistic / other approaches can do some things well shouldn't erase the need for all of LAI. Side note: let's make sure not to go too far in the other direction and claim just because everything can be modeled using logical formalisms, we should do away with probabilistic approaches.
	- Furthermore, Bayesian approaches, for example, use a subset of what logicist AI can express.
- The mind is continuous, and therefore dynamical systems are superior. Selmer seems to argue again that the arguments put forward by Spivey (associated with Dynamical systems here) are not relevant to the central claim of this paper, that LAI should be separate.
- Surely, human-level cognition is *partly* sub-symbolic. Selmer acknowledges that maybe toddlers might use some automatic, non-deliberative process, but they still need logic as they grow. 
	TRANSDUCTION: "the translation of raw data from the environment into logicist form." (p. 27) Stage 1 is sensory data stuff, stage 2 is when it's turned into declarative representations in some logical system (which is, in general, "not a conscious process, but at least in principle it can be. As such, it is a process that can itself be carried out by reasoning; hence, naturally enough, the reasoning can be captured in a logical system.")
	- He is "happy to concede that stage-one transduction may best be mechanized in non-logicist ways." But hl-intelligence CAN EXIST without any physical interaction between the creature and its outside environment at the level of stage-one transduction.
	- What concrete benefits flow from divorce? Selmer asks why any field is ever separate, and it has to do with something that is only attainable if it is separate. This something, with LAI, is "unification of logicist activities in service of reaching the ultimate goal: building a person." Logicist experts exist who are doing different things, but if they unite towards this common goal we might have benefit.},
	Author = {Bringsjord, Selmer},
	Date-Added = {2013-05-06 20:51:07 -0400},
	Date-Modified = {2014-08-11 13:29:34 +0000},
	Journal = {Journal of Applied Logic},
	Pages = {502-525},
	Title = {The Logicist Manifesto: At Long Last Let Logic-Based AI Become a Field Unto Itself},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1NCX0xBSV9NYW5pZmVzdG9fMDkxODA4LnBkZtIXCxgZV05TLmRhdGFPEQHoAAAAAAHoAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcbU0JfTEFJX01hbmlmZXN0b18wOTE4MDgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SHs2tx8MAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM2uAAMAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBaTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAU0JfTEFJX01hbmlmZXN0b18wOTE4MDgucGRmAA4AOAAbAFMAQgBfAEwAQQBJAF8ATQBhAG4AaQBmAGUAcwB0AG8AXwAwADkAMQA4ADAAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAR1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvU0JfTEFJX01hbmlmZXN0b18wOTE4MDgucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOANMA2ADgAswCzgLTAt4C5wL1AvkDAAMJAw4DGwMeAzADMwM4AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAzo=}}

@inproceedings{Lovett2010,
	Annote = {http://www.spatiallearning.org/publications_pdfs/CogSci10_Ravens_Final.pdf

One of the key works in strengthening their claim to surpassing the TC.

Uses Raven's Progressive Matrices (Raven, Raven, and Court, 2000)
"Though RPM is a visual task, performance on it correlates highly with other assessment tasks, many of them non-visual", the implication being that it uses skills beyond spatial reasoning.

This builds on their previous works on the RPMs (Lovett, Forbus, & Usher 2007) because it's more sophisticated.
"Like before, all inputs are automatically computed from vectorized input {\ldots} Spatial representations are automatically generated using the CogSketch (Forbus et al., 2008) sketch understanding system."
"There are two ways of providing input to CogSketch. A user can either draw out a sketch within CogSketch, or import a set of shapes created in PowerPoint. In either case, it is the user's responsibility to segment an image into objects---CogSketch does not do this automatically. Essentially, the user is performing part of the job of perceptual organization{\ldots}" (3)
CogSketch then tries to form relations between the objects in the sketch automatically, forming hierarchies, etc.

Model based on 1991 finding that "people generally begin solving a matrix problem by comparing adjacent pairs of images in each row of the problem" (4).
Creates a *pattern of variance*, which represents how the objects change across a row of images. SME then does second-order comparison between top two rows, rates their similarity. Build generalization representing what is common to the rows, then look for an answer that fits this role in the third row.

Results:
44/48 problems solved correctly (equivalent to 56/60 on overall test, which matches "the performance of above-average American adults on the Standard Progressive Matrices").},
	Author = {Lovett, Andrew and Forbus, Kenneth and Usher, Jeffrey},
	Booktitle = {Proceedings of CogSci},
	Date-Added = {2013-04-24 16:01:52 -0400},
	Date-Modified = {2013-04-24 16:03:34 -0400},
	Title = {A structure mapping model of {Raven's Progressive Matrices}},
	Volume = {10},
	Year = {2010}}

@article{Lovett2009,
	Annote = {Cited by Gentner as an example of "automatic spatial encoding of sketched materials", a possible answer to the TC.},
	Author = {Lovett, A. and Gentner, D. and Forbus, K. and Sagi, E.},
	Date-Added = {2013-04-17 19:01:01 -0400},
	Date-Modified = {2013-04-17 19:02:21 -0400},
	Journal = {Cognitive Systems Research},
	Pages = {216-228},
	Title = {Using analogical mapping to simulate time-course phenomena in perceptual similarity},
	Volume = {10},
	Year = {2009}}

@inproceedings{Govindarajulu2013,
	Author = {Govindarajulu, Naveen S. and Licato, John and Bringsjord, Selmer},
	Booktitle = {Unconventional computation and natural computation - 12th international conference (UCNC 2013)},
	Date-Added = {2013-04-16 02:16:47 -0400},
	Date-Modified = {2013-07-07 14:26:40 +0200},
	Editor = {Mauri, Giancarlo and Dennunzio, Alberto and Manzoni, Luca and Porreca, Antonio E.},
	Pages = {102-112},
	Title = {Small Steps Toward Hypercomputation via Infinitary Machine Proof Verification and Proof Generation},
	Year = {2013}}

@conference{Roy2010,
	Annote = {Available at http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5596954&tag=1

"We argue that the subsymbolic distributed representation at the non-cognitive neural layer (McClelland and others) is sufficient to represent a concept or symbol and that an additional layer of cognitive level subconcepts (Smolensky) is redundant."

Five possible knowledge representation schemes posited by Frixione et al. [9]:
Symbolic:
	Compositional symbolic
	Local non-compositional symbolic
	Distributed non-compositional symbolic - (connectionist approach)
Subsymbolic: (all distributed)
	Cognitive subsymbolic
	Neural subsymbolic

Problems with the subconcept view:
	A. The subconcepts don't yet exist in the infant's mind - "there is no reason to believe that the infant has already acquired the necessary subconcepts (milk, bottle, nipple and so on) by learning to recognize other objects."
	B. From a computational point of view, discovering or learning subconcepts could make the learning problem intractable
	C. Brain learns on the basis of need or value
	D. The sequence of learning concepts and subconcepts},
	Author = {Roy, Asim},
	Booktitle = {The 2010 International Joint Conference on Neural Networks (IJCNN)},
	Date-Added = {2013-04-14 19:33:41 -0400},
	Date-Modified = {2013-04-14 19:34:53 -0400},
	Pages = {1-6},
	Title = {Is the connectionist notion of subconcepts flawed?},
	Year = {2010}}

@incollection{Stewart2012,
	Annote = {http://ctnsrv.uwaterloo.ca/cnrglab/sites/ctnsrv.uwaterloo.ca.cnrglab/files/papers/Stewart.Compositionality.pdf

cited for evidence that localist representation requires more neurons in the brain than are availalbe, and VSAs (structure-sensitive distributed architectures)

"[I]t seems clear that there are explanatory advantages to having the neural level of description in addition to the purely classical [symbolic] one. A realistic neural explanation opens the door to a wealth of new methods for analyzing and investigating cognitive behaviour, such as fMRI, EEG, single-cell recordings, and the rest of modern neuroscience. Without such an explanation, there is no way to generate rigorous constraints from such evidence, adn now ay to create testable neurological predictions. Cutting ourselves off from this empirical data because of our theoretical committments {\ldots} is a case of putting the cart before the horse.

As will be seen, the classical symbolic approaches are problematic, while a non-classical Vector Symbolic Approach accounts for behavioral limitations via realistic neural constraints."

Four different cognitive theories examined:
- they all meet Jackendoff's criteria for compositionality:
	- can represent symbols and relations between symbols using a connectionist approach

1) LISA
- he notes that the subsymbols are LOCALIST, as they represent features that have explicit interpretations. These correspond to small populations of neurons, "in which the members of each population code very selectively for a single entity"
- Says that if there are 4k nouns and 2k verbs, we need 32,000,000,000 populations of neurons to represent the possibility that for each verb, any noun could be an agent or a theme, but there are only 100,000,000,000 neurons in the human brain!

2) Neural blackboard architectures
- says they "greatly reduce" the problem of how many neurons are required that LISA has
- van der Velde and de Kamp (2006); neural groups can be temporarily bound to particular atomic concepts, and those neural groups can be combined to form structures. (I thought LISA could do this too)
- but he still estimates that 800million neurons are needed, which is a large amount

3) Tensor products
- (1) and (2) both represent atoms with neural groups and have neural connections represent their relations. Smolensky (1990) uses something different based on tensor products.
- instead of a particular neuron representing dog or cat, a pattern of activity over various neurons represents it.
- "The core idea behind the tensor product approach is to make use of a vector representation for the atomic components and to build up structures using algebraic manipulations."
- takes into account the fact that neurons are noisy
- degrades gracefully, whereas (1) and (2) experience "catastrophic failures" with small deviations from the required structures.
- you can extract the original components exactly, even though the tensor products disguise the data somewhat.

4) Non-classical architectures
- the previous three are implementations of classical symbol systems (though Smolensky doesn't agree that Tensor products are).
- VSAs (Gayler 2003) are similar to tensor product approach, but that "abandon the idea of being able to perfectly extract the original components".
- Holographic reduced representation (HRR, Plate 2003) is a VSA this paper focuses on.
- "makes use of atomic representation vectors of the same form as that used in the tensor product approach discussed above: vectors of numbers with a total length of one. Other VSAs, such as Binary Splatter Codes, only allow the values 0 and 1 for each dimension."
- "The key difference between HRRs and the tensor product approach is that in HRRs, *everything* is a vector with fixed length. {\ldots} However, this is accomplished at the expense of accurance[sic]: as the complexity of the structure increases, the expected accuracy of the decoding will decrease. [as opposed to LISA and neural blackboard architecture]"},
	Author = {Stewart, Terrence and Eliasmith, Chris},
	Booktitle = {Oxford handbook of compositionality},
	Date-Added = {2013-04-14 18:13:41 -0400},
	Date-Modified = {2013-04-14 19:28:04 -0400},
	Editor = {Hinzen, W. and Werning, M. and Machery, E.},
	Publisher = {Oxford University Press},
	Title = {Compositionality and biologically plausible models},
	Year = {2012}}

@article{Browne2001,
	Annote = {summary of connectionist models that can perform symbolic tasks like structural representation and rule-based reasoning
available at: http://ac.els-cdn.com/S0893608001001095/1-s2.0-S0893608001001095-main.pdf?_tid=1cc1dd8e-a54a-11e2-b759-00000aab0f27&acdnat=1365975030_1bafe53712a053df88c4b4618523f280 

Major models

Scalability?

Tasks they can perform

Classifying hybrid systems
	- Sun and Bookman 1994 - single-module architectures vs. multi-module architectures
	- Medsker 1994 - degree of coupling between neural and symbolic components
	- Hilario (1997,2000) - unified vs hybrid
	- McGarry et al 1999a - Unified hybrid, Transformational hybrid, or Modular hybrid},
	Author = {Browne, Antony and Sun, Ron},
	Date-Added = {2013-04-14 17:31:01 -0400},
	Date-Modified = {2013-04-14 17:41:00 -0400},
	Journal = {Neural Networks},
	Pages = {1331-1355},
	Title = {Connectionist inference models},
	Volume = {14},
	Year = {2001}}

@article{Rachkovskij2013,
	Annote = {Uses sparse binary representations, also offers interesting arguments for why localist representations aren't good enough for scalability.
Available at http://www.sciencedirect.com/science/article/pii/S2212683X12000552

"APNNs [Associative-Projective Neural Networks, their creation in this paper] provide scalability and flexibility due to a number of design features."
"We treat the term 'model' similar to 'representation' {\ldots} [supposing] that representations reflect some aspects of nature and behavior of items, as models in science, technology, arts do."


"Such peculiarities of local and symbolic representations lead to a weak potential for scaling in terms of required memory size; difficulties in representation of similar items and estimation of similarity, problems with generalization, storage of classes and class instances, with emergence of multiple and flexible classification (is-a) hierarchies; inadequacy for context-dependent representation and processing. {\ldots} [particularly for] complex hierarchical compositional models. For example, the exponential growth in the number of neurons required to locally represent all potentially possible combinatorial structures demands many orders of magnitude more neurons than are found in the human brain (Stewart & Eliasmith, 2012)".

"Distributed representations offer a potential to overcome these drawbacks {\ldots} However, until recently the ideas inherent in Hebb's paradigm have not been developed enough, especially the problem of representing hierarchical compositional structures {\ldots} APNNs are a BICA employing structure-sensitive sparse binary distributed representations to provide a solution to at least some of the problems with symbolic and localist representations." (66)

"In fact, a number of connectionist schemes have been proposed capable of forming representations of hierarchical (recursive) structures {\ldots} binding procedures (analogues of grouping brackets in symbolic representations) were developed to avoid the "superposition catastrophe""
"to avoid some drawbacks [of those models], some schemes for structure-sensitive distributed representations, also known as Vector Symbolic Architectures (VSAs {\ldots}) were proposed. {\ldots} binding operations are done on-the-fly, without iterative learning, and do not change dimensionality of representation vector. So, VSAs allow hierarchical compositional structures to be distributedly represented by various kinds of "reduced descriptions"". 






},
	Author = {Rachkovskij, Dmitri A. and Kussul, Ernst M. and Baidyk, Tatiana N.},
	Date-Added = {2013-04-14 16:47:32 -0400},
	Date-Modified = {2013-04-14 17:29:11 -0400},
	Journal = {Biologically inspired cognitive architectures},
	Pages = {64-86},
	Title = {Building a world model with structure-sensitive sparse binary distributed representations},
	Volume = {3},
	Year = {2013}}

@incollection{Mitchell1995,
	Annote = {
Chapter 6 (Hofstadter)


   * "Very few (if any) other computer models focus, as Copycat does, on the *construction* of representations for the source and target situations, and on how this construction interacts with the mapping process." (275)
   * Comparisons with SME
   * 
      * Gentner's theory restricts what counts as analogy to those which use systematicity as opposed to "a comparison in which both attributes and relations are mapped is a *literal similarity*, not an analogy." (277)
      * "The only knowledge the program has of the two situations consists of their syntactic structures ...; it has no knowledge of any of the *concepts* involved in the two situations. In other words, there is no prior structure containing any facts about water, liquids, heat, flow, or even physical objects. All processing is based solely on syntactic structural features of the two given representations." (279)
      * Gentner's principles "capture something important about analogy-making, butthere are often other pressures in an analogy: both superficial and abstract similarities that may not be parts of systematic wholes, but are still strong contenders in a competition." Example given is ( aabc : aabd :: ijkk : ? ) , pure systematicity would give ijll, rather than hjkk. 
      * "Another problem with Gentner's theory is that for any complex situation, there are many possible sets of relations that exhibit systematicity, and it is not explained how certain ones are considered for mapping and not others, on syntactic grounds alone." Heat flow example, he describes, "syntactic structure alone is insufficient to determine which facts are pant of a relevant systematic whole, and which are isolated and irrelevant" [as opposed to semantic knowledge] (281).
      * "For SME, not only are the attributes and relations in each situation laid out in advance, but there is no notion of differential relevance among them: which ones get used in an analogy is entirely a function of the syntactic structure connecting them." (281)
      * "...her theory does not include any notion of conceptual similarity or of slippage, notions absolutely central to the Copycat project. ... The analogy is already effectively given in the representations." (282)
      * "Yet another problem ... is that it relies on a precise and unambiguous representation of situations in the language of predicate logic. The structure-mapping theory's reliance on syntax alone requires that situations be broken up very clearly into objects, attributes, functions, first-order relations, second-order relations, and so on. ... But suppose that ... *heat* had been described not as an object, but as an attribute of *coffee*...; or suppose that *heat flow* had been given as a 3-place rather than a 4-place relation ... Any of these quite plausible changes would totally block a successful application of the structure mapping theory." (282) "The problem is that in the real world, the labels "object", "attribute", and "relation" are very blurry, and people ... have to use them very flexibly ... And to do this, semantics must be taken into account (this point is also made by Johnson-Laird, 1989)" (282) "...Thus, a serious weakness of the structure-mapping theory is its inability to deal with any flexibility in the representation of situations."
      * "...the possibility for real-time representational flexibility is *fundamentally* lacking in a program like SME, which relies solely on the syntax of predicate-logic representations that are supplied to it before the fact. For such a program to work, the representations have to be tailored carefully. This discrepancy between architectures reflects a significant philosophical difference about analogy-making." (283)
      * "[SME] doesn't attempt to model the underlying concepts or the dynamic perceptual processes in the psychologically realistic manner that Copycat does"
      * SME does an exhaustive search that gives only one "type" of answer, but the authors here want to find both immediately-appealing/high-frequency answers and those that are more insightful and require deeper searches. This harms psychological realism. (284)
   * Criticisms of ACME

      * Like SME, it tries all syntactically plausible pairings; it uses a "logical-compatibility constraint" in which semantics plays no role at all
      * Shares with SME "the following major problem, discussed above: the representations of knowledge used are rigid, and are also tailored specially for each new analogy. ... it has an optional 'semantic unit' giving semantic similarities, ... bt the similarities are also decided in advance by the programmer for the purposes of the given analogy, and are frozen." Same with how pragmatic features are frozen ahead of time.
      * Finally, it models only the mapping stage whereas Copycat's philosophy says mapping cannot be separated from perceiving and reformulating perceptions and assessments of similarities in response to pressures.

   * Copycat's position along the symbolic/subsymbolic spectrum

      * "The faith of the subsymbolic paradigm is that [many things] are emergent statistical effects of a large number of small, local, and distributed subcognitive events with no global executive. This is the philosophy underlying connectionist networks, classifier systems, and Copycat as well."
      * "the actual *program* [of copycat] fits somehwere in between (although as we said ... Copycat is not a hybrid of the two paradigms). ... Concepts in Copycat could be thought of as 'semi-distributed', since a concept in the Slipnet is probabilistically distributed over only a small number of nodes --- a central node (e.g., successor) and the nodes in its probabilistic halo (e.g., predecessor), to which it can probabilistically slip."

},
	Author = {Mitchell, Melanie and Hofstadter, Douglas R.},
	Booktitle = {Fluid concepts and creative analogies: computer models of the fundamental mechanisms of thought},
	Chapter = {6},
	Date-Added = {2013-04-14 02:00:12 -0400},
	Date-Modified = {2013-04-14 02:02:16 -0400},
	Editor = {Hofstadter, Douglas R. and the Fluid Analogies Research Group},
	Publisher = {Basic Books, Inc},
	Title = {Perspectives on {C}opycat: comparisons with recent work},
	Year = {1995}}

@article{Roy2012,
	Annote = {Available at http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3576056/

presents "the theory that localist representation is used widely in the brain starting from its earliest levels of processing."

Stronger claim than previous views that only suggested localist representation existed for objects and concepts, this says it's widely employed.

- localism does not exclude redundancy in representation

Evidence:
	- "Johnson et al. {\ldots} found" a bunch of cells in macaques were "color-selective". This and other things suggest meaning and interpretation "of cell activity exist starting at the lowest levels of sensory signal processing", which is enough to satisfy one of the alternate definitions of localist representations.
	- Cells in later processing stages also have meaning and interpretation:
		- hippocampal place cells that fire when an animal is in a specific location
		- medial temporal lobe (MTL) cells have highly selective response to complex stimuli like gender and facial expression, pictures of objects, animals, faces, etc. Similar category encoding in inferior temporal cortex. Quian Quiroga et al. (2000) found a neuron in the parahippocampal cortex that fired to pictures of Tower of Pisa and Eiffel Tower, but not to other landmarks.
		- other evidence

Conclusion: If the requirement of cells as having "meaning and interpretation" on a standalone basis and not dependent on activations of other cells is sufficient, there is evidence to conclude that this meets the definition of localist cells.

He also has other papers arguing for this point of view, I think this was the shortest and easiest to read.},
	Author = {Roy, Asim},
	Date-Added = {2013-04-13 20:05:58 -0400},
	Date-Modified = {2013-04-13 20:21:54 -0400},
	Journal = {Frontiers in psychology},
	Number = {551},
	Title = {A theory of the brain: localist representation is used widely in the brain},
	Volume = {3},
	Year = {2012}}

@article{McClelland2010,
	Annote = {Available at: http://onlinelibrary.wiley.com/doi/10.1111/j.1756-8765.2010.01116.x/full

Talks about sub- or non-symbolic processes and how many other approaches are emergent from these, including many things that the symbolic approach merely approximates (units, structures, rules, etc.) "The greatest achievements of human cognition may largely be emergent phenomena."

"While it might not have seemed so until recently, it has become clear that statistical and symbolic approaches can easily coexist with each other, as they do in the structured probabilistic models of Kemp and Tenenbaum (2009) and Goodman, Mansighka, et al. (2008). " But he notes they are "quite different from the emergentist approaches this article is considering."

"A difficulty with Hofstadter's and Minsky's ideas [on emergence] was the vagueness that accompanied their breadth. It seems fair to say that these ideas remain more sources of inspiration than actual tools for working toward an explicit understanding of human mental abilities" (sec. 3).

"The idea that the global state toward which a network settles, rather than a single unit within the network, corresponds to a memory represents the needed conceptual advance to go beyond the proto-emergence of the localist models to a full-blown emergentist approach, in which the representation for a familiar item cannot be found stored separately in any part of the system, and in which its retrieval as a memory emerges from the interactions among simpler units each doing something subcognitive, and very simple." (sec 3.2)

The rest of the paper talks about things related to emergence and its history in the cog.sci literature.},
	Author = {McClelland, James L.},
	Date-Added = {2013-04-13 19:09:48 -0400},
	Date-Modified = {2013-04-13 19:11:43 -0400},
	Journal = {Topics in Cognitive Science},
	Number = {4},
	Pages = {751-770},
	Title = {Emergence in cognitive science},
	Volume = {2},
	Year = {2010}}

@incollection{Hinton1986,
	Annote = {Very in-depth, heavily cited article on distributed representation, from the PDP group

Available on http://psych.stanford.edu/~jlm/papers/PDP/Chapter3.pdf


Virtues of distributed representations:
- memory as inference
	Content-addressable memory: they can recall items from partial descriptions of the contents of those items, e.g. "it is an actor, it is intelligent, california" might allow for access of "Arnold Schwartzenegger". "One way of thinking about distributed memories is in terms of a very large set of plausible inference rules. Each active unit represents a 'microfeature' of an item, and the connection strengths stand for plausible 'microinferences' between microfeatures."
- similarity and generalization
	they automatically give rise to generalizations; due to their basis in statistical reasoning.
- creating new concepts
	they "make it possible to create new concepts without allocating new hardware."

Others
- "they can make more efficient use of parallel hardware than local representations." (96)
},
	Author = {Hinton, Geoffrey E. and McClelland, J.L. and Rumelhart, David E.},
	Booktitle = {Parallel distributed processing: explorations in the microstructure of cognition},
	Date-Added = {2013-04-12 19:50:49 -0400},
	Date-Modified = {2014-01-17 17:22:33 +0000},
	Editor = {Rumelhart, David E. and McClelland, J.L.},
	Publisher = {MIT Press},
	Title = {{Distributed Representations}},
	Volume = {1},
	Year = {1986}}

@inproceedings{Krumnack2008,
	Address = {Aukland, New Zealand},
	Annote = {"In this paper, we propose a framework to deal with the problem of re-representation in a logic-based model for analogy making."

"Indurkhya [1] develops a theory in which the computation of analogies is based on the *accommodation* of an internal concept network to an input (resulting in a re-representation of the concept network), or the *projection* of a concept network to the input (resulting in a re-representation of the input), or both."

As far as I can tell, the way that it approaches re-representation is to show how logic makes it easier: for example, it may allow you to carefully define which predicates order doesn't matter in. It does seem like with HDTP, re-representation can be pretty well built in to the algorithm.},
	Author = {Krumnack, Ulf and Gust, Helmar and K{\"u}hnberger, Kai-uwe and Schwering, Angela},
	Booktitle = {Proceedings of the 21st {A}ustralasian Joint Conference on Artificial Intelligence},
	Date-Added = {2013-04-11 17:50:36 -0400},
	Date-Modified = {2013-06-25 09:24:15 +0200},
	Title = {Re-representation in a logic-based model for analogy-making},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2tydW1uYWNrX0FJMDgucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFrcnVtbmFja19BSTA4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxCQzYyo4gAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzYzhIgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBrcnVtbmFja19BSTA4LnBkZgAOACQAEQBrAHIAdQBtAG4AYQBjAGsAXwBBAEkAMAA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9rcnVtbmFja19BSTA4LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@article{Chi1981,
	Author = {Chi, Michelene T.H. and Feltovich, Paul J. and Glaser, Robert},
	Date-Added = {2013-04-11 17:42:24 -0400},
	Date-Modified = {2013-04-11 17:48:21 -0400},
	Journal = {Cognitive Science},
	Title = {Categorization and representation of physics problems by experts and novices},
	Volume = {5},
	Year = {1981}}

@inproceedings{Yan2003,
	Author = {Yan, Jin and Forbus, Ken and Gentner, Dedre},
	Booktitle = {Proceedings of the 25th annual conference of the cognitive science society},
	Date-Added = {2013-04-11 17:30:29 -0400},
	Date-Modified = {2013-04-11 17:31:55 -0400},
	Title = {A theory of rerepresentation in analogical matching},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1lhbkZvcmJ1c0dlbnRuZXIwMy5wZGbSFwsYGVdOUy5kYXRhTxEB1AAAAAAB1AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHFllhbkZvcmJ1c0dlbnRuZXIwMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPErTNjKOkAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADNjNvkAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAVU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AFlhbkZvcmJ1c0dlbnRuZXIwMy5wZGYAAA4ALgAWAFkAYQBuAEYAbwByAGIAdQBzAEcAZQBuAHQAbgBlAHIAMAAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9ZYW5Gb3JidXNHZW50bmVyMDMucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AzgDTANsCswK1AroCxQLOAtwC4ALnAvAC9QMCAwUDFwMaAx8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADIQ==}}

@inproceedings{Auer2007,
	Annote = {main citation for DBpedia},
	Author = {Auer, S\"{o}ren and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
	Booktitle = {Proceedings of the 6th International Semantic Web Conference (ISWC2007)},
	Date-Added = {2013-04-11 17:22:33 -0400},
	Date-Modified = {2013-04-11 17:28:48 -0400},
	Title = {{DBpedia}: a nucleus for a web of open data},
	Year = {2007}}

@inproceedings{Bollacker2008,
	Annote = {Main citation for freebase},
	Author = {Bollacker, Kurt and Evans, Colin and Paritosh, Praveen and Sturge, Tim and Taylor, Jamie},
	Booktitle = {Proceedings of the 2008 ACM SIGMOD International conference on Management of data (SIGMOD '08)},
	Date-Added = {2013-04-11 17:09:50 -0400},
	Date-Modified = {2013-04-11 17:21:45 -0400},
	Publisher = {ACM},
	Title = {Freebase: a collaboratively created graph database for structuring human knowledge},
	Year = {2008}}

@inproceedings{Matuszek2006,
	Annote = {citation for Cyc},
	Author = {Matuszek, Cynthia and Cabral, John and Witbrock, Michael and DeOliveira, John},
	Booktitle = {Proceedings of the 2006 AAAI sprint symposium on formalizing and compiling background knowledge and its applications to knowledge representation and question answering},
	Date-Added = {2013-04-11 17:02:52 -0400},
	Date-Modified = {2013-12-30 14:50:29 -0500},
	Title = {An introduction to the syntax and content of {C}yc},
	Volume = {3864},
	Year = {2006}}

@article{Licato2013a,
	Author = {Licato, John and Govindarajulu, Naveen S. and Bringsjord, Selmer and Pomeranz, Michael and Gittelson, Logan},
	Date-Added = {2013-04-10 20:46:45 -0400},
	Date-Modified = {2013-11-12 13:04:29 -0500},
	Journal = {Proceedings of the 23rd Annual International Joint Conference on Artificial Intelligence (IJCAI-13)},
	Title = {{Analogico-Deductive Generation of {G}\"{o}del's First Incompleteness Theorem from the Liar Paradox}},
	Year = {2013}}

@incollection{Gentner1997a,
	Author = {Gentner, Dedre and Brem, S. and Ferguson, R.W. and Wolff, P. and Markman, A.B. and Forbus, Ken},
	Booktitle = {Creative thought: An investigation of conceptual structures and processes},
	Date-Added = {2013-04-10 20:42:12 -0400},
	Date-Modified = {2013-11-03 00:53:42 -0400},
	Editor = {Ward, T.B. and Smith, S.M. and Vaid, J.},
	Pages = {403-459},
	Publisher = {American Psychological Association},
	Title = {Analogy and creativity in the works of {J}ohannes {K}epler},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0dlbnRuZXJCcmVtOTcucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFHZW50bmVyQnJlbTk3LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw+wzYt/lQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzYu31QAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBHZW50bmVyQnJlbTk3LnBkZgAOACQAEQBHAGUAbgB0AG4AZQByAEIAcgBlAG0AOQA3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9HZW50bmVyQnJlbTk3LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@book{Holyoak1995,
	Address = {Cambridge, MA},
	Author = {Holyoak, Keith J. and Thagard, Paul},
	Date-Added = {2013-04-10 20:39:52 -0400},
	Date-Modified = {2013-04-10 20:40:50 -0400},
	Publisher = {MIT Press},
	Title = {Mental leaps: analogy in creative thought},
	Year = {1995}}

@book{Finke1992,
	Address = {Cambridge, MA},
	Author = {Finke, R.A. and Ward, T.B. and Smith, S.M.},
	Date-Added = {2013-04-10 20:38:44 -0400},
	Date-Modified = {2013-04-10 20:39:28 -0400},
	Publisher = {MIT Press},
	Title = {Creative cognition: theory, research, and applications},
	Year = {1992}}

@book{Finke1990,
	Author = {Finke, R.A.},
	Date-Added = {2013-04-10 20:36:33 -0400},
	Date-Modified = {2013-04-10 20:38:26 -0400},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Creative imagery: discoveries and inventions in visualization},
	Year = {1990}}

@inproceedings{Gentner2006,
	Annote = {Cited by Gentner in support of claim that structural alignment is used psychologically to compute similarities/differences.

"According to structure-mapping, commonalities and differences that are connected to the common structure are more salient than those that are not. This means that alignable differences are more salient than non-alignable differences."

Another "structure-mapping claim [is] that participants will find it easier to note differences between concepts and images that are fairly similar (and consequently more alignable) than between concepts and images that are substantially different (and therefore more difficult to align)".

But note that they admit mental distance models and models that use feature spaces might better predict how quickly participants will identify THAT images are different, but structure mapping is necessary to identify WHAT the differences are and which differences are made more salient: "Both mental distance models and feature models would therefore predict a positive relation between the two tasks: the fewer the differences that exist between two objects, the harder it should be *both* to detect that they are diferent and to identify a specific difference between them. Structure mapping theory makes a different prediction [which is that] participants will find it easier to identify a specific different between A and B [which share many features as well as a common organizing structure] than between A and C [because they have a low degree of structural overlap]." This is what this paper's experiment tests.},
	Author = {Gentner, Dedre and Sagi, Eyal},
	Booktitle = {Proceedings of the 28th Annual Conference of the Cognitive Science Society},
	Date-Added = {2013-04-08 06:14:06 -0400},
	Date-Modified = {2013-09-09 21:42:00 -0400},
	Editor = {Sun, Ron and Sagi, Eyal},
	Title = {{Does ``Different" Imply a Difference? A Comparison of Two Tasks}},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0dlbnRuZXJTYWdpMDYucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFHZW50bmVyU2FnaTA2LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw/SzYgQkQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzYhI0QAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBHZW50bmVyU2FnaTA2LnBkZgAOACQAEQBHAGUAbgB0AG4AZQByAFMAYQBnAGkAMAA2AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9HZW50bmVyU2FnaTA2LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@incollection{Hummel2002,
	Annote = {Cited by Hummel as the paper supporting the idea that models of analogy with localist representations have trouble with generalization.},
	Author = {Hummel, John E. and Holyoak, Keith J.},
	Booktitle = {Creativity, cognition, and knowledge: an interaction},
	Date-Added = {2013-04-07 18:45:50 -0400},
	Date-Modified = {2013-04-07 18:51:15 -0400},
	Editor = {Dartnall, Terry},
	Publisher = {Greenwood Press},
	Title = {Analogy and creativity: schema induction in a structure-sensitive connectionist model},
	Year = {2002}}

@article{Eliasmith2001,
	Annote = {citation given by Emruli2013; apparently this also compares to LISA and ACME, also SME. System is called Drama, and it is actually based on ACME and HRRs (holographic reduced representations).

42 pages! Just gonna skim through this.

"We also claim that *Drama* is an existence proof of using distributed representations to model high-level cognitive phenomena."

To gain the benefits of connectionist and structural representations, they can either improve the semantic flexibility of symbolic representations (perhaps like META-R does) or improve the structural flexibility of distributed representations. They chose the latter option because:
- distributed representations provide lots of benefits, and neurological realism not found in symbolic models
- "providing a distributed model of the analogical mapping process would validate the contentious claim that connectionist models will scale to the complexity of high-level human cognition"
- "The most significant theoretical innovation of the *Drama* model comes with its implementation of the similarity constraint. Unlike previous models, Drama actually combines this constraint with the structural constraint to generate mappings. Both structure and similarity determine the outcome of the mapping process at every stage" (6).

Holographic Reduced Representations
- Here they are 512-dimensional vectors (7)
- superposition and correlation are the two primary operations, but they still use the dot product. How is this supposed to be neurologically plausible?
- Two major (admitted) faults of this approach are imperfect encoding/decoding, and noisy representations (table 1).

Comparison with LISA
- "{\ldots}it is far from clear that [LISA] will be able to handle complex analogies. {\ldots} it is only able to store one proposition in working memory at a time, and it can only represent one structural level at a time" (33)
- "{\ldots}there does not appear to be a way for LISA to distinguish between two of the same second-order propositions in one "story". For example, if there were two causal relations with propositions in each place in a target, LISA would not be able to distinguish them in their mappings to a source with two similar causal relations."
- "Currently, Drama does not sufficiently account for [working memory] limitations, though there is a limitation on the size of the conceptual memory in the Drama model. However, it is far from clear that LISA has done a satisfactory job in accounting for these limitations either."
- Even though LISA claims to be a distributed model (does it really?), "the structural relations amongst components of propositions are encoded using purely localist methods. There are units dedicated to entire propositions, as well as each sub-part of the proposition. This form of encoding is highly unrealistic (churchland and Sejnowski, 1992)" (33-34). ---this is an entire book as a citation, with no further evidence given!},
	Author = {Eliasmith, Chris and Thagard, Paul},
	Date-Added = {2013-03-23 02:59:00 -0400},
	Date-Modified = {2013-03-23 03:40:49 -0400},
	Journal = {{Cognitive Science}},
	Number = {2},
	Pages = {245-286},
	Title = {Integrating structure and meaning: a distributed model of analogical mapping},
	Volume = {25},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QSC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEtczIuMC1TMDM2NDAyMTMwMTAwMDM2Mi1tYWluLnBkZtIXCxgZV05TLmRhdGFPEQH+AAAAAAH+AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfMS1zMi4wLVMwMzY0MDIxMzAxMDAwI0UzQzUwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48UM1yyv8AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM1zAz8AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMS1zMi4wLVMwMzY0MDIxMzAxMDAwI0UzQzUwLnBkZgAOAEQAIQAxAC0AcwAyAC4AMAAtAFMAMAAzADYANAAwADIAMQAzADAAMQAwADAAMAAzADYAMgAtAG0AYQBpAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAE1Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEtczIuMC1TMDM2NDAyMTMwMTAwMDM2Mi1tYWluLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDZAN4A5gLoAuoC7wL6AwMDEQMVAxwDJQMqAzcDOgNMA08DVAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANW}}

@article{Evans2008,
	Annote = {System 1 and System 2 - common way to distinguish between lower-level and higher-level systems

FEATURES ATTRIBUTED TO DUAL PROCESSES AND SYSTEMS

Consciousness
- echoes of what system "controls" what; system 1 is often used for unconscious processes and behaviors
- [A common belief now] "is that System 2 thinking requires access to a central working memory system of limited capacity, whereas System 1 does not."

Age of Evolution
- People tend to assume System 1 cognition evolved before System 2
- "massive modularity" hypothesis defended by Tooby & Cosmides and others, claims domain-general processes are unlikely to evolve as opposed to domain-specific ones. Dual-processing theorists tend to oppose this, but recent work seems to be trying to make it more compatible.

Functional Characteristics
- System 1 usually rapid, automatic, domain-specific; System 2 usually slow, controlled, domain-general

Individual Differences
- what is the relation between these two systems and general intelligence?

APPLICATIONS OF DUAL-PROCESS THEORIES IN DIFFERENT DOMAINS

Dual-Process Theories of Reasoning
- Wason selection task essentially established the field of the psychology of deductive reasoning
- Debate between mental models (MM) and mental logic (ML) guys has dominated recent history of this field
- ML: abstract inference rules; MM: An argument is valid if there are no counterexamples to it.
- "{\ldots}it may be that higher-ability [logical thinking] people do not engage in more System 2 reasoning but rather are simply more successful when they do so" (11). 

Dual-Process Theories of Judgment and Decision Making
- Three main research programs:
	- Heuristics and biases / probability judgments
	- Decision making under risk
	- Social judgment theory and the lens model
- Kahneman & Frederick's theory, similarly to Evans' heuristic-analytic theory, assumes that system 1 processes produce judgments, which must be endorsed "by the (analytic) System 2, which often does so casually" (12).
- If we evolved a module for processing frequency information which is primarily in system 1, "[c]onsistent with this, there is now much evidence that what facilitates Bayesian reasoning is a problem structure that cues explicit mental models of nested-set relationships" (13).
- There are claims that even system 1 reasoning is deliberative and even superior (Dijksterhuis et al. 2006)

Dual-Process Theories of Social Cognition
- "The proposal of new accounts or at least new labels for dual processes in social cognition has reached near epidemic proportions" (14)
- Heuristic-systematic model is a long-established dual-process theory, but heuristics here sound "more like the recognition-primed decision making of Klein (1999) than the contextualization process postulated by reasoning theorists {\ldots} In fact, heuristic processing so defined could be taken to be a form of System 2 or rule-based reasoning"
- "Many studies have used the methodology of semantic priming, borrowed from the literature on implicit memory {\ldots} when people are asked to view photographs of males or females and required to proces them in a semantic manner, their subsequent threshold for word recognition is primed for stereotype-consistent words" (15).
- X-system: amygdala, basal ganglia, lateral temporal cortex - associated with system 1
- C-system: anterior cingulate cortex, prefrontal cortex, medial-temporal lobe - associated with system 2, executive control (16)

CONCLUSION

- it's not clear what links all the processes categorized under system 1 or 2
- he suggests the following:
	- type 2 processes require access to a single, capacity-limited central working memory resource; this implies slow, sequential, capacity-limited features.
	- type 1 processes do not require such access
- "In short, my conclusion is that although dual-process theories enjoy good empirical support [, the idea] they are all related to the same underlying two system of cognition is probably mistaken, at least in the way that Systems 1 and 2 are being defined in the current literatures." (17)},
	Author = {Evans, Jonathan St. B. T.},
	Date-Added = {2013-03-22 03:51:29 -0400},
	Date-Modified = {2013-03-22 03:59:47 -0400},
	Journal = {Annual Review of Psychology},
	Pages = {255-278},
	Title = {Dual-processing accounts of reasoning, judgment, and social cognition},
	Volume = {59},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QUS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FubnVyZXYlMkVwc3ljaCUyRTU5JTJFMTAzMDA2JTJFMDkzNjI5LnBkZtIXCxgZV05TLmRhdGFPEQIYAAAAAAIYAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfYW5udXJldiUyRXBzeWNoJTJFNTklI0UzQ0M2LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48xs1xhZ4AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM1xvd4AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAYW5udXJldiUyRXBzeWNoJTJFNTklI0UzQ0M2LnBkZgAOAFYAKgBhAG4AbgB1AHIAZQB2ACUAMgBFAHAAcwB5AGMAaAAlADIARQA1ADkAJQAyAEUAMQAwADMAMAAwADYAJQAyAEUAMAA5ADMANgAyADkALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFZVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FubnVyZXYlMkVwc3ljaCUyRTU5JTJFMTAzMDA2JTJFMDkzNjI5LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAOIA5wDvAwsDDQMSAx0DJgM0AzgDPwNIA00DWgNdA28DcgN3AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA3k=}}

@article{Emruli2013,
	Annote = {Scooped my shit man! Although it says it was received on March 2012, so they must have working on it in very early 2012 or even late 2011.

Best summary of the paper:
"The aim of this work is to investigate whether such mapping vectors [which have up to now usually been manually constructed] can be stored in an associative memory so that multiple mappings can be learnt from examples and applied to novel inputs, which in principle can be unlabeled. We show that this is possible and demonstrate the solution using compositional structures that are similar to those considered by others." (13)

inputs x_j, mappings x_i -> y_i, analogies x_j -> y_j
- claims "After learning three examples, the model generalizes correctly to novel examples. {\ldots} The model can learn analogical mappings of generic two-place relationships".
- Analogical mapping: "{\ldots}the process of mapping relations and objects from one situation (a source), x, to another (a target), y; M : x -> y." (1)
- learns mappings x_{k,z} -> y_{k,z} where k denotes different examples of one particular relationship z.
- An SDM (sparse distributed memory) operates on high-dimensional binary vectors {\ldots} are useful representations of compositional structures [14-18]. (2)
- they use these structures to represent, operate on, and produce mapping vectors that apparently can generalize as well.
- AMU - Analogical Mapping Unit, which "enables learning and application of mappings in a simple way". This is their contribution.
- BSC - Binary Spatter Code. A binary vector x_k = (x_{k,1}, {\ldots}, x_{k_D}) represents "roles, fillers, relations, and compositional structures (4). Two operators:
	- Binding - combine two vectors into a new one which is different from the originals, and is such that given one of the originals you can recover the other.
	- Bundling - combine multiple vectors (usually algebraic sum).
- When bundling vectors you can generalize using vectors you haven't even seen before (equations 6,7)
- Creates new structure, to interpret what you have you have to use things like *probing*.

SPARSE DISTRIBUTED MEMORY
- address and counter matrices are created, which essentially will store all the vectors and allow recall of those vectors.
- retrieval: use query vector and address matrix to activate some counter vectors within the counter 

DISCUSSION
- "The AMU has a one-shot learning process and it is able to recall mappings that are in the training set"
- "{\ldots}by calculating the probability of error in the simulation experiments, we conclude that it is sufficient to use binary mapping vectors"
- I'm not clear on how this thing is supposed to represent more complex structures{\ldots}they limit it to 2-place predicates here and claim they are following Gentner's two principles? Ha!



},
	Author = {Emruli, Blerim and Sandin, Fredrik},
	Date-Added = {2013-03-21 16:30:14 -0400},
	Date-Modified = {2013-03-21 23:22:22 -0400},
	Journal = {Cognitive Computation},
	Month = {March},
	Title = {Analogical mapping with sparse distributed memory: A simple model that learns to generalize from examples},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QTC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FydCUzQTEwLjEwMDclMkZzMTI1NTktMDEzLTkyMDYtMy5wZGbSFwsYGVdOUy5kYXRhTxECCgAAAAACCgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHH2FydCUzQTEwLjEwMDclMkZzMTI1NSNFM0NDQy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPMzNcOWcAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADNcR3cAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAXk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGFydCUzQTEwLjEwMDclMkZzMTI1NSNFM0NDQy5wZGYADgBMACUAYQByAHQAJQAzAEEAMQAwAC4AMQAwADAANwAlADIARgBzADEAMgA1ADUAOQAtADAAMQAzAC0AOQAyADAANgAtADMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFFVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FydCUzQTEwLjEwMDclMkZzMTI1NTktMDEzLTkyMDYtMy5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A3QDiAOoC+AL6Av8DCgMTAyEDJQMsAzUDOgNHA0oDXANfA2QAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADZg==}}

@article{Sun1992b,
	Author = {Sun, Ron},
	Date-Added = {2013-03-13 09:07:48 -0400},
	Date-Modified = {2013-03-13 15:38:36 -0400},
	Journal = {ConnectionScience},
	Number = {2},
	Pages = {93-124},
	Title = {On variable binding in connectionist networks},
	Volume = {4},
	Year = {1992},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi5jb25uMTk5Mi5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEHN1bi5jb25uMTk5Mi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEo3NZk3VAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADNZoYVAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHN1bi5jb25uMTk5Mi5wZGYAAA4AIgAQAHMAdQBuAC4AYwBvAG4AbgAxADkAOQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9zdW4uY29ubjE5OTIucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@inproceedings{Sun1992a,
	Address = {Hillsdale, NJ},
	Author = {Sun, Ron},
	Booktitle = {Proceedings of the 14th Cognitive Science Society Conference},
	Date-Added = {2013-03-13 00:13:35 -0400},
	Date-Modified = {2013-03-13 15:37:16 -0400},
	Pages = {1134-1139},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Fuzzy Evidential Logic: A Model of Causality for Commonsense Reasoning},
	Year = {1992},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xNy4yODgwLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjE3LjI4ODAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48Xs1ldSoAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAM1lrWoAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjE3LjI4ODAucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADEANwAuADIAOAA4ADAALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xNy4yODgwLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@book{Smith2007,
	Address = {Cambridge, UK},
	Annote = {http://www.scribd.com/doc/51607996/13/Negation-complete-theories-are-decidable},
	Author = {Smith, Peter},
	Date-Added = {2013-01-29 23:40:16 -0500},
	Date-Modified = {2013-02-05 14:55:40 -0500},
	Publisher = {Cambridge University Press},
	Title = {{An Introduction to G{\"o}del's Theorems}},
	Year = {2007}}

@book{Smullyan1987,
	Author = {Smullyan, Raymond},
	Date-Added = {2013-01-29 19:38:18 -0500},
	Date-Modified = {2013-01-30 21:25:58 -0500},
	Publisher = {Alfred A. Knopf, Inc.},
	Title = {{Forever Undecided : A Puzzle Guide to G{\"o}del}},
	Year = {1987}}

@book{Norton2011,
	Annote = {In here he talks about some of the difficulties of formalizing approaches to analogical inference (ultimately he doesn't believe it's possible); this is the text that introduced me to Bartha's work, which he describes as the most important work to explore that direction in a while. He essentially agrees with Owen, saying:
	"While there will be similarities among different analogical inferences, there will be no overarching similarity of sufficient power to allow the separation of good and bad inductive inference by purely formal means. ... no matter how elaborate these schemas may become, none proves to be final and complete. That this difficulty is irremediable is predicted by [his] material theory of induction."

- "[I]n this [Bartha's articulation] model, an analogical inference passes a property, expressed in inferential terms, from the source to the target. That means the analysis is meta-logical, since the analogical inferences are performed at a higher, that is a 'meta,' level on lower level structures that are in turn characterized by inferential properties." This, he says, makes it much harder to formalize analogy because a formal account must "provide a schema for the analogical parts of the inference at the meta-level, and also schemas for each of the lower level forms of inductive inference. In short, it must solve the formal problems of analogical inference and also every other form of inference it invokes." (12-13)

He favors the material view of analogy rather than the formal one, where he doesn't think there's a general form that can apply to all analogies. However, "[t]here will be a loose similarity only between different analogical inferences in that, in all of them, we are authorized to pass properties from one system to another. There is no universal schema such as is sought by a formal theory." (13)

More problems attempts to find a formal schema for analogy will come across:
- A simple schema will at best fit a range of cases imperfectly. 
- To fit better, you'll have to get more and more complicated. "These refinements will allow a better fit, but the fit will never succeed perfectly for every case."},
	Author = {Norton, John D.},
	Date-Added = {2012-12-14 02:35:52 -0500},
	Date-Modified = {2013-09-28 22:38:13 -0400},
	Publisher = {Forthcoming},
	Title = {Formal and material approaches to analogical inference},
	Year = {Forthcoming},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0FuYWxvZ3kucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwtBbmFsb2d5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjymzPBA3wAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzPCHLwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBBbmFsb2d5LnBkZgAOABgACwBBAG4AYQBsAG8AZwB5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9BbmFsb2d5LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@book{Bartha2010,
	Annote = {Cited by Norton and others as the most important tratment of the role of analogy in argumentation since Hesse (1950's). 

=============================
CHAPTER 1
=============================
Defines analogy: "a comparison between two objects, or systems of objects, that highlights respects in which they are thought to be similar." (1) Also: "An *analogy* between S and T is a mapping \phi between objects, properties, relations, and functions in S and those in T. Not all items in S and T need to be paired up. ... Relations R and R* correspond if \phi(R) = R*..." (13).
Why is it important to understand analogical arguments?
	- It has had a role as a heuristic tool, a predictive tool, a tool for conceptual unification, and justification.
	- Problem 1: They have an almost mystical ability to fulfill these roles: "Steiner (1998) argues that a series of deeply mysterious analogies played a fundamental role in breakthroughs in nineteeth- and twentieth-century physics. In his view, we cannot explain why these spectacular cases of analogical reasoning had the slightest plausibility, let alone why they succeeded in advancing physics."
	- Problem 2: "We have no substantive normative theory of analogical arguments"; no way to clearly distinguish between good and bad analogies.
	- Problem 3: We don't fully know how to incorporate analogical reasoning within a model of theoretical confirmation.
	- He defends this thesis: "A conclusion reached via analogical reasoning is justified only insofar as a reconstruction of the reasoning as an analogical argument can justify that conclusion." In his view, analogical arguments can only tell us if a "hypothesis is *plausible*." (6)

Open-Textured Predicate - What we are dealing with when we judge that two things are the same because the same (more or less the same) predicate can be applied to both of them. E.G. are two cases instances of "unforeseeable circumstances"(9)?

Notation: S,T are source and target respectively, unstarred symbols (a, P, R, f) for items in source domain, starred (a*, P*, R*, f*) for items in target domain.

Horizontal relations are similarity or difference relationships within a domain, vertical are the standard mapping relations we're used to. Introduced by Hesse originally, along with the tabular method of representing analogies (14).

Keynes (1921) introduced these terms:
Positive analogy - accepted or known similarities.
Negative analogy - accepted or known differences.
Neutral analogy - accepted propositions about S for which it is not known whether an analog holds in T.
Hypothetical analogy - The proposition Q in the neutral analogy that is the focus of our attention (14).

prima facie/minimal plausibility - when a hypothesis has two things:
	- epistemic support: an appreciable likelihood of being successful/true
	- pragmatic importance: worth investigating, given feasibility and interest (18)
This is a modal interpretation of plausibility; there is no easy way to translate prima facie plausibility into the language of probability. (18)

"There are no widely acknowledge commonsense inference rules for analogical arguments, despite the confidence with which such arguments are endorsed or rejected." (21)

Identifies two conceptions of analogies used to evaluate them:
	- Sampling/Inductive conception - Mill's view, a competition between the known points of agreement and those of disagreement.
	- Structuralist/Deductive conception - Hempel's (1965) view, based on formal resemblence and isomorphism.
	- He will argue in chapter 2 that these are both wrong. (21) Gives brief examples of analogical arguments that violate both, yet are (or at least at one point were) considered analogical arguments.

The Articulation Model
- His two-part theory of analogical arguments.
- Proposes a classification scheme based on the different types of vertical relations in the source and target; they "provide the clue to determining which similarities and differences are relevant." (25)
- Prior Association - The vertical relation in the source domain that is the focus on the analogical argument.
- Principle 1: Requirement of Prior Association
	The description of the source domain must include an explicitly stated vertical relation which the analogical argument is supposed to extend in some way to the target domain.
- Mathematical analogies: Where the prior association is a proof that certain assumptions entail a theorem about the source domain, and therefore similar assumptions in the target domain entail a similar conclusion.
- Explanatory analogies: Where the prior association is that hypothesis Q explains observed consequences of P (called Q).
- Potential for generalization
- Principle 2: Potential for generalization
	A good analogical argument is one where, at minimum, there is no compelling reason to deny that the prior association that obtains in the source domain could be generalized in a way that extends to the target domain.
- Then what makes an argument for analogy stand is whether the set of vertical relations in the source domain (the prior association) provide support for the conclusion that similar connections obtain in the target domain.
- This allows two ways to attack the argument:
	- Criticize the prior association in the source domain
	- Argue that the attempt to transfer that association to the target domain is blocked in some way. (27)

Distinguishes between validation (showing an inference conforms to some rules or standard) and vindiction (which is more of an after-the-fact demonstration of a policy's effectiveness in achieving certain goals). "A vindication of a theory of analogical arguments might be a demonstration that a reasonable proportion of the arguments endorsed by that theory lead to true conclusions." (30) What he argues for in this book he can only describe as "partial validation" of his theory, and he believes this is the most one can expect.

Closes the chapter by briefly discussing the relation between bayesian confirmation and prima facie plausibility.


===========================================
CHAPTER 2 - PHILOSOPHICAL THEORIES
===========================================
- He regards his theory as a refinement of Hesse (1966), and hers as a sophisticated expression of Aristotle's model.

2.2 Aristotle on Analogy
	- Aristotle identified two argument forms: paradeigma (argument from example; actually more like induction followed by a deductive syllogism) and homoiotes (argument from likeness).
	- Aristotle is credited with the view that analogical arguments are a subclass of plausibility arguments.
	- Though he criticized his predecessors for arguments based on superficial similarities, he offers no procedure to judge which attributes are too superficial to pass the homoiotes test.
	- Four criteria from Aristotle stand out:
		- The strength of an analogy depends on the number of similarities.
		- Similarity reduces to identical properties and relations.
		- Good analogies derive from underlying common causes or general laws.
		- A good analogical argument need not presuppose acquaintance with the underlying universal (generalization).

2.3 Hesse's Theory
	- Models and Analogies in Science (1966), chapters 2 and 3 is what he focuses on.
	- Similarity-identity reduction. Assumption made by Hesse, that all similarities can be resolved into relationships of identity and difference. However, Bartha notes that alternative analyses of similarity may be available (consider mathematical analogies).
	- Three requirements Hesse formulates:
		- Requirement of material analogy. The horiontal relations must include similarities between observable principles. Contrast material with formal analogy, which holds if both domains are "interpretations of the same formal theory" (Hesse 1966, p.68). This conflicts with "most recent computational theories of analogical reasoning" (42), explicitly Gentner's systematicity requirement. But for Hesse, analogies are useful be cause we "have no *theory* of the target domain---and specifically, no theoretical knowledge of the vertical relations among objects in the target" (42). If we knew a lot about the structure of the target already, the analogical transfer wouldn't be as useful. Bartha says this account is too dismissive of formal analogies, she has difficulty justifying the weight attached to "pre-theoretic" similarities, and finally her model assumes too little knowledge of the target domain.
		- Causal condition. The vertical relations must be causal relations "in some acceptable scientific sense." Bartha calls this "too restrictive" (43), it cannot for example account for analogies" founded upon strong statistical corelation in the absence of any *known* causal connection."
		- No-essential-difference condition. The essential properties and causal relations of the source domain must not have been shown to be part of the negative analogy. Bartha again calls this too restrictive, giving the example of analogies between a triangle and a square, or other polygon. Clearly there are essential differences between the shapes, yet convincing analogies still hold.

2.4 Analogy as Deduction
	- Approach suggested and developed mainly by Russell (1986a), Davies and Russell (1987), and Davies (1988).
	- Based on the concept of a determination rule, a relation between binary values (which I assume correspond to properties or features of objects in the domains).
	- Russell and Davies "maintain that background knowledge of a determination rule underlies many of our analogical inferences. This assertion is questionable." (47)
	- We have no well-supported determination rule that can fro example support the analogical similarity between animals and humans, though we make this analogy all the time in laboratory testing.
	- Weitzenfeld (1984) instead suggests that analogical arguments are deductive arguments with a missing premise, which need not necessarily be background knowledge. Suggests three ways to find this premise:
		- Enumeration: examining the source and target domains statistically. 
		- Surveillance: Perceiving a similarity based on structural isomorphism.
		- Inference: Seems to be based on background theoretical considerations.
	- Overall, since finding Weitzenfeld's missing premise is based on plausibility arguments anyway, it seems to offer us little more in the way of justification than what we started with.

2.5 Analogy as Enumerative Induction
	- Some portray it as either generalization from a single case or a statistical / sampling argument.
	- Single case induction. Bartha calls it also too restrictive. It offers little to "advance the search for criteria that help us to distinguish between relevant and irrelevant similarities, and hence between good and bad analogical arguments." (50) I furthermore add that it does not explain how we are able to find analogy so quickly, and evaluate analogy so quickly: imagine the possible amount of generalizations for a single case. How can we comb through them so quickly and focus in on the ones relevant to the simialrities with the target domain? Something else is clearly at work here.
	- Sampling arguments. E.g. Mill, who calls analogy a competition between the positive and negative analogies (though not in that vocabulary); Harrod (1956) bases it on the binomial distribution formula. Bartha's criticisms: The method of counting the differences required for these calculations are poorly defined (what counts as one difference? Many similar accounts depend on the knowledge that our list of attributes is complete.); what justification is there that the samples selected are random? Clearly we choose source analogs by some other method different than pulling marbles out of a black bag.

2.6 Skeptical Objections
	- Agassi (1964,1988) has two arguments claiming to show "that most analogical arguments *cannot* be justified." (52)
	- 1: Analogical arguments amount to not much more than single-case generalization. Although we may sympathize with this criticism as it applies to certain accounts of analogy, Agassi's example is a toy one that seems to confuse analogy as a plausibility argument with analogy as a closure argument.
	- 2: Analogies are always proposed within a context of background assumptions, without which they are useless. This is clearly disproved by the types of analogies in mathematical domains, and the types we work with in the computational field.
	- 2b: Analogical arguments rely on methodological essentialism, which is false. Methodological essentialism is the view that human intuition reliably identifies natural kinds. I think we can safely ignore this criticism, because my human intuition reliably identifies this as unimportant.


===========================================
CHAPTER 3 - COMPUTATIONAL THEORIES
===========================================
Main question he tries to answer is "whether computational theories are broad enough to provide genuine insight into the sort of analogical reasoning that occurs in the sciences." (59)
Breaks computational theories of analogy into two types:
	- Structuralist: analogies are founded on parallel representations about two domains, and an isomorphism is found. Subdivides into connectionist / structuralist.
	- Case-based: Two domains share a cluster of salient, or relevant, dimensions.
By contrast, Bartha's "project focuses on philosophical problems linked to the evaluation and justification of analogical arguments, with particular attention given to their use in scientific reasoning. [His] review of computational models will concentrate on their potential and their limitations for illuminating such problems." (61)

Proposes four criteria to evaluate computational models:
	- Predictiveness: How well does a computational theory make definite predictions about which analogies are more plausible than others?
	- Applicability: How well does it apply? Is its evaluation criteria justified? Do its judgments of "best" analogies involve prima facie plausibility?
	- Scope: Does it apply to a large class of problems and explain diverse phenomena associated with analogical reasoning?
	- Simplicity: Should be a feature of computational theories just like it is of scientific theories, but since analogy is complicated "...the importance of simplicity should not be exaggerated." (62)

3.2: An Early Effort: Evans's ANALOGY Program
	- Summarizes ANALOGY, which "foreshadowed the structuralist view of analogy".
	- Its limitations all "have to do with its scope."

3.3 Structuralist Approaches
	- The Structure-mapping theory
		- discusses standard stuff about SMT
		- SP (Gentner's Systematicity Principle): A predicate that belongs to a mappable system of mutually interconnecting relationships is more likely to be imported into the target than is an isolated predicate.
		- Repeats Hofstadter's criticism that "the analogy is already effectively given in the representations."
		- "The first and most obvious problem has to do with predictiveness...a purely structural theory of analogy is highly sensitive to the details of representation." (67)
		- Scope: "...it is not always appropriate to give priority to systematic, high-level relational matches" (69). Claims that sometimes surface features matter more (?).
		- Applicability: Claims even some of Gentner's work suggests that people tend to focus on surface similarities unless otherwise is suggested.
		- "The Systematicity Principle is normative, not descriptive. It is a principle meant to characterize good or plausible analogical reasoning, and it is the most important normative principle underlying current work on analogies in cognitive science" (70).
		- Says "increased systematicity is not *sufficient* for increased plausibility".
		- Since SP doesn't take into account the valence (direction of relevance), it ignores preventative relationships. For example, earth is like mars, therefore life is likely to be on mars, but there are preventative causes like how cold Mars is; Mars' temperature is *negatively relevant* to the existence of life. He claims this is an example where removing the extra systematic information (the temperature) would increase the plausibility of the inferred argument. "Increased systematicity does not always increase plausibility; reduced systematicity does not always decrease it. The elimination of systematic overlap contributes to plausibility when what is eliminated is a counteractive cause. The focus on counteractive causes makes this very clear, but the more general point is that without taking into account the *nature* of the relationships of various factors to the hypothetical analogy, systematicity can be misleading" (71). 
	- A Constraint-satisfaction Model
		- ACME, Holyoak and Thagard's attempt to address SME's problems
		- "On predictiveness and applicability, it appears that the constraint-satisfaction model fares little better than the structure-mapping theory. Sensitivity to the initial representation is even more of a problem, since in addition to the propositional description of the domains, the user must provide specific similarity weights and pragmatic cues" (73).
		- Thagard's new model, Drama (Eliasmith and Thagard 2001), claims to minimize the hand-tailored input problem.

3.4 Case-based Reasoning
	Every CBR program has four components: A library of past cases, an indexing scheme, a method for matching a new case with similar past ones, and a method of adapting past solutions.
	There are four types of index commonly applied:
		1. Correlated factors or dimensions.
		2. Causal factors or relationships. Like dimensions, but supplemented with a causal model of the relevant domain.
		3. Teleological or goal-related concepts. E.g., to produce a meal with a recipe, to win a war, etc.
		4. Derivational indices. Features of attempted solutions to a past case, e.g. steps in a proof.
	Hypo - Ashley (1990)
		- CBR in the domain of trade secrets law.
		- Three reasons "to think that the idea used in HYPO could not easily be extended to scientific reasoning by analogy." (1) there's often only one source/target in scientific analogies. (2) HYPO has a fixed set of dimensions. (3) Scientific analogies are usually based on specific causal or logical relationships, which HYPO can't model.
	Prodigy and Derivational Analogy - Carbonell (1986)
		- Transformational analogy was the initial approach
		- Derivational analogy allows things like translating procedures from one programming language to another
		- Derivational analogy can only be used in domains where problem solutions can be derived via a set of operators and inference rules with definite preconditions and effects. This limits its scope.
	CBR: Limitations and Wider Relevance. Limitations of this approach are summarized:
		- Lacks a complete set of determining factors. 
		- Requires a dense library of source cases.
		- No plausibility criteria: Most shed no light on the problem of evaluating the plausibility of analogical arguments.

3.5 The copycat program - Hofstadter (1995), Mitchell (1993). 
	- Hofstadter rejects structuralism partially because "by the time we have 'crisp' representations ..., most of the work is done" (84). 
	- Involves fluid concepts, or "halos" that are probabilistic clouds that emerge as a result of the process. This is what Hofstadter believes concepts are like, and Bartha somewhat sympathizes.
	- Hofstadter and Mitchel think the fluidity of their concepts is a key advantage over other approaches.
	- "Copycat fares well in terms of the criteria laid out [earlier]". It is not known how well it does with issues of scope.
	- In Bartha's view, "Copycat presents a powerful case that analogy-making is in large part the perception of patterns, and that it is properly modeled with low-level cognitive processes. But in no way does this eliminate the need for a logical model of analogical reasoning" (87), since it doesn't explain what makes a good analogy.
	- "Copycat offers a bottom approach to analogical cognition. ... [Bartha's] approach ... is top-down. [He] is convinced that there is room for both approaches" (88).

3.6 Conclusion
	- "No existing computational theory, however, provides a good general normative theory of analogical arguments in science." He has argued "that neither the structuralist nor the case-based approach can be extended to a general understanding of analogical arguments."
	- Systematicity is the only thing like a norm that structuralist models incorporate, and it is only at best statistically correlated with plausibility, which Bartha is trying to understand.

===========================================
CHAPTER 4 - THE ARTICULATION MODEL
===========================================
Since many philosophical theories don't discriminate well between good and bad analogies, and computational models dismiss normative accounts altogethers, his articulation model is created for evaluating analogical arguments. His summary of requirements for a normative theory of analogy:
1) Clarity and consistency - must be able to evaluate clearly things like evaluation criteria, analogical representation, and must apply to the entirety of analogy.
2) Applicability / predictive adequacy - must discriminate plausibly between good/bad analogical arguments.
3) Explanatory power - must provide criteria amenable to philosophical justification; show how good analogies contribute to plausibility.
4) Scope
5) Simplicity
6) Nontriviality - shouldn't simply say "analogies are irrelevant to justification".
- He proposes to understand these things by looking first at the nature of the vertical relationships, so he can "classify and evaluate analogical arguments on the basis of [the] prior association" (94).
- He takes "interdomain correspondence - relationships of similarity and difference - for granted. This sets [his] project apart from work on analogy in cognitive science, where the focus of research is on the generation of mappings between domains."

4.2 Classification and Examples
	- The type of argument can be classified depending on properties of the direction of the prior association. P is the positive analogy, Q is the hypothetical analogy.
		1) Predictive analogies (P -> Q) P is prior to Q in the association. e.g. A property known about a triangle, then you conjecture something analogous applies to a tetrahedron.
		2) Explanatory analogies (Q -> P) Q is prior to P, e.g. to explain that the absence of electrical influence inside a hollow charged spherical shell is evidence charges attract and repel with an inverse square force, by analogy to something else.
		3) Functional analogies (P <-> Q) Association in both directions. P may be the efficient cause, while Q would be prior as the final cause.
		4) Correlative analogies (P |. Q) (|. is a downward arrow) Symmetric association, no direction of priority. Relationship is statistical correlation. No reason to think that P or Q causes the other.
	- Another dimension is its mode, which can be either deductive or inductive. Chart on p. 98 (I photographed it)

4.3 The Articulation Model
	- Two fundamental principles. There must be a prior association/clear connection in the source domain between the known similarities and the further similarity that is projected to hold in the target domain, which can be logical, causal, explanatory, or a correlation.
	- Second, there must be a *potential for generalization* of this association from the source domain to the target, which would support the conclusion of the analogical argument.
	- FORMAL VERSION:
		An assessment of plausibility takes place against a background of potentially relevant factors F, which consist of:
			- The set \phi of all factors (besides the conclusion) that explicitly appear in the argument
			- All sets \Psi of factors (other than conclusions) that appear in other salient analogical arguments advanced in favor of the same or rival conclusions
			- A set B of unstated background factors (also called the background context)
		We are trying to find two things, Prima facie Plausibility (modal notion) and for those that are prima facie plausible, Qualitative Plausibility:
		
		Prima facie Plausibility - An analogical argument is prima facie plausible if:
			1. Overlap. \phi+ \cap P != \emptyset 	(there must be some relevant/contributing factor common to the source and target domains; the positive analogy plays a relevant part in the prior association)
			2. No-critical-difference. \phi^C \cap N = \emptyset       (no critical factors belong to the negative analogy)
		Qualitative Plausibility - Depends on three criteria:
			1. Stength of the prior association - Evaluating its strength depends on the type of analogical argument.
			2. Extent of the positive analogy - How strong is the positive analogy, compared to the negative and neurtral components? Often shifting critical factors from the negative or neutral to the positive analogy is possible to strengthen the analogical argument, or from negative to neutral.
			3. Multiple analogies - are there other analogies which may contribute to or weaken the strength of the conclusion?

		\phi - The set of factors appearing explicitly in the argument = \phi^C \cup \phi^S \cup \phi^I
		\phi^C - set of critical (or critically relevant) factors
		\phi^S set of secondary (or secondarily relevant) factors
		\phi^I set of irrelevant factors (often empty)
		\Beta - the set of background factors
		\phi+ - The subset of relevant factors consisting of those that are both present and have positive valence (meaning it is a contributive cause for Q)
		\phi- - The set of relevant factors that are present and have negative valence
		P - positive analogy, all members \phi represented as belonging to the source and target domains
		N - negative analogy
		O - neutral analogy

		Prior Association - A relation R(\phi_1, ..., \phi_m, \pi_1, ..., \pi_n, Q) where each \phi_i and \pi_i belongs to \phi
		
4.4 Mathematical Analogies
	4.4.1 Prior Association for Mathematical Analogy
		\phi |- Q
		- Where Q is the proposition whose analog is projected to hold in the target
		- \phi is the set of explicit assumptions used in the proof
		- Unstated background assumptions are not part of the prior association
		- The prior association is that Q follows from \phi through some derivation
		- The analogical argument suggests a similar entailment relationship implies an analogous proposition Q* in the target domain
		- The precondition here is just that the proof be mathematically acceptable (which he says requires that it "satisfy a competent mathematician").
	Uses the example: the medians of a triangle intersect at a common point, therefore they also do for a tetrahedron. 
	"The important idea, once again, is that analogies are a precursor to generalization. In mathematical analogies, to generalize is to formulate and prove a result in a setting that comprehends both the source and target domains. To treat analogies as the first step in such a process seems as reasonable in mathematics as anywhere, since most (perhaps all) successful analogies do lead to generalizations. ... But, of course, when we aregue by analogy we cannot appeal to (and are often aware of) any such generalization" (109).
	4.4.2 Prima facie Plausibility for Mathematical Analogies
		1) Overlap. Some fact used in the source proof must belong to the positive analogy, P.
		2) No-critical-difference. Nothing used in the source proof can correspond to something known to be false in the target domain. That is, no critical assumption belongs to the negative analogy, N (110).

4.5 Predictive/Probabilistic Analogies
	- Examples given: Drugs tested on animals are likely to work on humans, and there are likely to be life on other worlds that are similar to earth in some respect
	- Prior association here is a causal explanation (even if it is not well known or only probabilistic).
	4.5.1 Prior Association for Predictive/Probabilistic Analogy
		Q because \phi^+ and \Pi, despite \phi^-
		- Q is hypothetical analogy
		- \phi+ and \phi- are sets/lists of relevant contributing and counteracting causal factors present in the source domain
		- \Pi = {\pi1, \pi2, ...} is a set/list of factors that are absent from the source
		- It may be helpful to introduce a background context \Beta of unstated assumptions, even though they are not formally part of the prior association
	4.5.2 Completeness Condition for Predictive/Probabilistic Analogy
		No defeating condition for any contributing cause in the explanation of Q may be known to hold in the source domain
	4.5.3 Prima facie Plausibility for Predictive/Probabilistic Analogies
		1) Overlap. Some contributing causal factor (in \phi+) must belong to the positive analogy, P
		2) No-critical-difference. Each identified contributing causal factor (in \phi+) must not be known to be absent in the target, and each salient defeater (in \Pi) must not be known to be present in the target.
	Using these, we can for example reject the argument that the moon should have life regardless of any similarities it has to earth, since it lacks an atmosphere and liquid water.
	- There are trade-offs with the way we formulate an analogy using this method. "The more contributing causes we include in the explanation, the stronger the association and the greater the potential for a strong analogical argument ... Yet each contributing clause listed counts as critical and thus increases the likelihood of finding a disanalogy between the source and the target domains."

4.6 Abductive Analogies
	4.6.1 Prior Association
		C,Q |- E
		- Observable result E is mathematically derived from hypothesis Q together with other assumptions C
		- Informally: "E follows from Q"
		- Objective of analogical argument is to convey plausibility upon an explanatory hypothesis Q*.
	Example: just like the production of a note on a stringed instrument or tuning fork leads to harmonic overtones, we might expect the discovery of corresponding harmonic overtones between the lines of visible spectra (suggested by G.G. Stokes)
	4.6.2 Pre-conditions
		1. the derivation must be valid
		2. the additional assumptions must be justified (note these two may be difficult to assess, he says he won't tackle those issues in this book)
	4.6.3 Precondition on the Target Association (for explanatory analogies)
		C*,Q* |- E*
		- E* represents an observable result, C* the boundary conditions and auxiliary hypotheses that apply to the target domain
		- Predictive analogies do not have such a precondition, because there the *conclusion* of the analogical argument is that it is plausible that such an entailment holds. For explanatory analogies, it is part of the foundation of the argument.
	Relation to hypothetico-deduction: "If we have a derivation of E* from Q* (together with C*), then it appears that Q* becomes plausible on grounds that pertain solely to the target domain. Indeed, according to a crude formulation of the hypothetico-deductive (H-D) model of confirmation, *any* hypothesis receives confirmation if it entails some result that is actually observed. If we know that Q* meets this condition, then what purpose does the analogy serve?" (124)
		Answers:
		- We still need to justify the additional assumptions C*
		- The H-D model fails to "distinguish seriously proposed from *ad hoc* hypotheses. Many hypotheses that are confirmed on a narrowly construed H-D model are rightly ignored as *ad hoc* or spurious. ... explanatory analogical arguments provide an important way to distinguish serious hypotheses from frivolous ones."
	4.6.4 Scope of Q
		Scope(Q) consists of E and every other salient observable consequence of Q together with C.
	In summary, evaluating plausibility for abductive analogical arguments depends upon:
		1) The validity of the derivations in the source/target domains
		2) the reasonableness of the additional assumptions in both domains
		3) The fact that no critical features (C or scope(Q)) beong to the negative analogy

4.7 Abductive/Probabilistic Analogies
	Like abductive analogies, except the explanatory connection is not represented as an entailment but in statistical terms or by means of a causal model.
	Example: Darwin's analogy between artificial and natural selection---just as in artificial selection species evolve to have traits favorable to the breeder, the probability of traits that increase fitness in the wild will emerge.

4.8 Functional Analogies
	Inferring similarities in function from similarities in form. 
	Example: In archaeology, referred to as the "method of ethnographic analogy" which allows you to infer the probable function of an artifact based on knowledge of how a similar artifact was used in a similar culture.

4.9 Correlative Analogies
	Analogies in which the prior association is merely statistical correlation. 
	- Since the prior association gives us very little information, this is particularly difficult for the articulation model.
	- Argues statistical correlation provides TOO LITTLE STRUCTURE to identify critical factors and provide guidance in assessing plausibility.
	4.9.1 Prior Association
		Pr[ Q | \phi and C] > Pr[ Q | C]
		Informally: \phi is *positively relevant* to Q given C.
		From this, we conclude Pr[ Q* | \phi* and C* ] > Pr[ Q* | C* ]

4.10 Multiple Analogies
	Bartha asserts that arguments involving a single source domain are more fundamental than those with multiple source domains, his defense:
		1. Ubiquity: Individual analogical arguments are very common
		2. Screening: Multiple analogs still require a method of screening for prima facie plausibility
		3. Rough independence: This screening can and should be made independently of the other analogies
	But what about cases where the fact that multiple source analogs are applicable strengthen the plausibility of the analogical argument? Bartha next explains how to extend the articulation model to account for this, where a partial ranking of source analogs exists such that we can discard any that offer hypotheses incompatible with more strongly plausible source analogs.
	This explains prima facie plausibility, but when it comes to quantitative plausibility (how does one combine the quantitative plausibility of source analogs?) he does "not have such a theory" and limits himself "to making a few observations" (147).

4.11 Conclusion
	- He has argued "that there is also considerable variation in logical type, as reflected in the classification scheme."
	- His general theory for evaluating analogical arguments is based on two fundamental principles: prior association and potential for generalization.
	- These two apply in all analogical arguments, but their logical form is different depending on category, and require supplementation "with subordinate models that both provide a basis for initial assessment and indicate fruitful directions for further study" (148).



===========================================
CHAPTER 5 - ANALOGIES IN MATHEMATICS
===========================================

- The concept of analogical similarity in mathematics can be very difficult to model with a simple strategy if at all possible, and he does not attempt to provide a comprehensive theory that will describe all possible kinds.
- Polya (1954) is the major work on this topic prior to this
- Regarding the level of detail at which we understand similarity, he will "not attempt to match the level of detail in [computational analogy] theories" (154), instead using his framework of advocate and critic: if a reasonably intelligent, skeptical but sympathetic critic must be satisfied that a similarity exists.
- Example: What is the analogical connection that allows us to realize that when using theorems about 2d objects and trying to figure out the analog for 3d objects, area is often analogically mapped to volume? We can say they're both instances of a certain general formula, but this doesn't seem to capture the intuitive notion that they are connected because they both capture the concept of "how much stuff" can fit inside.
- He says this is reminiscent of Goodman's (1965) paradox (grue and bleen)
- Admissible - a correspondence is admissible if it is an acceptable basis for an analogical argument (this is expanded on in sections 5.4 - 5.6)

5.2
The problem of specious resemblance: ? Something to do with an artificially manipulated formula pair that is done so to create an analogy? (154-6)

5.3 Isomorphism
	- Although isomorphism is often the standard used for similarity, it is too "rigid to accommodate many intuitively plausible analogical arguments, even within the field of mathematics" (160).
	- His criticisms
		- Isomorphisms require perfect certainty
		- Isomorphisms require bijections
		- It is too restrictive to capture the diverse forms of similarity in mathematical analogies: e.g., geometric analogies like area and volume, which "is not possible [!] under an isomorphism"
	- There is one thing he likes about isomorphisms:
		5.3.3 Consistent Mapping Condition
			An admissible analogy relation \phi must be consistent: any designated relation, function, or object of the source domain S has at most one analog in the target domain. In other words, \phi is a function from designated relations, functions, and objects of S to those of T.
5.4 Algebraic Similarity
	An *algebraic similarity* between relations R1,...,Rm, functions F1,...,Fn, and constants c1,...,cp of S, and corresponding Ri*,Fi*,ci*:i=1...m,n,p of T is expresse by the second order propositional function:
		\Phi(R1,...,Rm; F1,...,Fn; c1,...,cp),
	Such that the two sentences
		\Phi(R1,...,Rm; F1,...,Fn; c1,...,cp)
		\Phi(R1*,...,Rm*; F1*,...,Fn*; c1*,...,cp*)
	that result from substituting the respective relations, functions, and constants for the variables are true in the respective domains S and T.
	Example: commutativity of addition/subtraction is expressed by:
		\Phi : (x)(y)(Fxy = Fyx)
	
5.5 Geometric Similarity
	Two expressions F and F* are geometrically similar if one of the following obtains:
		a) F = F(m) and F* = F(n), where F(k) is an expression parameterized by a positive integer k in some range including m and n
			e.g. f(x) = x^2 and f*(x) = x^4 both instances of F(k) = x^k
		b) F = F(a) and F* = F(b) where F(t) is an expression parameterized by a real number t in some range including a and b
			e.g. f(x) = x^{n/4} and f*(x) = x^{n/2} both instances of F(t) = x^{tn}
		c) F = F(x1,...,xm) and F*=F(x1,...,xn) where F(x1,...,xk) is an expression with k arguments, defined for a range of values of k including m and n
			e.g. Area(x,y) = xy and Volume(x,y,z) = xyz both instances of F(x1,...,xk) = x1...xk
	- The problem of specious resemblance - two expressions with no meaningful similarity can be rewritten to have a purely syntactic similarity and satisfy geometric similarity. He suggests fixing this by adding the requirement of Internal Coherence:
	- Internal coherence: For a geometric similarity to count as admissible, the relevant relations and functions should be expressed using standard representation, unless some justification internal to the domain can be given for a nonstandard representation. More specifically, any novel representation should be justified in terms of the proof that is the prior association for the analogical argument.
	- "The proposal is that any novel way of representing features of the source or target domain must have a motivation that is independent of the analogy and its purposes, a rational internal to the domain." (170)
	- He reiterates that he rejects theories of similarity based on isomorphisms, a sort of primitive semantic relation, and those that reduce similarity to identity.

5.6 Asymptotic Similarity
	
Plausibility III (final formulation, p.177) for mathematical analogies.
	1) Overlap. Some explicit assumption in the proof must correspond admissibly to a fact known to be true in the target domain (or an appropriate dense subset, in the case of asymptotic similarity). (The positive analogy is nontrivial.)
	2) No-critical-difference. No explicit assumption in the proof can correspond admissibly to something known to be false in the target domain (or an appropriate dense subset, in the case of aymptotic similarity). (No critical assumption belongs to the negative analogy.)

5.7 Plausibility and Analogy in Mathematics
	- Why should an analogy that satisfies the "Plausibility III" test have a plausible conclusion?
	- He notes this is only a modal notion; and that "It is certainly worth exploring the prospects for a probabilistic interpretation of plausibility", one that avoids the possibility of logical omniscience that doesn't just reduce to the problem of finding the proof itself.
	- He suggests "that the plausibility of analogical reasoning is often best construed not precisely in terms of probability but, rather, in terms of *relative conditional betting quotients* (we might call them quasi-probabilities); and further, that these betting quotients are *symmetry-based.* At the heart of an analogical argument is the judgment that a conditional bet on Q* given P* is approximately equal in value to a conditional bet on Q given P---even though one may not have an exact value in mind. And the basis for that judgment is the symmetry of the two situations: the reasoning that pertains to your evaluations of these two conditional bets must be the same" (182).
	- He will discuss his approach to justification further in chapter 8.

5.8 A larger role for mathematical analogies
	- As a heuristic, analogies can serve two roles in mathematics: the psychological "suggestion-generator", and the logical establisher of plausibility (the latter of which is his focus).
	- Analogies also play a role in unifying branches of mathematics: geometry and algebra, number theory and complex function theory, etc.
	- "If an analogy that looks likely to be fruitful in light of experience somehow [does not meet this book's plausibility] criteria, our model does not mandate total rejection of the argument---it leaves us with the option of modification" (186).


===========================================
CHAPTER 6 - SIMILARITY AND PATTERNS OF GENERALIZATION
===========================================

6.1 Introduction
- "The central idea of the articulation model is that the proper way to evaluate an analogical argument is to assess its potential for generalization."
- Discusses 3 common types of similarity, which he notes tend to lead to 3 different types of generalizations (when the analogies are successful). (195-6)
- When talking about computational models, they tend to "treat analogical mapping as a process driven by the objective of maximizing overall similarity {\ldots} Although these models allow for initial similarity judgments{\ldots}, individual features of the source and target domains ultimately count as similar if placed in correspondence by the "best" global mapping." In contrast, on his account, "the goal of an analogical argument is to generalize a particular logical or explanatory relationship rather than to maximize overall similarity. This contrast reflects [his] orientation toward normative concerns. It may be psychologically realistic to suppose that what triggers analogical reasoning is an initial perception of striking similarities, and that what drives it toward a conclusion is a passion for global similarity," (196) but he is more concerned with how to evaluate analogies AFTER that.

6.2 Feature Matching and Correlative Analogies
- Quine (1969, 1973) suggested that natural selection gave us an instinct for making good similarity judgments and singling out natural kinds. But Bartha objects saying we make lots of errors (I'm not sure how this is an objection to what seems like an argument for an imperfect heuristic). (199-201)
- [Steven Jay] "Gould's analysis makes it very clear that simple-minded naturalism about scientific kinds (and scientific analogies) [like that expressed by Quine] is a nonstarter." (201)
- Criteria for inferring the existence of a common kind:
	- 6.2.1 Scarcity (of each individual feature) - The more uncommon the cited similarity, the greater the likelihood that it picks out a distinct kind.
	- 6.2.2 Congruence - A cluster of matching features that is comparatively rare contributes greatly to the plausibility of a common kind.
	- 6.2.3 Independence - We should excluse similarities that appear redundant relative to others on the list.
	- 6.2.4 Qualitativeness and Discreteness - Reject quantitative and continuous characters for those that are qualitative and discrete, as they are more reliable indicators of a stable group.
	- 6.2.5 Discipline-specific Constraints - The above should be balanced against discipline-specific guidelines meant to distinguish between misleading and informative similarities.

6.3 Formal Similarity and Pythagorean Analogies
- These often have to do with some sort of structural (syntactic) isomorphism, or *nomic isomorphism* in Hempel's terms.
- Bartha doesn't want to limit formal analogy to nomic isomorphism; he wants to allow for cases in which the formulas that will end up being isomorphic don't exist yet, but can be *extracted*. 
- Formal analogy - exists between two domains whenever we can abstract a common mathematical form (typically equations), regardless of whether this relates laws or descriptions of empirical phenomena. (209)
- Formal similar - Two objects, relations, or functions that correspond within the context of a formal analogy; they are interpretations of the same symbol in the common abstract form.
- Pythagorean analogies - Steiner's term; refers to purely mathematical similarities with no known physical interpretation at the time they are proposed, even if one emerges later (211). E.g., the pythagoreans reasoned that numbers and their properties corresponded to the universe, so based on what they found on how numbers behaved they would infer other worlds existed, etc. He argues scientists today (think Einstein, or quantum theory's predictions based on mathematics) are their modern descendants.
- Steiner's objection is summarized: "unless we suppose that the aesthetic sensibilities of the human mind are somehow aligned with the natural world {\ldots} , there is no basis for expecting that they should provide even the weakest of guidance in seeking the fundamental laws of nature." "Does a sentence have an enhanced claim to be true because it is a palindrome?"
- Bartha reminds us of the computational (Gentner et al) response to this objection: that many pythagorean analogies can in fact establish a measure of plausibility (such as SME). But the problem is "justification is not the central concern in such theories, and perhaps comes too easily if one constructs representations of two domains that exhibit similar syntactic structure." (217)
- Bartha's chosen response is to show that the impression of pythagorean analogies dissolves when the finer structure of the arguments are considered (in other words, they're not as based on pure mathematical inferences that aren't rooted in anything physical as one might think). He results in the following formulation:
- 6.3.6 Modified Requirement of Physical Analogy - A necessary condition for a *composite* analogical argument in the empirical sciences to be plausible is that in at least *one* of the component analogies, the relevant similarities that constitute the basis for the argument have known physical significance. (221)
- "{\ldots}the solution here is similar to our solution in the mathematical case: to impose a requirement that our representations have a motivation that is independent of the analogy. That is why we need [6.3.6]" (223).

6.4 Parametric Similarity and Continuity Arguments
- Parametric similarity - Any relationship between features that can be usefully represented by the assignment of values to one or more continuous or gradually varying parameters (supposed to be similar to geometric similarity for mathematical analogies). (224)
- The examples he gives involve a causal relationship with four important points of contrast:
	- Direct and indirect analogies - Indirect analogies are where the conclusion is inferred from a uniformity which is generalized from known cases, and then on the basis of this generalization an inference is applied to the target domain. Direct analogies are those where this uniformity doesn't play a role.
	- Connected and unconnected analogies - There may be a time series or something linking the source and target domains causally using hypothesized intermediate cases. Further, continuous and noncontinuous connections are from connected cases where the intermediate cases are real-valued or integer-valued.
	- Historical and nonhistorical analogies - where the intermediate cases linking source and target are temporally connected. Subcase of the previous item.
	- Stability arguments and proportionality arguments - Does the variable of interest remain constant through the parametric change? Or is the argument that it changes proportionally to other factors (e.g. small changes pass through generations, therefore over time entire species change dramatically)?
- "On [his] theory, for a *prima facie* plausible analogical argument, there must be some support for a generalization that applies to both the source and target domains. As [he has] just been arguing, for continuity arguments, the relevant type of generalization is an invariant relationship" (228).
- Several strategies might provide support for such a relationship:
	- General survey - Collect lots of examples
	- Continous connection and the simple stability argument - simple stability argument has 3 parts:
		- Continuous function - The thing changing over time is a continuous function of certain parameters (e.g. the art styles of a society depend on culture, etc)
		- Discrete values - The set of possible values is finite (and hence discrete[?])
		- Continuous connection - There is a continous transition between the source and target items (the art style of ancient greece and modern greece)
	- Extreme Cases / upper and lower bounds - if the variation is not constant, or perhaps there is no determinate invariant. 
	- Nearly continuous chain and hypothetical cases - generate a hypothetical case that requires a small transformation to refute an analogical argument or make a difficult one easier to accept.
	- Proximate target - Show src and target domains to be proximate (relevant conditions are nearly the same in both). 
	- Insensitivity arguments - Weakest strategy of these; involves claiming that the generalization applies because the factors which change are irrelevant (e.g. mars must have life because the differences from earth don't matter towards supporting life)

===========================================
CHAPTER 7 - ANALOGY AND EPISTEMIC VALUES
===========================================

7.1 Introduction
- He wants to present arguments to support his conclusion, which is that "Good analogical arguments share a common logical core, despite wide variation across disciplines and historical contexts [, and that core is] captured by two simple and fundamental principles: prior association and potential for generalization. There must be a clearly articulated connection in the source domain, and there must be reason to believe that such a connection can be generalized to cover the target domain." (239)
- A hypothesis is prima facie plausible if it is "supported by an analogical argument which satisfies [those] two fundamental principles, and if there is no independent reason to reject it".

7.2 Review of Commonsense Guidelines
- He reminds us of 8 commonsense criteria he laid out in earlier chapters (240-41)
- "{\ldots}what matters is not so much the number of similarities and differences as their importance, and that importance is taken into account by our second principle: potential for generalization." (241)

7.3 Conservative and Progressive Values
- Talks about conservative and progressive forces in scientific inquiry. Conservative forces tend to resist modifications to current beliefs. Innovative/progressive forces favor theories that are fruitful, have wide scope, and unification.
- Discusses Kuhn's views, and how he didn't value analogy explicitly but Bartha believes it is important and very common

7.4 Analogy in Legal Reasoning
- Stare decisis - the doctrine of precedent, generally how decisions are bound by previous ones and simultaneously bind subsequent ones.
- Ratio decidendi - the portion of the judgment in which a judge enunciates a general legal principle(s) on which the decision is based. So a sort of elaboration of which features of the current case are similar and bound by previous cases.
- He argues that the principles of prior association and potential for generalization are embodied in the ratio decidendi (248).
- "The principal benefits cited for stare decisis, then, are stability, consistency, and the continuous and orderly development of the legal system. These are conservative political and moral values." (249)
- He wants to avoid arguing for western (particularly british) law as the pinnacle of achievement, and avoids committing to this by moving "to a model in which the different dimensions of value are represented in vector form, rather than combined into a single number" (250).
- Discusses the relation between stare decisis and the concept of justice---how is justice guaranteed by it? (251)

7.5 Law and Science
- Tries to develop a "high-level analogy between law and science" so that the arguments for stare decisis and such in law can be applied to scientific reasoning as well. Using analogy to justify the use of analogy.
- "{\ldots}we find that the basic assumptions in our justification for *stare decisis* all have analogs in the practice of science" (253).
- discusses some major differences between science and law:
	1- fundamental goals differ: dispensation of justice vs. truth "or some surrogate such as empirical adequacy". 
	2- law is normative, science is descriptive
	3- importance of conservative values - in science, we often value theories that innovate greatly.
	4- range of alternatives - what other legal options are there besides stare decisis?
	5- nature of prior associations - scientific prior associations are usually causal, logical, etc; legal ones are based on relationships of legal relevance.
	6- prevalence of open-textured predicates (see section 1.3 for def. of open-textured)
	7- obligation vs permission - in law, a good analogy is binding; in science it doesn't necessitate acceptance of a hypothesis.
	8- richness of case library
- he aims to show that these differences are "either irrelevant or can be accommodated without destroying the argument" (254).
- reminds us that we only care about methods for assessing plausibility, so science's primary goals of truth don't matter too much for us; this is essentially his answer to the first 4.
- The definition of plausibility as "worthy of investigation" allows us to sever it from any direct connection to the truth (256). Note that it might require some version of an instrumentalist view of truth.
- weakly optimal methods - those that assess worth by achieving a balance between conservative and progressive values - that is, if no other available method does better along every relevant dimension. Says this is a necessary condition for plausibility (257). Hypotheses supported by weakly optimal methods are the only ones that can be considered prima facie plausible. It is also a sufficient condition, if we assume that we "can and should perform an initial plausibility screening without assigning weights to the different epistemic values. {\ldots} An individual screening [should] be broad-minded. We want to allow, for instance, that two conjectures might both be plausible even if they could not both be true."
- closes the chapter by responding to the other objections one at a time

===========================================
CHAPTER 8 - ANALOGY AND SYMMETRY
===========================================

8.1 Introduction
- attempts to develop an account of symmetry (between the source and target domains), to determine how it fits with the current theory of analogy. 
- relies on a probabilistic (Bayesian) setting; aims to show that an analogical argument satisfying his model's requirements should justify the assignment of *nonnegligible prior probability* to a hypothesis (266).

8.2 The Modal Argument
- Symmetry arguments
	- Symmetry is "a precisely defined relationship of similarity between two objects." (266) Two problems are symmetrical if their relevant or essential structure is identical. 
	- Symmetry transformation - a mapping that preserves some designated feature or class of features.
	- Perfect symmetry between two problems is the same as perfect analogy; where all points of difference are known (or believed) to be irrelevant, and all features relevant to the solution belong to the positive analogy. (267)
	- Objective symmetries are those in which the relevant set of invariant features is part of a widely shared and objectively justifiable model (268). Contrast with subjective symmetries.
	- Practical applications of symmetry are oriented toward actions (e.g. to decide how much to pay for a car); contrasted with theoretical applications (which may be mathematical as well). (268)
- Symmetry Principles and Practical Reasoning
	- Positive Symmetry Principle (Van Fraasen 1989): Structurally similar problems must receive correspondingly similar solutions.
	- Negative Symmetry Principle - An asymmetry can only come from a preceding asymmetry.
	- "Experience has shown that symmetry arguments can lead to inconsistency" (269) This might be the case when an inconsistency of source cases already exists; an overreliance on symmetry might then amplify this inconsistency.
	- Bartha further formulates some principles to link the concept of symmetry to his concept of prima facie plausibility.
- The General Modal Argument
	- Starts with a good concise reminder of prima facie plausibility and stuff (275)
	- draws more connections between symmetry principles and his principles for prima facie plausibility in analogy

8.3 Prior Probabilities
- How can analogical reasoning be accommodated within a probabilistic, broadly Bayesian framework for belief updating? The remainder of the chapter focuses on this question.
- In this section: extreme bayesians might argue that analogy is unnecessary and unable to properly place any sort of rational constraints on prior probabilities. How can we argue against this?
- Bayesian epistemology involves interpreting probabilities subjectively (degree of belief in a hypothesis).
- The Mish-mash view of bayesianism is the one in which "there may be no crisp formal constraints upon our prior probabilities besides coherence, but it is nevertheless perfectly legitimate to demand justification for particular assignments." (283)
- In contrast, logical Bayesianism says you can sometimes determine prior probabilities using *inside* information about an experimental setup. There is much more literature on this, apparently.
- Analogical reasoning appeals to adherents "of both the mish-mash and the logical approaches, since it combines elements of both styles." (285)

8.4 Symmetry Arguments and Subjective Probability
- Classical Principle of Indifference: If there are n mutually exclusive possibilities h1{\ldots}hn and e gives no more reason to believe any one of these is more likely to be true than any other, than P(h_i | e) is the same for all i=1{\ldots}n
- But this leads to "well-known paradoxes", like the one on page (285). Essentially we calculate probabilities based on what information is available to us about the domain, the distribution, etc. 
- Bartha doesn't want to defend any grand symmetry principle, but to "make room for modest principles by countering arguments that lead to the complete dismissal of symmetry as a rational basis for probabilities." (286)
- I'm honestly lost on the rest of this section, I don't understand the prior literature and the debate that this is obviously in the middle of.

8.5 Analogical Arguments and Prior Probabilities
- He believes that analogical arguments meeting his requirements "have more than heuristic value: they proide a measure of justification for their conclusion." He supports this by relating his theory of analogy to the Bayesian model of confirmation.
- They want to show that if an analogical argument begins with a credible proposition and meets his criteria, then the assignment of nonnegligible probability to its conclusion is justified.
- Remember, an analogical conclusion meets the criteria for prima facie plausibility if it (1) has an acceptable prior association R, (2) a nontrivial positive analogy, and (3) no known critical difference from the target domain.
- He basically shows that the conditional probability of the conclusion given the conditional probability of its source analog proposition is less, but in the "same ballpark." 
- A modal argument might have a sequence of hypotheses of decreasing plausibility until we reach one that's no longer plausible, but the probability-based version doesn't suffer from this, each one has a similar, but lower probability to the last. So the final hypothesis is probably very unlikely, but not much more so than the previous one in the sequence.
- The modal approach is thus "powerless to accommodate distinctions in degree of plausibility."

8.6 Implications and Objections
- One of the biggest problems with his theory, he says, is that it offers no measure of similarity between source and target domains. "Because of this, the theory remains first and foremost a modal analysis: its main business lies with the initial screening of hypotheses for *prima facie* plausibility." (300)
- How can an analogical argument change the probability of an already existing proposition without offering any new evidence? He uses van Fraassen's suggestion that updating by conditionalization (like those who require new evidence to update probabilities) is too rigid to accommodate all types of belief change. (301)
- "Perhaps the most important point to emphasize here, once again, is that my theory supplies only a constraint on *pairs* of conditional probability assignments (in the two domains). It mandates that we bring two conditional probabilities into line, ensuring that one probability is nonnegligible with respect to the other. It does not tell us how to accomplish this. It does not propose any mechanism or rule for equalizing the two conditional probabilities."
- What reason do we have to expect analogical arguments to work? "the best answer I can give is that our models of analogical reasoning provide a forum that lets us debate about, and ultimately identify, the 'right' critical factors, and hence the appropriate invariants for establishing symmetry between the two domains." (303)

===========================================
CHAPTER 9 - A WIDER ROLE FOR ANALOGIES
===========================================

- "Briefly, for an analogical argument to be good, it must clearly articulate a relationship (the prior association) in the source domain and then demonstrate the potential for generalizing that relationship to the target domain."
- Chapter 7 tried to justify this theory by showing good analogies suggest optimal balances between competing epistemic values
- Chapter 8 tried to justify it by tracing it to symmetry principles
- This chapter wants to discuss the use of analogy that isn't "structured puzzle-solving", rather outside of normal science like how animals use analogy for activities that appear to be "neither rule-governed nor oriented toward generalization."
- Does his theory apply outside of normal science? He wants to say it can be adapted, though the resulting theory is "less sharp." This chapter is about him creating an "extended" version of his theory.

9.2 Revolutionary Analogies
- Can analogical arguments support plausibility judgments either during [scientific] revolutions or in the development of an original paradigm? 
	- Clearly such analogies exist, and are not only employed to make revolutionary hypotheses plausible, they are required for the backing of these hypotheses (308). He cites examples from Darwin and Maxwell where they use analogy to give their hypotheses [prima facie] plausibility.
- Second, if such revolutionary analogies do exist, can their role be explained by Bartha's theory for normal science?
	- This is "problematic" for his theory; the examples from Darwin and Maxwell don't appear to satisfy prior association and potential generalization relatively!
- Case 1 : Nonscientific source domain
	- In cases like Darwin's, where the source domain for the analogy is a nonscientific phenomena and it doesn't appear to satisfy prior association because of the "fuzziness" of the source domain, or because it is pure experience
	- The problem is that since there is no "science" describing the phenomena in the source, the prior association cannot be articulated in conformity with some generally accepted pattern of explanation or derivation
	- Two solutions: either drop that strict requirement for prior association (that it be in conformity with yadayada), or "wing it" by creating a prior association that seems to fit the case at hand.
	- Such a modification to the theory is significant, since it introduces a new step in which a new acceptable pattern of association based on the current case is created.
- Case 2 : Remote source domain
	- This is in cases like Maxwell's, where the analogy's source domain is a different scientific one. Problematic because is there real potential for generalization between two domains dealing with different objects, forces, predicates, etc.?
	- This apparently isn't a problem for computational theories of analogy, which assume that similarity between higher-order logical relations is sufficient for analogy. He agrees that *with respect to the particular analogical arguments of maxwell*, the domains are not remote, but instead of basing it on shared higher order relations, he says the domains are similar because they "fall into the same category as many others in normal science {\ldots} These are abductive analogical arguments, which rely upon a formal analogy to make an explanatory hypothesis plausible. {\ldots} The analogical argument must rest upon similarities between *observable effects* in the two domains [which have a PHYSICAL interpretation]." (311-2)
	- A better example where there is no potential for generalization is Hume's between money and fluid. He ultimately gives up, saying, "I cannot prove that all historically plausible scientific analogies satisfy my requirement that there must be serious potential for generalization. But the thesis is both historically and philosophically viable. It provides the only means I can think of for making the link between analogical arguments and plausibility." (313)
Visual Reasoning
	- His requirements for a good analogy "seems to exclude all `reasoning' via visual analogy, which must inevitably fail to meet both requirements." (314)
	- He doesn't think it does exclude visual analogy. A logical model of analogical reasoning is still necessary to determine what a *good* analogy is, and therefore "Most theories of visual analogy belong with perceptual models of analogical cognition."

9.3 Analogical Arguments Outside of Science
- If the prior association is clearly defined in form (like in formal science), it is an *idealization*---an assumption made to develop a model that gives us partial understanding of some phenomenon.
- Discusses weakening requirements for the prior association
- The "threshold" criterion: a theory of analogy should have some minimum threshold for prima facie plausibility. His extended theory insists the P.A. should be capable of generalization, and preserves its adherence to this criterion.
- "While there is no prospect of articulating a form of prior association, there can be no plausible analogical argument." (316) The "elitism" objection says this can't be true because children and animals can reason analogically. He seems to defer this to the research by Gentner et al. Also he reminds us this is not a problem for those interested in normative theories: "we need a model to assess the validity of any analogical argument, regardless of whether its original advocate is capable of providing one." (317)

9.4 An Analogical Argument for Entity Realism
- Hacking's (1983) argument for entity realism (which sounds to me like Platonism, except it argues for the existence of some unobservable entities) is here summarized as an argument from analogy, and one that is good according to Bartha's theory.
- It is an analogy from the domain of macroscopic ("middle-sized") objects to that of unobservable entities.

9.5 Thought Experiments and Hypothetical Models
- Mental models can be seen as connected intimately with analogy, as in Nersessian (1993). MM construction is done by drawing an analogy from real or imaginary worlds.
- Norton's thesis that "thought experiments can often be reconstructed as arguments", and furthermore that "cogent thought experiments can always be reconstructed as good arguments."
- Not all thought experiments depend on mental models, but all involve hypothetical models (321).
- "How can thought experiments provide new knowledge about the world?" under this view becomes: "How can an analogical argument based on a hypothetical source domain provide support for its conclusion?"
- Kuhn's answer was that it didn't provide new answers about the world, but it helped teach the scientist and find contradictions or conflicts in his mode of thought.
- This view is "like my proposal, although I focus on symmetry (rather than logical consistency) as the source of constraint." (324)
- "The great advantage of a real source domain [over a hypothetical one] is that causal and statistical relationships can be independently verified; they have a life of their own, independently of the analogy. This observation accounts for the fact that most compelling thought experiments belong to the formal sciences." (325)

9.6 Empirical Studies and Computational Models
- Aims to explore "some connections between my own theory and what has come to be the dominant approach for cognitive scientists who work on analogical reasoning."
- Claims views like SMT have both descriptive psychological and normative theories, where Bartha thinks it's important to investigate them separately. But he knows they can't be totally separate, and this section tries to find the connections.
- Has some suggestions on "how a reorientation toward normative issues {\ldots} might contribute to future research on analogical reasoning."
The Structure Mapping Theory and its Successors
	- "It is fair to say, however, that both the psychological literature and the computational models have devoted considerably more attention to the empirical adequacy of their theories than to normative aspects of analogical reasoning. {\ldots} [Identifying certain features as being influential in the mapping process] is not the same as evaluating whether or not we have a plausible analogical argument." (327)
	- "The basic problem is thus: for structuralists, there is no such thing as an analogical argument. And if there are no analogical arguments, it becomes very difficult to find a theoretical role for norms." (328)
	- Structuralist theories fail the "theshold criterion" as well, since they only have an infinite continuum of better or worse, replacing it with norms of degree. 
	- "The issue turns on whether there can be critical disanalogies that invalidate an analogical argument {\ldots} It is hard to see how a constraint-based approach can accommodate them."

Looking Ahead
- Three suggestions on why psychological and computational models of an. reasoning require at least basic normative account of args.:
	1) To define a threshold for prima facie plausibility.
	2) His two major principles - prior association and potential for generalization - may be helpful empirically. Even in "psychologically realist model[s], we should still expect certain commonsense norms to be widely reflected in analogical reasoning." (329) Structuralist accounts miss the mark on potential for generalization because they don't guide the identification of critical factors, which is necessary for determining the success or failure of an ana. arg.
	3) His theory prescribes norms for different types of prior association, and in his theory gaps in the observational record may count as critical. "Neither point is captured by systematicity. These specialized norms of analogical reasoning may be of interest independently of the rest of my theory." (330)

9.7 Defective Analogical Arguments
- FOL doesn't tell us what to do with invalid arguments any more than his theory tells us what to do with defective an.args.
- "The best strategy for dealing with the initial failure of an analogical argument is often to try to make it work by finding a reformulation rather than to abandon it."
- But when to ultimately call it quits? No sharp rule, but if we have "a clear prior association, extensive similarity between two domains, and no alternative plausible hypothesis" then we should keep trying!},
	Author = {Bartha, Paul F.A.},
	Date-Added = {2012-12-10 22:31:07 -0500},
	Date-Modified = {2013-09-09 21:41:22 -0400},
	Publisher = {Oxford University Press},
	Title = {{By Parallel Reasoning: The Construction and Evaluation of Analogical Arguments}},
	Year = {2010}}

@book{Bundy2005,
	Annote = {Rippling "formalizes a particular pattern of reasoning found in mathematics, where formulas are manipulated in a way that increases their similarities by incrementally reducing their differences." (3)

"A proof planner reasons with *methods*. A method consists of a tactic together with its specification, i.e. its preconditions and effects. Methods are often hierarchical in that a method may be built from sub-methods." (3)

Annotations - they specify which parts of formulas must be preserved and what can be changed (and in what ways). So they restrict what rippling can do. 


   * skeleton must be wff, whereas the rest of it (the wave-fronts) don't need to be.

   * there is a precise measure of when an application of a rule made progress, which will be described in chapter 4.

   * wave-rule : a rewrite rule with annotations. They must preserve skeletons (the skeletons of Lhs and Rhs must be the same) and must be measure-decreasing (the annotation of the Rhs must represent progress over the annotation of the Lhs) (13)

   * "Rippling is well-suited to logical theories based on recusively defined functions: the movement of wave-fronts reflects the way in which function values are passed as the output of one function to the input of another as its argument. [However, it doesn't work as well for theories based on recursively defined *relations*,] A version of rippling, called *relational rippling*, has been developed for such relational theories (Bundy & Lombart, 1995)" (23)
},
	Author = {Bundy, Alan and Basin, David and Hunter, Dieter and Ireland, Andrew},
	Date-Added = {2012-11-20 21:46:48 -0500},
	Date-Modified = {2013-02-25 22:10:58 -0500},
	Publisher = {Cambridge University Press},
	Title = {Rippling: Meta-Level Guidance for Mathematical Reasoning},
	Year = {2005}}

@phdthesis{AboulHosn2006,
	Annote = {Located at https://dspace.library.cornell.edu/handle/1813/3936

Didn't read it all, but it contains an excellent summary of applications of analogy to ATP, including carbonell's work, and Melis/Whittle.

Carbonell's distinctions:
Transformational analogy - matches theorem statements, then tries to adapt the source proof to solve the target theorem.
Derivational analogy - matches source and target proofs instead of theorems.

Melis/Whittle's distinctions:
Internal analogy - When CLaM needs to choose a term to perform induction on, its analogy system suggests one based on the terms chosen by previous calls to the critic. It shows "measurable reductions" in the time it takes to perform an inductive proof in CLaM.
External analogy - Implemented by procedure called ABALONE. Tries to find a second-order mapping from source to target theorems. Uses rippling.


PROOF ABSTRACTION

Differs from proof by analogy because it tries to abstract first and solve problems later, rather than applying solutions instantly.
Allows for the building of a "proof library", and research in this direction is described.},
	Author = {Aboul-Hosn, Kamal},
	Date-Added = {2012-11-17 05:11:05 -0500},
	Date-Modified = {2013-01-30 20:16:18 -0500},
	School = {Cornell University},
	Title = {A Proof-Theoretic Approach to Mathematical Knowledge Management},
	Year = {2006}}

@article{Murdock2011,
	Annote = {Uses the structure mapping algorithms to find similarity between content in questions and passages in Jeopardy. "It contributes a significant amount to Watson's effectiveness."

"DeepQA does not explicitly do reasoning of [the analogical] sort, but may in future work."

LFACS (Logical Form Answer Candidate Scorer), used by Watson, which is based on a structure mapping algorithm similar to SME. They get questions (or "answers") from Jeopardy, and then LFACS helps to evaluate possible passages that might provide evidence for a proper response. However, its contribution is small: "less than half of one percent in the full system".

It reasons over "syntactic-semantic graphs". 

Example:
"It's believed Shakespeare wrote part of a 1595 play about this "Utopia" author."
Imagine we have a passage:
"We saw a 16th century play about Thomas More, who wrote Utopia."

Score evaluation comes from the sum of the match scores for the local match hypotheses included in the maximal consistent global map.

They cut it short, saying "Details evaluations of deep evidence scoring components will be presented in a future publication."},
	Author = {Murdock, J. William},
	Date-Added = {2012-11-17 04:29:00 -0500},
	Date-Modified = {2013-01-30 20:35:23 -0500},
	Journal = {Lecture Notes in Computer Science},
	Pages = {6-10},
	Title = {Structure Mapping for Jeopardy! Clues},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2ljY2JyMjAxMW11cmRvY2tfd2ViLnBkZtIXCxgZV05TLmRhdGFPEQHcAAAAAAHcAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcYaWNjYnIyMDExbXVyZG9ja193ZWIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8QX8zMwvwAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMzNCUwAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBXTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAaWNjYnIyMDExbXVyZG9ja193ZWIucGRmAAAOADIAGABpAGMAYwBiAHIAMgAwADEAMQBtAHUAcgBkAG8AYwBrAF8AdwBlAGIALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAERVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2ljY2JyMjAxMW11cmRvY2tfd2ViLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOANAA1QDdAr0CvwLEAs8C2ALmAuoC8QL6Av8DDAMPAyEDJAMpAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAys=}}

@article{Ontanon2012,
	Annote = {Describes using anti-unification as a measure of similarity between two terms, and also cites work that has been doing this for quite a while. Whereas AU is typically used for inductive learning, they talk about how to use it for similarity.},
	Author = {Ontanon, Santiago and Plaza, Enric},
	Date-Added = {2012-11-17 04:26:12 -0500},
	Date-Modified = {2013-01-30 20:34:38 -0500},
	Journal = {Machine Learning},
	Number = {1},
	Pages = {57-92},
	Title = {Similarity Measures Over Refinement Graphs},
	Volume = {87},
	Year = {2012}}

@article{Ullmann1976,
	Annote = {Referenced by Weber (2011, "Fast Subgraph Isomorphism Detection for Graph-Based Retrieval") as being "known as one of the fastest methods. The algorithm attains efficiency by inferentially eliminating successor nodes in the tree search."},
	Author = {Ullman, J.},
	Date-Added = {2012-11-17 04:02:51 -0500},
	Date-Modified = {2013-01-30 21:00:06 -0500},
	Journal = {Journal of the ACM (JACM)},
	Pages = {31-42},
	Title = {An Algorithm for Subgraph Isomorphism},
	Volume = {23(I)},
	Year = {1976},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1VsbG1hbl9BbGdvcml0aG0ucGRm0hcLGBlXTlMuZGF0YU8RAcwAAAAAAcwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxRVbGxtYW5fQWxnb3JpdGhtLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxKnzMy9cAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzM0DwAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFNNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBVbGxtYW5fQWxnb3JpdGhtLnBkZgAADgAqABQAVQBsAGwAbQBhAG4AXwBBAGwAZwBvAHIAaQB0AGgAbQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQFVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvVWxsbWFuX0FsZ29yaXRobS5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDMANEA2QKpAqsCsAK7AsQC0gLWAt0C5gLrAvgC+wMNAxADFQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMX}}

@article{Spellman1992,
	Annote = {Early ACME-related discussion of the analogy between the first gulf war and WWII, in response to analogies made by politicians at the time which were used as rationale for US involvement. They also did a human study to see what their tendencies were with these sorts of analogies.},
	Author = {Spellman, Barbara A. and Holyoak, Keith J.},
	Date-Added = {2012-11-15 03:07:39 -0500},
	Date-Modified = {2013-01-30 21:02:18 -0500},
	Journal = {Journal of Personality and Social Psychology},
	Pages = {913-933},
	Title = {If Saddam is Hitler then Who is George Bush?},
	Volume = {62},
	Year = {1992},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BzcC02Mi02LTkxMy5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEHBzcC02Mi02LTkxMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEQjMygzpAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADMylM5AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHBzcC02Mi02LTkxMy5wZGYAAA4AIgAQAHAAcwBwAC0ANgAyAC0ANgAtADkAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9wc3AtNjItNi05MTMucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@incollection{Dunbar1999,
	Address = {New York, New York, USA},
	Annote = {Evidence of analogy and model-based reasoning occurring in actual scientific reasoning.
They actually attended a group's lab meetings and analyzed the use of reasoning from their discussions.



ANALOGY

They found that scientists frequently use analogy when there is not a straightforward answer to their current problem (88). 

- 99 analogies were made at 16 meetings. 

- The goals they had when they made analogies fell into 4 classes: Formulate a hypothesis, design an experiment, fix an experiment, or explain a result.

- When formulating hypotheses, they tended to make analogies to other organisms with similar underlying structure or biological mechanisms: e.g., from ebola virus to HIV. (50%). But distant analogies (like to the song "Hotel california") only happened 2%. This tended to happen when talking to people outside of their lab.},
	Author = {Dunbar, Kevin},
	Booktitle = {{Model-based Reasoning in Scientific Discovery}},
	Date-Added = {2012-11-09 23:49:14 -0500},
	Date-Modified = {2013-01-30 21:23:06 -0500},
	Editor = {Magnani, Lorenzo and Nersessian, Nancy J. and Thagard, Paul},
	Publisher = {Kluwer Academic / Plenum Publishers},
	Title = {{How Scientists Build Models InVivo Science as a Window on the Scientific Mind}},
	Year = {1999}}

@incollection{Nersessian1999,
	Address = {New York, New York, USA},
	Annote = {Argues that analogical ability as used in model construction is extremely useful. use this as citation when discussing hypothesis generation by analogy.

"Assuming that analogy is at best a form of inductive argument leads to the conclusion of Carnap that "reasoning by analogy can yield only weak results" (1950, p. 589). Looking at examples of productive reasoning by analogy in science shows it to yield powerful and creative results. The way to resolve the discrepancy is to see that reasoning by analogy is not argument but model construction." (20)},
	Author = {Nersessian, Nancy J.},
	Booktitle = {{Model-Based Reasoning in Scientific Discovery}},
	Date-Added = {2012-11-09 16:48:18 -0500},
	Date-Modified = {2013-01-30 21:25:07 -0500},
	Editor = {Magnani, Lorenzo and Nersessian, Nancy J. and Thagard, Paul},
	Publisher = {Kluwer Academic / Plenum Publishers},
	Title = {{Model-Based Reasoning in Conceptual Change}},
	Year = {1999}}

@incollection{Wang1995,
	Annote = {paper referred to by Selmer (1999) as being a description of the model-based reasoning of Godel written by a personal friend of his. But it doesn't so much describe his model-based thinking as it relates to the incompleteness theorems, only as it relates to this issue of computabilism.

computabilism - the position whose central component is the belief that computers can think.
[psychological] parallelism - the belief that minds and brains are equivalent in the precise sense that there is a one-to-one correlation between one's mental states and brain states.

Although most scientists and philosophers today "...take parallelism for granted, there are recent thinkers such as Husserl, Bergson, Wittgenstein and Godel who all regard parallelism as a *prejudice* of our time." (163)

"Godel's line of thought seems to move from conjecture to conjecture. (a) Mental procedures can go further than mechanical procedures. (b) The number of mind's states may converge to infinity in the course of its development. (c) 'Now there may exist systematic methods of accelerating, specializing, and uniquely developing this development, e.g. by asking the right questions on the basis of mechanical procedures.' Godel appeared to view (c) as one of the possible ways to prove (b). It is, however, not easy to envisage what a precise characterization of a systematic, but not mechanical, method, say f introducing larger ordinal numbers of stronger axioms of infinity, would look like. Godel did recognize this difficulty." (184-185)
------my thoughts: this is an excellent example of model-based thinking---he moves from conjecture to conjecture, not quite being sure how (or whether it is possible) to bridge the gap between them...it is the ability to move from one conjecture to another without a solid proof-based reasoning method between them that I think distinguishes model-based reasoning from traditional symbolic reasoning methods.

More:
A conjecture Godel told Wang:
	"It would be a result of great interest to prove that the shortest decision procedure requires a long time to decide comparatively short propositions. More specifically, it may be possible to prove: For every decidable system and every decision procedure for it, there exists some formula of length less than 200 whose shortest proof is longer than 10^20. Such a result would actually mean that machines can't replace the human mind, which can give short proofs by giving a new idea." (187)
-------my thoughts: this reasoning has something to do with the idea that since humans can quickly form something like proofs at a higher level (consisting of higher level conjectures and such) they will always be able to reason better than machines at this sort of thing.},
	Author = {Wang, Hao},
	Booktitle = {{Nature's Imagination: The Frontiers of Scientific Vision}},
	Date-Added = {2012-11-09 15:58:50 -0500},
	Date-Modified = {2013-01-30 21:26:10 -0500},
	Editor = {Cornwell, John},
	Publisher = {Oxford University Press},
	Title = {{On 'Computabilism' and Physicalism: Some Subproblems}},
	Year = {1995}}

@inproceedings{Johnson2001,
	Annote = {One of the papers ralph sent me to describe sketches in category theory. Describes SkDM, the sketch data model, which is "a new semantic modelling paradigm based on category theory (specifically on categorical universal algebra)". It is also based on the category-theoretic notion of 'mixed sketch' [3] [4]

Sketch data model:
	- semantic data model
	- closely related to ER modeling [7] and functional data models, in fact it is formally specified by giving an ER sketch.
	- a sketch data model E is a graph, like an ER graph, together with specifications of commutative diagrams, limits and coproducts.
	- they emphasize that this is a very simple structure: all of these notions can be described in terms of a graph with an associative composition of arrows which has identities (such a graph is called a category).


FORMAL DEFINITIONS FOR THE SkDM

(in notebook)},
	Author = {Johnson, Michael and Rosebrugh, Robert and Dampney, C.N.G.},
	Booktitle = {ADC '01 Proceedings of the 12th Australasian Database Conference},
	Date-Added = {2012-11-09 04:33:53 -0500},
	Date-Modified = {2013-01-30 20:46:05 -0500},
	Pages = {29-36},
	Title = {View Updates in a Semantic Data Modelling Paradigm},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xNS45MTQ3LnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjE1LjkxNDcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48W8zB/D4AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMzCQo4AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjE1LjkxNDcucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADEANQAuADkAMQA0ADcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xNS45MTQ3LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@article{Bringsjord1998,
	Annote = {MBR - model based reasoning
MBR_D - deductive variety of model based reasoning, allows for diagrams, mental images

Q1 - could a computing machine ever prove G1 in the MODEL-BASED MANNER human logicians and mathematicians prove it?
Q1* - could a computing machine ever prove theorems in the model-based manner human logicians and mathematicians prove them?

His suspicion is no, they can't.

Formulation of G1 : Suppose \phi is consistent and decidable, and Rep \phi as well. Then there is an S_ar-sentence \phi_g s.t. neither \phi |- \lowerphi_g nor \phi |- -\lowerphi_g

He defines all of the metaconcepts - godel numbering, consistency, etc. in model-based terms.

"Readers interested in the 'model-based' mind of Godel himself are encouraged to read [18] for a marvelous introduction, delivered by Godel's friend Hao Wang"



What exactly is distinctive about a model-based explanation and proof of G1?
	
C1 If agent S proves P in a model-based fashion, then
	1. S understands underlying objects, concepts, propositions, and relations: o1,...,on
	2. S represents o1,...,on in BOTH linguistic and visual modes (the visual modes yield o~1,...,o~n); and
	3. S manipulates representations o~1,...,o~n in order to carry out inferences



Quaife's proof [13]:
- Done by OTTER
- encoded in modal K4 ("normal" modal logic)
- proof only actually uses four inferences (reprinted on p.16)

repurposing the definition of model-based fashion for otter:
C1' - If computer C running OTTER proves G1 in model-based fashion:
	1. C understands underlying o1,...,on;
	2. (same as C1.2)
	3. C manipulates representations o~1,...,o~n in order to carry out inferences

Selmer says neither 1,2, nor 3 are true in otter's case. 2 and 3 are easy to throw out, he uses a searlean argument to throw out 1.

Objection from hyperproof:
Hyperproof is (from what I gather) a way to do visual proofs. Yet it's not model-based enough because:
- it can only construct very primitive visual simulations; the simian machines Selmer describes in this paper cannot be done
- Hyperproof is simply OTTER with a facility to represent first order formulas in grid-form. It doesn't do anything that has a different representation because at its core its representation is exactly FOL. "Hyperproof *itself* does not represent underlying information; rather, people *use* Hyperproof to represent information *they* understand.
},
	Author = {Bringsjord, Selmer},
	Date-Added = {2012-11-08 21:24:40 -0500},
	Date-Modified = {2013-01-30 21:22:36 -0500},
	Journal = {Philosophica},
	Pages = {51-76},
	Title = {{Is (G{\"o}delian) Model-Based Deductive Reasoning Computational?}},
	Volume = {61},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xNS45MTQ3LnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjE1LjkxNDcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48W8zB/D4AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMzCQo4AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjE1LjkxNDcucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADEANQAuADkAMQA0ADcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xNS45MTQ3LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@article{Bringsjord2004,
	Annote = {Says lucas's arguments and penrose's defenses of them based on hypoercomputability based on Godel's IT have failed, but not 'irremediably' so. Selmer purports to show that "since it is mathematically possible that human minds are hypercomputers, such minds ARE in fact hypercomputers."

"From the standpoint of symbolic logic and mathematics, the vagueness of [a precise definition of] computationalism is unacceptable."

"...we now understand well that there *are* information processing machines that can exceed the Turing Limit" (175)
these include: inductive TMs, infinite-time TMs, Zeus machines

Dxyi = x decides if y halts on input i.},
	Author = {Bringsjord, Selmer and Arkoudas, Konstantine},
	Date-Added = {2012-11-07 04:10:40 -0500},
	Date-Modified = {2013-01-30 20:28:04 -0500},
	Journal = {Theoretical Computer Science},
	Pages = {167-190},
	Title = {The Modal Argument for Hypercomputing Minds},
	Volume = {317},
	Year = {2004}}

@mastersthesis{Conkey2011,
	Annote = {Sieg and Field "presented automated proofs of Godel's theorems at an abstract axiomatic level; they used an appropriate expansion of the strategic considerations that guide the search of the automated theorem prover AProS. The representability conditions that allow the syntactic notions of the metalanguage to be represented inside the object language were taken as axioms in the automated proofs."

metatheoretic notions uses like 'formula', 'proof', 'theorem'

"The present work seeks to provide foundational support to the proofs of Godel's theorems at the abstract level by formally verifying the representability conditions that permit the representation of the metatheory inside the object theory."

METATHEORY DESCRIPTION

each binary tree can be uniquely mapped to an ordered pair in ZF.
Metatheory has:
- logical connectives, quantifiers, and variables ranging over all binary trees: X,X_1,X_2,...
- syntax for binary trees:
	- S = empty tree
	- X = [X1,X2] == tree with left, right subtrees
- axioms for binary trees (p.5)
- projections:
	- left projection (S)_1 = S 


REPRESENTABILITY

Every notion in the metatheory that is shown to be representable is first formalized in the metatheory using inductive definitions and represented as an object by assigning it a binary tree representation. Two things must be satisfied:
- For the metatheoretic notion P, it must be the case that:
	P(X1,...,Xn) -> ZF |- p(`X1',...,`Xn')
	not P(X1,...,Xn) -> ZF |- -p(`X1',...,`Xn')
Then P is representable in ZF.
They show that the metatheoretic notion of equality can be represented inside of ZF.},
	Author = {Conkey, Adam},
	Date-Added = {2012-11-06 18:50:27 -0500},
	Date-Modified = {2013-01-30 20:25:46 -0500},
	School = {Carnegie Mellon University},
	Title = {Deepening the Automated Search for G{\"o}del's Proofs},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YW8QXAAuAC4ALwAuAC4ALwBEAG8AYwB1AG0AZQBuAHQAcwAvAFMAaABhAHIAZQBkAC8AcgBlAHMAZQBhAHIAYwBoAC8AUABhAHAAZQByAHMALwBEAGUAZQBwAGUAbgBpAG4AZwAgAHQAaABlACAAQQB1AHQAbwBtAGEAdABlAGQAIABTAGUAYQByAGMAaAAgAGYAbwByACAARwBvAwgAZABlAGwAcwAgAFAAcgBvAG8AZgBzAC4AcABkAGbSFwsYGVdOUy5kYXRhTxECOgAAAAACOgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHH0RlZXBlbmluZyB0aGUgQXV0b21hdCNGMERBOC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDajMvwzZAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADMv1MpAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAXk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AERlZXBlbmluZyB0aGUgQXV0b21hdCNGMERBOC5wZGYADgBsADUARABlAGUAcABlAG4AaQBuAGcAIAB0AGgAZQAgAEEAdQB0AG8AbQBhAHQAZQBkACAAUwBlAGEAcgBjAGgAIABmAG8AcgAgAEcAbwMIAGQAZQBsAHMAIABQAHIAbwBvAGYAcwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAYlVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvRGVlcGVuaW5nIHRoZSBBdXRvbWF0ZWQgU2VhcmNoIGZvciBHb8yIZGVscyBQcm9vZnMucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4BSQFOAVYDlAOWA5sDpgOvA70DwQPIA9ED1gPjA+YD+AP7BAAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAEAg==}}

@article{Sieg2005,
	Annote = {Contains a good summary of literature on automated proof attempts of Godel's IT (section 4).

Claims to have heuristics that allow for things like moving between the object-and meta-theory. Guiding question of their investigation is: What is needed, in addition to purely logical considerations, for finding proofs of significant theorems in a fully automated way?

Earlier they did the meta-mathematical work of proving the incompleteness theorems for ZF* (Zemelo-Fraenkel without infinity) in a formal first-order theory of binary trees and elementary inductive definitions called TEM (Theory for Elementary Meta-Mathematics) [10,11]. 


COMPARISONS TO OTHER WORK
Ammon [1] - SHUNYATA program, uses Kleene's version in "Introduction to Metamathematics." Problems are: 
	- he claims G (undecidable sentence) is constructed from elementary rules of formula construction, but "that the formula so constructed expresses its unprovability has to be ensured by other means". 
	- His paper contains neither a logical calculus nor a systematic proof procedure using the rules of that calculus, rather he has open-ended heuristics.

Quaife [15] - Proves them "at a suitable level of abstraction" based in modal logic K4. He also only has his system (called ITP) establish the unprovability of G, not its negation under w-consistency. More conceptual and technically straightforward than Ammon, but it's unclear how the search is directed, and therefore its status as being "automated" is in question. "Would proofs of the main theorems be found, if only the axioms were available?"

Bundy et al. [5] - Uses OTTER, which came from ITP. Meant to show how 'abstraction' could be used. NOT fully automated, "since both the choice of the abstraction and the subsequent refinement of the abstract proof into the original language require external guidance."

Shankar [17] - Uses Rosser's version of first inc. theorem. Not sure what his criticisms (if any) of Shankar's approach are.




Criticisms by selmer of these approaches (from http://kryten.mm.rpi.edu/PRES/AUTDISSYMP/sb_remarks_autdis_GI_G2.pdf )

Ammon - Criticises his "self-appraisal", and his claim that he implicitly rediscovered Cantor's diagonal method
Quaife - same criticism as this paper, also read "Is Godelian Model-based deductive reasoning computational?" in Philosophica.
Sieg and Field(this paper) - Claims they have "quaife-ishness" that is confessed on p.325. Suggests they define 'discovery' better.},
	Author = {Sieg, Wilfried and Field, Clinton},
	Date-Added = {2012-11-06 17:20:42 -0500},
	Date-Modified = {2013-01-30 21:03:10 -0500},
	Journal = {Annals of Pure and Applied Logic},
	Month = {May},
	Number = {1-3},
	Pages = {319-338},
	Title = {Automated Search for G{\"o}del's Proofs},
	Volume = {133},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2dvZGVsX3Byb29mcyBTSUVHLnBkZtIXCxgZV05TLmRhdGFPEQHQAAAAAAHQAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcVZ29kZWxfcHJvb2ZzIFNJRUcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8P6sy/CPkAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMy/T0kAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBUTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAZ29kZWxfcHJvb2ZzIFNJRUcucGRmAA4ALAAVAGcAbwBkAGUAbABfAHAAcgBvAG8AZgBzACAAUwBJAEUARwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQVVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvZ29kZWxfcHJvb2ZzIFNJRUcucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAM0A0gDaAq4CsAK1AsACyQLXAtsC4gLrAvAC/QMAAxIDFQMaAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAxw=}}

@book{Jagannathan1989,
	Annote = {INTRODUCTION: H. Penny Nii

Introduction identifies characteristics of a problem that make them good candidates for blackboard approach:
- large solution space
- noisy, unreliable data
- variety of input data and a need to integrate diverse information
- the need for many independent or semi-independent pieces of knowledge to cooperate in forming a solution
- the need to use multiple reasoning methods
- the need for multiple lines of reasoning
- the need for an evolutionary solution

"Because the information provided by the expert is rarely organized to fit a particular problem-solving model, the knowledge engineer initially needs a model with flexible methods for representing and applying pieces of knowledge. Once the task is well understood, it can be reformulated for a simpler problem-solving method." (xxv)

RAPID PROTOTYPING (p.xxvii) is a great reason for blackboards:  Whenever the problems are ill-structured, with poorly defined goals and an absence of a predetermined decision path, blackboards are great for an exploratory approach.

"First, the blackboard approach requires no *a priori* determined reasoning path. Because an ill-structured problem does not have a predetermined decision path to a solution, the selection of what to do next must be made while the problem is in the process of being solved. The incremental and opportunistic problem-solving approach in blackboard systems provides the capability to do precisely that."

"...the blackboard approach allows the postponement of design decisions. For example, [in robot case where we don't know how sensors should interact]. Until an appropriate combination of sensors is found, the system needs to be open-ended."

"...the blackboard approach provides freedom from message-passing constraints." (since the specialists should be modular)},
	Date-Added = {2012-11-04 11:53:15 -0500},
	Date-Modified = {2013-01-30 21:24:25 -0500},
	Editor = {Jagannathan, V. and Dodhiawala, Rajendra and Baum, Lawrence S.},
	Publisher = {Academic Press},
	Title = {{Blackboard Architectures and Applications}},
	Year = {1989}}

@book{Luger2008,
	Annote = {From ch. 6, regarding blackboard systems:

Talks about blackboards, but doesn't say much about the details of how they work, other than the high-level description that we're all familiar with already. Offers citations to more recent developments in blackboard systems, but none later than 1988.},
	Author = {Luger, George F.},
	Date-Added = {2012-11-03 20:47:51 -0400},
	Date-Modified = {2013-01-30 20:43:23 -0500},
	Publisher = {Pearson Education, Inc},
	Title = {Artificial Intelligence: Structures and Strategies for Complex Problem Solving},
	Volume = {6},
	Year = {2008}}

@inproceedings{Forbus1989,
	Annote = {Gives more insight into how structural evaluation score (used by SME) is calculated.

"We restrict evaluation rules to use only local, structural properties in assigning scores. For example, MH's receive some initial score based on the kinds of items matched (relation, function, or attribute). Under structure-mapping only propositions involving identical relations or attributes match, so the same initial score is used for all relations and attributes ... this parameter is called Same-Predicate. The parameter Same-Function is used for identical functions."

"...a match hypothesis MH adds its score, scaled by the parameter Trickle-Down, to the match hypothesis linking the arguments of the items matched by MH."

"We do not normalize Gmap scores, since doing so would only introduce further parameters without theoretical motivations." ---But they do normalize scores in 2005: http://www.aaai.org/Papers/AAAI/2005/AAAI05-122.pdf and they even go on to discuss normalization in this paper.},
	Author = {Forbus, Kenneth D. and Gentner, Dedre},
	Booktitle = {Proceedings of the eleventh annual Conference of the Cognitive Science Society},
	Date-Added = {2012-10-21 15:15:08 -0400},
	Date-Modified = {2013-04-15 20:41:27 -0400},
	Title = {Structural Evaluation of Analogies: What Counts},
	Volume = {34},
	Year = {1989},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2VzZW5maW4oc2VhcmNoYWJsZSkucGRm0hcLGBlXTlMuZGF0YU8RAdgAAAAAAdgAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rxdlc2VuZmluKHNlYXJjaGFibGUpLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw4EzKnB6gAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzKn6KgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFZNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBlc2VuZmluKHNlYXJjaGFibGUpLnBkZgAOADAAFwBlAHMAZQBuAGYAaQBuACgAcwBlAGEAcgBjAGgAYQBiAGwAZQApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBDVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9lc2VuZmluKHNlYXJjaGFibGUpLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDPANQA3AK4AroCvwLKAtMC4QLlAuwC9QL6AwcDCgMcAx8DJAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMm}}

@article{Justice2006,
	Annote = {LP for graphs with unlabeled edges. Can be used to give lower/upper bounds on d. Is sub-optimal. They also show that the graph edit distance, when derived from a metric cost function, is a metric itself on the set of undirected, unweighted graphs with vertex attributes (p. 15). Better than an older LP attempt [citation 20] that "seeks to minimize the difference in adjacency matrix norms for graphs with the same number of vertices," whereas this paper "is a sort of generalization for the graph edit distance on attributed graphs." (p.19)

"...it has been shown that the optimal ECGI [error correcting graph isomorphism?] under a certain graph edit cost function will find the MCS [maximum common subgraph] [24]. ... These procedures are applicable for only small graphs." (p.4)

What they call a BLP (binary linear program) is just what I call an integer program limited to the values {0,1}. P. 10: "Since solving a BLP is NP-Hard [10], we show how to obtain upper and lower bounds for the GED in polynomial time by using solution techniques for standard linear programming and the assignment problem [40]. These bounds may be useful in the event that the problem is so large that solving the BLP is impractical."

"We provide a formulation of the graph edit distance whereby error-correcting graph matching may be performed by solving a binary linear program ... We first present a general framework for computing the GED between attributed, unweighted graphs by treating them as subgraphs of a larger graph referred to as the edit grid. It is argued that the edit grid need only have as many vertices as the sum of the total number of vertices in the graphs being compared. We show that graph editing is equivalent to altering the state of the edit grid and prove that the GED derived in this way is a metric provided the cost function for individual edit operations is a metric."

HOW TO CALCULATE THE LOWER/UPPER BOUNDS:

To find from G0 to G1, create GW (G_Omega), the edit grid. 
G0 = (V0, E0, l0)
l0: V0 -> Alphabet of labels
phi: special label not in the alphabet

GW = (W, WxW, l_W) = edit grid, complete graph. |W| = N. They argue it need be no larger than |V0| + |V1|.
V0 is a strict subset of W
E0 is a strict subset of WxW
for all u in V0, l_W(u) = l0(v). Other vertices in W get null label phi.



Linear program for d_c(G0, G1), the edit distance: (p.19)

min SUM(i=1...n) SUM(j=1...n) c( l(A^i_0), l(A^j_1)) P^ij + (1/2) c(0,1) (S+T)^ij
s.t.:
	(A_0 P - P A_1 + S - T)^ij = 0 	[for all i,j]
	SUM(i) P^ik = SUM(j) P^kj = 1	[for all k]

Where:
c(x,y) = 
l(x) = labeling function
A^x_y = 
P^ij = 
S = 
T = 

RECOVERING EDIT PATH: do something to the adjacency matrix, described on p.19

LOWER BOUND: simply relax the IP to an LP (bottom of p.19)

UPPER BOUND: (IP on p. 20). It is actually an assignment problem, and can be solved by Hungarian method. },
	Author = {Justice, Derek and Hero, Alfred},
	Date-Added = {2012-10-20 20:01:12 -0400},
	Date-Modified = {2013-01-30 20:45:45 -0500},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Pages = {1214},
	Title = {A Binary Linear Programming Formulation of the Graph Edit Distance},
	Volume = {28},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0p1c3RpY2VIZXJvLnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPSnVzdGljZUhlcm8ucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Qhsyos2IAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMyo66IAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoASnVzdGljZUhlcm8ucGRmAA4AIAAPAEoAdQBzAHQAaQBjAGUASABlAHIAbwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvSnVzdGljZUhlcm8ucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@incollection{Bunke2009,
	Annote = {Seems to be the most recent survey-like paper by Bunke, who is a leading expert in graph edit distance. 

http://books.google.com/books?id=l9zURPH2GiUC&printsec=frontcover#v=onepage&q&f=false

"no universally accepted metric [of dissimilarity] on graphs is available."

Graph edit distance is used to transform graphs explicitly into feature vectors. This allows that standard methods in object classification [17], originally developed for vectors, become applicable to graphs.

graph G = (V,E,mu,nu)
mu: V -> Lv node-labeling fn
nu: E -> Le edge-labeling fn
Y(g1, g2) = set of all edit paths transforming g1 to g2
d(g1, g2) = edit distance - minimum path in Y


Error-tolerant graph matching
	ANNs [19,52] for DAGs, [2,26] general graph matching, 
	Spectral decomposition [32,56] - represent graphs by eigendecomposition of their adjacenty or laplacian matrix
	graduated assignment [21]
	random walks [22]

If an approximation of the edit distance is acceptable in a certain application, then the suboptimality can usually be traded for a shorter, usually polynomials, matching time [13]

OPTIMAL ALGORITHMS
- Method based on A* algorithm [24] is widely used, a best-first search algorithm, like on p.119. Can be augmented with heuristics as well. "...the computational complexity of the edit distance algorithm, whether or not a heuristic function h(p) is used to govern the tree traversal process, is exponential in the number of nodes of the involved graphs."

SUBOPTIMAL ALGORITHMS
	- Restricted types of graphs: planar [25, 35], bounded-valence [31], trees [54], graphs with unique node labels [15]. Usually based in local search (optimizing local criteria rather than global). 
	- LP for graphs with unlabeled edges: [27], can give lower/upper bounds on d.
	- Genetic algorithms [14]
	- Heuristic-A* [39]
	- Bipartite Graph matching [42] - given two nodes, compare their local structure. Optimize this globally using assignment problem algorithms (munkres'). BP is therefore only "cubic in the number of nodes of the two underlying graphs. ... [This makes] GED feasible for graphs with up to 130 nodes."
	



TO CHECK OUT
LP for graphs with unlabeled edges: [27]
[12,61] - the graph matching problem is stated as a labeling problem},
	Author = {Bunke, Horst and Riesen, Kaspar},
	Booktitle = {{Analysis of Complex Networks: from Biology to Linguistics}},
	Date-Added = {2012-10-20 01:31:28 -0400},
	Date-Modified = {2013-01-30 21:22:50 -0500},
	Editor = {Dehmer, Matthias and Emmert-Streib, Frank},
	Publisher = {Wiley-VCH},
	Title = {{Graph Edit Distance - Optimal and Suboptimal Algorithms with Applications}},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QmS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL01hdHRoaWFzX0RlaG1lcixfRnJhbmtfRW1tZXJ0LVN0cmVpYi1BbmFseXNpc19vZl9Db21wbGV4X05ldHdvcmtzX19Gcm9tX0Jpb2xvZ3lfdG9fTGluZ3Vpc3RpY3MtV2lsZXktVkNIKDIwMDkpLnBkZtIXCxgZV05TLmRhdGFPEQLwAAAAAALwAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfTWF0dGhpYXNfRGVobWVyLF9GcmFuI0YxMEJFLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8QvsyoloUAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMyozsUAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoATWF0dGhpYXNfRGVobWVyLF9GcmFuI0YxMEJFLnBkZgAOAOYAcgBNAGEAdAB0AGgAaQBhAHMAXwBEAGUAaABtAGUAcgAsAF8ARgByAGEAbgBrAF8ARQBtAG0AZQByAHQALQBTAHQAcgBlAGkAYgAtAEEAbgBhAGwAeQBzAGkAcwBfAG8AZgBfAEMAbwBtAHAAbABlAHgAXwBOAGUAdAB3AG8AcgBrAHMAXwBfAEYAcgBvAG0AXwBCAGkAbwBsAG8AZwB5AF8AdABvAF8ATABpAG4AZwB1AGkAcwB0AGkAYwBzAC0AVwBpAGwAZQB5AC0AVgBDAEgAKAAyADAAMAA5ACkALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAJ5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL01hdHRoaWFzX0RlaG1lcixfRnJhbmtfRW1tZXJ0LVN0cmVpYi1BbmFseXNpc19vZl9Db21wbGV4X05ldHdvcmtzX19Gcm9tX0Jpb2xvZ3lfdG9fTGluZ3Vpc3RpY3MtV2lsZXktVkNIKDIwMDkpLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOASoBLwE3BCsELQQyBD0ERgRUBFgEXwRoBG0EegR9BI8EkgSXAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAABJk=}}

@article{Zhang1996,
	Annote = {According to Bille, this is the best (perhaps only?) known algorithm for poly-time mapping of unordered trees with unbounded degree. Requires that they be constrained. Time is:

O(|T1| |T2| (deg(T1) + deg(T2) log(deg(I1) + deg(I2)))

where deg(T1), as far as I can tell, is the max degree of any node in T1.},
	Author = {Zhang, Kaizhong},
	Date-Added = {2012-10-19 16:12:20 -0400},
	Date-Modified = {2013-01-30 20:57:29 -0500},
	Journal = {Algorithmica},
	Number = {3},
	Pages = {205-222},
	Title = {A Constrained Edit Distance Between Unordered Labeled Trees},
	Volume = {15},
	Year = {1996},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICgxMikucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFmdWxsdGV4dCAoMTIpLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw8ozKcsSAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzKdkiAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBmdWxsdGV4dCAoMTIpLnBkZgAOACQAEQBmAHUAbABsAHQAZQB4AHQAIAAoADEAMgApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoMTIpLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@article{Akutsu2010,
	Annote = {Another good summary of tree edit distance algorithms, although this focuses more on applications to bioinformatics. Again, there is no discussion on finding the label mappings.},
	Author = {Akutsu, Tatsuya},
	Date-Added = {2012-10-19 15:10:49 -0400},
	Date-Modified = {2013-01-30 20:16:04 -0500},
	Journal = {IEICE Transactions on Information and Systems},
	Number = {2},
	Pages = {208-218},
	Title = {Tree Edit Distance Problems: Algorithms and Applications to Bioinformatics},
	Volume = {E93-D},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3RyYW5zaW5mLkU5My5ELjIwOC5wZGbSFwsYGVdOUy5kYXRhTxEB1AAAAAAB1AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHFnRyYW5zaW5mLkU5My5ELjIwOC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEqPMpx3sAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADMp1YsAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAVU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHRyYW5zaW5mLkU5My5ELjIwOC5wZGYAAA4ALgAWAHQAcgBhAG4AcwBpAG4AZgAuAEUAOQAzAC4ARAAuADIAMAA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy90cmFuc2luZi5FOTMuRC4yMDgucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AzgDTANsCswK1AroCxQLOAtwC4ALnAvAC9QMCAwUDFwMaAx8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADIQ==}}

@article{Heumann2009,
	Annote = {Recent paper to cite on applications of tree matching (specifically tree edit distance) to neuroinformatics. They use it to find dissimilarity between three-dimensional neuronal cells, by representing neurons as labeled trees. },
	Author = {Heumann, Holger and Wittum, Gabriel},
	Date-Added = {2012-10-19 15:05:05 -0400},
	Date-Modified = {2013-01-30 20:47:17 -0500},
	Journal = {Neuroinformatics},
	Number = {3},
	Pages = {179-190},
	Title = {The Tree-Edit-Distance, a Measure for Quantifying Neuronal Morphology},
	Volume = {7},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICgxMSkucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFmdWxsdGV4dCAoMTEpLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw8izKcdtQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzKdV9QAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBmdWxsdGV4dCAoMTEpLnBkZgAOACQAEQBmAHUAbABsAHQAZQB4AHQAIAAoADEAMQApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoMTEpLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@article{Ferrara2011,
	Annote = {Recent paper that gives a good summary of the state of the art in tree matching as it's applied to web data extraction. There is no discussion on label equivalence finding. },
	Author = {Ferrara, Emilio and Baumgartner, Robert},
	Date-Added = {2012-10-19 15:03:02 -0400},
	Date-Modified = {2013-01-30 20:23:02 -0500},
	Journal = {Smart Innovation, Systems and Technologies},
	Pages = {41-54},
	Title = {Automatic Wrapper Adaptation by Tree Edit Distance Matching},
	Volume = {8},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2VkaXRzdXJ2ZXlfYmlsbGUucGRm0hcLGBlXTlMuZGF0YU8RAcwAAAAAAcwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxRlZGl0c3VydmV5X2JpbGxlLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw4CzKcbyAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzKdUCAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFNNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBlZGl0c3VydmV5X2JpbGxlLnBkZgAADgAqABQAZQBkAGkAdABzAHUAcgB2AGUAeQBfAGIAaQBsAGwAZQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQFVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvZWRpdHN1cnZleV9iaWxsZS5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDMANEA2QKpAqsCsAK7AsQC0gLWAt0C5gLrAvgC+wMNAxADFQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMX}}

@article{Bille2005,
	Annote = {Best guide on tree matching algorithms I could find.},
	Author = {Bille, Philip},
	Date-Added = {2012-10-19 15:00:16 -0400},
	Date-Modified = {2013-01-30 20:29:15 -0500},
	Journal = {Theoretical Computer Science},
	Number = {1-3},
	Pages = {217-239},
	Title = {A Survey on Tree Edit Distance and Related Problems},
	Volume = {337},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2VkaXRzdXJ2ZXlfYmlsbGUucGRm0hcLGBlXTlMuZGF0YU8RAcwAAAAAAcwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxRlZGl0c3VydmV5X2JpbGxlLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw4CzKcbyAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzKdUCAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFNNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBlZGl0c3VydmV5X2JpbGxlLnBkZgAADgAqABQAZQBkAGkAdABzAHUAcgB2AGUAeQBfAGIAaQBsAGwAZQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQFVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvZWRpdHN1cnZleV9iaWxsZS5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDMANEA2QKpAqsCsAK7AsQC0gLWAt0C5gLrAvgC+wMNAxADFQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMX}}

@techreport{Gust2003,
	Annote = {Better description of anti-unification than the 2006 paper and how },
	Author = {Gust, Helmar and K{\"u}hnberger, Kai-uwe and Schmid, U.},
	Date-Added = {2012-10-11 04:29:38 -0400},
	Date-Modified = {2013-01-30 20:49:21 -0500},
	Institution = {University of Osnabr{\"u}ck},
	Title = {Anti-Unification of Axiomatic Systems},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FudGl1bmlmaWNhdGlvbi5wZGbSFwsYGVdOUy5kYXRhTxEByAAAAAAByAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHE2FudGl1bmlmaWNhdGlvbi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPMjMm/ugAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADMnDPgAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAUk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGFudGl1bmlmaWNhdGlvbi5wZGYADgAoABMAYQBuAHQAaQB1AG4AaQBmAGkAYwBhAHQAaQBvAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD9Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FudGl1bmlmaWNhdGlvbi5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AywDQANgCpAKmAqsCtgK/As0C0QLYAuEC5gLzAvYDCAMLAxAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADEg==}}

@article{LicatoUnpublished,
	Author = {Licato, John},
	Date-Added = {2012-10-11 03:50:22 -0400},
	Date-Modified = {2012-10-11 03:51:19 -0400},
	Journal = {You suck at this that's why this got rejected},
	Title = {Applying analogical reasoning to structured, semantically-rich domains},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMC4uLy4uL0Rlc2t0b3AvcmFpcl9vbGQvcGFwZXJzLzIwMTIuQ0lLTS9NQUlOLnBkZtIXCxgZV05TLmRhdGFPEQGmAAAAAAGmAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADJAgkZSCsAAA8jLncITUFJTi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD4bVeMxhEREAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAACTIwMTIuQ0lLTQAAEAAIAADJAk9pAAAAEQAIAADMYUlRAAAAAQAYDyMudw8isZUPImJOAA4mZgAOJlsAAJMnAAIASk1hY2ludG9zaCBIRDpVc2VyczoAbGljYXRqOgBEZXNrdG9wOgByYWlyX29sZDoAcGFwZXJzOgAyMDEyLkNJS006AE1BSU4ucGRmAA4AEgAIAE0AQQBJAE4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADdVc2Vycy9saWNhdGovRGVza3RvcC9yYWlyX29sZC9wYXBlcnMvMjAxMi5DSUtNL01BSU4ucGRmAAATAAEvAAAVAAIADf//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMEAxgDOAngCegJ/AooCkwKhAqUCrAK1AroCxwLKAtwC3wLkAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAuY=}}

@article{Gust2006,
	Annote = {Cited by the Krumnack 2007 antiunification paper as the one that describes the heuristics used in hdtp and more details about the algorithms used.

HDTP is really a generalization of anti-unification

HDTP-A is the algorithm they use to compute generalizations and the corresponding substitutions (which is based on the implementation in [12]).

The author does a good job of taking the naturally intuitive concept of analogy and abstracting it away using such a complicated formalism that there is almost nothing left of the original. 

source domain: "rich domain with large amount of facts and laws determining the conceptualization" (106)
- Facts and Laws are quantified

Example heuristics they use are on page 109

"It is not simple to specify what good [solutions] should mean in this context." (109)

Section 5 - HDTP's modeling of domains involves types, which helps to ensure that inferred properties apply to the right classes / sorts.},
	Author = {Gust, Helmar and K{\"u}hnberger, Kai-uwe and Schmid, U.},
	Date-Added = {2012-10-10 20:59:58 -0400},
	Date-Modified = {2013-07-07 14:11:20 +0200},
	Journal = {Theoretical Computer Science},
	Number = {1},
	Pages = {98-117},
	Title = {Metaphors and Heuristic-Driven Theory Projection (HDTP)},
	Volume = {354},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QSC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEtczIuMC1TMDMwNDM5NzUwNTAwODU2WC1tYWluLnBkZtIXCxgZV05TLmRhdGFPEQH+AAAAAAH+AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfMS1zMi4wLVMwMzA0Mzk3NTA1MDA4I0UzQzRFLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48TsybkaMAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMybyeMAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMS1zMi4wLVMwMzA0Mzk3NTA1MDA4I0UzQzRFLnBkZgAOAEQAIQAxAC0AcwAyAC4AMAAtAFMAMAAzADAANAAzADkANwA1ADAANQAwADAAOAA1ADYAWAAtAG0AYQBpAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAE1Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEtczIuMC1TMDMwNDM5NzUwNTAwODU2WC1tYWluLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDZAN4A5gLoAuoC7wL6AwMDEQMVAxwDJQMqAzcDOgNMA08DVAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANW}}

@article{Anderson2005,
	Annote = {Discusses the logical and the biological aspects of self-awareness and self-reference.

},
	Author = {Anderson, Michael L. and Perlis, Donald R.},
	Date-Added = {2012-09-23 10:05:49 -0400},
	Date-Modified = {2013-01-30 20:15:44 -0500},
	Journal = {Phenomenology and the Cognitive Sciences},
	Pages = {297-333},
	Title = {The Roots of Self-Awareness},
	Volume = {4},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICgxMCkucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFmdWxsdGV4dCAoMTApLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw8WzISPcAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzITHsAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBmdWxsdGV4dCAoMTApLnBkZgAOACQAEQBmAHUAbABsAHQAZQB4AHQAIAAoADEAMAApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoMTApLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@inproceedings{Zee2009,
	Address = {New York, New York, USA},
	Annote = {Most recent paper I could find that extended work by Arkoudas (barely). Like most proof languages, concerned with proving correctness of programs. Their system is called Jahob, and it makes it "possible for developers to control proofs of program correctness properties while remaining completely within a single unified programming and verification environment."},
	Author = {Zee, Karen and Kuncak, Viktor and Rinard, Martin C.},
	Booktitle = {Proceedings of the 2009 ACM SIGPLAN Conference on Programming Language Design and Implementation},
	Date-Added = {2012-09-23 09:55:00 -0400},
	Date-Modified = {2013-01-30 20:57:48 -0500},
	Organization = {ACM},
	Pages = {338-351},
	Title = {An Integrated Proof Language for Imperative Programs},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QYC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1plZUVUQUwwOUludGVncmF0ZWRQcm9vZkxhbmd1YWdlZm9ySW1wZXJhdGl2ZVByb2dyYW1zLnBkZtIXCxgZV05TLmRhdGFPEQJGAAAAAAJGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfWmVlRVRBTDA5SW50ZWdyYXRlZFByI0YxMkI2LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8StsyEjOEAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMyExSEAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAWmVlRVRBTDA5SW50ZWdyYXRlZFByI0YxMkI2LnBkZgAOAHQAOQBaAGUAZQBFAFQAQQBMADAAOQBJAG4AdABlAGcAcgBhAHQAZQBkAFAAcgBvAG8AZgBMAGEAbgBnAHUAYQBnAGUAZgBvAHIASQBtAHAAZQByAGEAdABpAHYAZQBQAHIAbwBnAHIAYQBtAHMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAGVVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1plZUVUQUwwOUludGVncmF0ZWRQcm9vZkxhbmd1YWdlZm9ySW1wZXJhdGl2ZVByb2dyYW1zLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDxAPYA/gNIA0oDTwNaA2MDcQN1A3wDhQOKA5cDmgOsA68DtAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAO2}}

@article{Anderson2007,
	Annote = {Reviews recent (2000-2007) research in two main areas:
Metareasoning - the monitoring and control of reasoning - Only focuses on work after 2000, read Michael Cox (2005) and Stefania Costantini (2002) for other summaries.
Metalearning - the monitoring and control of learning

Any-time Algorithm: One designed to generate solutions of continually increasing quality, so whenever it is terminated it gives the best currently available solution given its time constraints.
Continual computation - tries to find not the best (optimal) solution, but the best use of idle computational resources between bouts of problem solving. "The metareasoning challenge here is to anticipate future needs and use idle time to prepare proactively for these expected problems."

..."the second area of metareasoning research, of trying to gather and represent information about the object-level reasoner or reasoning process, and using this information to improve performance. Most of this work falls into the category of logic-based AI and is aimed at improving the performance ... of theorem provers. For instance, Konstantine Arkoudas and Selmer Bringsjord's (2004) work...[can] take advantage of higher-order structures and quantify over elements of the object-level language, thereby significantly enhancing efficiency."


"Vincent Conitzer and Tuomas Sandholm (2003) point out that ... the problem of allocating deliberation time across any-time algorithms running on different problem instances is [NP-complete]." They show some other related problems are NP-Hard as well.

SELF REFERENCE
"Thomas Bolander (2003) lays out some of the problems inherent in logical reasoning with self-reference ... [e.g.], "This sentence is false.""
Len Schubert (2005) - Outlines basic enhancements to typical knowledge representation and reasoning schemas required of systems which want to support self-knowledge
Melanie Mitchell (2005) asks how self-representation and self-control should even be concieved in the case of distributed and decentralized systems
Schmidhuber (2005) Describes the "Godel machine", which is supposed to be able to improve itself through metalearning and self-referential knowledge. But the "computational complexity of this approach is prohibitively expensive."
Holland (2003) and Anderson and Perlis (2005b) are computationally grounded starting points for starting in the topic of self-reference.

Bolander, T. 2003. Logical Theories for Agent Introspection. Ph.D. dissertation, Computer Science, Technical University of Denmark, Lyngby, Denmark.

Schmidhuber, J. 2005. Completely Self-Ref- erential Optimal Reinforcement Learners. Paper presented at the International Con- ference on Artificial Neural Networks (IJC- NN), 31 July--4 August, Montreal, Quebec, Canada.

Schubert, L. 2005. Some Kr&R Require- ments for Self-Awareness. In Metacognition in Computation: Papers from the 2005 AAAI Spring Symposium, Technical Report SS-05- 04, ed. M. Anderson and T. Oates. Menlo Park, CA: AAAI Press.

Mitchell, M. 2005. Self-Awareness and Con- trol in Decentralized Systems. In Metacogni- tion in Computation: Papers from the 2005 AAAI Spring Symposium, Technical Report SS-05-04, ed. M. Anderson and T. Oates. Menlo Park, CA: AAAI Press.

Holland, O., ed. 2003. Machine Conscious- ness. London: Academic Press.

Anderson, M., and Perlis, D. 2005b. The Roots of Self- Awareness. Phenomenology and the Cognitive Sciences 4(3): 297--333.},
	Author = {Anderson, Michael L. and Oates, Tim},
	Date-Added = {2012-09-22 17:14:36 -0400},
	Date-Modified = {2013-01-30 20:15:33 -0500},
	Journal = {AI Magazine},
	Number = {1},
	Title = {A Review of Recent Research in Metareasoning and Metalearning},
	Volume = {28},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Zkc2ZzZC5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCmZkc2ZzZC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDhLMg88NAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADMhAdNAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZkc2ZzZC5wZGYAAA4AFgAKAGYAZABzAGYAcwBkAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mZHNmc2QucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==}}

@article{Dosen2012,
	Annote = {Discusses a way to define an isomorphism between two formulas in propositional logic. Has implications for my work on analogical mapping. Essentially their method allows for logical equivalencies, but requires also that variables are the same on each side (so that P OR Q maps to (not not P) OR Q, but not A OR B). Still good to cite anyway. In hardcopy of Mathematical Logic Quarterly.},
	Author = {Dosen, Kosta and Petric, Zoran},
	Date-Added = {2012-09-22 12:21:02 -0400},
	Date-Modified = {2013-01-30 20:24:44 -0500},
	Journal = {Mathematical Logic Quarterly},
	Number = {1-2},
	Title = {Isomorphic Formulae in Classical Propositional Logic},
	Volume = {58},
	Year = {2012}}

@article{Arkoudas2005,
	Annote = {Uses Athena to encode a sequent calculus for a "multi-agent epistemic logic," and aim to develop a tactic for solving the generalized version of the "wise men problem".

"We embed a multi-agent epistemic logic into many-sorted first-order logic in a proof-theoretic rather than in a model-theoretic way. ... first-order logic becomes our metalanguage and the epistemic logic becomes our object language. We then use standard first-order logic (our metalanguage) to reason about proofs in the object logic."

"Tactics are proof algorithms, which, unlike conventional algorithms, are guaranteed to produce sound results. That is, if and when a tactic outputs a result P that it claims to be a theorem, we can be assured that P is indeed a theorem. ... In Athena tactics are called *methods*, and are particularly easy to formulate owing to Athena's Fitch-style natural deduction system and its assumption-base semantics".

NOTATION
Ka(P) - agent a knows proposition P
C(P) - it is common knowledge that P holds
sequent - ordered pair <T,P> with a context T (set of propositions) and proposition P. Also represented as T |- P. P,T or T,P is an abbreviation for T U {P}. In athena it's represented:
	(declare sequent (-> ((FSet-Of Prop) Prop) Boolean))

FORMALIZING THE GENERAL WISE-MEN PUZZLE
They define a method on p.9 that can be used to create the proof of the generalized wise-men puzzle that has n as a parameter.

Discusses advantages of using Athena over other systems (p.13):
- It is more readable as compared to using Hilbert proof systems
- Integratability with systems like Vampire and Spass helps with automation and ease of implementation
- Athena uses proofs and proof tactics / methods easily.
- "Our emphasis on automation also differentiates our work from that of Basin et al. [10] using Isabelle, which only addresses proof presentation in modal logics, not automatic proof discovery."},
	Author = {Arkoudas, Konstantine and Bringsjord, Selmer},
	Date-Added = {2012-09-21 19:42:23 -0400},
	Date-Modified = {2012-09-22 12:40:42 -0400},
	Journal = {Computational Logic in Multi-Agent Systems},
	Number = {149},
	Title = {Metareasoning for multi-agent epistemic logics},
	Volume = {3487},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS45Mi43OTI3LnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjkyLjc5MjcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48ccyCc+MAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMyCrCMAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjkyLjc5MjcucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADkAMgAuADcAOQAyADcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS45Mi43OTI3LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@article{Schwering2009,
	Annote = {One of the papers given to us by Tarek regarding HDTP (heuristic-driven theory projection). He says it contains the theoretical foundations of the current version (although he says that someone will be writing changes in the implementation soon).


- HDTP based on a first-order logical language
- also takes the standard approach where the source domain is given explicitly. 
- Superficial similarity "can be determined via the number of common symbols in the source and target domain formalizations."
- Very rigorously defined knowledge representation., strongly based in FOL.
- They claim "due to its first-order representation of domain knowledge, HDTP has a greater expressive power compared to other analogy models ... a logic-based representation allows for reasoning on formulas and for a re-representation of knowledge" (5)

USE OF ANTI-UNIFICATION
- "For analogy making, Plotkin's first-order anti-unification is not powerful enough, since structural commonalities are ignored if they are embedded in different contexts. Therefore, HDTP extends classical anti-unification by introducing a new kind of restricted higher-order anti-unification."
- "We extend classical first-order terms by introducing variables that can take arguments" (8).
- Their basic substitutions "...are sufficient for generalizations in analogical reasoning and meet the requirement to only generate less complex anti-instances." These are things like renaming variables, fixation (replacing a variable with an equivalent function), argument insertion, permutation.
- They have a method for measuring the complexity of a substitution or generalization.
- Using anti-unification in analogy "...is very powerful: unlike many other analogy models, HDTP matches functions and predicates with same and different labels, but anti-instances for identical function and predicate names are more specific than for differing ones."
- "The major restriction of HDTP alignment is logical consistency: an alignment is only accepted if the generalized formula is consistent with the rest of the generalized theory."
- Also, "HDTP supports the idea of one-to-one mapping in the heuristic, but does not reject alignable formulas which violate the one-to-one mapping criterion." The point here is, the degree to which the model supports various criteria (such as 1-to-1 mapping) is a property OF THE ALGORITHM ITSELF, which is more difficult to modify than if it were a property of a flexibly removable heruistic. This is my argument for using FHM. Either the heuristic is part of the algorithm, or it must be inserted into the knowledge representation itself (like with lisa and adding extra nodes/weights/connections to model heuristic connections), the latter is 'cheating' because it requires that we know something about the individual knowledge pieces beforehand (moreso than with domain-specific heuristics).

RE-REPRESENTATION
- "...the logical framework used in HDTP entails a mechanism for re-representation in a quite natural way: a logical representation of a domain does not only provide the axioms, that are explicitly given, but also makes all formulas available that can be inferred from the axioms by logical deduction."
- They "extend the notion of anti-unification to theories" instead of just formulas; they theoretically map not just the formulas but all of their logical consequences as well.

MODELING COGNITIVE ABILITIES WITH HDTP
- "HDTP is a formal model based on a logical language in the tradition of artificial intelligence. Logical languages have proven suitable to model knowledge on domains, however they have been criticized for being restricted to logical inferences. It is unclear to what extent logical reasoning can be called cognitively plausible."
- "Other neuro-inspired analogy models such as LISA [...] are not explicitly compared [here] to HDTP, as the way of representation and establishing an analogical relations [sic] differ significantly."},
	Author = {Schwering, Angela and Krumnack, Ulf and K{\"u}hnberger, Kai-uwe and Gust, Helmar},
	Date-Added = {2012-09-10 09:25:15 -0400},
	Date-Modified = {2013-01-30 21:03:44 -0500},
	Journal = {Cognitive Systems Research},
	Number = {3},
	Pages = {251-269},
	Title = {Syntactic Principles of Heuristic-Driven Theory Projection},
	Volume = {10},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QLy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzIwMDkucGRm0hcLGBlXTlMuZGF0YU8RAZwAAAAAAZwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwgyMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjyIzHNhKgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzHOZagAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEdNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgAyMDA5LnBkZgAADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIANFVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvMjAwOS5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDAAMUAzQJtAm8CdAJ/AogClgKaAqECqgKvArwCvwLRAtQC2QAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALb}}

@webpage{Arkoudas_omega,
	Annote = {"Every type-w DPL properly contains a type-a DPL, which can be used to present proofs in a lucid and detailed form ... Derived inference rules are expressed as user-defined methods, which are "proof recipes" that take arguments and dynamically perform appropriate deductions. Methods arise naturally via parametric abstraction over type-a proofs."

Parametric Abstraction - "Perhaps the most serious limitation of type-a DPLs is the lack of an abstraction mechanism. In particular, there is no parametric abstraction: there is no way to abstract a given proof over one or more concrete objects in order to formulate a "proof recipe" that can be reused in many different situations by supplying different values for the parameters."

You can introduce an abstraction operator PHI, for example:
foo = PHI P. assume P in
                    suppose-absurd -P in
                         absurd P,-P
foo is a method abstracted over P

Method - "For now (p.3) the term "method" can be understood simply as shorthand for "derived inference rule", although later we will see that methods are more general and powerful than what are commonly understood as derived inference rules." They return propositions that are conclusions, just like regular deductions. Other methods can be passed in as parameters as well.
Methods perform inference, whereas basic operators like (AND) perform computations: AND is a FUNCTION that returns a proposition (the disjunction a AND b).

We have deductions D and methods F.
D ::= !E F1 ... Fn | assume E in D
F ::= E | D
Where E are expressions: all constants, identifiers, propositions, methods, and functions. The ! notation is a method application/call, done that way to distinguish from function calls. E.g.:
!double-negation (!right-and A ^ --B)
right-and A ^ --B; double-negation --B
These both are equivalent and evaluate to B.

Recursive definitions:
the "fix" construct allows this (p.18). e.g.:
fix convert.lambda P.match P
     (Q and R ? Q or (convert R))
     (Q? Q)
},
	Date-Added = {2012-09-09 03:42:58 -0400},
	Date-Modified = {2012-09-10 09:25:01 -0400},
	Lastchecked = {9/9/2012},
	Title = {Type- DPLs},
	Url = {http://people.csail.mit.edu/kostas/dpls/ndlOmega.pdf},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL25kbE9tZWdhLnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMbmRsT21lZ2EucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Q5cxxwLoAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMxx+PoAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAbmRsT21lZ2EucGRmAAAOABoADABuAGQAbABPAG0AZQBnAGEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL25kbE9tZWdhLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=}}

@article{Ray2005,
	Annote = {     - "Roughly put, Tarski's considered sense of the term allows that one language system might be essentially richer than another either by having higher order variables, by having axioms that are stronger in a certain way, or in virtue of a difference in available forms of definition."
     - There always exists a language of higher order: those that just have variables are order 1, those that range over variables are 2, those that range over things that range over variables are 3, etc.
     - That footnote also hints at a third way a language could be essentially richer, having to do with the ability to turn a recursive definition into an explicit one.
     - Author identifies a footnote by Tarski in which he clearly states that we need to either "introduce into the meta-language variables of a higher logical type than those which occur in the object-language; or else to assume axiomatically in the meta-language the existence of classes that are more comprehensive than all those whose existence can be established in the object-language." In author's words, "the rules of definition of [the metalanguage] admit recursive definitions and the rules of definition [of the object language] do not."
     - An explicit statement of Tarski's essential richness thesis "turns out to be nothing less than an emended version of Tarski's central result on truth -- which has gone unrecognized in the literature. It also turns out the essential richness claim is only a somewhat loose gloss of the essential richness thesis."
     - Author suggests a fourth way: "Tarski should have made an allowance for a fourth way - via forms of inference - since the effect of an axiomatic enrichment could be carried out instead by an enrichment of inference rules."
     - "Careful examination of Tarski's texts reveals that he was not centrally concerned with the question of when an *arbitrarily given* language has a truth definition for another arbitrarily given language. Rather, Tarski addressed himself in the first instance to the question of when a solution of the definition problem was possible for an arbitrarily given *object* language. ... the big question was whether *one could construct* an appropriate metalanguage in which a truth definition could be given for the *given* object language."

Author's formulation of Tarki's essential richness thesis:

ERT-A.
     (i) For semantically-open formalized language L, and semantically-open exactly-specified language M, if M is essentially richer than L and M is an extending metalanguage for L, then a formally correct and materially adequate semantic definition of true sentence of L can be constructed in M with the help only of general logical expressions, of the expressions of L, and of terms from the morphology of language.
     (ii) For every such L, there is at least one M that is essentially richer than L, and which is an extending metalanguage for L.

ERT-B.
     For semantically-open formalized language L, and semantically-open exactly-specified metalanguage M, if a formally correct and materially adequate semantic definition of true sentence of L can be constructed in M, then M is essentially richer than L.

using these clarified definitions, he then refutes the criticisms of DeVidi and Solomon.
},
	Author = {Ray, Greg},
	Date-Added = {2012-09-08 08:08:09 -0400},
	Date-Modified = {2013-01-30 21:04:59 -0500},
	Journal = {Journal of Philosophical Logic},
	Number = {4},
	Pages = {433-457},
	Title = {On the Matter of Essential Richness},
	Volume = {34},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Vzc2VudGlhbFJpY2huZXNzLnBkZtIXCxgZV05TLmRhdGFPEQHQAAAAAAHQAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcVZXNzZW50aWFsUmljaG5lc3MucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8OB8xwQuMAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMxweyMAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBUTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAZXNzZW50aWFsUmljaG5lc3MucGRmAA4ALAAVAGUAcwBzAGUAbgB0AGkAYQBsAFIAaQBjAGgAbgBlAHMAcwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQVVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvZXNzZW50aWFsUmljaG5lc3MucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAM0A0gDaAq4CsAK1AsACyQLXAtsC4gLrAvAC/QMAAxIDFQMaAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAxw=}}

@article{Forbus2012,
	Annote = {Argues that the current state of cognitive systems is unacceptable---we work on such small problems when we should be focusing on integrated systems for true progress to be made.

Argues that the analogy of "building bricks" in cogsci research doesn't work, that's not how we build buildings! We build it one whole building at a time and learn from our mistakes!

Cites Cassimatis et al. (2009) on the nature of a cognitive simulation (p. 48)

The 'individual solutions' that independent researchers in the field seek out "may be too far apart...and not stable enough, to support bridges."

Regarding Watson as an example, "...the acid test of operating in an integrated environment strengthened their development."

"Most architectures developed specifically for particular funding programs, for example, tend to vanish when the program is over."

His "Bets":
	- Build minds, not brains: Computation is a theoretical model that must collectively unite and abstract different fields: AI, psychology, neuroscience, linguistics, philosophy, etc; not be held back by them! Describes Marr's (1982) levels of description, says that his lab focuses on the "Process" and "Information" levels, avoiding the "Implementation" level because of the uncertainty in neuroscience.
	- Sources of evidence: We should be careful to check what sources of evidence are valid for us---fMRIs don't justify everything! Pay attention to Newell's (1990) decomposition of phenomena according to their time scales.
	- Kinds of minds: It may be okay to produce super-human minds, and we shouldn't only limit ourselves to modeling human psychological phenomena exactly.
	- Analogy, Logic, and Statistics: The three pillars of intelligence: Argues for the centrality of analogical ability just like logical ability (and suggests it may even subsume deductive reasoning).
	- Building social organisms
	},
	Author = {Forbus, Kenneth D.},
	Date-Added = {2012-09-06 02:12:01 -0400},
	Date-Modified = {2013-01-30 20:19:59 -0500},
	Journal = {Advances in Cognitive Systems},
	Pages = {47-58},
	Title = {How Minds Will Be Built},
	Volume = {1},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhcGVyLTEtNi5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDXBhcGVyLTEtNi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEPDMbbbCAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADMbe8CAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHBhcGVyLTEtNi5wZGYADgAcAA0AcABhAHAAZQByAC0AMQAtADYALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhcGVyLTEtNi5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==}}

@webpage{Arkoudas_alpha,
	Annote = {Describes type-alpha DPLs, particularly a formalization of fitch called NDL:

NDL:

P = proposition
D = deduction

hypothetical or conditional: deduction of the form "assume HYPOTHESIS in BODY". Body is the scope of the hypothesis.
SZ(D) = size of a deduction

NDL's grammar is ambiguous.
Composition operator (;) associates to the right:
D1;D2;D3 = D1;(D2;D3)

B |- D ~> P
B = assumption base, finite set of propositions (premises)
D = proof
P = proposition derived from D, with respect to premises B.
e.g.:
B U {--P} |- double-negation --P ~> P
means an application of "double-negation" to --P results in P, provided that --P is in the assumption base.

e1 ? -> e2,e3
means: if e1 true? then e2; else e3.

suppose-absurd P in D
allows for reasoning by contradiction

DENOTATIONAL SEMANTICS FOR NDL

meaning function M defined:
M : Ded -> AB -> Prop U {error}
Where AB = all assumption bases for NDL. Takes deduction D, assumption base B, and produces either error token or proposition. It is a *function over assumption bases*. The process of obtaining M[[D]]B is called "evaluating D in B". It is O(n) complexity on average, O(n log n) worst case.
example:
M[[modus-ponens P->Q,P]]B = {P->Q,P} (subset operator) B ? -> Q, error

To check if a proof is well-formed, use the conclusion function C(D):
C(D1;D2) = C(D2)
C(assume P in D) = (P -> C(D))
define function FA(D), the free assumptions of D:
FA : Dedu -> P_infinite(Prop)
P_infinite(Prop) is the set of all finite subsets of Prop.


Equivalence
Two proofs D1 and D2 are observationally equivalent with respect to an assumption base B (written D1  D2) when:
for all P:   B |- D1 ~> P   iff   B |- D2 ~> P
This is a decidable algorithm.
If two proofs D1 and D2 are observationally equivalent with respect to all B, then we just say they are observationally equivalent:
D1  D2.
This is NOT an associative relationship.
Observational equivalence IS decidable (p.12).},
	Author = {Arkoudas, Konstantine},
	Date-Added = {2012-09-06 02:06:44 -0400},
	Date-Modified = {2012-09-06 02:09:51 -0400},
	Lastchecked = {9/6/2012},
	Title = {Formalizing natural deduction with assumption bases},
	Url = {http://www.cag.csail.mit.edu/~kostas/dpls/ndl/simplify/proofSimp.pdf},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL25kbFplcm8ucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwtuZGxaZXJvLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxDnzG21oQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzG3t4QAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBuZGxaZXJvLnBkZgAOABgACwBuAGQAbABaAGUAcgBvAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9uZGxaZXJvLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@electronic{Mauldin,
	Author = {Mauldin},
	Date-Added = {2012-08-28 13:02:35 -0400},
	Date-Modified = {2012-08-28 13:03:19 -0400},
	Title = {Two versions of the liar paradox},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL01hdWRsaW5UZXh0LnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPTWF1ZGxpblRleHQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Qw8xh40YAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMxiG4YAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoATWF1ZGxpblRleHQucGRmAA4AIAAPAE0AYQB1AGQAbABpAG4AVABlAHgAdAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvTWF1ZGxpblRleHQucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@techreport{Elman1989,
	Address = {University of California, San Diego},
	Author = {Elman, J.L.},
	Date-Added = {2012-08-23 16:17:50 -0400},
	Date-Modified = {2013-01-30 20:23:21 -0500},
	Institution = {Center for Research in Language},
	Number = {8903},
	Title = {Representation and Structure in Connectionist Models},
	Type = {Technical Report},
	Year = {1989}}

@incollection{Shore2012,
	Address = {Cambridge, MA},
	Author = {Shore, B.},
	Booktitle = {Grounding Social Sciences in Cognitive Sciences},
	Date-Added = {2012-08-23 16:14:39 -0400},
	Date-Modified = {2012-08-23 16:16:06 -0400},
	Editor = {Sun, Ron},
	Publisher = {MIT Press},
	Title = {{Egocentric and Allocentric Perspective in Cultural Models}},
	Year = {2012}}

@techreport{Guarini2005,
	Author = {Guarini, Marcello},
	Date-Added = {2012-08-23 16:12:00 -0400},
	Date-Modified = {2012-08-23 16:13:16 -0400},
	Institution = {{Technical Report for Machine Ethics Symposium, American Association for Artificial Intelligence Fall Symposium}},
	Month = {November},
	Title = {{Particularism and Generalism: How AI Can Help Us to Understand Moral Cognition}},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0FJJk1vcmFsQ29nbml0aW9uLnBkZtIXCxgZV05TLmRhdGFPEQHQAAAAAAHQAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcVQUkmTW9yYWxDb2duaXRpb24ucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48oMxcBrkAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMxcPvkAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBUTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAQUkmTW9yYWxDb2duaXRpb24ucGRmAA4ALAAVAEEASQAmAE0AbwByAGEAbABDAG8AZwBuAGkAdABpAG8AbgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQVVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvQUkmTW9yYWxDb2duaXRpb24ucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAM0A0gDaAq4CsAK1AsACyQLXAtsC4gLrAvAC/QMAAxIDFQMaAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAxw=}}

@article{Guarini2010,
	Author = {Guarini, Marcello},
	Date-Added = {2012-08-23 16:10:18 -0400},
	Date-Modified = {2012-08-23 16:11:31 -0400},
	Journal = {Minds and Machines},
	Number = {3},
	Pages = {385-422},
	Title = {{Particularism, Analogy, and Moral Cognition}},
	Volume = {20},
	Year = {2010}}

@misc{Weber1998,
	Author = {Weber, E.U.},
	Date-Added = {2012-08-23 16:08:23 -0400},
	Date-Modified = {2012-08-23 16:09:33 -0400},
	Howpublished = {{Presidential Address, Annual Meeting, Society of Judgment and Decision Making, Dallas, TX}},
	Title = {{From Shakespeare to Spielberg: Predicting Modes of Decision Making}},
	Year = {1998}}

@article{Bennis2010,
	Author = {Bennis, W.M. and Medin, D.L. and Bartels, D.M.},
	Date-Added = {2012-08-23 16:07:14 -0400},
	Date-Modified = {2012-08-23 16:07:58 -0400},
	Journal = {Perspectives on Psychological Science},
	Pages = {187-202},
	Title = {{The Costs and Benefits of Calculation and Moral Rules}},
	Volume = {5},
	Year = {2010}}

@article{Sun2012a,
	Author = {Sun, Ron},
	Date-Added = {2012-08-23 16:04:38 -0400},
	Date-Modified = {2013-05-20 21:59:48 -0400},
	Journal = {Cognitive Computing},
	Title = {{Moral Judgment, Human Motivation, and Neural Networks}},
	Year = {forthcoming},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL21vcmFsLXNpbS5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDW1vcmFsLXNpbS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEN/MXAVLAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADMXD2LAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AG1vcmFsLXNpbS5wZGYADgAcAA0AbQBvAHIAYQBsAC0AcwBpAG0ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL21vcmFsLXNpbS5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==}}

@article{Mikhail,
	Annote = {UMG (universal moral grammar) "seeks to describe the nature and origin of moral knowledge by using concepts and models similar to those used in Chomsky's program in linguistics."

Goes through some observations, then talks about two fundamental arguments UMG relies on:
- Argument for moral grammar - the properties of moral judgment imply that the mind contains a moral grammar: a complex and possibly domain-specific set of rules, concepts and principles that generates and relates mental representations of various types.
- Argument from poverty of the moral stimulus - the manner in which this grammar is acquired implies that at least some of its core attributes must be innate},
	Author = {Mikhail, John},
	Date-Added = {2012-08-19 03:20:15 -0700},
	Date-Modified = {2013-01-30 20:37:31 -0500},
	Journal = {TRENDS in Cognitive Sciences},
	Number = {4},
	Title = {Universal Moral Grammar: Theory, Evidence and the Future},
	Volume = {11},
	Year = {?}}

@article{Doumas2008,
	Annote = {Main citation for DORA

"the most basic prerequisite to explicitly relational thought is the capacity to detect relational (and featural) invariants in the environment." (2)

semantic units:
	visual invariants: round, square, shiny
	relational invariants: more, less, same
	dimensional properties: size-3, height-3, color-red
	perceptual properties: sweet, noisy, rough
	complex perceptual/cognitive properties: furry, barks, has-wheels, fast
	category information: apple, dog, fire engine
	individual identifiers: me, Spot, Jane, mommy

P - propositional units
RB - role binding units
PO - object (circles) and predicate (triangle) units
semantic units

"Our approach is based on four constraints ... [which] constitute our core theoretical claims." These are:
- "role-filler binding representations reduce the problem of learning relations to the problems of learning object properties or relational roles (single-place predicates) and linking them together to form multiplace relational strutures."
- "Comparison can lead to the discovery and predication of shared properties."
- "A common vocabulary of representational primitives codes both predicates and their arguments." Implemented by having "both predicates and objects share the same pool of semantic units." But I don't know if this is fully satisfying---how does it explain the creation of new semantic units, and thus new experiences? I think that each semantic unit must itself be rooted in structure, and (except for the very very primitive sensory semantic units) should allow for the creation of new semantics through chunking and new representations, as a normal part of experience.
- "Mapping predicates of smaller arity can lead to the formation of higher arity structures." 

A new PO unit is recruited "whenever two existing predicates or objects are explicitly compared to one another." This is theoretically based in exemplar theory, where "a category is represented in memory by storing, individually, all *e* exemplars of that category."

Suppose that someone already has the ability to recognize objects in the visual field. Doumas's account of how the higher-than relation comes about requires that one already has a notion of height. But what subfeatures do height itself emerge from? I think rather, it's better to explain that height comes by conceptualizing an action schema, that of moving the eyes upward. But then, what is "upward"? That itself, I think, is sufficiently low level to be reduced to a fixed set of sensory outputs, in this case the neuron groups that roll the eye upward.

More detail on how "higher-than" comes about in Doumas's account: They note that children start by categorizing some things as high, and some as low. In other words, the theory is that the two-place predicate "higher-than" comes about by some fusion of the single-place predicates high and low. (p. 22) This is plausible to me. But still I am not satisfied with the assumption that predicates coding for height can be treated as primitives. I want to explain how they come about.
He says "Beginning with representations of whole objects it learns representations of specific values of height. From these, it learns representations of *higher* and *lower* that are tied to specific heights or to specific categorical values (i.e., representations of *higher* that are also "high" and representations of "lower" that are also "low). From these, it finally learns representations of higher-than and lower-than that are indepenent of object features and context".
To be fair, they acknowledge some things:
- "Most of the relations DORA learned in the simulations reported here are relations with an underlying metric dimension...In the case of a relation like *chases*, however...Each role seems to somehow refer to the other. ... DORA predicts that relations like *chase* and *bigger-than* should follow identical learning trajectories. Specifically, it predicts that a child should understand what it is to be a chaser or a chased before he or she understands the full-blown *chase* relation. ... The model, as it stands, does not speak to where the semantic invariants underlying *chases* or *loves* (or *ameliorates*) come from, but it does speak to the question of how they eventually become predicates that can take arguments".},
	Author = {Doumas, Leonidas A. and Hummel, John E. and Sandhofer, C.M.},
	Date-Added = {2012-08-08 13:55:17 -0400},
	Date-Modified = {2014-06-02 16:48:57 +0000},
	Journal = {Psychological Review},
	Pages = {1-43},
	Title = {A Theory of the Discovery and Predication of Relational Concepts},
	Volume = {115},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0RPUkFfUFJfMDgucGRm0hcLGBlXTlMuZGF0YU8RAbQAAAAAAbQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rw5ET1JBX1BSXzA4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw20zEggfQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzEhYvQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAE1NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBET1JBX1BSXzA4LnBkZgAADgAeAA4ARABPAFIAQQBfAFAAUgBfADAAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAOlVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvRE9SQV9QUl8wOC5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDGAMsA0wKLAo0CkgKdAqYCtAK4Ar8CyALNAtoC3QLvAvIC9wAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAL5}}

@unpublished{Arkoudas2009b,
	Annote = {Primary reference for the Cognitive Event Calculus},
	Author = {Arkoudas, Konstantine and Bringsjord, Selmer},
	Date-Added = {2012-07-10 11:44:56 -0400},
	Date-Modified = {2012-07-10 11:45:49 -0400},
	Note = {Available at http://kryten.mm.rpi.edu/PRICAI_w_sequentcalc_041709.pdf},
	Title = {Propositional attitudes and causation},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1BSSUNBSV93X3NlcXVlbnRjYWxjXzA0MTcwOS5wZGbSFwsYGVdOUy5kYXRhTxEB+AAAAAAB+AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHH1BSSUNBSV93X3NlcXVlbnRjYWxjXzA0MTcwOS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEQbMIcYlAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADMIf5lAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAXk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AFBSSUNBSV93X3NlcXVlbnRjYWxjXzA0MTcwOS5wZGYADgBAAB8AUABSAEkAQwBBAEkAXwB3AF8AcwBlAHEAdQBlAG4AdABjAGEAbABjAF8AMAA0ADEANwAwADkALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAEtVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1BSSUNBSV93X3NlcXVlbnRjYWxjXzA0MTcwOS5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A1wDcAOQC4ALiAucC8gL7AwkDDQMUAx0DIgMvAzIDRANHA0wAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADTg==}}

@unpublished{Bringsjord2011a,
	Author = {Bringsjord, Selmer},
	Date-Added = {2012-07-10 11:42:24 -0400},
	Date-Modified = {2013-05-18 01:46:50 -0400},
	Note = {Available at http://kryten.mm.rpi.edu/Bringsjord_SimpleSoulsVsExtendedMinds_020411.pdf},
	Title = {Chisholm's Simple Souls vs. Clark's Extended Selves},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QVy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0JyaW5nc2pvcmRfU2ltcGxlU291bHNWc0V4dGVuZGVkTWluZHNfMDIwNDExLnBkZtIXCxgZV05TLmRhdGFPEQIqAAAAAAIqAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfQnJpbmdzam9yZF9TaW1wbGVTb3VsI0UzQ0RFLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA483swhxW0AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMwh/a0AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAQnJpbmdzam9yZF9TaW1wbGVTb3VsI0UzQ0RFLnBkZgAOAGIAMABCAHIAaQBuAGcAcwBqAG8AcgBkAF8AUwBpAG0AcABsAGUAUwBvAHUAbABzAFYAcwBFAHgAdABlAG4AZABlAGQATQBpAG4AZABzAF8AMAAyADAANAAxADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFxVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0JyaW5nc2pvcmRfU2ltcGxlU291bHNWc0V4dGVuZGVkTWluZHNfMDIwNDExLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAOgA7QD1AyMDJQMqAzUDPgNMA1ADVwNgA2UDcgN1A4cDigOPAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA5E=}}

@electronic{Norvig2011,
	Annote = {Peter Norvig responds to Chomsky's comments, where he:
derided researchers in machine learning who use purely statistical methods to produce behavior that mimics something in the world, but who don't try to understand the meaning of that behavior. Chomsky compared such researchers to scientists who might study the dance made by a bee returning to the hive, and who could produce a statistically based simulation of such a dance without attempting to understand why the bee behaved that way. "That's a notion of [scientific] success that's very novel. I don't know of anything like it in the history of science," said Chomsky.

Defines a statistical model as:
"a mathematical model which is modified or trained by the input of data points."

He thinks Chomsky's words meant that success of "modeling the world" is novel, and "providing insight" is more important: we must answer WHY things are, not just HOW they are. He takes articles from Science and cites some of the 2010 Nobel prize winners in science as examples of how science does try to model the world, rather than provide insight. 

Argues that things like the great vowel shift couldn't be easily explained with categorical models (grammars with parameters), but can be with continuous, gradually changing probabilistic models. Same with exceptions to the grammar rules, like the proper use of the word "quake".

COMMENTS DISCUSSION



READ:

10. Johnson, Kent (2004) Gold's Theorem and cognitive science, Philosophy of Science, Vol. 71, pp. 571-592.
The best article I've seen on what Gold's Theorem actually says and what has been claimed about it (correctly and incorrectly). Concludes that Gold has something to say about formal languages, but nothing about child language acquisition.

11. Lappin, Shalom and Shieber, Stuart M. (2007) Machine learning theory and practice as a source of insight into universal grammar., Journal of Linguistics, Vol. 43, No. 2, pp. 393-427.
An excellent article discussing the poverty of the stimulus, the fact that all models have bias, the difference between supervised and unsupervised learning, and modern (PAC or VC) learning theory. It provides alternatives to the model of Universal Grammar consisting of a fixed set of binary parameters.

2. Breiman, Leo (2001) Statistical Modeling: The Two Cultures, Statistical Science, Vol. 16, No. 3, 199-231.
Breiman does a great job of describing the two approaches, explaining the benefits of his approach, and defending his points in the vary interesting commentary with eminent statisticians: Cox, Efron, Hoadley, and Parzen.},
	Author = {Norvig, Peter},
	Date-Added = {2012-06-12 19:35:01 -0400},
	Date-Modified = {2014-09-15 04:29:51 +0000},
	Lastchecked = {June 2012},
	Title = {On Chomsky and the Two Cultures of Statistical Learning},
	Url = {http://norvig.com/chomsky.html},
	Urldate = {June 2012},
	Year = {2011},
	Bdsk-Url-1 = {http://norvig.com/chomsky.html}}

@inproceedings{Krumnack2007,
	Annote = {Heuristic-Driven Theory Projection (HDTP) - symbolic analogy model that uses anti-unification to find cross-domain analogies based on structural comparison

First-order anti-unification, given f(a,b) and g(a,b), would generalize to Y. Higher-order would generalize to F(a,b). 

lgg - least general generalization, what anti-unification tries to find (where unification tries to find mgu, most general unifier)

But there are multiple possible lgg's. So they define a complexity measure for statements, and then use that to define a complexity of a generalization. The preferred generalization is then the one with the least complexity.

The algorithm they use is a bottom-up breadth-first strategy.

ALGORITHM:

- Given source and target domain, which are sets of formulas represented in many-sorted FOL. (Th_s and Th_t)
- Use heuristics to select a formula from Th_s and Th_t
- Construct a generalization with the corresponding substitutions (Th_g)
- Interpret the generalizations

A generalization for pair of terms <s,t> is a triple <g,t1,t2> with a germ g and substitutions t1,t2, such that:
s <--(t1)-- g --(t2)--> t

Complexity of substitution:
The complexity of a basic substitution s is defined as:
C(s) = 
0 if s = a renaming of one var to another with the same arity
1 if s = a fixation (replacing of a variable by a function symbol of the same arity)
k+1 if s = an argument insertion of k arguments
1 if s = an argument permutation

The complexity of a composition of basic substitutions is C(s1,...,sn) = sum C(si) and for an arbitrary substitution C(s) is min{ C(s1,...,sm) | s1...sm = s}.

Complexity of generalization:
Let <g,t1,t2> be a generalization for terms <s,t>. The complexity of the generalization is C(<g,t1,t2>) = C(t1) + C(t2)


Read source [8] for "the syntactic, semantic, and algorithmic properties of HDTP."},
	Author = {Krumnack, Ulf and Schwering, Angela and Gust, Helmar and K{\"u}hnberger, Kai-uwe},
	Booktitle = {Proceedings of Twenties Australian Joint Conference on Artificial Intelligence, LNAI 4830},
	Date-Added = {2012-06-05 17:18:07 -0400},
	Date-Modified = {2012-10-09 23:51:15 -0400},
	Pages = {273-282},
	Publisher = {Springer},
	Title = {Restricted Higher-Order Anti-Unification for Analogy Making},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QLi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3Jlcy5wZGbSFwsYGVdOUy5kYXRhTxEBmAAAAAABmAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHB3Jlcy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEfDL8/BbAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADL9CibAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIARk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHJlcy5wZGYADgAQAAcAcgBlAHMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADNVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3Jlcy5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AvwDEAMwCaAJqAm8CegKDApEClQKcAqUCqgK3AroCzALPAtQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC1g==}}

@techreport{Jamnik1999,
	Annote = {Looks like another proposal, but from back in 1999. But it tries to use Melis' work. Excellent summary of the literature so far.

Kling, 1971 - Tries to map inference rules used
Munyer - similar
Carbonell - term "transformational analogy" refers to analogies between two problem representations; "derivational analogy" also looks for analogies between problem solving activities (also including failed and successful proof attempts).
Bledsoe
Owen - Built on Kling and Munyers' systems.
Guinchiglia and Villafiorita - ABSFOL. Uses something like overlap for source and target, and the rest is abstracted away. But "The abstraction is defined by the user and is not mechanised."
Kolbe and Walther - similar to previous
Melis and Whittle - ABALONE, built on top of CLAM.},
	Author = {Jamnik, Mateja},
	Date-Added = {2012-06-03 04:11:07 -0400},
	Date-Modified = {2012-06-05 17:17:54 -0400},
	Institution = {School of Computer Science, The University of Birmingham},
	Title = {Analogy and Automated Reasoning},
	Year = {1999},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4zOS44MzUxLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjM5LjgzNTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48ZMvqv0cAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMvq94cAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjM5LjgzNTEucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADMAOQAuADgAMwA1ADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4zOS44MzUxLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@techreport{Jones2010,
	Annote = {Proposal for an automated theorem prover that will use a high-level analogical mapping. A lot of the focus seems to be on how to create a formal high-level language (a "high-level strategy language") to describe a proof.

PO - proof obligation

"The discussion is still speculative, and in order to develop the language we will need to get out "hands dirty" by analysing a large number of proof obligations from a large number of (large scale) developments."},
	Author = {Jones, Cliff B. and Grov, Gudmund and Bundy, Alan},
	Date-Added = {2012-06-03 03:43:14 -0400},
	Date-Modified = {2013-01-30 20:45:52 -0500},
	Institution = {School of Computing Science, Newcastle University},
	Title = {Ideas for a High-Level Proof Strategy Language},
	Type = {Technical Report},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QLy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEyMTAucGRm0hcLGBlXTlMuZGF0YU8RAZwAAAAAAZwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwgxMjEwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjx5y+q/LgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy+r3bgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEdNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgAxMjEwLnBkZgAADgASAAgAMQAyADEAMAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIANFVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvMTIxMC5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDAAMUAzQJtAm8CdAJ/AogClgKaAqECqgKvArwCvwLRAtQC2QAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALb}}

@conference{Licato2011,
	Author = {Licato, John and Bringsjord, Selmer},
	Booktitle = {Advances in Cognitive Systems - 2011 AAAI Fall Symposium Series},
	Date-Added = {2012-05-30 13:51:29 -0400},
	Date-Modified = {2012-05-30 13:53:04 -0400},
	Title = {In Defense of the Neo-Piagetian Approach to Modeling and Engineering Human-Level Cognitive Systems},
	Year = {2011}}

@book{Owen1990,
	Annote = {According to Melis:
	- In here he's also cited as providing an analysis of Kling (1971) and Munyer (1981) and finding their approaches inadequate.
	- suggests heuristics for identifying the key steps in proofs. Then the proof parts leading from one key step to another can be proposed as subproofs.


CHAPTER 2

Normative vs. Cognitive accounts of analogical reasoning
Normative - Attempt to provide an analytical justification for analogical reasoning
Cognitive - Attempt to model how humans perform and use analogy


CHAPTER 3

Some heuristics:
Identical symbols heuristic - Identical associations make good analogues, and matches containing high proportions of identical associations make good analogies. Used by Munyer. Owen argues it is a weak heuristic, because "many examples involve genuine translations."
Partial homomorphism heuristic - Good analogies respect the structure of the terms used. Used by Munyer and Kling.
Semantic type heuristic - Analogies should try to preserve semantic type (defined by Kling), which is a sort of categorization of predicates. In otherwords, it draws from a previously defined hierarchy of predicates.
Argument type heuristic - (Kling) Similar to semantic type, except applies to arguments / objects. Owen argues the strength of this heuristic is variable.
Consistent translation heuristic - (Kling) The match is kept as consistent as possible so symbols align. He cites ACME as an example of a matcher that allows inconsistencies. 
Syntactic type heuristic - (Kling) Matches should have same type, such as propositional connectives with only other propositional connectives, etc. This may be implied by the partial homomorphism heuristic. Owen's discussion finds this difficult to assess.

},
	Author = {Owen, S.},
	Date-Added = {2012-05-28 21:43:46 -0400},
	Date-Modified = {2013-01-30 21:25:21 -0500},
	Publisher = {Academic Press},
	Title = {{Analogy for Automated Reasoning}},
	Year = {1990}}

@inproceedings{Bundy1988,
	Annote = {Melis cites this as being where proof plans were introduced. Also possibly where methods were introduced?

Proof plans should be:
- Useful
- General
- Expectant: contain some expectation of success
- Uncertain: also we can't guarantee success, we want to use plans in areas that are undecidable. In other words they need flexibility.
- Pathable: A failed plan should be fixable by providing alternate steps.
- Learnable: We should be able to acquire new plans through experience.

"we call the specification of a tactic, a *method*. A method is a frame containing information about the preconditions and effects of a tactic." (115) 
"A method represents an assertion in the meta-logic, namely that if a goal formula matches the input pattern and if the preconditions are true of it then the tactic is applicable. Furthermore, if the tactic application is successful then the resulting formula will match the output pattern and the effects will be true of it."

Typical sorts used in the "meta-logic":
exprs - set of all expressions
terms - set of all terms
nums - set of all natural numbers
posns - set of all lists of natural numbers

Typical terms used in metalogic:
exp-at(Exp,Posn) - sub-expression in expression Exp at position Posn. Positions are lists of numbers which define an occurrence of one expression within another. For exampe, [2,1] is the position of the 2nd argument of the 1st argument, eg the x in f(g(2,x),3).
single-occ(SubExp,Posn,SupExp) - means SupExp contains precisely one occurrence of SubExp and this is at Posn.},
	Author = {Bundy, A.},
	Booktitle = {Proceedings of the 9th International Conference on Automated Deduction},
	Date-Added = {2012-05-28 18:02:45 -0400},
	Date-Modified = {2013-01-30 20:27:44 -0500},
	Pages = {111-120},
	Publisher = {SpringerLink},
	Title = {The Use of Explicit Plans to Guide Inductive Proofs},
	Volume = {310},
	Year = {1988},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0J1bmR5QV9UaGUgVXNlIG9mIEV4cGxpY2l0LnBkZtIXCxgZV05TLmRhdGFPEQH0AAAAAAH0AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEceQnVuZHlBX1RoZSBVc2Ugb2YgRXhwbGljaXQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA49mcvpbj4AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMvppn4AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBdTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAQnVuZHlBX1RoZSBVc2Ugb2YgRXhwbGljaXQucGRmAAAOAD4AHgBCAHUAbgBkAHkAQQBfAFQAaABlACAAVQBzAGUAIABvAGYAIABFAHgAcABsAGkAYwBpAHQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAEpVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0J1bmR5QV9UaGUgVXNlIG9mIEV4cGxpY2l0LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOANYA2wDjAtsC3QLiAu0C9gMEAwgDDwMYAx0DKgMtAz8DQgNHAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA0k=}}

@inproceedings{Huang1992,
	Annote = {Defines the notion of method that Melis uses, and differentiates it from Bundy's account:

Bundy has a tactic slot where Melis has a declarative proof schema and a procedure implementing the schema. Bundy views methods as "essentially a triple consisting of a tactic, a precondition, and a postcondition. There the tactic is a piece of program code that can manipulate the actual proof in a controlled way." Melis' definition extends on Bundy's by "separating the procedural and declarative knowledge in the tactic part of methods. [They] propose a notion of method, that consists of a five-tuple: precondition, postcondition, rating (these three tell when to apply a method), and the declarative content as well as the procedural content". },
	Author = {Huang, Xiaorong and Kerber, Manfred and Kohlhase, Michael},
	Booktitle = {Proceedings of Jahrestagung fur Kunstliche Intelligenz, Saarbrucken},
	Date-Added = {2012-05-28 17:56:25 -0400},
	Date-Modified = {2012-05-28 17:57:52 -0400},
	Publisher = {Springer},
	Title = {Methods - The Basic Units for Planning and Verifying Proofs},
	Year = {1992},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS41My4zNzMzLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjUzLjM3MzMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48aMvpbYEAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMvppcEAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjUzLjM3MzMucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADUAMwAuADMANwAzADMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS41My4zNzMzLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@conference{Melis1995,
	Annote = {Melis' IJCAI paper.

"{\ldots}computational accounts of theorem proving by analogy have been dominated by the idea of mapping symbols of the source theorem to symbols of the target theorem and employing an extended symbol map for transferring single proof steps of the source to the target."
She found this inadequate because:
	- Methods, rather than single calculus steps, are transferred analogically
	- Simple symbol mapping is insufficient for many cases
	- Only parts of the source and target are transferred in many cases, not the whole thing

"We postulate that the transfer of plans by using and transforming their methods is the rght level of abstraction at which to draw analogies {\ldots} Proof-plans encode the structure of a proof {\ldots} [and] may record justifications for the proof planning decisions, e.g. the relevant control knowledge, and this information can be reused for constructing a target proof-plan."},
	Author = {Melis, Erica},
	Booktitle = {International Joint Conference on Artificial Intelligence (IJCAI-95)},
	Date-Added = {2012-05-28 13:38:31 -0400},
	Date-Modified = {2012-05-28 13:39:51 -0400},
	Title = {A Model of Analogy-Driven Proof-Plan Construction},
	Year = {1995},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL21lbGlzSUpDQUkucGRm0hcLGBlXTlMuZGF0YU8RAbQAAAAAAbQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rw5tZWxpc0lKQ0FJLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxDay+kw0AAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy+lpEAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAE1NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBtZWxpc0lKQ0FJLnBkZgAADgAeAA4AbQBlAGwAaQBzAEkASgBDAEEASQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAOlVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvbWVsaXNJSkNBSS5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDGAMsA0wKLAo0CkgKdAqYCtAK4Ar8CyALNAtoC3QLvAvIC9wAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAL5}}

@conference{Melis1996,
	Annote = {Main lessons are in the conclusion, but I didn't get much out of this.},
	Author = {Melis, Erica},
	Booktitle = {German Annual Conference on Artificial Intelligence},
	Date-Added = {2012-05-28 13:01:37 -0400},
	Date-Modified = {2012-05-28 13:36:11 -0400},
	Title = {When to Prove Theorems by Analogy?},
	Year = {1996},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3doZW5BbmFsb2d5LnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPd2hlbkFuYWxvZ3kucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SrsvpLlQAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMvpZpQAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAd2hlbkFuYWxvZ3kucGRmAA4AIAAPAHcAaABlAG4AQQBuAGEAbABvAGcAeQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvd2hlbkFuYWxvZ3kucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@inproceedings{Melis1993,
	Annote = {The paper that she refers to heavily in earlier works, but for some reason not in later works. Provides good summary (page 9) of previous attempts at theorem proving with analogy.

They use natural deduction as the proof calculus.

NOTATION:
phi_i = phi_j - if formulas phi_i and phi_j are equal up to a renaming of their free variables.
phi[a/b] - the formula resulting from replacing a with b in phi.
ass(M1) = assumptions of a method
thm(M1) theorem
postconditions match - if ass(M1) subset of ass(M2) union Knowledge base (all axioms, defnitions, and already-proven theorems), and conclusions(M1) = conclusions(M2).

Problem P - the assumptions, and one conclusion thm. Problem is written: (ass;thm)
Methods - plan operators; they operate on proof trees where the nodes are problem sets.
Complete plan of a problem P - A tree consisting of verified methods that have certain properties so that a complete proof plan is a tree.


"In summary, computational accounts of theorem proving by analogy have been more or less dominated by the idea to map symbols of the base problem (and its proof) to the symbols of the target and then to construct the desired proof from the given proof at the calculus level (e.g., resolution) by a translation of each single proof step." (10)


Overall algorithm on page 16
Procedures for proof planning: Given method M1 = base problem P1 and its proof, and M2 = target problem P2 and no proof, we want to reform M1 into methods M11, {\ldots}, M1k such that postcondition of M1k matches P2.
	Initialize - set up parameters
	Reformulation
	Match - like the mapping step. Tries to match methods such that ass(M1i) is a subset of (ass(M2i) union KB) and concl(M1i) = concl(M2i).
	Reversion
	Verification
	Proof planning - not described here, she cites [5] and says it's the "usual proof planning procedure."

They identify (in conclusion) three types of analogy-driven proofs:
- mapping of proofs directly on to each other (this is what she says are the most common approaches up to her work)
- analogies based on abstractions of proofs
- analogies based on abstracted and then reformulated proofs

She identifies a type of problem from the HUA book that she says simple "symbol mapping" analogy-driven proofs cannot solve, on page 46. One deals with homomorphisms into F-semimoduls, the other with homomorphisms into semigroups. But since the definitions of homomorphisms are slightly different, they differ on the proof-level even though at a higher level they are both the same (both homomorphisms). So a straight symbol matching method will generate incorrect or not generate necessary lines. },
	Author = {Melis, Erica},
	Booktitle = {SEKI-Report SR-93-07},
	Date-Added = {2012-05-27 17:30:38 -0400},
	Date-Modified = {2013-01-30 20:39:40 -0500},
	Title = {Change of Representation in Theorem Proving by Analogy},
	Year = {1993},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS41My42ODExLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjUzLjY4MTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48asvoFZAAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMvoTdAAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjUzLjY4MTEucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADUAMwAuADYAOAAxADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS41My42ODExLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@article{Melis2006,
	Annote = {Most recent paper on this topic, as far as I can tell, by Melis.

This paper is a good starting point, because:
"After more than a decade of development and experimentation this article presents our current `final' stable solu- tion, introducing conceptually clean notions and notation and finally backs it all up with several large case studies."

DEFINITIONS:

Proof planning 
"Proof planning [7] is a technique for theorem proving in which proofs are planned at a higher level of abstraction, where individual choices can be mathematically motivated by the semantics of the domain. Thus, proof planning swings the pendulum from the desert of the blind but ultra-efficient search-based paradigm of classical automated theorem proving to the green grass of knowledge based systems. In particular, proof planning tackles theorems not only using general logic based methods but also by using domain-specific and general mathematical knowledge, encoded explicitly into methods and control [39,41]."

MULTI - proof planning system that implements the three proof planning strategies described in this paper
OMEGA - (With greek letter omega in place of the 'O') Theorem proving environment from U. of Saarbrucken that uses proof planning and other techniques; uses MULTI, and natural deduction variant of soft-sorted version of lambda-calculus.

Methods - the elements of proof plans. They "partially describe changes of proof states by pre and postconditions (called premises and conclusions), which are formulae / sequents in a higher-order language, and conclusions are considered logically inferable from the premises."
Solution plan - The goal of proof planning is to find these. They are a sequence (or hierarchy) of instantiated methods that transform the initial state (assumptions) into one containing the conjecture. They represent "an inference of the conclusion from the premises."

Backward / Forward methods - Backwards methods reduce a goal to new goals (premises), forwards do the opposite.

Control rules - mathematical knowledge about how to proceed in a certain situation.

Strategy - employs a specific refinement or modification algorithm and a subset of methods and control rules.

Methods and control rules by themselves aren't structured and flexible enough (658).



Decomposition - splitting planner into independent algorithms. The types they use are (only first 3 are focused on in paper):
	PPlanner - refines a proof plan by applying methods
	InstVar - refines proof plan by instantiating variables
	BackTrack - modifies plan by backtracking to a previous choice point
	Exp - refines proof plan by expanding complex steps
	ATP - refines proof plan by calling an external theorem proving system to solve a subproblem
	CPlanner - refines proof plan by transferring steps from source proof plan to target proof plan.

},
	Author = {Melis, Erica and Meier, Andreas and Siekmann, Jorg},
	Date-Added = {2012-05-27 10:09:56 -0400},
	Date-Modified = {2013-01-30 20:37:37 -0500},
	Journal = {Artificial Intelligence},
	Pages = {656-684},
	Title = {Proof Planning with Multiple Strategies},
	Volume = {172},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QSC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEtczIuMC1TMDAwNDM3MDIwNzAwMTk2OC1tYWluLnBkZtIXCxgZV05TLmRhdGFPEQH+AAAAAAH+AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfMS1zMi4wLVMwMDA0MzcwMjA3MDAxI0UzQzRDLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48TMvnrv8AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMvn5z8AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMS1zMi4wLVMwMDA0MzcwMjA3MDAxI0UzQzRDLnBkZgAOAEQAIQAxAC0AcwAyAC4AMAAtAFMAMAAwADAANAAzADcAMAAyADAANwAwADAAMQA5ADYAOAAtAG0AYQBpAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAE1Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEtczIuMC1TMDAwNDM3MDIwNzAwMTk2OC1tYWluLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDZAN4A5gLoAuoC7wL6AwMDEQMVAxwDJQMqAzcDOgNMA08DVAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANW}}

@conference{Melis1994,
	Annote = {Uses analogy, encompassed in her "Proof planning" method, to prove the pumping lemma for CFL using analogy from a proof of REGULAR.

"We do not focus on initial  generation of proof plans here,
but start  already with a source proof plan."

Very short paper, refers to mellis 1993 a lot for details.},
	Author = {Melis, Erica and Veloso, Manuela},
	Booktitle = {AAAI Workshop on Case-Based Reasoning},
	Date-Added = {2012-05-25 23:49:53 -0400},
	Date-Modified = {2013-01-30 20:39:31 -0500},
	Pages = {13-17},
	Title = {Analogy Makes Proofs Feasible},
	Year = {1994},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1dTOTQtMDEtMDAzLnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPV1M5NC0wMS0wMDMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SsMvlyikAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMvmAmkAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAV1M5NC0wMS0wMDMucGRmAA4AIAAPAFcAUwA5ADQALQAwADEALQAwADAAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvV1M5NC0wMS0wMDMucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@article{DiFranzo2011,
	Author = {DiFranzo, Dominic and Graves, Alvaro and Erickson, John S. and Ding, Li and Michaelis, James and Lebo, Timothy and Patton, Evan and Williams, Gregory Todd and Li, Xian and Zheng, Jin Guang},
	Date-Added = {2012-05-25 01:47:32 -0400},
	Date-Modified = {2013-01-30 20:24:55 -0500},
	Journal = {Linking Government Data},
	Pages = {205-219},
	Title = {The Web is my Back-End: Creating Mashups with Linked Open Government Data},
	Volume = {3},
	Year = {2011}}

@inproceedings{Vrandecic2010,
	Address = {Raleigh, NC},
	Author = {Vrandecic, Denny and Lange, Christoph and Hausenblas, Michael and Bao, Jie and Ding, Li},
	Booktitle = {Proceedings of the WebSci10: Extending the Fronteirs of Society On-Line},
	Date-Added = {2012-05-25 01:44:23 -0400},
	Date-Modified = {2012-05-25 01:45:32 -0400},
	Title = {Semantics of Governmental Statistics Data},
	Year = {2010}}

@inproceedings{Pantel2005,
	Author = {Pantel, Patrick and Philpot, Andrew and Hovy, Eduard H.},
	Booktitle = {Proceedings of the 17th International Conference on Scientific and Statistical Database Management},
	Date-Added = {2012-05-25 01:41:09 -0400},
	Date-Modified = {2013-01-30 20:34:07 -0500},
	Pages = {14-23},
	Title = {An Information Theoretic Model for Database Alignment},
	Year = {2005}}

@conference{Duchenne2009,
	Author = {Duchenne, O. and Bach, F. and Kweon, I. and Ponce, J.},
	Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
	Date-Added = {2012-05-25 01:28:27 -0400},
	Date-Modified = {2013-01-30 20:24:12 -0500},
	Pages = {1980-1987},
	Title = {A Tensor-Based Algorithm for High-Order Graph Matching},
	Year = {2009}}

@conference{Leordeanu2009,
	Author = {Leordeanu, M.},
	Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
	Date-Added = {2012-05-25 01:26:41 -0400},
	Date-Modified = {2013-01-30 20:43:43 -0500},
	Pages = {864-871},
	Title = {Unsupervised Learning for Graph Matching},
	Year = {2009}}

@inproceedings{Guhe2009,
	Annote = {Citation for use of analogy in math. From Kayla:

The authors, researchers at the School of Informatics at the University of Edinburgh explore the origin and evolution
of the Descartes-Euler conjecture. A background is given on the origin of geometry through analogies. The general
method given is to find and represent fruitful source domain, form associations, make predictions and inferences,
then verify new ideas. Descartes' three dimensional analogue of Pythagoras' Theorem is discussed, along with the
analogy and mapping between polyhedral and polygonal domains. It is concluded that analogy, formulation and
modification played a large role in the discovery and development these concepts, conjecture and proof.},
	Author = {Guhe, Pease M. and Smaill, A.},
	Booktitle = {Proceedings of the Second International Conference on Analogy},
	Date-Added = {2012-05-24 00:41:17 -0400},
	Date-Modified = {2013-01-30 20:49:30 -0500},
	Title = {Analogy Formation and Modification in Geometry},
	Year = {2009}}

@conference{Kerber1989,
	Annote = {Kayla gave this as example of use of analogy in mathematics, along with Guhe 2009:

The authors, Manfred Kerber, discusses the method of finding a corresponding category of a problem, then finding
an analogous theorem in this category along with an analogous proof to ultimately try to transform the proof
to a new theorem. Through examples focused on equivalence relation problems, it is shown how analogy can
be used to find preconditions (relevant axioms) and thus solve the proof in parts. For these examples, a general
heuristic: ``prove equal things with equal pre-conditions'' is used. This technique can also be used in other proofs of
corresponding structures such as rings, fields, vector spaces, etc.},
	Author = {Kerber, Manfred},
	Booktitle = {Analogical and Inductive Inference; International Workshop},
	Date-Added = {2012-05-24 00:36:01 -0400},
	Date-Modified = {2012-05-24 00:40:53 -0400},
	Editor = {Jantke, K.P.},
	Publisher = {Springer-Verlag},
	Title = {Some Aspects of Analogy in Mathematical Reasoning},
	Year = {1989}}

@article{Gold1996,
	Annote = {Perhaps most heavily cited paper on graph matching algorithms. },
	Author = {Gold, S. and Rangarajan, A.},
	Date-Added = {2012-05-22 16:06:46 -0400},
	Date-Modified = {2013-01-30 20:56:16 -0500},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Number = {4},
	Pages = {377-388},
	Title = {A Graduated ASsignment Algorithm for Graph Matching},
	Volume = {18},
	Year = {1996}}

@article{Umeyama1988,
	Author = {Umeyama, S.},
	Date-Added = {2012-05-22 16:05:44 -0400},
	Date-Modified = {2012-05-22 16:06:38 -0400},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Number = {5},
	Pages = {695-703},
	Title = {An Eigendecomposition Approach to Weighted Graph Matching Problems},
	Volume = {10},
	Year = {1988}}

@webpage{ZaslavskiyCode,
	Annote = {Website for Graph-M code, where Zaslavskiy's path finding algorithm for graph matching is implemented.},
	Author = {Zaslavskiy, M. and Bach, F. and Vert, J-P.},
	Date-Added = {2012-05-22 16:03:23 -0400},
	Date-Modified = {2012-05-22 16:04:44 -0400},
	Lastchecked = {5/22/2012},
	Url = {http://cbio.ensmp.fr/graphm/},
	Bdsk-Url-1 = {http://cbio.ensmp.fr/graphm/}}

@article{Zaslavskiy2009,
	Annote = {Performs perhaps the best in comparison to the other fast methods.},
	Author = {Zaslavskiy, M. and Bach, F. and Vert, J-P.},
	Date-Added = {2012-05-22 16:01:15 -0400},
	Date-Modified = {2013-01-30 20:58:04 -0500},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Number = {12},
	Pages = {2227-2242},
	Title = {A Path Following Algorithm for the Graph Matching Problem},
	Volume = {31},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BhdGhfZm9sbG93aW5nX3BhbWkucGRm0hcLGBlXTlMuZGF0YU8RAdgAAAAAAdgAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxdwYXRoX2ZvbGxvd2luZ19wYW1pLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxD7zLOmSgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAzLPeigAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFZNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBwYXRoX2ZvbGxvd2luZ19wYW1pLnBkZgAOADAAFwBwAGEAdABoAF8AZgBvAGwAbABvAHcAaQBuAGcAXwBwAGEAbQBpAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBDVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9wYXRoX2ZvbGxvd2luZ19wYW1pLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDPANQA3AK4AroCvwLKAtMC4QLlAuwC9QL6AwcDCgMcAx8DJAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMm}}

@article{Munkres1957,
	Annote = {Along with Kuhn 1955, this is citation for Hungarian / Munkres algorithm},
	Author = {Munkres, J.},
	Date-Added = {2012-05-22 13:52:34 -0400},
	Date-Modified = {2012-05-22 13:53:26 -0400},
	Journal = {Journal of the Society of Industrial and Applied Mathematics},
	Month = {March},
	Number = {1},
	Pages = {32-38},
	Title = {Algorithms for the Assignment and Transportation Problems},
	Volume = {5},
	Year = {1957}}

@article{Kuhn1955,
	Annote = {along with Munkres 1957, one of the main citations for the Munkres / Hungarian algorithm},
	Author = {Kuhn, Harold W.},
	Date-Added = {2012-05-22 13:51:35 -0400},
	Date-Modified = {2013-01-30 21:24:42 -0500},
	Journal = {{Naval Research Logistics Quarterly}},
	Pages = {83-97},
	Title = {{The Hungarian Method for the Assignment Problem}},
	Volume = {2},
	Year = {1955}}

@article{Gao2010,
	Annote = {summary of graph-edit distance (GED) methods up to this point. Unfortunately it doesn't go into algorithms and complexities in detail very well.

Non-attributed graphs only include connectivity structure information (unlabeled graphs); they are usually converted into strings and edit distance is used to compare them through DP [5], [22], [23]

Edges can also have attributes, labeling function l:

l: V -> L_N
or alpha: V -> L_N, beta: E -> L_E for labeled edges

G = (V,E,alpha,beta)

isomorphism: bijection f: V1 -> V2 s.t.
alpha_1(x) = alpha_2(f(x)) for all x in V1
beta_1((x,y)) = beta_2((f(x), f(y))) for all (x,y) in E1


GRAPH EDIT DISTANCE

Operations: node insertion, edge insertion, node/edge deletion, node/edge substitution

- SOM (self-organizing map), unsupervised ANN method. Seems to work well with detecting letter distortion.
- Probability-based methods. },
	Author = {Gao, Xinbo and Xiao, Bing and Tao, Dacheng},
	Date-Added = {2012-05-03 17:53:09 -0400},
	Date-Modified = {2013-01-30 21:23:28 -0500},
	Journal = {{Pattern Analysis and Applications}},
	Number = {1},
	Pages = {113-129},
	Title = {{A Survey of Graph Edit Distance}},
	Volume = {13},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICg5KS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGZ1bGx0ZXh0ICg5KS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPD4PLyHaAAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLyK7AAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZ1bGx0ZXh0ICg5KS5wZGYAAA4AIgAQAGYAdQBsAGwAdABlAHgAdAAgACgAOQApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoOSkucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@article{Riesen2009,
	Annote = {To solve the graph isomorphism problem they have an algorithm that uses the Munkres / Hungarian matching algorithm. The insight is that in order to encode edge distance they have some method that encodes local edge information into the node comparisons, so that the value given to the hungarian algorithm for node pair (u,v) includes information about the local structural similarity of the two nodes.

They take the edges adjacent to node u (Eu) and the edges adjacent to node v (Ev) and apply another cost matrix to figure out the minimum sum of edge edit costs. These edge edit costs are added to the entry Cu,v in the original table.},
	Author = {Riesen, Kaspar and Bunke, Horst},
	Date-Added = {2012-05-03 17:04:39 -0400},
	Date-Modified = {2013-01-30 21:25:36 -0500},
	Journal = {{Image and Vision Computing}},
	Number = {7},
	Pages = {950-959},
	Title = {{Approximate Graph Edit Distance Computation by Means of Bipartite Graph Matching}},
	Volume = {27},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FwcHJveC5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCmFwcHJveC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPMrLyG2sAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLyKXsAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGFwcHJveC5wZGYAAA4AFgAKAGEAcABwAHIAbwB4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hcHByb3gucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==}}

@incollection{Wilson2001,
	Address = {Cambridge, MA},
	Annote = {Describes STAR-2 Model, which differs from others in that it uses tensor products and their mathematically convenient properties to facilitate analogical reasoning. This chapter also contains a LOT of good examples of test cases for analogical systems.},
	Author = {Wilson, William H. and Halford, Graeme S. and Gray, Brett and Phillips, Steven},
	Booktitle = {The Analogical Mind: Perspectives from Cognitive Science},
	Chapter = {4},
	Date-Added = {2012-04-25 15:22:45 -0400},
	Date-Modified = {2012-05-20 19:22:54 -0400},
	Editor = {Gentner, Dedre and Holyoak, Keith J. and Boicho, K. Kokinov},
	Publisher = {The MIT Press},
	Title = {{The STAR-2 Model for Mapping Hierarchically Structured Analogs}},
	Year = {2001}}

@article{Holyoak1989,
	Annote = {Use as main citation for ACME and multiconstraint
                  theory.  Algorithm: Uses as input sentences in
                  predicate calculus, like SME: "no particular
                  devotion to predicate calculus as a representation
                  language (Thagard 1984) is maintained here; it is
                  used because of its simplicity and
                  familiarity. Other more complex representation
                  languages should be amenable to similar treatment."
                  Optional information about semantic similarity and
                  pragmatic importance also allowed.},
	Author = {Holyoak, Keith J. and Thagard, Paul},
	Date-Added = {2012-04-24 10:43:25 -0400},
	Date-Modified = {2013-01-30 21:23:48 -0500},
	Journal = {Cognitive Science},
	Number = {3},
	Title = {{Analogical Mapping by Constraint Satisfaction}},
	Volume = {13},
	Year = {1989},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0FuTWFwaW5nLnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMQW5NYXBpbmcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48xMu0h0sAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMu0v4sAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAQW5NYXBpbmcucGRmAAAOABoADABBAG4ATQBhAHAAaQBuAGcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0FuTWFwaW5nLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=}}

@article{Gentner1986,
	Annote = {Gentner's theory allows for at least three predictions:
1) transparent object correspondencies [surface similarity?] promote accurate mapping
2) systematic knowledge of the base domain [higher-level structural matches] promotes accurate analogical mapping
3) the effect of systematicity will be stronger the more difficult (the less transparent) the analogical mapping.

They used stories which varied along two dimensions:
- systematicity. In systematic stories the protagonist had a stated habit or trait, and the story had a moral made explicit at the end. Nonsystematic did not.
- mapping conditions / transparency. They had high transparency (meaning high surface similarity: similar characters and similar roles), medium, and low transparency.


results:
- systematicity only seemed to benefit the older group
- difficult mapping did rely more on systematicity.},
	Author = {Gentner, Dedre and Toupin, Cecile},
	Date-Added = {2012-04-24 10:42:34 -0400},
	Date-Modified = {2012-04-25 12:28:10 -0400},
	Journal = {Cognitive Science},
	Pages = {277-300},
	Title = {{Systematicity and Surface Similarity in the Development of Analogy}},
	Volume = {10},
	Year = {1986},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0dlbnRuZXJUb3VwaW44Ni5wZGbSFwsYGVdOUy5kYXRhTxEByAAAAAAByAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHE0dlbnRuZXJUb3VwaW44Ni5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPD9zLvDQPAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLvGxPAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAUk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AEdlbnRuZXJUb3VwaW44Ni5wZGYADgAoABMARwBlAG4AdABuAGUAcgBUAG8AdQBwAGkAbgA4ADYALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD9Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0dlbnRuZXJUb3VwaW44Ni5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AywDQANgCpAKmAqsCtgK/As0C0QLYAuEC5gLzAvYDCAMLAxAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADEg==}}

@article{Halford2010,
	Annote = {He makes the overall claim that relational knowledge (defined precisely in this paper) is necessary for higher-level cognition, and talks about why. Briefly discusses and compares and contrasts DORA and STAR.

tensor product: The tensor product of two vectors u=(u1,u2,{\ldots},um) and v=(v1,v2,{\ldots},vn) is a 2-subscript object similar to a matrix, B=(b_ij) where b_ij = u_i v_j. Tensor products have several convenient mathematical properties.

Intension of a relation - The relation symbol / predicate.
Extension - The ordered tuples / arguments of a relation.},
	Author = {Halford, Graeme S and Wilson, William H. and Phillips, Steven},
	Date-Added = {2012-04-22 10:01:32 -0400},
	Date-Modified = {2013-01-30 20:47:33 -0500},
	Journal = {TRENDS in Cognitive Sciences},
	Number = {11},
	Pages = {497-505},
	Title = {Relational Knowledge: The Foundation of Higher Cognition},
	Volume = {14},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3JlbGF0aW9uYWxub3dsZWRnZUhhbGZvcmQucGRm0hcLGBlXTlMuZGF0YU8RAfAAAAAAAfAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx1yZWxhdGlvbmFsbm93bGVkZ2VIYWxmb3JkLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxHqy7mHdAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy7m/tAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFxNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgByZWxhdGlvbmFsbm93bGVkZ2VIYWxmb3JkLnBkZgAOADwAHQByAGUAbABhAHQAaQBvAG4AYQBsAG4AbwB3AGwAZQBkAGcAZQBIAGEAbABmAG8AcgBkAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBJVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9yZWxhdGlvbmFsbm93bGVkZ2VIYWxmb3JkLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDVANoA4gLWAtgC3QLoAvEC/wMDAwoDEwMYAyUDKAM6Az0DQgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANE}}

@article{Falkenhainer1989,
	Annote = {Main citation given for SME


to evaluate "quality" of the match, three criteria used:
structural - # of similarities and differences, degree of structural similarity involved, and amount and type of new knowledge the analogy provides through candidate inferences
validity - does match and inferences make sense, and it might require additional inferential work to refine results
relevance - is analogy useful to the reasoner's current purposes?
"Structure-mapping focuses on structural criteria only, since they define and distinguish analogy from other types of inference"


Global Mappings (gmaps) consist of:
Correspondences - pairwise matches between expressions and entities of the two dgroups
Candidate inferences - set of new expressions which the comparison suggests holds in the target group
SES / Structural evaluation score - numerical estimate of match quality. Is "simply the sum of the evidence for its match hypotheses." (22)
	

SES calculation:
"computed in two phases, each using match evidence rules to assign and manage numerical scores. the first phase assigns weights to individual match hypotheses, and the second phase computes a score for each gmap by combining the evidence for the match hypotheses comprising its correspondences."

There are match evidence rules that checks for certain things and assigns evidence, such as :
	"If the base item and target item of a match hypothesis are expressions with the same functors, then supply 0.5 evidence in favor of the match hypothesis." (appendix A has other evidence rules)
	- allows for implementation of systematicity constraint (prefer expressions with higher-order relationship matches). This is implemented with a "trickle-down"-type evidence rule

SES score is then just the sum of the match hypotheses.



When matching, each graph walk takes at most O(Ni) where Ni is number of nodes reachable from current match hypothesis root. Worst case of steps that merge the match hypotheses into gmaps, however, is O(N!).
"{\ldots}[when there are the same number of base expressions as target expressions, this] reduces to the problem of finding all isomorphic mappings between two equal size sets, which is O(N!)."


Appendix B shows the water flow heat flow example and others. 

SRC:
(entity_inanimate water)
(entity_inanimate beaker)
(entity_inanimate vial)
(entity_inanimate pipe)
(greater (diameter beaker) (diameter vial))
(cause 
	(greater (pressure beaker) (pressure vial))
	(flow beaker vial water pipe)
)
(flat-top water)
(liquid water)

TGT:
(entity_inanimate coffee)
(entity_inanimate ice-cube)
(entity_inanimate bar)
(entity_inanimate heat)
(greater (temperature coffee) (temperature ice-cube))
(flow coffee ice-cube heat bar)
(flat-top coffee)
(liquid coffee)},
	Author = {Falkenhainer, Brian and Forbus, Kenneth D. and Gentner, Dedre},
	Date-Added = {2012-04-11 12:54:03 -0400},
	Date-Modified = {2013-06-26 21:45:58 +0200},
	Journal = {{Artificial Intelligence}},
	Pages = {1-63},
	Title = {{The Structure-Mapping Engine: Algorithm and Examples}},
	Volume = {41},
	Year = {1989},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NtZWZmMihzZWFyY2hhYmxlKS5wZGbSFwsYGVdOUy5kYXRhTxEB1AAAAAAB1AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHFnNtZWZmMihzZWFyY2hhYmxlKS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEmLLQ6NhAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLQ+mxAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAVU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHNtZWZmMihzZWFyY2hhYmxlKS5wZGYAAA4ALgAWAHMAbQBlAGYAZgAyACgAcwBlAGEAcgBjAGgAYQBiAGwAZQApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9zbWVmZjIoc2VhcmNoYWJsZSkucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AzgDTANsCswK1AroCxQLOAtwC4ALnAvAC9QMCAwUDFwMaAx8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADIQ==}}

@article{Thibaut2010,
	Annote = {Tries to bridge the gap between theories that describe how analogical ability improves with age. Explains distinction between weak and strong associations.


Strongly associated vs weakly associated: all children sleep in beds, but child does not immediately bring bed to mind. Thus it is a weak association.

Some strong associations: spider : web :: bee : hive ; bird : nest :: dog : doghouse
Some weak associations: wolf : meat :: goat : grass ; bird : plane :: fish : boat

If children have more limited cognitive resources than adults, they should have a harder time drawing analogies based on weak associations.

They did not offer a numerical measure of association, only two categories: weak and strong associations.},
	Author = {Thibaut, J. P. and French, Robert M. and Vezneva, M.},
	Date-Added = {2012-04-10 21:53:42 -0400},
	Date-Modified = {2013-01-30 21:00:34 -0500},
	Journal = {Psychonomics Bulletin Review},
	Number = {4},
	Pages = {569-574},
	Title = {Cognitive Load and Semantic Analogies: Searching Semantic Space},
	Volume = {17},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICg4KS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGZ1bGx0ZXh0ICg4KS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPD3vLql1vAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLqpWvAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZ1bGx0ZXh0ICg4KS5wZGYAAA4AIgAQAGYAdQBsAGwAdABlAHgAdAAgACgAOAApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoOCkucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@article{Salvucci2001,
	Annote = {Describes his Path-mapping theory of analogy, which is built from ACT-R. He says since Gentner's work studies analogy by itself, this work is an attempt to integrate what we know about analogy into a larger theory of the mind.

Path mapping theory:

Analogs are made of objects, relations, and roles.
objects - semantic constants
relations - link objects or relations together according to their function
roles - link objects and relations to form higher-order conceptual structures. Each one made of:
	parent: pointer to parent relation
	parent-type: semantic type of parent relation
	slot: relation slot the object fills in the relation
	child: a pointer to the child object or relation
	child-type


Path mapping - maps a single source object to a single target object by finding analogous paths between the objects and their highest-order parent relations, or root relations.},
	Author = {Salvucci, D. D. and Anderson, John R.},
	Date-Added = {2012-04-10 02:57:39 -0400},
	Date-Modified = {2013-01-30 21:04:13 -0500},
	Journal = {Cognitive Science},
	Pages = {67-110},
	Title = {Integrating Analogical Mapping and General Problem Solving: The Path-Mapping Theory},
	Volume = {25},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1NhbHZ1Y2NpLUNTMDEucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFTYWx2dWNjaS1DUzAxLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxIby6pIewAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy6qAuwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBTYWx2dWNjaS1DUzAxLnBkZgAOACQAEQBTAGEAbAB2AHUAYwBjAGkALQBDAFMAMAAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9TYWx2dWNjaS1DUzAxLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@article{French2002,
	Annote = {Summary of the computational approaches to analogy. All the way back in 2002, though. },
	Author = {French, Robert M.},
	Date-Added = {2012-04-10 02:27:40 -0400},
	Date-Modified = {2012-04-10 02:28:25 -0400},
	Journal = {TRENDS in Cognitive Sciences},
	Month = {May},
	Number = {5},
	Title = {The Computational Modeling of Analogy-Making},
	Volume = {6},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NjaWVuY2UgKDcpLnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPc2NpZW5jZSAoNykucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SRMupSxAAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMupg1AAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAc2NpZW5jZSAoNykucGRmAA4AIAAPAHMAYwBpAGUAbgBjAGUAIAAoADcAKQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvc2NpZW5jZSAoNykucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@article{Volle2010,
	Annote = {tend to point to one central region for analogical and complex relational reasoning: rostral prefrontal cortex (rostral PFC), approximately Brodmann area 10 (BA10)

"Our study ..., interpreted together with other findings from the literature, [suggests] that the role of the rostral PFC in interaction with other regions is to generate more structured and abstract mental representations."

First experiment designed to isolate which part of the brain generated and processed structured representations. Second tried to isolate part responsible for mapping process.

a lateral BA10 region was "found to be ctivated during any phase of analogical reasoning, compared with a control task that involved attribute matching only. Unlike other rostral prefrontal regions, this region was activated from the time of the presentation of the source alone ... before the source could be compared with a target. This may suggest that this region is involved in generating or processing abstract and structured representations, processes that are needed in both phases of analogy tasks. However ... [it is also involved in other things like] relational mapping ... "
"taken as a whole, this study suggests a novel functional organization of rostral PFC, with different subregions supporting distinct cognitive processes...".

},
	Author = {Volle, Emmanuelle and Gilbert, Sam J. and Benoit, Roland G. and Burgess, Paul W.},
	Date-Added = {2012-04-09 14:21:43 -0400},
	Date-Modified = {2012-04-09 14:23:04 -0400},
	Journal = {Cerebral Cortex},
	Number = {11},
	Pages = {2647-2659},
	Title = {Specialization of the Rostral Prefrontal Cortex for Distinct Analogy Processes},
	Volume = {20},
	Year = {2010}}

@unpublished{Fletcher2009,
	Annote = {Got from internet, good summary and review of SVMs.},
	Author = {Fletcher, Tristan},
	Date-Added = {2012-04-08 20:01:17 -0400},
	Date-Modified = {2012-04-08 20:01:57 -0400},
	Title = {Support Vector Machines Explained},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1NWTSBFeHBsYWluZWQucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFTVk0gRXhwbGFpbmVkLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxKWy6ee8wAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy6fXMwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBTVk0gRXhwbGFpbmVkLnBkZgAOACQAEQBTAFYATQAgAEUAeABwAGwAYQBpAG4AZQBkAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9TVk0gRXhwbGFpbmVkLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@unpublished{Taddeo2012a,
	Annote = {Provide an analysis of the requirement that must be satisfied by any hypothesis seeking to solve the SGP, the "zero semantical commitment condition". 

Categorizes three approaches used to solve SGP (symbol grounding problem): representationalism, semi-representationalism, and non-representationalism.

"the conclusion reached in [this] review --- that symbol grounding is a crucial but still unresolved problem"

Since the SGP is concerned with HOW an AA autonomously elaborates on its semantics for the symbols it processes, the interpretation of the symbols must be intrinsic to the symbol system itself, and cannot be extrinsic or parasitic on the fact that symbols have meaning for, or are provided by, an interpreter. It follows:
a) No form of innatism is allowed; no semantic resources should be presupposed as pre-installed in AA, and
b) no form of externalism is allowed, no semantic resources should be uploaded from the "outside" by some deus ex machina already semantically proficient. However,
c) it is possible that the AA has its own capacities and resources to be able to ground its symbols, only such resources must not be semantical in the first place.

(a) - (c) define the Z condition (zero semantical commitment condition).


REPRESENTATIONALIST APPROACH

They solve SGP by grounding AA's symbols to the internal representations of those symbols (which are manipulations of its perceptual data). They take the perceptual data (or at least a part of it), abstract it using its categorical and conceptual representations, and use those representations to ground its symbols.
Problem is the available representations, whether categorical or perceptual, only ground the symbols by presupposing the semantic capacities or resources which the approach is supposed to show are evolvable by an AA in the first place. Since such processes which ground the raw data to the symbols makes use of a semantic background, it doesn't explain how that semantic background comes about. (vague: what is this semantic background?)

Talks about why unsupervised neural network learning methods don't work to define the base-level semantics: They still need to have built-in biases and feature-detectors in order to reach the desired output. Such semantic resources are necessarily hard-coded by a supervisor, according to pre-established criteria. Moreover, {\ldots} once they have been trained, [they] still need to have their output checked [?] to see whether the obtained structure makes any sense with respect to the input data space. This difficult process of validation is carried out externally by a supervisor. So in this case too, whatever grounding they can provide is still entirely extrinsic. {\ldots} "Quadruped animal", as a category, is not the outcome of [such a system's] intrinsic grounding because [it] must already have had quite a lot of semantic help to reach that conclusion.
[is he then arguing that if future systems have biases encoded in them, and on the basis of those alone, using an unsupervised learning algorithm, can autonomously learn all concepts a human can reasonably be expected to, then the symbol grounding problem is solved? It certainly seems so. In this sense, the main criticism of such systems is that they have not demonstrated sufficient autonomy. The criticism is thus best answered, it seems, only by the brave researcher[s] that can put their money where their mouth[s] are and actually create a sufficiently large-scale learning system.]

Cangelosi et al. (2000) identify two methods to acquire new categories:
sensorimotor toil
symbolic theft - to stress the benefit of not being forced to learn from a direct sensorimotor experience when a new category is in question.

Initially, organisms evolve an ability to build some categories through direct sensorimotor toil. Then some organisms must have experimented with the propositional combination of the names of these categories and discover the advantage of this new way of learning categories, thus "stealing their knowledge by hearsay". However, the crucial issue of how organisms might have initially learnt to semanticise the data resulting from their sensorimotor activities remains unsolved, and so does the SGP.

If there is an internal or internally developed semantic resource allowing the AA to organize its categories functionally and ground its symbols autonomously, (as in Sun), it might work, but he criticizes it as follows:

- Since Sun's first-level learning guides behavior of the AA by considering both the structure of the external world and the innate biases or built-in constraints and predispositions which also depend on the (ontogenetic and phylogenetic) history of agent-world interaction, it already violates the Z-condition (15), though he doesn't say which part is violated. (the case can be made for all three, but the externalism condition's applicability here is dubious: the "comportment" level's influence from the outside world is unintentional, and preconceptual. It extracts semantic information from outside sources no more than a sensory system recieving raw data does. And it would be ludicrous to not allow sensory systems at least that indulgence!)
- Since CLARION uses four neural networks, the difficulties with using NNs to solve SGP apply (section 4.1). 
- CLARION's dependence on Q-learning (reinforcement) requires external verification, "importing from the outside the very condition that allows CLARION to semanticize, since tasks, goals, success, failure, rewards and punishments are all established by the programmer. The semantical commitment could not be more explicit"
- Sun interprets the functional nature of higher-level concepts as innate and intrinsic features of the AA, namely its intentionality. But it's unclear how the AA is supposed to acquire this necessary intentionality. (is he unaware of the Motivation-centered subsystem?) Even if the intentionality of the representations can come from an internal process drawing on first-level learning processes (comportment), it remains unexplained how this first-level intentionality might arise in the first place. How does even a very primitive, simple and initial form of intentionality develop autonomously from the direct interactions between the AA and its environment? Presupposing its presence is not an answer [why not?]. Evolution is not an answer, because evolutional algorithms depend on the programmer to define the fitness function externally. [What! First of all, In real life the fitness function is an emergent feature of agents and the environment---factors determine survival, and the agents which better meet those factors survive with higher probability. That the agents who survive can be described as better meeting the criteria of the fitness function is a necessary consequence of this process, one that is done without intentional action on the part of the agents. Secondly, it gets off topic: why is it such a stretch to assume that some complex evolutionary process gave agents an innate first-level intentionality? Is the author trying to piss me off?]
- },
	Author = {Taddeo, Mariarosaria and Floridi, Luciano},
	Date-Added = {2012-04-06 19:06:11 -0400},
	Date-Modified = {2012-04-06 19:08:15 -0400},
	Note = {Forthcoming in Journal of Experimental and Theoretical Artificial Intelligence},
	Title = {Solving the Symbol Grounding Problem: a Critical Review of Fifteen Years of Research},
	Year = {2012}}

@article{Harnad1990,
	Annote = {Supposed to be the classical formulation of the symbol grounding problem: "How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols?"

His solution: "Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds:
1) Iconic representations, which are analogs of proximal sensory projections of distal objects and events, and
2) Categorical representations, which are learned and innate feature-detectors that pic out the invariant features of object and event categories from their sensory projections.

Provides definition of a symbol system:
1) set of arbitrary physical tokens: scratches on paper, holes on tape, etc, that are:
2) manipulated on the basis of explicit rules that are
3) likewise physical tokens and strings of tokens. The rule-governed symbol-token manipulation is based
4) purely on the shape of the symbol tokens (not their "meaning"), i.e., it is purely syntactic, and consists of
5) rulefully combining and recombining symbol tokens. There are
6) primitive atomic symbol tokens and
7) composite symbol-token strings. The entire system and all its parts - the atomic tokens, composite tokens, syntactic manipulations both actual and possible and the rules - are all
8) semantically interpretable: the syntax can be systematically assigned a meaning e.g., as standing for objects, as describing states of affairs.

Wittgenstein (1953) emphasized the difference between explicit and implicit rules: It is not the same to "follow" a rule (explicitly) and merely to behave "in accordance with" a rule (implicitly). The critical difference is compositeness and systematicity. The explicitly represented symbolic rule is part of a formal system, it is decomposable unless primitive, its application and manipulation is purely formal (syntactic, shape-dependent), and the entire system must be semantically interpretable, not just the chunk in question. {\ldots} So the mere fact that a behavior is "interpretable" as ruleful does not mean it is really governed by a symbolic rule. Semantic interpretability must be coupled with:
explicit representation
syntactic manipulability
and systematicity in order to be symbolic.
If you weaken them, you lose the grip on what looks like a natural category and sever the links with the formal theory of computation.

Gives example: Imagine to learn chinese, all you had was a chinese-chinese dictionary. How would you ever learn what the words meant? 

Discrimination - can tell how different two horses are, and how alike they are.
Identification - we can reliably call it a horse, as opposed to donkey or mule.

"The expectation has often been voiced that "top-down" (symbolic) approaches to modeling cognition will somehow meet "bottom-up" (sensory) approaches somewhere in between. If the grounding considerations in this paper are valid, then this expectation is hopelessly modular and there is really only one viable route from sense to symbols: from the ground up."},
	Author = {Harnad, S.},
	Date-Added = {2012-04-06 17:58:47 -0400},
	Date-Modified = {2012-04-06 18:02:01 -0400},
	Journal = {Physica D},
	Pages = {335-346},
	Title = {The Symbol Grounding Problem},
	Volume = {42},
	Year = {1990},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2hhcm5hZDkwX3NncHJvYmxlbS5wZGbSFwsYGVdOUy5kYXRhTxEB1AAAAAAB1AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHFmhhcm5hZDkwX3NncHJvYmxlbS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEBzLpN/fAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLpRgfAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAVU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGhhcm5hZDkwX3NncHJvYmxlbS5wZGYAAA4ALgAWAGgAYQByAG4AYQBkADkAMABfAHMAZwBwAHIAbwBiAGwAZQBtAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9oYXJuYWQ5MF9zZ3Byb2JsZW0ucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AzgDTANsCswK1AroCxQLOAtwC4ALnAvAC9QMCAwUDFwMaAx8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADIQ==}}

@article{Burges1998,
	Annote = {Awesome tutorial on SVMs.},
	Author = {Burges, Christopher J.C.},
	Date-Added = {2012-04-01 21:07:58 -0400},
	Date-Modified = {2012-04-01 21:09:06 -0400},
	Journal = {Data Mining and Knowledge Discovery},
	Pages = {121-176},
	Title = {A Tutorial on Support Vector Machines for Pattern Recognition},
	Volume = {2},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1cHBvcnQtdmVjdG9yLW1hY2hpbmVzNC5wZGbSFwsYGVdOUy5kYXRhTxEB7AAAAAAB7AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHHHN1cHBvcnQtdmVjdG9yLW1hY2hpbmVzNC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEpTLnnQVAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLnqxVAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAW01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHN1cHBvcnQtdmVjdG9yLW1hY2hpbmVzNC5wZGYAAA4AOgAcAHMAdQBwAHAAbwByAHQALQB2AGUAYwB0AG8AcgAtAG0AYQBjAGgAaQBuAGUAcwA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBIVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9zdXBwb3J0LXZlY3Rvci1tYWNoaW5lczQucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A1ADZAOEC0QLTAtgC4wLsAvoC/gMFAw4DEwMgAyMDNQM4Az0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADPw==}}

@webpage{Chomsky2,
	Annote = {Chomsky talks about the problem with statistical methods in the understanding of language, and the poverty of the simulus.

He criticizes those who act as if bayesian explanations are sufficient for everything.

Around 42:00 - word segmentation, it's been known for years that looking at transitional probabilities doesn't work. Charles Yang "showed that years ago," and a "way around it": combine it with prosodic information. Chomsky uses this to criticize the connectionists / statistical people. Argument is based on supposed claim that there is nothing more than statistical methods, that other factors are not needed to explain language.

He argues you should allow yourself to be puzzled, rather than have the "everything is answered already" attitude the statistical guys do. Example: Aristotle's ideas that steam floats was just said to be because everything goes to its right place, but galileo allowed himself to be puzzled by it. He wanted an explanation at a deeper level, not a superficial one.

1:02:00 - chader(?) and christiansen(?), paper suggesting that anaphora is a normal cognitive process of trying to resolve a problem as quickly as possible. Counterexample: "Who do they expect to see each other?" But you can't understand this from surface analysis of data. Once you point that out, he says, more complicated statistical analysis comes out, ignoring that the simpler UG models could explain things better.

Mentions Wallace's objection (1:20:30), that we have higher mathematical abilities and it never would have been developed through natural selection, it must have come from other mechanisms designed to do something else.},
	Date-Added = {2012-03-28 23:46:49 -0400},
	Date-Modified = {2012-03-28 23:54:26 -0400},
	Url = {http://www.reddit.com/r/chomsky/comments/rgqlp/chomsky_lecture_ucl_on_the_poverty_of_the_stimulus/},
	Bdsk-Url-1 = {http://www.reddit.com/r/chomsky/comments/rgqlp/chomsky_lecture_ucl_on_the_poverty_of_the_stimulus/}}

@article{Ross1989,
	Annote = {One of the citations given for similarity-based analog retrieval, along with:

gentner1993
Holyoak1987
Ross1989},
	Author = {Ross, Brian H.},
	Date-Added = {2012-03-21 23:05:34 -0400},
	Date-Modified = {2012-03-21 23:08:50 -0400},
	Journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	Number = {3},
	Pages = {456-468},
	Title = {Distinguishing Types of Superficial Similarities: Different Effects on the Access and Use of Earlier Problems},
	Volume = {15},
	Year = {1989},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3hsbS0xNS0zLTQ1Ni5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEHhsbS0xNS0zLTQ1Ni5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPErLLkA+xAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLkEfxAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHhsbS0xNS0zLTQ1Ni5wZGYAAA4AIgAQAHgAbABtAC0AMQA1AC0AMwAtADQANQA2AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy94bG0tMTUtMy00NTYucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@article{Holyoak1987,
	Annote = {One of the citations given for similarity-based analog retrieval, along with:

gentner1993
Holyoak1987
Ross1989},
	Author = {Holyoak, Keith J. and Koh, Kyunghee},
	Date-Added = {2012-03-21 23:04:39 -0400},
	Date-Modified = {2013-01-30 20:47:03 -0500},
	Journal = {Memory and Cognition},
	Number = {4},
	Pages = {332-340},
	Title = {Surface and Structural Similarity in Analogical Transfer},
	Volume = {15},
	Year = {1987},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICg3KS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGZ1bGx0ZXh0ICg3KS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPD2/LkA76AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLkEc6AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZ1bGx0ZXh0ICg3KS5wZGYAAA4AIgAQAGYAdQBsAGwAdABlAHgAdAAgACgANwApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoNykucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@article{Gentner1993,
	Annote = {One of the citations given for similarity-based analog retrieval, along with:

gentner1993
Holyoak1987
Ross1989},
	Author = {Gentner, Dedre and Rattermann, Mary Jo and Forbus, Kenneth},
	Date-Added = {2012-03-21 05:06:40 -0400},
	Date-Modified = {2012-03-21 23:03:02 -0400},
	Journal = {Cognitive Psychology},
	Pages = {524-575},
	Title = {{The Roles of Similarity in Transfer: Separating Retrievability from Inferential Soundness}},
	Volume = {25},
	Year = {1993},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NjaWVuY2UgKDYpLnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPc2NpZW5jZSAoNikucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SNMuQDlAAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMuQRpAAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAc2NpZW5jZSAoNikucGRmAA4AIAAPAHMAYwBpAGUAbgBjAGUAIAAoADYAKQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvc2NpZW5jZSAoNikucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@article{Forbus2009b,
	Annote = {citation given for Companions architecture},
	Author = {Forbus, Kenneth and Klenk, Matthew and Hinrichs, Thomas},
	Date-Added = {2012-03-21 05:04:30 -0400},
	Date-Modified = {2012-03-21 05:06:22 -0400},
	Journal = {IEEE Intelligent Systems},
	Number = {4},
	Pages = {36-46},
	Title = {Compaion Cognitive Systems: Design Goals and Lessons Learned So Far},
	Volume = {24},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzA1MTcyODg4LnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMMDUxNzI4ODgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48SsuPEZkAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMuPSdkAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMDUxNzI4ODgucGRmAAAOABoADAAwADUAMQA3ADIAOAA4ADgALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzA1MTcyODg4LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=}}

@article{Forbus1995,
	Annote = {Citation given for MAC/FAC},
	Author = {Forbus, Kenneth and Gentner, Dedre and Law, Keith},
	Date-Added = {2012-03-21 04:58:21 -0400},
	Date-Modified = {2013-01-30 20:20:39 -0500},
	Journal = {Cognitive Science},
	Pages = {141-205},
	Title = {MAC/FAC: A Model of Similarity-Based Retrieval},
	Volume = {19},
	Year = {1995},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3MxNTUxNjcwOWNvZzE5MDJfMS5wZGbSFwsYGVdOUy5kYXRhTxEB1AAAAAAB1AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHFnMxNTUxNjcwOWNvZzE5MDJfMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEfzLjxC4AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLj0j4AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAVU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHMxNTUxNjcwOWNvZzE5MDJfMS5wZGYAAA4ALgAWAHMAMQA1ADUAMQA2ADcAMAA5AGMAbwBnADEAOQAwADIAXwAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9zMTU1MTY3MDljb2cxOTAyXzEucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AzgDTANsCswK1AroCxQLOAtwC4ALnAvAC9QMCAwUDFwMaAx8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADIQ==}}

@inproceedings{Bringsjord2008b,
	Annote = {citation used for SLATE.},
	Author = {Bringsjord, Selmer and Taylor, Joshua and Shilliday, Andrew and Clark, Micah and Arkoudas, Konstantine},
	Booktitle = {Proceedings of the 8th International Workshop on Computational Models of Natural Argument (CMNA 8)},
	Date-Added = {2012-03-14 02:39:50 -0400},
	Date-Modified = {2012-03-14 02:42:16 -0400},
	Editor = {Grasso, Floriana and Green, Nancy and Kibble, Rodger and Reed, Chris},
	Title = {Slate: An Argument-Centered Intelligent Assistant to Human Reasoners},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QUC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0JyaW5nc2pvcmRfZXRhbF9TbGF0ZV9jbW5hX2NyY18wNjE3MDgucGRm0hcLGBlXTlMuZGF0YU8RAhYAAAAAAhYAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx9CcmluZ3Nqb3JkX2V0YWxfU2xhdGUjRTNDREMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjzcy4W2ZwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4XupwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAF5NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBCcmluZ3Nqb3JkX2V0YWxfU2xhdGUjRTNDREMucGRmAA4AVAApAEIAcgBpAG4AZwBzAGoAbwByAGQAXwBlAHQAYQBsAF8AUwBsAGEAdABlAF8AYwBtAG4AYQBfAGMAcgBjAF8AMAA2ADEANwAwADgALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFVVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0JyaW5nc2pvcmRfZXRhbF9TbGF0ZV9jbW5hX2NyY18wNjE3MDgucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAOEA5gDuAwgDCgMPAxoDIwMxAzUDPANFA0oDVwNaA2wDbwN0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA3Y=}}

@article{Gentner2011,
	Annote = {Good summary and intro to comp. models of analogy.

Two assumptions:
1) People have *structured* representations where higher order relations constrain the lower-order relations
2) Gentner's systematicity principle(citation 9): The analogical mapping operate to prefer matching systems of relations governed by higher-order constraining relations such as cause or implies, rather than isolated matches. E.g., subject often do not simply infer ANY fact present in the base but not the target; their inferences were implicitly geared toward finding a larger matching system.

Argument against connectionist models: "{\ldots}other kinds of higher order relations can also serve to constrain analogical inference, including logical and mathematical relations, such as implication, and perceptual regularities, such as symmetry or monotonicity. To capture the processing of causal theories, explanations, logical proofs, and other such inferential systems requires structured representations; they cannot be effectively represented via mental distance models or feature set models (for further discussion, see Ref 1)."

"{\ldots}mapping is known to be sensitive to structural overlap, while retrieval is dominated by surface overlap." (citations 14-16)

Says LISA is also a model of Retrieval? (268) It's right, LISA does try to be (but doesn't seem to try as hard as MAC/FAC)

"[Models like] LISA [, when trying to decide how to construct the mapping,] start from key statements in the base and attempt to find matches for them in the target. [This top-down approach doesn't scale] particularly well. {\ldots} For top-down strategies, there is the additional problem of selecting which aspects of the base to project, followed by finding ways to fit it to the target. Consequently, such models tend ot use a variety o heuristics to minimize search." (270)


RETRIEVAL

constraints on retrieval:
- retrieval from LTM is domainated by surface matches (cite 14-16), contrasted with how mapping tends to come from structural alignment.

MAC/FAC : when it has a case in working memory, it computes a simple feature vector from the structural representation and uses that in a parallel search of LTM. Then generates up to 3 candidate memory items, which are passed to SME.

LISA on the other hand, sees retrieval and mapping as an integrated process. The shared semantic features help "prime both retrieval of descriptions and mapping connections between entities."



LARGE-SCALE

Companions architecture is composed of SME, MAC/FAC, and SEQL (for generalization). "To date the companions architecture is the only one that has been tested in experiments in which the inputs were produced by groups other than the researchers, and where the results were independently evaluated by other organizations" (273).

"{\ldots}the particular synchronous binding scheme used by LISa means that it is [sic] can match only three relations at a time; whether it can handle complex analogies by shifting the focus of attention around different parts of the representations remains an open question."



THE PROBLEM OF "HAND-CODING"

"In most current models, the representations are created by the experimenters, leading to the tailorability concern: that is, that (whether knowingly or not) the researchers have encoded the items in such a way as to give them the desired results. One way to avoid hand-coding is the use pre-existing databases and automatic (or semi-automatic) parsing and semantic representation of the input text. Another route, at least for visual materials, is to use atomatic spatial encoding of sketched materials."},
	Author = {Gentner, Dedre and Forbus, Kenneth},
	Date-Added = {2012-03-12 20:44:25 -0400},
	Date-Modified = {2012-03-13 18:36:46 -0400},
	Journal = {Wiley Interdisciplinary Reviews: Cognitive Science},
	Number = {3},
	Pages = {266-276},
	Title = {{Computational Models of Analogy}},
	Volume = {2},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzE2MTYyMy5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCjE2MTYyMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPH/LhBQ6AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLhEx6AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6ADE2MTYyMy5wZGYAAA4AFgAKADEANgAxADYAMgAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy8xNjE2MjMucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==}}

@book{Gentner2001,
	Annote = {	 	Preface
 	Contributors
1	 	Introduction: The Place of Analogy in Cognition 
by Keith J. Holyoak, Dedre Gentner and Boicho N. Kokinov
I	 	Computational and Theoretical Approaches
2	 	Exploring Analogy in the Large 
by Kenneth D. Forbus
3	 	Integrating Memory and Reasoning in Analogy-Making: The AMBR Model 
by Boicho N. Kokinov and Alexander Petrov
4	 	The STAR-2 Model for Mapping Hierarchically Structured Analogs 
by William H. Wilson, Graeme S. Halford, Brett Gray and Steven Phillips
5	 	Toward an Understanding of Analogy within a Biological Symbol System 
by Keith J. Holyoak and John E. Hummel
II	 	Arena of Analogical Thought
6	 	Metaphor is like Analogy 
by Dedre Gentner, Brian Bowdle, Phillip Wolff and Consuelo Boronat
7	 	Conceptual Blending and Analogy 
by Gilles Fauconnier
8	 	Setting Limits on Analogy: Why Conceptual Combination Is Not Structural Alignment 
by Mark T. Keane and Fintan Costello
9	 	The Analogical Paradox: Why Analogy Is So Easy in Naturalistic Setting Yet So Difficult in the Psychological Laboratory 
by Kevin Dunbar
10	 	Emotional Analogies and Analogical Inference 
by Paul Thagard and Cameron Shelley
11	 	Analogy and Analogical Comparison in Choice 
by Arthur B. Markman and C. Page Moreau
12	 	Semantic Alignments in Mathematical Word Problems 
by Miriam Bassok
III	 	Developmental and Comparative Approaches
13	 	Analogical Reasoning in Children 
by Usha Goswami
14	 	Can an Ape Reason Analogically? Comprehension and Production of Analogical Problems by Sarah, a Chimpanzee (Pan troglodytes) 
by David L. Oden, Roger K. R. Thompson and Daved Premack
15	 	Epilogue: Analogy as the Core of Cognition 
by Douglas R. Hofstadter
 	Index},
	Date-Added = {2012-03-10 13:11:03 -0500},
	Date-Modified = {2012-03-10 13:12:48 -0500},
	Editor = {Gentner, Dedre and Holyoak, Keith J. and Boicho, K. Kokinov},
	Publisher = {The MIT Press},
	Title = {The Analogical Mind: Perspectives from Cognitive Science},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDE1LnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSYW5hbG9neV9jaGFwMTUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48tMuBA0wAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMuBSZwAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAYW5hbG9neV9jaGFwMTUucGRmAAAOACYAEgBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAAxADUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDE1LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=},
	Bdsk-File-2 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDE0LnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSYW5hbG9neV9jaGFwMTQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48ssuBA0cAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMuBSZcAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAYW5hbG9neV9jaGFwMTQucGRmAAAOACYAEgBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAAxADQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDE0LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=},
	Bdsk-File-3 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDEzLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSYW5hbG9neV9jaGFwMTMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48sMuBAz8AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMuBSY8AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAYW5hbG9neV9jaGFwMTMucGRmAAAOACYAEgBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAAxADMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDEzLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=},
	Bdsk-File-4 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDEyLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSYW5hbG9neV9jaGFwMTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48rsuBAzsAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMuBSYsAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAYW5hbG9neV9jaGFwMTIucGRmAAAOACYAEgBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAAxADIALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDEyLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=},
	Bdsk-File-5 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDExICgxKS5wZGbSFwsYGVdOUy5kYXRhTxEB1AAAAAAB1AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHFmFuYWxvZ3lfY2hhcDExICgxKS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPKzLgQM1AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLgUmFAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAVU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGFuYWxvZ3lfY2hhcDExICgxKS5wZGYAAA4ALgAWAGEAbgBhAGwAbwBnAHkAXwBjAGgAYQBwADEAMQAgACgAMQApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXAxMSAoMSkucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AzgDTANsCswK1AroCxQLOAtwC4ALnAvAC9QMCAwUDFwMaAx8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADIQ==},
	Bdsk-File-6 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDEwLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSYW5hbG9neV9jaGFwMTAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48qsuBAzAAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMuBSYAAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAYW5hbG9neV9jaGFwMTAucGRmAAAOACYAEgBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAAxADAALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDEwLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=},
	Bdsk-File-7 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDkucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFhbmFsb2d5X2NoYXA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjzCy4EDKwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4FJewAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBhbmFsb2d5X2NoYXA5LnBkZgAOACQAEQBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXA5LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI},
	Bdsk-File-8 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDgucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFhbmFsb2d5X2NoYXA4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjzAy4EDJgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4FJdgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBhbmFsb2d5X2NoYXA4LnBkZgAOACQAEQBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXA4LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI},
	Bdsk-File-9 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDcucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFhbmFsb2d5X2NoYXA3LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjy+y4EDIQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4FJcQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBhbmFsb2d5X2NoYXA3LnBkZgAOACQAEQBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAA3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXA3LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI},
	Bdsk-File-10 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDYucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFhbmFsb2d5X2NoYXA2LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjy8y4EDHAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4FJbAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBhbmFsb2d5X2NoYXA2LnBkZgAOACQAEQBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAA2AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXA2LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI},
	Bdsk-File-11 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDUucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFhbmFsb2d5X2NoYXA1LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjy6y4EDFwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4FJZwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBhbmFsb2d5X2NoYXA1LnBkZgAOACQAEQBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAA1AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXA1LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI},
	Bdsk-File-12 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDQucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFhbmFsb2d5X2NoYXA0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjy4y4EDEgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4FJYgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBhbmFsb2d5X2NoYXA0LnBkZgAOACQAEQBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXA0LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI},
	Bdsk-File-13 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QIS4uLy4uLy4uLy5UcmFzaC9hbmFsb2d5X2NoYXAzLnBkZtIXCxgZV05TLmRhdGFPEQF+AAAAAAF+AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADJAgkZSCsAAAAOK9sRYW5hbG9neV9jaGFwMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACi8gasuBAwwAAAAAAAAAAAADAAIAAAkgAAAAAAAAAAAAAAAAAAAABi5UcmFzaAAQAAgAAMkCT2kAAAARAAgAAMuBSVwAAAABAAwADivbAA4mWwAAkycAAgAyTWFjaW50b3NoIEhEOlVzZXJzOmxpY2F0ajouVHJhc2g6YW5hbG9neV9jaGFwMy5wZGYADgAkABEAYQBuAGEAbABvAGcAeQBfAGMAaABhAHAAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAJVVzZXJzL2xpY2F0ai8uVHJhc2gvYW5hbG9neV9jaGFwMy5wZGYAABMAAS8AABUAAgAN//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AsgC3AL8CQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==},
	Bdsk-File-14 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDEucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFhbmFsb2d5X2NoYXAxLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjyoy4EDAwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4FJUwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBhbmFsb2d5X2NoYXAxLnBkZgAOACQAEQBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXAxLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI},
	Bdsk-File-15 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDIucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFhbmFsb2d5X2NoYXAyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjy2y4EC7gAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4FJPgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBhbmFsb2d5X2NoYXAyLnBkZgAOACQAEQBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXAyLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@article{Craddock2012,
	Abstract = {Memory is attributed to strengthened synaptic connections among particular brain neurons, yet synaptic membrane components are transient, whereas memories can endure. This suggests synaptic information is encoded and `hard-wired' elsewhere, e.g. at molecular levels within the post-synaptic neuron. In long-term potentiation (LTP), a cellular and molecular model for memory, post-synaptic calcium ion (Ca2+) flux activates the hexagonal Ca2+-calmodulin dependent kinase II (CaMKII), a dodacameric holoenzyme containing 2 hexagonal sets of 6 kinase domains. Each kinase domain can either phosphorylate substrate proteins, or not (i.e. encoding one bit). Thus each set of extended CaMKII kinases can potentially encode synaptic Ca2+ information via phosphorylation as ordered arrays of binary `bits'. Candidate sites for CaMKII phosphorylation-encoded molecular memory include microtubules (MTs), cylindrical organelles whose surfaces represent a regular lattice with a pattern of hexagonal polymers of the protein tubulin. Using molecular mechanics modeling and electrostatic profiling, we find that spatial dimensions and geometry of the extended CaMKII kinase domains precisely match those of MT hexagonal lattices. This suggests sets of six CaMKII kinase domains phosphorylate hexagonal MT lattice neighborhoods collectively, e.g. conveying synaptic information as ordered arrays of six ``bits'', and thus ``bytes'', with 64 to 5,281 possible bit states per CaMKII-MT byte. Signaling and encoding in MTs and other cytoskeletal structures offer rapid, robust solid-state information processing which may reflect a general code for MT-based memory and information processing within neurons and other eukaryotic cells.},
	Annote = {Explores possibility that 'arrays of bits' can be stored using some method they discovered.},
	Author = {Craddock, Travis J.A. and Tuszynski, Jack A. and Hameroff, Stuart},
	Date-Added = {2012-03-09 16:57:37 -0500},
	Date-Modified = {2012-03-09 16:59:10 -0500},
	Journal = {http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1002421},
	Title = {Cytoskeletal Signaling: Is Memory Encoded in Microtuble Lattices by CaMKII Phosphorylation?},
	Year = {2012?}}

@article{Smith2010,
	Author = {Smith III, Clay V. and Licato, John},
	Date-Added = {2012-03-08 04:36:33 -0500},
	Date-Modified = {2012-03-08 04:37:55 -0500},
	Journal = {Journal of Systemics, Cybernetics and Informatics},
	Number = {3},
	Pages = {72-79},
	Title = {A Voice Operated Tour Planning System for Autonomous Mobile Robots},
	Volume = {8},
	Year = {2010}}

@inproceedings{Licato2012,
	Address = {Toronto, Canada},
	Author = {Licato, John and Bringsjord, Selmer and Hummel, John E.},
	Booktitle = {{Rethinking Cognitive Development: Proceedings of the 42nd Annual Meeting of the Jean Piaget Society}},
	Date-Added = {2012-03-08 03:15:47 -0500},
	Date-Modified = {2013-01-30 21:24:53 -0500},
	Title = {{Exploring the Role of Analogico-Deductive Reasoning in the Balance-Beam Task}},
	Url = {https://docs.google.com/open?id=0B1S661sacQp6NDJ0YzVXajJMWVU},
	Year = {2012},
	Bdsk-Url-1 = {https://docs.google.com/open?id=0B1S661sacQp6NDJ0YzVXajJMWVU}}

@incollection{Bringsjord2012,
	Address = {8, square des Bouleaux, 75019 Paris, France},
	Author = {Bringsjord, Selmer and Licato, John},
	Booktitle = {{Theoretical Foundations of Artificial General Intelligence}},
	Date-Added = {2012-03-05 19:34:11 -0500},
	Date-Modified = {2014-05-13 01:48:09 +0000},
	Editor = {Pei Wang and Ben Goertzel},
	Pages = {25-48},
	Publisher = {Atlantis Press},
	Title = {{Psychometric Artificial General Intelligence: The Piaget-MacGyver Room}},
	Url = {http://kryten.mm.rpi.edu/Bringsjord\_Licato\_PAGI\_071512.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://kryten.mm.rpi.edu/Bringsjord%5C_Licato%5C_PAGI%5C_071512.pdf}}

@article{Siegler1981,
	Annote = {Cited with Siegler1976 as main source of original rule-based approach to BBT},
	Author = {Siegler, Robert S.},
	Date-Added = {2012-03-05 02:04:32 -0500},
	Date-Modified = {2013-01-30 21:02:56 -0500},
	Journal = {Monographs of the Society for Research in Child Development},
	Number = {2},
	Pages = {1-74},
	Title = {Developmental Sequences Within and Between Concepts},
	Volume = {46},
	Year = {1981}}

@article{Normandeau1989,
	Annote = {Examined two critiques of rule-assessment methodology:
a - It doesn't take into consideration other rules subjects use
b - Its multiple-choice format misrepresents subjects' cognitive level.

Experiment 1 evaluated subjects "according to Siegler's (1976, 1981) rules and re-evaluated according to a modified set of rules that included the addition rule (Wilkening & Anderson, 1982) and two other rules:"

Rule 3A: A "perceptual-muddle-through" rule, which was presented as an alternative pattern of rule 3 by Klahr and Siegler (1978). Users of this rule focus on the larger weight or distance and make a perceptual decision about whether the balane should go down on the side of the larger distance or weight.

Rule QP: Dealt with qualitative proportionality. Users of this rule consider "both weight and distance and conclude that a heavy weight at a small distance on one side of the fulcrum should compensate for a light weight at a greater distance on the other side of the fulcrum and therefore predict that the balance scale will remain horizontal for all conflict problems."

RESULTS:
"Under Siegler's rules, cognitive ability was underestimated in 36.3% of the students in the present study. More specifically, Rule 3 seemed to underestimate the knowledge and understanding of a fair number of subjects (29.9%), who were reclassified as using Rule 3A, the addition rule, or the QP rule. {\ldots} The high proportion of students using the addition rule supports Wilkening and Anderson's (1982) suggestion that this rule should be considered a specific pattern of responding in the balance-scale task."


"Siegler{\ldots}suggested a parallel between Piagetian stages and his rules. According to Siegler [1976, 1981], Rule 1 corresponds to Level 1; Rules 2 and 3, to Level 2; and Rule 4, to Level 3." (245)

"{\ldots}in the second study, we found the addition rule and the QP rule to reflect a higher level of ability than Siegler's Rule 3. With [sic] addition rule, adolescents coordinate the weight and distance on each side of the fulcrum before comparing them in a manner similar to Case's (1985) dimensional stage. Adolescents using the QP rule engage in a qualitative weight-distance compensation. This rule {\ldots} does permit the coordination of two systems of reference, weight and distance, on both sides of the fulcrum in the same operation. As such it represents a higher level of functioning than the addition rule. Including these rules may increase the diagnostic value of the rule-assessment methodology, especially with adolescents and adults, who are more likely to be using integrative rules other than the torque rule."

The "torque rule" is another name for Rule IV, where they multiply "for each side the number of pices by the distance from the fulcrum and predicting that the balance will tip down on the side of the greater product."},
	Author = {Normandeau, Sylvie and Lariv{\'e}e, Serge and Roulin, Jean-Luc and Longeot, Fran{\c c}ois},
	Date-Added = {2012-03-01 17:52:08 -0500},
	Date-Modified = {2012-03-01 18:00:42 -0500},
	Journal = {Journal of Genetic Psychology},
	Number = {3},
	Pages = {237-249},
	Title = {The Balance-Scale Dilemma: Either the Subject or the Experimenter Muddles Through},
	Volume = {150},
	Year = {1989},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzUyNjE2NDkucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rws1MjYxNjQ5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjyPy3VnvQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy3WuDQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgA1MjYxNjQ5LnBkZgAOABgACwA1ADIANgAxADYANAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy81MjYxNjQ5LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@article{Wilkening1982,
	Annote = {Shows that the decision tree methodology, such as that used by Siegler (1976), is "unable to assess algebraic integration rules; instead, it concludes that they are nonintegration, binary decision rules." He rejects it in favor of Anderson's "functional measurement methodology."

Difference between two methods:
Siegler's "embodies the assumption that the subject compares the objects one dimension at a time and typically does not integrate the dimensions for either object." Its methodology relies "primarily on numberical responses about degree of preference between the two objects."
Anderson's "was developed primarily to search for integration rules." Its methodology relies "primarily on choice data."

Piaget and Inhelder (1958, p. 172) "demonstrated that 10-year-olds have at least a "qualitative" rule for the combination of weight and distance; they know that a weight "weighs more" at a greater distance from the fulcrum. Siegler's results imply that even the majority of 17-year-olds do not know this qualitative rule."

"Indeed, functional measurement studies have shown algebraic integration rules in subjects as young as 4 years of age{\ldots}there is considerable evidence for a general-purpose adding-type rule{\ldots}If subjects solve the balance problems using this general-purpose adding rule, then Siegler's (1976, 1981) rule assessments may misrepresent their knowledge."

An adding-type rule may look like the following:

IF aw_L + bd_L < aw_R + bd_R THEN say "right side down" (219)

where a,b are weighting parameters, w_L d_L are weight, distance on left side

Multiplying integration rule might look like:

IF aw_L x bd_L < aw_R x bd_R THEN say right side down (223)


FUNCTIONAL MEASUREMENT AS A RULE-ASSESSMENT METHODOLOGY

- they usually use numerical rather than multiple-choice responses for subjects
- you basically take one of the equations above, solve for a variable (like d_R) and use that to make predictions

concludes that functional measurement methodology can do everything Siegler's decision-tree model can, and more.},
	Author = {Wilkening, Friedrich and Anderson, Norman H.},
	Date-Added = {2012-03-01 16:25:55 -0500},
	Date-Modified = {2012-03-01 16:27:50 -0500},
	Journal = {Psychological Bulletin},
	Number = {1},
	Pages = {215-237},
	Title = {Comparison of Two Rule-Assessment Methodologies for Studying Cognitive Development and Knowledge Structure},
	Volume = {92},
	Year = {1982},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2J1bC05Mi0xLTIxNS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGJ1bC05Mi0xLTIxNS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPODLdVOIAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLdZnYAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGJ1bC05Mi0xLTIxNS5wZGYAAA4AIgAQAGIAdQBsAC0AOQAyAC0AMQAtADIAMQA1AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9idWwtOTItMS0yMTUucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@article{Ferretti1986,
	Annote = {paper that first introduced the torque difference effect, which is supposed to be a problem for symbolic/rule-based approaches

},
	Author = {Ferretti, Ralph P. and Butterfield, Earl C.},
	Date-Added = {2012-02-29 18:19:20 -0500},
	Date-Modified = {2013-01-30 20:22:47 -0500},
	Journal = {Child Development},
	Number = {6},
	Title = {Are Children's Rule-Assessment Classifications Invariant Across Instances of Problem Types?},
	Volume = {57},
	Year = {1986},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzcyNTIyMTMucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rws3MjUyMjEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjyby3QcowAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy3Ri8wAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgA3MjUyMjEzLnBkZgAOABgACwA3ADIANQAyADIAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy83MjUyMjEzLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@article{Jansen1997,
	Annote = {Talks about the BBT's torque difference effect of Ferretti and Butterfield (1986), but concludes that this effect is only really seen with large differences.},
	Author = {Jansen, Brenda R. J. and van der Maas, Han L. J.},
	Date-Added = {2012-02-29 18:14:04 -0500},
	Date-Modified = {2013-01-30 20:46:38 -0500},
	Journal = {Developmental Review},
	Pages = {321-357},
	Title = {Statistical Test of the Rule Assessment Methodology by Latent Class Analysis},
	Volume = {17},
	Year = {1997}}

@article{Schmidt1996,
	Annote = {citation given for a dynamic model of the BBT.},
	Author = {Schmidt, William C. and Ling, C. X.},
	Date-Added = {2012-02-29 18:12:04 -0500},
	Date-Modified = {2013-01-30 21:03:59 -0500},
	Journal = {Machine Learning},
	Pages = {203-230},
	Title = {A Decision-Tree Model of Balance Scale Development},
	Volume = {24},
	Year = {1996}}

@inproceedings{Sage1983,
	Annote = {Along with Langley1987, this citation is given for production systems modeling the BBT.
},
	Author = {Sage, S. and Langley, Pat},
	Booktitle = {Proceedings of the Eighth International Joint Conference on Artificial Intelligence},
	Date-Added = {2012-02-29 18:10:00 -0500},
	Date-Modified = {2013-01-30 21:04:22 -0500},
	Editor = {Bundy, A.},
	Pages = {94-96},
	Title = {Modeling Cognitive Development on the Balance Scalen Task},
	Volume = {1},
	Year = {1983}}

@incollection{Langley1987,
	Annote = {along with Sage1983, citation given for a production rule model of the BBT.},
	Author = {Langley, Pat},
	Booktitle = {Production System Models of Learning and Development},
	Date-Added = {2012-02-29 18:08:27 -0500},
	Date-Modified = {2013-01-30 20:44:11 -0500},
	Editor = {Klahr, David and Lang and Neches, R.},
	Publisher = {MIT Press},
	Title = {A General Theory of Discrimination Learning},
	Year = {1987}}

@article{Siegler1976,
	Annote = {The landmark publication that started computational models of BBT, this introduces Siegler's 4-rule model. the rules are:

--------------------------------------------------------------------------------
RULE 1:

If weight same:
	Predict(Balance)
Else
	Predict(Greater weight goes down)


RULE II:

If weight same:
	If distance same:
		P(balance)
	else
		P(greater distance goes down)
else
	P(greater weight goes down)


RULE III:

If weight same:
	If distance same:
		P(balance)
	else
		P(greater distance down)
else
	if distance same:
		P(greater weight down)
	else
		if greater weight same side as greater distance:
			P(greater weight and distance down)
		else
			MUDDLE THROUGH


RULE IV:

If weight same:
	If distance same:
		P(balance)
	else:
		P(greater distance down)
else:
	If distance same:
		P(greater weight down)
	else
		if greater weight same side as greater distance
			P(greater weight and distance down)
		else
			if cross products same
				P(balance)
			else
				P(greater product down)
--------------------------------------------------------------------------------

ENCODING HYPOTHESIS: "Five-year-olds are less able to acquire new information than 8-year-olds because their encoding of stimuli is less adequate."
In order to study encoding independent of their performance, a method used by Chase and Simon (1973) was employed: Give chess masters unorganized arrangements of a chess board, and ask them to reproduce them (by memory?). They did this with the balance scales},
	Author = {Siegler, Robert S.},
	Date-Added = {2012-02-29 14:18:03 -0500},
	Date-Modified = {2013-01-30 21:03:02 -0500},
	Journal = {Cognitive Psychology},
	Pages = {481-520},
	Title = {Three Aspects of Cognitive Development},
	Volume = {8},
	Year = {1976},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NpZWdsZXI3Ni5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDXNpZWdsZXI3Ni5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPElPLc+SWAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLdCrmAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHNpZWdsZXI3Ni5wZGYADgAcAA0AcwBpAGUAZwBsAGUAcgA3ADYALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NpZWdsZXI3Ni5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==}}

@incollection{McClelland1995,
	Annote = {Along with McClelland1989, this is one of the main citations for McClelland's PDP model of the BBT},
	Author = {McClelland, J.L.},
	Booktitle = {Developing Cognitive Competence: New Approaches to Process Modeling},
	Date-Added = {2012-02-29 14:13:40 -0500},
	Date-Modified = {2013-01-30 20:42:23 -0500},
	Editor = {Simon, T.J. and Halford, Graeme S},
	Publisher = {Psychology Press},
	Title = {A Connectionist Perspective on Knowledge and Development},
	Year = {1995}}

@incollection{McClelland1989,
	Annote = {citation used for McClelland's PDP model of balance scale task.},
	Author = {McClelland, J.L.},
	Booktitle = {Parallel Distributed Processing: Implications for Psychology and Neurobiology},
	Date-Added = {2012-02-29 14:11:37 -0500},
	Date-Modified = {2013-01-30 20:42:58 -0500},
	Editor = {Morris, R.G.M.},
	Publisher = {Oxford University Press},
	Title = {Parallel Distributed Processing: Implications for Cognition and Development},
	Year = {1989}}

@article{vanRijn2003,
	Annote = {Provides a good review of the computational models of the BBT up to this point. 

They list four criteria for which "Only if a computational model satisfies these four criteria, it can be considered a model of the full range of behavior associated with the balance scale task."

EC1) Rule-like behavior: Behavior of model should be classifiable into rules (which can be done using LCA if necessary). Also, the transitions between rules must be explained.

EC2) Rule sets: These rules must include Siegler's 4, and the addition rule (Normandeau et al, 1989), in a fixed order.

EC3) Transition patterns without feedback: Must explain transitions IN THE ABSENCE OF FEEDBACK. "this criterion only applies to the transition from Rule I to Rule II as detailed results concerning the transitions between the other Rules are not available."

EC4) Torque Difference effect: Must reproduce torque difference effect for large torque values but not necessarily for small difference values.


COMPUTATIONAL MODELS

Production rules - Klahr and Siegler (1978), Sage and Langley (1983), Langley (1987)
Decision trees - Schmidt and Ling (1996), original Siegler?
Neural network models - McClelland (1989, 1995), shultz. Both fail "the no-feedback criterion (EC3), because the model is only able to learn by feedback-dependent back-propagation."
Hybrid - Their own ACT-R-based model

Page 236 has a table with criterion that each of these classes of models fail and pass. They list all of them as failing EC3 (but note that "This does NOT mean that models with [fail] evaluations cannot [later] be extended to match the criteria better.")






Normandeau et al. 1989 - identifies the "addition rule", which says that the answer is based on the addition of weight and distance values when presented with conflict items.

Klahr, D., & Siegler, R. (1978). The representation of children's knowledge. In H. Reese & L. Lipsitt (Eds.),
Advances in child development and behavior (pp. 61--116). New York, NY: Academic Press.

Langley, P. (1987). A general theory of discrimination learning. In D. Klahr, P. Langley, & R. Neches (Eds.),
Production system models of learning and development. Cambridge, MA: MIT Press.

Normandeau, S., Larivee, S., Roulin, J. L., & Longeot, F. (1989). The balance-scale dilemma: Either the subject or
the experimenter muddles through. Journal of Genetic Psychology, 150(3), 237--250.

Sage, S., & Langley, P. (1983). Modeling cognitive development on the balance scale task. In A. Bundy (Ed.), Proceedings of the Eight International Joint Conference on Artificial Intelligence (Vol. 1, pp. 94--96), Karlsruhe, Germany.

Schmidt, W. C., & Ling, C. X. (1996). A decision-tree model of balance scale development. Machine Learning, 24, 203--230.},
	Author = {van Rijn, Hedderik and van Someren, Maarten and van der Maas, Han L. J.},
	Date-Added = {2012-02-29 01:31:33 -0500},
	Date-Modified = {2013-01-30 20:59:22 -0500},
	Journal = {Cognitive Science},
	Pages = {227-257},
	Title = {Modeling Developmental Transitions on the Balance Scale Task},
	Volume = {27},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NjaWVuY2UgKDUpLnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPc2NpZW5jZSAoNSkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SMctzMNEAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMtzdyEAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAc2NpZW5jZSAoNSkucGRmAA4AIAAPAHMAYwBpAGUAbgBjAGUAIAAoADUAKQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvc2NpZW5jZSAoNSkucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@incollection{vanderMaas2009,
	Annote = {Discuss two approaches: Connectionism, and non-linear dynamical system theory (NDST)

Dynamic system - broadly defined as any application of concepts, methods, and models from the mathematical study of non-linear dynamical systems to developmental psychology. Any research on phase transitions, or chaos. They see connectionist models as a subset of the larger class of dynamical models.

"Old-fashioned cognitive development" - "distinctively human" abilities like reasoning, planning, abstract thinking (rather than low-level pattern recognition, motor action, etc, as both connectionism and NDST do best).

They criticize the claim that the non-symbolic, graded, and dynamic properties of connectionist/NDST approaches provide the best account of higher cognitive functioning, and say it's overstated.

"the balance scale task is used as a benchmark task in computational modeling.
Specifically, in the last 25 years a number of symbolic and connectionist models have
been proposed to explain the empirical results (van Rijn, van Someren, & van der
Maas, 2003)"

Connectionist model - McClelland (1989, 1995)
McClelland, J. L. (1989). Parallel distributed processing: implications for cognition and development. In R. G. M. Morris (Ed.), Parallel distributed processing: Implications for psychology and neurobiology (pp. 8-45). Oxford: Clarendon Press.
McClelland, J. L. (1995). A connectionist perspective on knowledge and development. In T. J. Simon & G. S. Halford (Eds.), Developing cognitive competence: New approaches to process modelling (pp. 157-204). Hillsdale, NJ: LEA.

Cascade correlation - Shultz, Mareshal and Schmidt (1994), Shultz (2003)
Shultz, T. R. (2003). Computational developmental psychology. Cambridge, MA: MIT Press.
Shultz, T. R., Mareschal, D., & Schmidt, W. (1994). Modeling cognitive development on balance scale phenomena. Machine Learning, 16, 57-86.

ACT-R - van Rijn, van Someren, van der Maas (2003) - sub-symbolic, that's why it's considered here.
Van Rijn, H., van Someren, M., & van der Maas, H. (2003). Modeling developmental transitions on the balance scale task. Cognitive Science, 27, 227-257.

They acknowledge that may features of NDST are consistent with piagetian concepts, and can explain things like disequilibrium and equilibriation. A major feature of NDST is self-organization (8), which is good and might be "the definite resolution of Fodor's famous learning paradox (Raijmakers & Molenaar, 2004)". 

The connectionists said only their models could explain the TD (torque difference) effect of Ferretti and Butterfield. This is the idea that rule classification is influenced by the differences in torque. A situation in which the torque difference is great is easier to solve than when they're close, even if there are less weights on the side with more torque. F&B then argue that this calls for non-symbolic models.

PROBLEMS WITH CONNECTIONIST MODELS

Jansen and van der Maas (1997) applied LCA to the PDP model, it was a "failure. There were no clear classes, and often fitting latent class model could not be found. Also the data of children appeared to be rather homogeneous within item types (no TD effects), whereas the PDP data were very heterogeneous." Quinlan et al. (2006) did something similar to cascade correlation network, and were able to find classes but rules were found that are not observed in empirical data. Also, CC model failed to use correct torque rule (author suggests it's because "the activation rules of these networks are additive.")

"{\ldots}without feedback, CC and PDP models will not be subject to any change in their weights. These networks learn by backpropagation of error that depends on feedback of a trainer. For that reason, we do not see how connectionist networks could show hyteresis. Furthermore, these networks do not show real phase transitions or self-organization." (18)

"Our present conclusion about the connectionist models is that they are largely unconvincing as models of proportional reasoning, and more generally as models of higher cognitive functioning." (19)

HYBRID MODELS

They acknowledge we shouldn't abandon neural/connectionist models completely, for obvious reasons.
Claim that the ACT-R architecture combines symbolic and non-symbolic aspects of information processing, such as by giving production rules activation values. They refer to Wermter and Sun (2000)!

NEURAL NETWORKS WITH FUNCTIONAL SELF-ORGANIZATION

Raijmakers & Molenaar, 2004 - self-organization in dynamical systems resolves Fodor's paradox? Raijmakers criticizes Quartz's (1993) claim that CC networks solve Fodor's paradox, since adding new hidden units are discrete changes that are just like adding conceptual resources; it'd be better if there were arbitrary small maturational quantitative changes in the network.

They suggest that neural networks in which the nonlinear phenomena have a function in learning are "the most promising way to proceed." (22)



READ: 
van Rijn et al. 2003 Modeling developmental transitions on the balance scale task. Cognitive Science, 27, 227-257. - discusses computational modeling history of BBT? 

Jansen and van der Maas (2002) The development of children's rule use on the balance scale task. Journal of Experimental Child Psychology, 81, 383-416.- discuss ad./disad. of latent class analysis to BBT. Also counter arguments to TD claim, namely that the effect shows up only in the most extreme level of TD, which doesn't actually occur in known balance scale tests.

Ferretti and Butterfield 1986 Are childrens' rule-assessment
classifications invariant across instances of problem types? Child Development, 57, 1419-1428.- explains TD effect, which connectionist models claim only they can answer and Siegler's can't.

Quinlan et al. 2006 Re-thinking stages of cognitive development: An appraisal of connectionist models of the balance scale task. Cognition, In press. - applied LCA to CC model, found problems.
All citations for models above},
	Author = {van der Maas, Han L. J. and Raijmakers, Maartje E.J.},
	Booktitle = {Toward a New Grand Theory of Development: Connectionism and Dynamical Systems Re-Considered},
	Date-Added = {2012-02-28 23:10:14 -0500},
	Date-Modified = {2013-01-30 20:59:57 -0500},
	Editor = {Spencer, J. and Thomas, M. S. C. and McClelland, J.L.},
	Pages = {229-312},
	Publisher = {Oxford Univ. Press},
	Title = {Transitions in Cognitive Development: Prospects and Limitations of a Neural Dynamic Approach},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2lvd2FjaGFwdGVyLnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPaW93YWNoYXB0ZXIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8QfstzGTkAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMtzX4kAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAaW93YWNoYXB0ZXIucGRmAA4AIAAPAGkAbwB3AGEAYwBoAGEAcAB0AGUAcgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvaW93YWNoYXB0ZXIucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@incollection{Klahr1999,
	Annote = {BALANCE BEAM TASK: Siegler (1976, 1978) was one of the most important, suggested that "children's different levels of knowledge about this task can be represented in the form of a sequence of four increasingly mature rules or models." (Siegler 1976)

Model 1: 
considers only number of weights on each side
Model 2:
difference in weight dominates, but if weight is equal then distance is considered.
Model 3:
always tests weight and distance. In the case where w1 > w2 and d2 > d1, child doesn't know what to do or makes random prediction.
Model 4: 
knowledge of sum-of-products, but they base prediction on simpler tests if they can.

Siegler's work was first represented with binary decision trees, then production-system based (Siegler 1978)


"{\ldots}it is instructive to consider the way in which such detailed models could characterize how much more than balance scale knkowledge, as such, is required by a child performing this task. For example, one of Klahr and Siegler's subjects tended to encode both weight and distances as either big or small. Their model for that subject dealt with the way in which the child maintained declarative memory elements representing the following pieces of information: Which side has *more* weight or distance, which side has a *big* weight or distance, what the current criterion value is (for big weights or distances), what the scale is expected to do, what the scale actually did, whether the prediction is yet to be made or has been made, and whether it is correct or incorrect. Thus, their model makes a strong claim about how much encoded knowledge must be available at any one moment and hence about the dynamics of declarative memory mentioned earlier. Although production system models do not generally impose any clear constraints on the size of working memory, they provide the potential for such an analysis."


CONNECTIONIST MODELS FOR BALANCE SCALE

She notes this area "is one of the few involved in higher order conceptual development in which connectionist models *have* been constructed."

Problem noted by McClelland (1989, 1995) is production system models tell us little about the underlying forces that lead children from one system of rules to the next. Also, they don't account for torque-difference effect: children do better when discrepancy between torques on each side of balance scale is increased (Ferretti & Butterfield, 1986; Wilkening & Anderson, 1982). 

McClelland - back propagation model. It was able to simulate model I, progressing to model III, but not IV because, as he argued, "some aspects of the use of Model IV by adults involved the application of full mathematical analysis." But it DID capture some of the torque distance effect.

Shultz et al. (1995) - used cascade correlation to extend McClelland's model, was able to learn model IV.


Ferretti and Butterfield 1986
Ferretti, R.P., and Butterfield E. C. (1986) Are children's rule assessment classification invariant across instances of problem types? Child development, 57, 1419-1428

McClelland 1989, 1995
McClelland, J.L. (1989) Parallel distributed processing: Implications for cognition and development. In R.G.M. Morris (Ed.), Parallel distributed processing: Implications for psychology and neurobiology. Oxford, England: Oxford University Press.
(1995) A connectionist perspective on knowledge and development. In T.J. Simon and G.S.Halford (Eds) Developing cognitive competence: new approaches to process modeling (p. 157-204)

Shultz et al 1995
Modeling cognitive development with a generative connectionist algorithm. In T.J. Simon and G.S.Halford (Eds) Developing cognitive competence: new approaches to process modeling (p. 205-262)

Siegler 1976
Three aspects of cognitive development. Cognitive psychology, 8, 481-520
(1996) Emerging minds. New York: Oxford U Press

Wilkening and Anderson, 1982
Representation and diagnosis of knowledge structures in developmental psychology. In H.H. Anderson, Contributions to integration theory, Vol. 3: Developmental.
},
	Author = {Klahr, David},
	Booktitle = {Conceptual Development : Piaget's Legacy},
	Chapter = {6},
	Date-Added = {2012-02-28 12:26:07 -0500},
	Date-Modified = {2012-02-28 12:27:17 -0500},
	Editor = {Kofsky, Ellin},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {The Conceptual Habitat: In What Kind of System Can Concepts Develop?},
	Year = {1999}}

@book{Kofsky1999,
	Address = {Mahwah, NJ},
	Annote = {Good source of summaries on the state of the art piagetian work (up to 1999). Free through rpi library website.

},
	Date-Added = {2012-02-27 22:49:29 -0500},
	Date-Modified = {2012-02-28 12:27:16 -0500},
	Editor = {Kofsky, Ellin},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Conceptual Development : Piaget's Legacy},
	Year = {1999}}

@inproceedings{Sowa2003,
	Address = {Dresden, Germany},
	Annote = {http://www.jfsowa.com/pubs/analog.htm

Talks about their "VivoMind" analogy engine (VAE), which combines logic and analogy in a way that supposes logical thinking emerges from analogical ability (this is opposed to ours which separates the two processes).

The VivoMind Analogy Engine (VAE), which is described in Section 3, is general enough to be used in any application domain. Therefore, VAE leads to fundamental questions about the nature of analogy that have been debated in the literature of cognitive science. One three-party debate has addressed many of those issues:

Thesis:  For the Structure Mapping Engine (SME), Falkenheimer, Forbus, and Gentner (1989) defined analogy as the recognition that "one thing is like another" if there is a mapping from a conceptual structure that describes the first one to a conceptual structure that describes the second. Their implementation in SME has been applied to a wide variety of practical applications and to psychological studies that compare the SME approach to the way people address the same problems.
Antithesis:  In their critique of SME, Chalmers, French, and Hofstadter (1992) consider analogy to be an aspect of a more general cognitive function called high-level perception (HLP), by which an organism constructs a conceptual representation of a situation. They "argue that perceptual processes cannot be separated from other cognitive processes even in principle, and therefore that traditional artificial-intelligence models cannot be defended by supposing the existence of a 'representation module' that supplies representations ready-made." They criticize the "hand-coded rigid representations" of SME and insist that "content-dependent, easily adaptable representations" must be "an essential part of any accurate model of cognition."
Synthesis:  In summarizing the debate, Morrison and Dietrich (1995) observed that the two positions represent different perspectives on related, but different aspects of cognition:  SME employs structure mapping as "a general mechanism for all kinds of possible comparison domains" while "HLP views analogy as a process from the bottom up; as a representation-building process based on low-level perceptual processes interacting with high-level concepts." In their response to the critics, Forbus et al. (1998) admitted that a greater integration with perceptual mechanisms is desirable, but they repeated their claim that psychological evidence is "overwhelmingly" in favor of structure mapping "as a model of human analogical processing."},
	Author = {Sowa, John F. and Majumdar, Arun K.},
	Booktitle = {Proceedings of the International Conference on Conceptual Structures},
	Date-Added = {2012-02-06 16:26:13 -0500},
	Date-Modified = {2012-02-06 16:28:42 -0500},
	Editor = {Aldo, A. and Lex, A. and Ganter, B.},
	Month = {July},
	Pages = {16-36},
	Publisher = {Springer-Verlag},
	Title = {Conceptual Structures for Knowledge Creation and Communication},
	Year = {2003}}

@electronic{Ng2011,
	Annote = {Talks about using sparse (en?)coding for vision processing, which can be applied to other fields as well such as audio processing. The algorithm finds features to form a sort of basis (think linear algebra) for the vector space, and then another featural level is extracted from that, and so on, allowing for a very deep learning to occur.

Claims to have course materials at http://www.stanford.edu/class/cs294a/handouts.html},
	Author = {Ng, Andrew},
	Date-Added = {2012-01-30 10:47:01 -0500},
	Date-Modified = {2012-03-29 21:23:41 -0400},
	Lastchecked = {1/30/2012},
	Title = {Bay Area Vision Meeting: Unsupervised Feature Learning and Deep Learning},
	Url = {http://www.youtube.com/watch?v=ZmNOAtZIgIk},
	Year = {2011},
	Bdsk-Url-1 = {http://www.youtube.com/watch?v=ZmNOAtZIgIk}}

@inproceedings{Reynolds2004,
	Annote = {They say of the Forbus paper:
"The culmination of nearly fifteen years of work in the field is presented in ``An Analogy Ontology for 
Integrating Analogical Processing and First-Principles Reasoning'' [10].  This paper describes two-way 
communications between a reasoning system and analogy software. However, the architecture employs 
the analogy software only as an add-on to a deductive inference engine with knowledge base (ontology). 
The analogy software uses the ontology to distinguish the categories of terms (e.g., relation, attribute, or 
logical connective) and to store and retrieve collections of terms as cases. We have gone far beyond this 
in using deductive reasoning and an ontology to filter the false hypotheses generated by analogy"



"Our algorithm approximates the algorithm developed by the analogy research group at Northwestern."

"In our example, "Bush" is substituted for "Churchill" and "FDR," because all those terms appear with the predicate "leader." But no pairing is made with the term "Saddam," which appears in the relation "dictator," even though "dictator" is a specialization of "leader.""
---Note that this could be a potential advantage of 



Their first phase generates hypotheses through analogy. The second phase filters out these hypotheses using deduction, using the "Vampire first order theorem prover [32,34]", in standard FOL. They try to find proofs or disproofs of hypotheses.},
	Author = {Reynolds, Jim and Pease, Adam and Li, John},
	Date-Added = {2012-01-23 16:04:31 -0500},
	Date-Modified = {2012-01-23 22:19:55 -0500},
	Organization = {IKE},
	Pages = {39-48},
	Title = {Analogy and Deduction for Knowledge Discovery},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0lLRTA0IGFuYWxvZ3kgcGFwZXIucGRm0hcLGBlXTlMuZGF0YU8RAdgAAAAAAdgAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxdJS0UwNCBhbmFsb2d5IHBhcGVyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxBhy0M4rgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy0N+/gAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFZNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBJS0UwNCBhbmFsb2d5IHBhcGVyLnBkZgAOADAAFwBJAEsARQAwADQAIABhAG4AYQBsAG8AZwB5ACAAcABhAHAAZQByAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBDVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9JS0UwNCBhbmFsb2d5IHBhcGVyLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDPANQA3AK4AroCvwLKAtMC4QLlAuwC9QL6AwcDCgMcAx8DJAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMm}}

@inproceedings{Forbus2002,
	Annote = {"Queries that include analogical operations can be formulated in the same way as standard logical inference, and analogical processing systems in turn can call on the services of first-principles reasoners for creating cases and validating their conjectures." (in abstract)

case-based reasoning (CBR) systems tend to use only minimal first-principles reasoning.

"the key insight of MAC/FAC is that memory contents should be filtered by an extremely cheap match that filters a potentially huge set of candidates, followed by a structural match (i.e., SME) to select the best from the handful of candidates found by the first stage".


The Analogy Ontology:
Cases - collections of facts / statements treated as an individual unit. (ist-Information ?case ?fact)
Matches - comparison btween a base and target, consisting of correspondences and mappings.
Mappings - A structurally consistent set of correspondences, a set of candidate inferences, and a structural evaluation score.
Correspondences - Relates an item in the base to an item in the target
Pragmatic constraints - restrictions on the kinds of correspondences created during the matching process.
Candidate inferences - Statement in the base that, based on correspondences in mapping, might be brought over into target.
Similarities and differences - qualitatively describes mapping's strengths and weaknesses.

INTEGRATING FIRST PRINCIPLES AND ANALOGICAL REASONING

Since each of the above is given a symbolic way to represent (in the lisp-like parenthetical notation), we can draw it out as an inference. This paper only describes how it is possible, does not go into depth into various ways to integrate it with different types of reasoning. 

"Other cognitive simulations of analogical processing, including ... LISA ..., have only been tested with small examples, and some are known to fail when tested with descriptions even one-tenth the size of what was needed to handle the problems described here." (SNAP!)},
	Author = {Forbus, Ken and Mostek, Thomas and Ferguson, Ron},
	Date-Added = {2012-01-23 11:14:56 -0500},
	Date-Modified = {2013-01-30 20:20:27 -0500},
	Organization = {AAAI/IAAI},
	Pages = {878-885},
	Title = {An Analogy Ontology for Integrating Analogical Processing and First-Principles Reasoning},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0NPR1NZUy1SUy1BTklDQTEtMjAwOS0wNy5wZGbSFwsYGVdOUy5kYXRhTxEB7AAAAAAB7AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHHENPR1NZUy1SUy1BTklDQTEtMjAwOS0wNy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOmrrLQuSDAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLQyrTAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAW01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AENPR1NZUy1SUy1BTklDQTEtMjAwOS0wNy5wZGYAAA4AOgAcAEMATwBHAFMAWQBTAC0AUgBTAC0AQQBOAEkAQwBBADEALQAyADAAMAA5AC0AMAA3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBIVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9DT0dTWVMtUlMtQU5JQ0ExLTIwMDktMDcucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A1ADZAOEC0QLTAtgC4wLsAvoC/gMFAw4DEwMgAyMDNQM4Az0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADPw==}}

@article{Klenk2009,
	Annote = {DTA (domain transfer via analogy) method - For learning new domain theories through cross-domain analogy.

worked solutions - examples that have been worked through and solved.

Summary of MAC/FAC:
MAC - first stage, uses cheap matcher to get few cases from case library
FAC - second stage, narrows down to one case based on structural evaluation score (MAC is unstructured)

They use representations from CycL ontology, "the predicate calculus language of the ResearchCyc knowledge base" (7), plus some of their own extensions.

DTA:
Step 1 - Learn the domain mapping. Use MAC/FAC, then SME
Step 2 - Initialize the target domain theory. For each encapsulated history in the base domain with correct quantities and types, transfer to the target domain theory.
Step 3 - Extend the target domain theory. Do second cross-domain analogy between base and target theoies. Resolve "skolem entities".
Step 4 - Verify the learned knowledge. Retry the problem whose failure began the process. Otherwise forget the domain theory and try again.


"Schwering et al. (2008) identifies the importance of combining analogy with deductive and inductive techniques for achieving human level reasoning."
"Analogy as Integrating Framework for Human-Level Reasoning, In The Proceedings of the 1st Conference on Artificial General Intelligence (AGI-08), Memphis, TN. 419-423."

},
	Author = {Klenk, Matthew and Forbus, Ken},
	Date-Added = {2012-01-23 10:18:01 -0500},
	Date-Modified = {2012-01-23 11:13:04 -0500},
	Journal = {Cognitive Systems Research},
	Number = {3},
	Pages = {240-250},
	Title = {Domain Transfer via Cross-Domain Analogy},
	Volume = {10},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0NPR1NZUy1SUy1BTklDQTEtMjAwOS0wNy5wZGbSFwsYGVdOUy5kYXRhTxEB7AAAAAAB7AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHHENPR1NZUy1SUy1BTklDQTEtMjAwOS0wNy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOmrrLQuSDAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLQyrTAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAW01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AENPR1NZUy1SUy1BTklDQTEtMjAwOS0wNy5wZGYAAA4AOgAcAEMATwBHAFMAWQBTAC0AUgBTAC0AQQBOAEkAQwBBADEALQAyADAAMAA5AC0AMAA3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBIVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9DT0dTWVMtUlMtQU5JQ0ExLTIwMDktMDcucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A1ADZAOEC0QLTAtgC4wLsAvoC/gMFAw4DEwMgAyMDNQM4Az0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADPw==}}

@webpage{Forbus2009a,
	Annote = {Talk given by Forbus at RPI.

TALK BY FORBUS (April 8, 2009)
http://www.cogsci.rpi.edu/pl/issues-cognitive-science-video-archive?vid=85&egid=&pageid=509&siteid=26

Argues that analogy is a "central mechanism of reasoning and learning", as opposed to the skill-based approach taken by most cognitive architectures today.

Suggests we've hit an "inflection point" in AI and cog sci, time to focus on larger scale and more difficult experiments. 

SME does inference in polynomial time, using greedy merging algorithm (since it is an NP-complete problem)

MAC/FAC provides similarity-based retrieval from case library given a problem's interpretation.

Describes his COMPANIONS cognitive architecture. 

Hard-wired in are: Problem categorization (qualitative, numeric or symbolic?), off-the-shelf equation solving, and answer selection. 

Applied it to dynamics questions from AP calculus. The scale is unprecedented, Forbus claims nobody ever attempted this many problems before. They found:
- Hard-wired classification was problematic, sometimes problems were both qualitative and symbolic for example.
- when it achieved relevant examples, which was frequently (he says it was a small size in memory) the analogical reasoning was done well.
- in within-domain problems they got 98.5% accuracy
- cross-domain, MAC/FAC went down to 40% correct retrieval. But when correct precedent, 87% correct in cross-domain transfer.

LEARNING BY READING

His "Learning Reader" system tries to learn from text, and answer questions. This requires an integration of deductive reasoning.

Notes that deductive systems tend to have the property that if they get an answer, they get it quickly; if they take a while to solve it they probably won't get the answer.

Limited to horn clauses.

Uses "Chamera / Charma?"'s "Horn clauses for back(chaining?)" of which there are no publications, but it allows for something cool.

Selmer asks him about generalization and deductive reasoning. Forbus answers that SEQL takes care of most of that these days.},
	Author = {Forbus, Kenneth},
	Date-Added = {2012-01-23 03:26:08 -0500},
	Date-Modified = {2012-03-13 23:44:46 -0400},
	Lastchecked = {1/23/2012},
	Title = {Steps Towards Human-Level AI},
	Url = {http://www.cogsci.rpi.edu/pl/issues-cognitive-science-video-archive?vid=85&egid=&pageid=509&siteid=26},
	Urldate = {4/8/2009},
	Year = {2009},
	Bdsk-Url-1 = {http://www.cogsci.rpi.edu/pl/issues-cognitive-science-video-archive?vid=85&egid=&pageid=509&siteid=26}}

@article{Shure1968,
	Annote = {80 children: 20 each of age 4, 6, 8, and 10, and 40 college students asked to make judgements about stories given to them. Found that "...the concepts for which there was the highest agreement in adults were developed the earliest in childhood."

"This study attempts: (a) to develop a set of propositions that might reasonably be expected to describe the basis of adult judgmets and thus constitute a "naive psychology"; (b) to establish whether these propositions are part of "naive psychology," where adult consensus of opinion is the criterion; (c) to investigate the acquisition of this level of consensus on the basis of judgments made by children at various age levels." (876)

They predefined some typical views of fairness, and then checked how much the subjects accepted or rejected a given postulate (implicitly of course, as they were given stories rather than the postulates directly).

"Nearly 100 per cent of the adult judgments were ... that benefits and obligations should be shared equally under these circumstances (propositions 1 and 4). " There was near universal consensus (among the adults) for some other areas, mostly matching predictions--except for in the area of "ownership".

Among the children:
Even 4 year olds agreed when given situations where both people had equal conditions. When judgements had to take into account generosity and selfishness, older children judged a person "nicer" who "helped clean up when he did not play than one who performed the same act when he did play", than younger children did. This seemed to increase linearly with age. If a child who played refused to clean up, he was seen as selfish more by older than younger children (another almost-linear increase in age). 


Judgements from equal and unequal enjoyment-of-benefits: Even 4 year olds
Judgements from },
	Author = {Shure, Myrna Beth},
	Date-Added = {2012-01-12 17:18:26 -1000},
	Date-Modified = {2012-01-12 17:42:50 -1000},
	Journal = {Child Development},
	Number = {3},
	Title = {Fairness, Generosity, and Selfishness: The Naive Psychology of Children and Young Adults},
	Volume = {39},
	Year = {1968}}

@article{Almas2010,
	Annote = {found that children's views of what is fair tended to start egalitarian (all should get the same amount of reward equally) to meritocratic (people can get more reward based on how much work they do or some other merit). The shift seemed to start from 5th grade and end around 9th grade, but the youngest students were in 5th grade; which doesn't help us with Piagetian concerns because 5th grade is already the start of formal operations stage. 

Interestingly, about 35% of the subjects of all age groups (consistently) were "libertarian": the opposite of the egalitarians, those that thought all inequalities are ok. It's not clear precisely how they differentiated between the libertarians and the meritocrats.},
	Author = {Almas, Ingvild and Cappelen, Alexander W. and Sorensen, Erik O., Tungodden, Bertil},
	Date-Added = {2012-01-12 16:49:26 -1000},
	Date-Modified = {2012-01-12 16:51:39 -1000},
	Journal = {Science},
	Number = {5982},
	Pages = {1176-1178},
	Title = {Fairness and the Development of Inequality Acceptance},
	Volume = {328},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QYC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0ZhaXJuZXNzIGFuZCB0aGUgRGV2ZWxvcG1lbnQgb2YgSW5lcXVhbGl0eSBBY2NlcHRhbmNlLnBkZtIXCxgZV05TLmRhdGFPEQJGAAAAAAJGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfRmFpcm5lc3MgYW5kIHRoZSBEZXZlI0YwRTExLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8OEcs1BbgAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMs1TAgAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoARmFpcm5lc3MgYW5kIHRoZSBEZXZlI0YwRTExLnBkZgAOAHQAOQBGAGEAaQByAG4AZQBzAHMAIABhAG4AZAAgAHQAaABlACAARABlAHYAZQBsAG8AcABtAGUAbgB0ACAAbwBmACAASQBuAGUAcQB1AGEAbABpAHQAeQAgAEEAYwBjAGUAcAB0AGEAbgBjAGUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAGVVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0ZhaXJuZXNzIGFuZCB0aGUgRGV2ZWxvcG1lbnQgb2YgSW5lcXVhbGl0eSBBY2NlcHRhbmNlLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDxAPYA/gNIA0oDTwNaA2MDcQN1A3wDhQOKA5cDmgOsA68DtAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAO2},
	Bdsk-File-2 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QaC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0ZhaXJuZXNzIGFuZCB0aGUgRGV2ZWxvcG1lbnQgb2YgSW5lcXVhbGl0eSBBY2NlcHRhbmNlIHRhYmxlIDIucGRm0hcLGBlXTlMuZGF0YU8RAl4AAAAAAl4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx9GYWlybmVzcyBhbmQgdGhlIERldmUjRjBFMEYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw4PyzUHcQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyzVNwQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAF5NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBGYWlybmVzcyBhbmQgdGhlIERldmUjRjBFMEYucGRmAA4AhABBAEYAYQBpAHIAbgBlAHMAcwAgAGEAbgBkACAAdABoAGUAIABEAGUAdgBlAGwAbwBwAG0AZQBuAHQAIABvAGYAIABJAG4AZQBxAHUAYQBsAGkAdAB5ACAAQQBjAGMAZQBwAHQAYQBuAGMAZQAgAHQAYQBiAGwAZQAgADIALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAG1Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0ZhaXJuZXNzIGFuZCB0aGUgRGV2ZWxvcG1lbnQgb2YgSW5lcXVhbGl0eSBBY2NlcHRhbmNlIHRhYmxlIDIucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAPkA/gEGA2gDagNvA3oDgwORA5UDnAOlA6oDtwO6A8wDzwPUAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA9Y=},
	Bdsk-File-3 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QaC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0ZhaXJuZXNzIGFuZCB0aGUgRGV2ZWxvcG1lbnQgb2YgSW5lcXVhbGl0eSBBY2NlcHRhbmNlIHRhYmxlIDEucGRm0hcLGBlXTlMuZGF0YU8RAl4AAAAAAl4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx9GYWlybmVzcyBhbmQgdGhlIERldmUjRjBFMEQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw4NyzUHVwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyzVNpwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAF5NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBGYWlybmVzcyBhbmQgdGhlIERldmUjRjBFMEQucGRmAA4AhABBAEYAYQBpAHIAbgBlAHMAcwAgAGEAbgBkACAAdABoAGUAIABEAGUAdgBlAGwAbwBwAG0AZQBuAHQAIABvAGYAIABJAG4AZQBxAHUAYQBsAGkAdAB5ACAAQQBjAGMAZQBwAHQAYQBuAGMAZQAgAHQAYQBiAGwAZQAgADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAG1Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0ZhaXJuZXNzIGFuZCB0aGUgRGV2ZWxvcG1lbnQgb2YgSW5lcXVhbGl0eSBBY2NlcHRhbmNlIHRhYmxlIDEucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAPkA/gEGA2gDagNvA3oDgwORA5UDnAOlA6oDtwO6A8wDzwPUAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA9Y=},
	Bdsk-File-4 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QZS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0ZhaXJuZXNzIGFuZCB0aGUgRGV2ZWxvcG1lbnQgb2YgSW5lcXVhbGl0eSBBY2NlcHRhbmNlIGZpZzEucGRm0hcLGBlXTlMuZGF0YU8RAlQAAAAAAlQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx9GYWlybmVzcyBhbmQgdGhlIERldmUjRjBFMEIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw4LyzUHPgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyzVNjgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAF5NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBGYWlybmVzcyBhbmQgdGhlIERldmUjRjBFMEIucGRmAA4AfgA+AEYAYQBpAHIAbgBlAHMAcwAgAGEAbgBkACAAdABoAGUAIABEAGUAdgBlAGwAbwBwAG0AZQBuAHQAIABvAGYAIABJAG4AZQBxAHUAYQBsAGkAdAB5ACAAQQBjAGMAZQBwAHQAYQBuAGMAZQAgAGYAaQBnADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAGpVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0ZhaXJuZXNzIGFuZCB0aGUgRGV2ZWxvcG1lbnQgb2YgSW5lcXVhbGl0eSBBY2NlcHRhbmNlIGZpZzEucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A9gD7AQMDWwNdA2IDbQN2A4QDiAOPA5gDnQOqA60DvwPCA8cAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADyQ==}}

@article{Sun2006,
	Author = {Sun, Ron and Zhang, Xi},
	Date-Added = {2012-01-07 12:29:05 -1000},
	Date-Modified = {2014-01-17 17:27:15 +0000},
	Journal = {Journal of Experimental and Theoretical Artificial Intelligence},
	Number = {2},
	Title = {{Accounting for a Variety of Reasoning Data Within a Cognitive Architecture}},
	Volume = {18},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi5haWo5NS5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDXN1bi5haWo5NS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEoPLLjAAAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLLnZQAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHN1bi5haWo5NS5wZGYADgAcAA0AcwB1AG4ALgBhAGkAagA5ADUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi5haWo5NS5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==}}

@article{Sun1995a,
	Annote = {Early description of the NACS, although he refers to it here as a new cognitive architecture (CONSYDERR)},
	Author = {Sun, Ron},
	Date-Added = {2012-01-07 12:21:35 -1000},
	Date-Modified = {2014-01-17 17:28:19 +0000},
	Journal = {Artificial Intelligence},
	Number = {2},
	Title = {{Robust Reasoning: Integrating Rule-Based and Similarity-Based Reasoning}},
	Volume = {75},
	Year = {1995},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi5haWo5NS5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDXN1bi5haWo5NS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEoPLLjAAAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLLnZQAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHN1bi5haWo5NS5wZGYADgAcAA0AcwB1AG4ALgBhAGkAagA5ADUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi5haWo5NS5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==}}

@article{Prado2011,
	Annote = {Summarize many studies on neuroimaging to find out how the brain carries out some types of deductive reasoning, and found that there is not one area that handles it, which they claim is contrary to Johnson-Laird.},
	Author = {Prado, Jerome and Chadha, Angad and Booth, James R.},
	Date-Added = {2011-12-20 18:56:32 -1000},
	Date-Modified = {2011-12-20 18:57:57 -1000},
	Journal = {Journal of Cognitive Neuroscience},
	Number = {11},
	Pages = {3483-3497},
	Title = {The Brain Network for Deductive Reasoning: A Quantitative Meta-analysis of 28 Neuroimaging Studies},
	Volume = {23},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QjS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1RoZSBCcmFpbiBOZXR3b3JrIGZvciBEZWR1Y3RpdmUgUmVhc29uaW5nXyBBIFF1YW50aXRhdGl2ZSBNZXRhLWFuYWx5c2lzIG9mIDI4IE5ldXJvaW1hZ2luZyBTdHVkaWVzLnBkZtIXCxgZV05TLmRhdGFPEQLMAAAAAALMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfVGhlIEJyYWluIE5ldHdvcmsgZm9yI0YxMjlELnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SncsW0RQAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMsXF2QAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAVGhlIEJyYWluIE5ldHdvcmsgZm9yI0YxMjlELnBkZgAOAM4AZgBUAGgAZQAgAEIAcgBhAGkAbgAgAE4AZQB0AHcAbwByAGsAIABmAG8AcgAgAEQAZQBkAHUAYwB0AGkAdgBlACAAUgBlAGEAcwBvAG4AaQBuAGcAXwAgAEEAIABRAHUAYQBuAHQAaQB0AGEAdABpAHYAZQAgAE0AZQB0AGEALQBhAG4AYQBsAHkAcwBpAHMAIABvAGYAIAAyADgAIABOAGUAdQByAG8AaQBtAGEAZwBpAG4AZwAgAFMAdAB1AGQAaQBlAHMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAJJVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1RoZSBCcmFpbiBOZXR3b3JrIGZvciBEZWR1Y3RpdmUgUmVhc29uaW5nXyBBIFF1YW50aXRhdGl2ZSBNZXRhLWFuYWx5c2lzIG9mIDI4IE5ldXJvaW1hZ2luZyBTdHVkaWVzLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAR4BIwErA/sD/QQCBA0EFgQkBCgELwQ4BD0ESgRNBF8EYgRnAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAABGk=}}

@article{Shultz1994,
	Annote = {Uses cascade-correlation neural network to model Piagetian balance scale task.

"The clarity and replicatability of balance scale phenomena with children, coupled with the classical developmental appeal of its stage-like character, have led to both rule-based (Klahr & Siegler, 1978; Langley, 1987; Newell, 1990) and connectionist (McClelland, 1989) models." (58)

},
	Author = {Shultz, Thomas R. and Mareschal, Denis and Schmidt, William C.},
	Date-Added = {2011-12-03 17:24:21 -0500},
	Date-Modified = {2011-12-03 17:25:14 -0500},
	Journal = {Machine Learning},
	Pages = {57-86},
	Title = {Modeling Cognitive Development on Balance Scale Phenomena},
	Volume = {16},
	Year = {1994},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICg2KS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGZ1bGx0ZXh0ICg2KS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPD13LAAP3AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLAEpHAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZ1bGx0ZXh0ICg2KS5wZGYAAA4AIgAQAGYAdQBsAGwAdABlAHgAdAAgACgANgApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoNikucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@article{Seifert1994,
	Annote = {Uses case-based reasoning to find "predictive features" that help it find appropriate examples of past examples / cases/ plans, and determine whether they are relevant.},
	Author = {Seifert, Colleen M. and Hammond, Kristian J. and Johnson, Hollyn M. and Converse, Timothy M. and McDougal, Thomas F. and Vanderstoep, Scott W.},
	Date-Added = {2011-12-03 17:10:34 -0500},
	Date-Modified = {2011-12-03 17:12:32 -0500},
	Journal = {Machine Learning},
	Pages = {37-56},
	Title = {Case-Based Learning: Predictive Features in Indexing},
	Volume = {16},
	Year = {1994},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICg1KS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGZ1bGx0ZXh0ICg1KS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPD03LAAPkAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLAEo0AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZ1bGx0ZXh0ICg1KS5wZGYAAA4AIgAQAGYAdQBsAGwAdABlAHgAdAAgACgANQApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoNSkucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@article{Turner2002,
	Annote = {Review of Jansen and van der Maas (2002) and Halford et al. (2002). 

Jansen (2002):
"In the end, one might argue that [their] study was design biased in a way to find evidence for rules. ... an interesting future question might be just what sorts of methods and/or data would be required to reject the notion that children use rules in the balance beam problem." (470)
"One aspect [of the paper] that we think could have been more fully developed concerns the psychological significance of children's rule use. What does children's rule use on the balance scale task tell us about cognitive development in general? ... the study could have usefully put this sugestive and potentially important finding into a broader context." (471)

Halford (2002):
Talk about how Halford argues that the rules children use are constrained by complexity (doesn't this just push it back further though). "But the spirit of complexity theory seems to have a more discrete basis, and cognitive progress under this model seems to come in jumps as one goes from N-ary to (N+1)-ary understanding. While one could still envision a discrete change in reasoning leading to a continuous change in performance ..., this is not the case with their data." (473)
"Other researchers have criticized [RC] theory because of the dificulty in comparing children's actual reasoning and the dimensional analyses predicted by the theory (Goswami, 1998; Sweller, 1998). Goswami (1998) argued that there is no way to independently assess the *arity* of the task. Halford et al. (1998) provided an outline for examining the *arity* of reasoning necessary for tasks that, at the very minimum, provides one *possible* way of defining the dimensionality of the task." (479)},
	Author = {Turner, Geoffrey F. W. and Thomas, Hoben},
	Date-Added = {2011-12-03 00:32:45 -0500},
	Date-Modified = {2011-12-03 01:02:56 -0500},
	Journal = {Journal of Experimental Child Psychology},
	Pages = {466-481},
	Title = {Bridging the Gap between Theory and Model: A Reflection on the Balance Scale Task},
	Volume = {81},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NjaWVuY2UgKDMpLnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPc2NpZW5jZSAoMykucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SLcr++/UAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMr/QkUAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAc2NpZW5jZSAoMykucGRmAA4AIAAPAHMAYwBpAGUAbgBjAGUAIAAoADMAKQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvc2NpZW5jZSAoMykucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@article{Jansen2002,
	Annote = {Focus on two questions:
- do children use rules, like Siegler (1976, 1981) proposed? Do they use additional rules?
- How consistently do they use the rules?

LCA (Latent Class Analysis) - Statistical technique that divides the sample into a limited number of latent classes. A class is characterized by a pattern of probabilities that indicate the chance of giving a certain response to an item. This, the authors claim, has some advantages over Siegler's RAM (rule assessment methodology).

Results: They found to what degree children use certain rules based on age (407)},
	Author = {Jansen, Brenda R. J. and van der Maas, Han L. J.},
	Date-Added = {2011-12-02 23:55:26 -0500},
	Date-Modified = {2011-12-02 23:58:17 -0500},
	Journal = {Journal of Experimental Child Psychology},
	Number = {4},
	Title = {The Development of Children's Rule Use on the Balance Scale Task},
	Volume = {81},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NjaWVuY2UgKDQpLnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPc2NpZW5jZSAoNCkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SL8r++/wAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMr/QkwAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAc2NpZW5jZSAoNCkucGRmAA4AIAAPAHMAYwBpAGUAbgBjAGUAIAAoADQAKQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvc2NpZW5jZSAoNCkucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@article{Halford2002,
	Annote = {Analyzes balance scale problem using relational complexity theory, which predicts that understanding based on weight or distance alone should start from age 2, and the ability to integrate weight with distance should come around age 5.

Siegler (1981) found evidence of rules commonly used in balance scale tasks.
Rule I - judgements are based solely on weight, irrespective of distance. Children aged 5 use this, but can be taught to use rule II.
Rule II - the effects of weight are correctly predicted, as with rule I. In addition, distance will be considered only if the weights are first found to be equal.
Rule III - Weight and distance are considered, but difficulty is encountered when weight is greater on one side, and distance is greater on the other.
Rule IV - compare product of weight and distance on each side.

The literature he reviews seems to repeat the following:
- There is little understanding of the balance scale before 5 years of age; RC theory predicts this
- Some see weight rules as primary (Siegler 1981) and some see distance as primary (Surber and Gzesh 1984); RC theory says either one is plausible since the ability to reason over multiple relationships doesn't develop until later. (420)

Predictions of RC theory- (1998a)
"Halford et al. ... presented a computational procedure for determining what effective relational complexity is for a given task." (1998a, Section 3.4.3)

balance-weight(W_left, W_right) - effect of weight
balance-distance(D_left, D_right)

compensation strategy: compute W_left - W_right and W_left - D_right (?? Is this supposed to be D_left?)
weight-difference(W_left, W_right, difference)
distance-difference(D_left, D_right, difference)
if weight-difference > distance-difference, then side with greater weight goes down.

addition strategy: compute sum of number of disks (weight) and steps from the center (distance). Ternary relations are:
+(W_left, D_left, SUM_w,d,l)
+(W_right, D_right, SUM_w,d,r)

product rule: uses quaternary relations:
balance-torque(W_left, D_left, W_right, D_right)
can be segmented by computing and comparing:
X(W_left, D_left, PRODUCT_w,d,l)
X(W_right, D_right, PRODUCT_w,d,r)

Predictions:
- children as young as 2 y.o. should understand weight effects when distance is constant, or vice versa. (Experiment 1)
- If weight and distance both vary, children under 5 will experience difficulty (Experiment 2)
- A large proportion of the age-related variance in balance scale performance should be accounted for by performance on tasks from other content domains that also involve equivalent relational information (analogically mapped?) (Experiment 3)



"A further purpose [of experiment 3] was to assess whether age-related variance in balance scale performance can be explained by the ability to process relational information in two other content domains: transitivity and class inclusion. Both of these concepts have been analyzed elsewhere (Halford, 1993; Halford et al., 1998a) as entailing ternary relations." (429)
},
	Author = {Halford, Graeme S and Andrews, Glenda and Dalton, Cherie and Boag, Christine and Zielinski, Tracey},
	Date-Added = {2011-12-02 19:50:26 -0500},
	Date-Modified = {2011-12-02 23:56:09 -0500},
	Journal = {Journal of Experimental Child Psychology},
	Number = {4},
	Pages = {417-445},
	Title = {Young Children's Performance on the Balance Scale: The Influence of Relational Complexity},
	Volume = {81},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NjaWVuY2UgKDEpLnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPc2NpZW5jZSAoMSkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SKcr+2MgAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMr/HxgAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAc2NpZW5jZSAoMSkucGRmAA4AIAAPAHMAYwBpAGUAbgBjAGUAIAAoADEAKQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvc2NpZW5jZSAoMSkucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=}}

@article{Halford1998,
	Annote = {Explains stage transformations, capacity of reasoning / working memory, and reasoning using logical inferences by using a neural-net-based (PDP) analogical model.

"We define conceptual complexity in terms of dimensionality, which is the number of entities that are related, as defined above. Dimensionality is similar to the idea of degrees of freedom; i.e. the number of independent sources of variation in a particular system."

Describes this conceptual complexity in terms of how many dimensions are used to describe the complexity of a problem. However, according to this, analogical reasoning should not be available until stage 4:
"At the fourth level concepts based on quaternary relations, and compositions of binary operations, can be represented. These include understanding proportion and ability to reason about relations between fractions, as well as understanding concepts such as distributivity, that are based on compositions of binary operations. In a broad sense this level of processing corresponds to Piaget's formal operations stage, which entails relations between binary operations (Halford, 1993a)" (293).

Describes how "chunking" allows for more complex computations -- for example if velocity requires two dimensions (v = s/t) then chunking it allows for more complicated things like acceleration (a = (v2-v1)/t).

Segmentation - splitting up which parts of a complex computation are "looked at" at a time so as to not violate capacity constraints.

Describes understanding of transitivity based on analogical mapping, then:
"This illustrates a point which is of some importance to the theory, which is that mapping into analogs or mental models imposes a processing load, the magnitude of which depends on the complexity of the structure involved." (298)

Summary of his theory: Cognitive growth depends on four factors:
- learning and induction, which allows child to build up a large store of world knowledge, and sources of analogs
- conceptual chunking
- serial processing strategy development (segmentation)
- development of ability to represent concepts of higher dimensionality: "the first three factors are essentially experiential, but the fourth is probably at least partly maturational." (305-306)},
	Author = {Halford, Graeme S and McCredden, J. E.},
	Date-Added = {2011-11-29 20:22:14 -0500},
	Date-Modified = {2011-11-29 21:31:02 -0500},
	Journal = {Learning and Instruction},
	Number = {4},
	Pages = {289-308},
	Title = {Cognitive Science Questions for Cognitive Development: The Concepts of Learning, Analogy, and Capacity},
	Volume = {8},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2hhbGZvcmQucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwtoYWxmb3JkLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxAJyvrYkwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyvse4wAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBoYWxmb3JkLnBkZgAOABgACwBoAGEAbABmAG8AcgBkAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9oYWxmb3JkLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@incollection{Holyoak2001,
	Annote = {Intro for book, but they do cite some interesting examples of analogical reasoning, such as the wave-particle duality of light thing},
	Author = {Holyoak, Keith J. and Gentner, Dedre and Kokinov, Boicho N.},
	Booktitle = {The Analogical Mind: Perspectives from Cognitive Science},
	Chapter = {1},
	Date-Added = {2011-11-20 19:22:16 -0500},
	Date-Modified = {2012-03-08 03:58:51 -0500},
	Editor = {Gentner, Dedre and Holyoak, Keith J. and Kokinov, Boicho N.},
	Publisher = {The MIT Press},
	Title = {Introduction: The Place of Analogy in Cognition},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDEucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFhbmFsb2d5X2NoYXAxLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjyoy4EDAwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4FJUwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBhbmFsb2d5X2NoYXAxLnBkZgAOACQAEQBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXAxLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@article{Christie2010,
	Abstract = {We test whether comparison can promote learning of new relational abstractions. In Experiment 1, preschoolers heard labels for novel spatial pat- terns and were asked to extend the label to one of two alternatives: one sharing an object with the standard or one having the same relational pattern as the standard. Children strongly preferred the object match when given one standard but were significantly more likely to choose the relational match when they compared two standards. Experiment 2 provided evidence that compari- son processing---as opposed to simply seeing two exemplars---is necessary for this relational effect. Preschoolers who were shown the two standards sequen- tially without a prompt to compare them preferred object matches, as did those who viewed only one standard. In contrast, those who saw the exemplars together, with a prompt to compare them, showed the same elevated relational responding as found in Experiment 1. We suggest that structural alignment processes are crucial to developing new relational abstractions.},
	Annote = {"we propose ... comparison between pairs of co-labeled items acts as a mechanism by which new hypotheses - including relational hypotheses - can be formed." (3)

"...children showed relational insight only when they saw the standards simultaneously and were invited to compare them. ... [T]he children did *not* entertain the relational hypothesis in any real sense until they engaged in comparison." (15)

"...[W]e argue that structural alignment provides a natural mechanism for the generation of new hypotheses, which can then be used in subsequent learning" (16).

They found that when given labelled examples of a relational concept, they used relational features to understand the new label, but if given only a single example they used object/semantic features.},
	Author = {Christie, Stella and Gentner, Dedre},
	Date-Added = {2011-10-27 06:16:55 -0400},
	Date-Modified = {2011-10-31 22:27:33 -0400},
	Journal = {Journal of Cognition and Development},
	Number = {3},
	Pages = {356-373},
	Title = {Where Hypotheses Come From: Learning New Relations by Structural Alignment},
	Volume = {11},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NocmlzdGllJkdlbnRuZXJfMjAxMC5wZGbSFwsYGVdOUy5kYXRhTxEB4AAAAAAB4AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHGWNocmlzdGllJkdlbnRuZXJfMjAxMC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOhxzKzqeCAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKzt/CAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAWE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGNocmlzdGllJkdlbnRuZXJfMjAxMC5wZGYADgA0ABkAYwBoAHIAaQBzAHQAaQBlACYARwBlAG4AdABuAGUAcgBfADIAMAAxADAALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAEVVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NocmlzdGllJkdlbnRuZXJfMjAxMC5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A0QDWAN4CwgLEAskC1ALdAusC7wL2Av8DBAMRAxQDJgMpAy4AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADMA==}}

@incollection{Hofstadter2001,
	Annote = {Argues for the fundamental and highly pervasive role of analogy in human thought.

"...reasoning and problem-solving have (at least I dearly hope!) been at long last recognized as lying far indeed from the core of human thought. If analogy were merely a special variety of something that in itself lies way out on the peripheries, then it would be but an itty-bitty blip in the broad blue sky of cognition. To me, however, analogy is anything but a bitty blip--rather, it's the very blue that fills the whole sky of cognition--analogy is *everything*, or very nearly so, in my view."

Talks about the vast lexical storage we have and the concepts contained within, and considers them as a source of source analogs.

Uses his concept of the "central loop" to describe an example of everyday thought (as opposed to complex, focused reasoning).

Has examples of many different translations of the same thing, relates this to analogy (presumably the tight connection between translation and analogy).

Ties this to the Sapir-Whorf hypothesis: If analogy is so central, then it follows that the character of communicated thought (which would serve as source analogues) would have an effect on what kind of thoughts we think (522). Very interesting!

Responds to the Dennett-style criticism of this sort of thinking as being a residue of "Cartesian theater"--where an inner eye watches as various images go parading by:
"To those who would scoff at the ver notion of any "inner screen" involved in cognition, I would point to the large body of work of perceptual psychologist Anne Treisman (e.g., Treisman 1988), which in my view established beyond any doubt the existence of temporary perceptual structures created on the fly in working memory (she calls them "object files')--a start contrast to the connectionist-style thesis that all cognition takes place in long-term memory, and that it consists merely of simultaneous conceptual activations (possibly with attached temporal phases, so as to handle the "binding problem") without any type of transfer to, or structure-building in, a distinct working area." (537)},
	Author = {Hofstadter, Douglas R.},
	Booktitle = {The Analogical Mind: Perspectives from Cognitive Science},
	Chapter = {15},
	Date-Added = {2011-10-25 05:34:53 -0400},
	Date-Modified = {2011-10-25 06:21:11 -0400},
	Editor = {Gentner, Dedre and Holyoak, Keith J. and Kokinov, Boicho N.},
	Publisher = {The MIT Press},
	Title = {Epilogue: Analogy as the Core of Cognition},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDE1LnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSYW5hbG9neV9jaGFwMTUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48tMuBA0wAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMuBSZwAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAYW5hbG9neV9jaGFwMTUucGRmAAAOACYAEgBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAAxADUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDE1LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@incollection{Keane2001,
	Annote = {Discusses how concept composition can NOT be achived using analogical reasoning / structural alignment. Also talks about why the multiconstraint approach is better than the structural alignment approach.

"Although structural alignment can account for results in a number of different domains, it is not a universal theory: in particular, there are a number of results in conceptual combination which it is unable to explain." 

"For the most part, we would defend the use of structure-mapping in the context of analogy, metaphor and similarity. However, we believe that it is inappropriate to extend this account to conceptual combination. Our argument is laid out in the remainder of the paper. First, we outline some of the empirical aspects of conceptual combination that have to be handled by any adequate theory. Second, we describe the dual-process theory, the theory that uses structural alignment, in some detail. Third, we propose an alternative account called the constraint theory. Fourth, we describe some critical evidence favoring the constraint theory over dual-process theory. In conclusion, we consider alternative arguments that may be made against constraint theory from a structure-mapping perspective. Unsurprisingly, perhaps, we consider such alternatives to lack a certain force." (291)

Describes Gentner's structure-mapping theory as having three main components:
1) One-to-one correspondence: comparison process maintains an isomorphism between elements of both domains
2) Parallel connectivity: if two statements are matched, then their arguments should be placed in correspondence, too
3) systematicity principle: larger systems of shared matches are preferred over smaller systems of matches, or fragmented, isolated matches

Types of interpretations in concept combination:
Relational interpretations - establish some relationship between the modifier concept (first word) and head concept (second word). "Bed pencil" would be a pencil you PUT BESIDE your bed, a special pencil USED BY a carpenter for bed making, a pencil USED TO DRAW PATTERNS on bed-clothes, etc. Note the capitalized parts are the relationships.
Property interpretations - A property of one concept is asserted of the other. A pencil SHAPED like a bed, a THIN bed, etc. Supposed to be very common, between 30 and 50 percent of the time (Wisniewski and Gentner 1991).
Conjunctive / Hybrid interpretations - concepts joined in some way, interpretation is both the modifier concept and the head concept. Eg: a big, flat pencil that is a bed for a doll. Note that interpretation describes something that is both a bed, and a pencil.
Known-concept interpretations - interpretation is an existing, known concept. Eg: Pencil case.

They then describe some phenomena related to the "focal concept", which is the main concept of an interpretation: " a bed that is thin" and "a pencil shaped like a bed" have bed and pencil as their focal concepts, respectively. But the first or second word isn't always the focal concept. Although rare, these "focus reversals" happen, like in the phrase "slipper bed"--interpreted as a slipper a chipmunk can sleep in.


DUAL PROCESS THEORY
Proposes that two main mechanisms underlie conceptual combination: structural alignment and scenario construction. Structural alignment is used to explain property interpretations (elephant fish = big fish, for example) and conjunctive interpretations. Scenario construction is used for relational interpretations, so paper won't focus on that.

THE CONSTRAINT THEORY
Rather than saying structural alignment is used in conceptual combination, this theory describes "conceptual combination as a process that constructs representations that satisfy the three constraints of diagnosticity, plausibility, and informativeness." (298)
Diagnosticity - Requires the construction of an interpretation containing diagnostic properties from each of the concepts being combined. Diagnostic properties of a concept are those which occur often in instances of that concept and rarely in instances of other concepts. So "a cactus fish is a prickly fish" because prickly-ness is more diagnostic of cactus than green. Diagnosticity also identifies the focal concept of an interpretation; "the focal concept of an interpretation is defined to be that part of the interpretation that possesses the diagnostic properties of the head noun of the phrase being interpreted."
Plausibility - Requires the construction of an interpretation containing semantic elements that are already known to co-occur on the basis of past experience.
Informativeness - Interpretation must convey a certain amount of new information. "a pencil bed is a bed made of wood" is therefore not acceptable.

"Representationally, like dual-process theory, constraint theory uses schemas with complex internal structures, containing attributes, relations and roles. However, unlike dual-process theory, constraint theory assumes that the combination process has access to a wide range of hetereogeneous knowledge, including prototypes of the concepts being combined, specific instances of those concepts, prototypes and instances of related concepts, general domain theories, and specific event representations involving these and other concepts. In short, constraint theory assumes that, from the beginning of the combination process, there is direct access to many different sources of knowledge. This position is to be contrasted with that of dual-process theory; namely, that the combination process is initially limited to summary, prototype information, with other types of knowledge only being used to elaborate a combined concept initially constructed from these prototypes" (299).
C^3 Model (Contraints on Conceptual Combination) is computational description of this, in Costello and Keane 2000.

Goes on to present evidence in favor of this theory, and responds to some arguments against it.},
	Author = {Keane, M. T. and Costello, F.},
	Booktitle = {The Analogical Mind: Perspectives from Cognitive Science},
	Chapter = {8},
	Date-Added = {2011-10-21 18:47:11 -0400},
	Date-Modified = {2011-10-21 18:50:27 -0400},
	Editor = {Gentner, Dedre and Holyoak, Keith J. and Kokinov, Boicho N.},
	Pages = {287-312},
	Publisher = {MIT Press},
	Title = {Setting Limits on Analogy : Why Conceptual Combination is Not Structural Alignment},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8Qfi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1NldHRpbmcgbGltaXRzIG9uIGFuYWxvZ3kgIFdoeSBjb25jZXB0dWFsIGNvbWJpbmF0aW9uIGlzIG5vdCBzdHJ1Y3R1cmFsIGFsaWdubWVudC4uaHRtbNIXCxgZV05TLmRhdGFPEQKgAAAAAAKgAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfU2V0dGluZyBsaW1pdHMgb24gYW4jRjEyNEYuaHRtbAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8ST8rJMmcAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMrJaqcAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAU2V0dGluZyBsaW1pdHMgb24gYW4jRjEyNEYuaHRtbAAOALAAVwBTAGUAdAB0AGkAbgBnACAAbABpAG0AaQB0AHMAIABvAG4AIABhAG4AYQBsAG8AZwB5ACAAIABXAGgAeQAgAGMAbwBuAGMAZQBwAHQAdQBhAGwAIABjAG8AbQBiAGkAbgBhAHQAaQBvAG4AIABpAHMAIABuAG8AdAAgAHMAdAByAHUAYwB0AHUAcgBhAGwAIABhAGwAaQBnAG4AbQBlAG4AdAAuAC4AaAB0AG0AbAAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAINVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1NldHRpbmcgbGltaXRzIG9uIGFuYWxvZ3kgIFdoeSBjb25jZXB0dWFsIGNvbWJpbmF0aW9uIGlzIG5vdCBzdHJ1Y3R1cmFsIGFsaWdubWVudC4uaHRtbAAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgEPARQBHAPAA8IDxwPSA9sD6QPtA/QD/QQCBA8EEgQkBCcELAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAQu},
	Bdsk-File-2 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDgucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFhbmFsb2d5X2NoYXA4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjzAy4EDJgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy4FJdgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBhbmFsb2d5X2NoYXA4LnBkZgAOACQAEQBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9hbmFsb2d5X2NoYXA4LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@article{Sun2007,
	Annote = {"to capture the verbalization effect, we changed the thresholds at the top level. The hypothesis is that, as explained earlier, verbalization tends to increase top-level activities, especially rule learning activities. To capture the explicit instruction effect, we simply encode the given explicit knowledge at the top level."

For RER, lower threshold means more verbalization (variable named "threshold"), and for IRL, higher threshold means more verbalization (threshold4) (p. 41 for details)

"It was shown in the simulations that IRL contributed more to the capturing of the human data than RER ...[suggesting] explicit hypothesis testing learning (as captured by IRL) was more important than implicit-to-explicit bottom-up learning (as in RER)." (44) [but isn't RER also HF?]},
	Author = {Sun, Ron and Zhang, Xi and Slusarz, P. and Mathews, R.},
	Date-Added = {2011-10-15 14:13:38 -0400},
	Date-Modified = {2011-10-15 14:23:14 -0400},
	Journal = {Neural Networks},
	Number = {1},
	Pages = {34-47},
	Title = {{The Interaction of Implicit Learning, Explicit Hypothesis Testing Learning, and Implicit-to-Explicit Knowledge Extraction}},
	Volume = {20},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi1ubjIwMDYtZi5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEHN1bi1ubjIwMDYtZi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEnnKv0ZLAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKv36LAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHN1bi1ubjIwMDYtZi5wZGYAAA4AIgAQAHMAdQBuAC0AbgBuADIAMAAwADYALQBmAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9zdW4tbm4yMDA2LWYucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@inproceedings{Sun2004b,
	Annote = {Looks at experiments 1,2,4, and 5 from Sloman (1998):
1 and 2 used significant SBR, 3 was mainly RBR, 5 was more of SBR but also RBR.

Experiments:
1) Subjects given pairs of arguments in the form of premise specificity:
	a. all flowers are susceptible to thrips => all roses are susceptible to thrips
	b. all plants are susceptible to thrips => all roses are susceptible to thrips
or inclusion similarity:
	a. all plants contain bryophytes => all flowers contain bryophytes
	b. all plants contain bryophytes => all mosses contain bryophytes

and asked to choose the stronger argument of each pair. People chose the similar ones rather than the correct answers.

2) subjects instead asked to rate likelihood of each argument, from 0 to 1. Means were:
inclusion specificity - 0.89
premise specificity - 0.86

4) same as experiment 2, except this time the category inclusion relation was included:
All plants contain bryophytes. All mosses are plants. => All mosses contain bryophytes.
Similarity-based phenomena almost disappeared.

5) same as experiment 2, except before rating they were asked to make category inclusion decisions. 


Whereas ACS corresponds more to procedural knowledge, the NACS is more declarative knowledge. This paper focuses more on the NACS.

Top level - GKS (general knowledge store). Set of chunks and explicit associative rules linking them.
Chunks are specified by a set of dimension-value  / attribute-value pairs describing an entity, and a chunk label. 1 chunk node per chunk, which is linked to the nodes at the bottom level representing the individual dimension-value pairs.

Bottom level - AMNs (associative memory networks). Implicit associative memories.

"Similarity is automatically computed whenever reasoning involves multiple chunks that are similar to one another."

Simulation setup:
- they created a chunk node for each concept: flowers, plants, etc. "the dimensional values of these chunks were represented as separate nodes in the AMNs, and thus the chunk nodes were linked to the AMNs." However, "although the associative memories were present, they were not very relevant for the performance of this task, because there was no sufficient prior training of the network with any data directly relevant to this task."
- to emphasize SBR, they set c_14=0.5, c_15=1.0.
- to emphasize RBR, they set c_14=1.0, c_15=1.0.
- for experiment 5 (somewhat more SBR), they set c_14=0.88, c_15=1.0
- to train the model, they presented dimension-value pairs (categorical features capturing similarities between entities) to both NACS levels. One pass enabled formation of chunks and associative rules in GKS (but not much implicit knowledge in AMNs).
- during test: when category name was given, it was matched with a corresponding chunk label. The matching chunk was activated to the full extent (1.0). },
	Author = {Sun, Ron and Zhang, Xi},
	Booktitle = {Proceedings of the 26th Annual Conference of the Cognitive Science Society},
	Date-Added = {2011-10-15 12:56:31 -0400},
	Date-Modified = {2014-01-17 17:27:07 +0000},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {{Accounting for Similarity-Based Reasoning within a Cognitive Architecture}},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi5jb2dzY2kwNC5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEHN1bi5jb2dzY2kwNC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEovKvzP3AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKv2w3AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHN1bi5jb2dzY2kwNC5wZGYAAA4AIgAQAHMAdQBuAC4AYwBvAGcAcwBjAGkAMAA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9zdW4uY29nc2NpMDQucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@article{Goswami1990b,
	Author = {Goswami, Usha and Brown, Ann L.},
	Date-Added = {2011-10-13 00:04:30 -0400},
	Date-Modified = {2013-01-30 20:55:55 -0500},
	Journal = {Cognition},
	Number = {3},
	Pages = {207-226},
	Title = {Higher-Order Structure and Relational Reasoning: Contrasting Analogical and Thematic Relations},
	Volume = {36},
	Year = {1990},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2ZpbmFsMi5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCmZpbmFsMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDnHKu+XGAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKvB4GAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZpbmFsMi5wZGYAAA4AFgAKAGYAaQBuAGEAbAAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9maW5hbDIucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==}}

@article{Goswami1990a,
	Annote = {she first agrees with the Piaget and Sternberg & Negro claim that younger children tend to solve analogies by association rather than true analogical reasoning. But "this is not evidence that younger children can solve analogies *only* by association, and cannot reason about higher-order relations." (72)

Similarly, "the developmental claim about younger children's ability to solve problem analogies [which says they tend to use surface similarity features] is very similar to the developmental claim about younger children's ability to solve classical analogies. ... Instead, they solve analogies by simpler strategies. These include solutions based on surface similarity (Gentner), solutions based on association (Sternberg), or solutions based on a combination of these lower-order relations (Piaget)." (73)

HYPOTHESIS: "Basing analogies on familiar causal mechanisms shoud support the extraction of higher-order relations and facilitate analogical reasoning."

Full list of analogies used given

She names four types of errors:
E = wrong object, correct transformation
F = correct object, wrong transformation
G = mere appearance match
H = thematic / category match
she then showed how these errors dropped between 3 and 4 year olds

"The data do not appear to support the idea that children fall back on mere appearance matching (response G) or associative relations (response H) when they are unable to complete the analogies. However, the frequent selection of response F could in fact arise from a mere appearance matching strategy." (81-82)

Experiment 2 tried to verify that the results in experiment 1 weren't due to appearance matching on the actual pictures given to the children. "The results clearly showed that this was not the case. ... This confirms that children as young as 3 years of age can solve analogies based on the relations of physical causality used in Experiment 1 without requiring surface similarity as a support cue." (91)

"We believe that the typical failure of children younger than 12 years in classical analogy tasks (e.g., Piaget et al. 1977; Sternberg & Nigro, 1980; Goldman et al., 1982) is due to task artifacts and not to a lack of cognitive competence. ... [S]uch failures stem from the use of higher-order relations that were too difficult for younger children to reason about." (92)

"However, if relations which are very difficult for young children form the basis of analogies, such as the complex causal relations used by Piaget et al. (1977) or the abstract semantic relations used by Sternberg and Nigro (1980), children will fall back on other strategies of analogy solution."


Pre-linguistic children are tested for analogical ability using experiments like one where they push an object to the edge of a table and beyond, without it falling. They look at it longer. "The recognition of how much contact is required to support an object in different situations must require a degree of relational comparison between one situation and the rest" (450). Another experiment where they are given *problem analogies*: They are shown how to solve a problem, then given an instance where they have a similar problem, such as using a string to reach a toy out of their reach. "They had to remove the barrier, to pull on the cloth so that the string attached to the toy came within their grasp, and then to pull on the string itself so that they could reach Ernie. Following success on the first trial, two different toy problem scenarios were presented, each using identical tools (cloths, boxes, and strings). However, each problem appeared to be different to the problems that preceded it, as the cloths, boxes and strings were always dissimilar to those encountered before. In addition, in each problem *two* strings and *two* cloths were provided, although only one pair could be used to reach the toy" (446).

"Infants and young children seek to *explain* their every day worlds to themselves." (448)

"There is quite a lot of evidence that infants are sensitive to cause-effect relations by about six months of age (See Goswami 1998 for a review). Other types of relations, such as spatial relations (*above* and *below*) and quantitative relations (*more than* and *less than*) are also detected by this age" (450).},
	Author = {Goswami, Usha and Brown, Ann L.},
	Date-Added = {2011-10-13 00:00:56 -0400},
	Date-Modified = {2014-01-29 00:20:59 +0000},
	Journal = {Cognition},
	Number = {1},
	Pages = {69-95},
	Title = {{Melting Chocolate and Melting Snowmen: Analogical Reasoning and Causal Relations}},
	Volume = {35},
	Year = {1990},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2ZpbmFsMS5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCmZpbmFsMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDhXKu+VIAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKvB2IAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZpbmFsMS5wZGYAAA4AFgAKAGYAaQBuAGEAbAAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9maW5hbDEucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==}}

@article{Hummel1997,
	Annote = {A much older version of LISA, replaced by (Hummel
                  2003).  Some notes about what factors increase
                  throughout development: A similar pattern is
                  apparent within the course of human cognitive
                  development.  Sensitivity to abstract relational
                  similarities increases with age (Smith, 1989), and
                  children's ability to comprehend deeper and more
                  complex analogies increases at least up until age
                  twelve (Phenomenon 14) (e.g., Gentner, 1988;
                  Goswami, 1989; Johnson & Pascuale-Leone, 1989).
                  This developmental pattern is doubtless in part due
                  to increases in children's knowledge; however, there
                  is also evidence that the shift is in part due to
                  maturational increases in the capacity of working
                  memory (Halford, 1992, 1993). (8) LISA does not by
                  any means provide a definitive explanation or even
                  description of phylogenetic and developmental
                  change; rather, as a theory of the adult human
                  architecture for analogical comparison, it provides
                  a set of potential hypotheses about constituent
                  mechanisms that may have evolved and/or may undergo
                  maturation.  Adult human competence in analogy, as
                  modeled by LISA, has the following requirements: (1)
                  the capacity to perform dynamic binding (which is
                  necessary for propositional thought); (2)
                  hierarchically-organized structure units that store
                  bindings in LTM; (3) both parent and daughter modes
                  of processing (to enable mapping of hierarchical
                  propositions despite the one-level restriction); (4)
                  the capacity to learn mapping connections; and (5)
                  attentional control of a phase buffer (working
                  memory) that strategically drives the comparison
                  process.  The above list, although not exhaustive,
                  at least provides some relatively specific
                  hypotheses about capacities that may undergo
                  phylogenetic and/or developmental change.  Our final
                  set of simulations explores one particularly simple
                  variable in LISA that may account for differences in
                  the complexity of analogies that can be mapped by
                  different individuals.  This variable is the size of
                  the phase set: the number of distinct role bindings
                  (SPs) that can be considered together prior to
                  updating the mapping connections.  Developmental and
                  phylogenetic limitations on the size of the phase
                  set may reflect a number of specific factors.  The
                  most intuitive is physiological: As noted in the
                  Introduction, the temporal properties of neural
                  firing necessarily limit the number of groups that
                  can be simultaneously active but mutually
                  desynchronized.  But this is by no means the only
                  variable (or necessarily even one of the variables)
                  that might affect phase set capacity.  Others
                  include (a) attentional and strategic variables
                  (i.e., what an individual knows to place into the
                  phase set together, as related to requirement (5)
                  above), (b) differences in the way a problem is
                  represented, and (c) differences in the
                  attentional/cognitive resources required by other
                  aspects of the task or by other tasks that must be
                  performed concurrently (e.g., a person who is
                  distracted may evidence a smaller phase set capacity
                  than a person who is free to devote full resources
                  to the mapping task).  We are not committed to any
                  strong claims about the origins of developmental
                  and/or phylogenetic differences in phase set size.
                  Rather, we are more interested in how such
                  differences may manifest themselves in an
                  individual's ability to perform mapping tasks of
                  varying complexity. (42) They actually simulate the
                  performance of children in different stages of
                  cognitive development (p 43-47), the factors they
                  use to simulate this were the size of the phase set:
                  when it only fired one binary proposition at a time,
                  it was worse off than when it fired two binary
                  propositions at a time. (page 46) "Every analog is
                  represented by a hierarchy of this type for each
                  proposition it contains. Object and predicate units
                  are not repeated within analogs. For example, if
                  John serves as an argument to multiple propositions
                  in a given analog, the same John unit will be
                  connected to multiple SP units. Each type of
                  structure unit plays an important role in the LISA's
                  operation. Having separate units for roles, objects,
                  and propositions allows the model to treat each such
                  entity as an entity, a capacity that is critical for
                  mapping analog elements onto one another. At the
                  same time, it is important to emphasize that the
                  structure units do not directly encode
                  meaning. Rather, they work together to impose (and
                  respond to) particular patterns of synchrony on the
                  semantic units; it is the only latter that encode
                  meaning."},
	Author = {Hummel, John E. and Holyoak, Keith J.},
	Date-Added = {2011-10-12 19:49:23 -0400},
	Date-Modified = {2011-10-16 01:17:27 -0400},
	Journal = {Psychological Review},
	Pages = {427-466},
	Title = {{Distributed Representations of Structure: A Theory of Analogical Access and Mapping}},
	Volume = {104},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0xJU0ExLnBkZtIXCxgZV05TLmRhdGFPEQGgAAAAAAGgAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcJTElTQTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Qlsq7n7kAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMq71/kAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBITWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoATElTQTEucGRmAA4AFAAJAEwASQBTAEEAMQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIANVVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvTElTQTEucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMEAxgDOAnICdAJ5AoQCjQKbAp8CpgKvArQCwQLEAtYC2QLeAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAuA=}}

@article{Hummel2003b,
	Author = {Hummel, John E. and Holyoak, Keith J.},
	Date-Added = {2011-10-12 18:30:30 -0400},
	Date-Modified = {2011-10-12 18:32:31 -0400},
	Journal = {Psychological Review},
	Pages = {220-264},
	Title = {{A Symbolic-Connectionist Theory of Relational Inference and Generalization}},
	Volume = {110},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2xpc2EyLnBkZtIXCxgZV05TLmRhdGFPEQGgAAAAAAGgAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcJbGlzYTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8QmMq7jTYAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMq7xXYAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBITWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAbGlzYTIucGRmAA4AFAAJAGwAaQBzAGEAMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIANVVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvbGlzYTIucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMEAxgDOAnICdAJ5AoQCjQKbAp8CpgKvArQCwQLEAtYC2QLeAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAuA=}}

@article{Bringsjord1991,
	Annote = {(INSERT NOTES FROM EARLIER)

---------------------------------------
Some propositions:

Connectionism vs Logicism
C_H - Hyper-Connectionism: symbolic thought is an illusion, epiphenomenon arising from neural network
C_S - Strong Connectionism: Cognition is, at bottom, the dynamical flow of subsymbolic information through a neural network
C_W - Weak Connectionism: "Rep but no rules." The brain uses symbolic representation a la logicism, but its processing is connectionist.
L_W - Weak Logicism: "From the ground up." Symbolic representation grounded bottom-up in iconic representations and feature detectors.
L_S - Strong Logicism: Logicism and connectionism pursued moduarly; in future they meet via connectionist-build "hook-ups" to outside world, which will send in low-level info to be translated into symbolic form for robot agent (Fodor, Pylyshyn, Pollock)
L_H - Hyper Logicism: Symbolic thought is all that is needed for genuine robot agent; no need for "human-like" interaction with physical world.

PBP - AIniks will succeed in building a robotic person S*.
PBP_C - Connectionist AIniks will succeed in building a robotic person S_C*
PBP_I - Logicist AIniks will succeed in building a robotic person S_L*, meeting will be "top-down"

PER_AUT - Persons are automata.
PER_TUR - Persons are TMs
PER_NN - Persons are neural networks.
PER_CA - Persons are cellular automata.
*note the PER_x propositions focus mostly on baseline computing power, and since sensors don't add or take away from this a separate prop is not needed

AI-F (AI Functionalism) - For every two 'brains' x and y, possibly constituted by radically different physical stuff: if the overall flow of information in x and y, represented as a pair of flow charts (or a pair of Turing machines, machine diagrams, etc) is the same, then if 'associated' with x there is an agent s in mental state S, there is an agent s' 'associated' with y which is also in S.

Church-Turing related:
CTT - Whatever can be rendered as an algorithm can be rendered as a suitable programmed TM, and vice versa.
CTT* - Whatever can be accomplished by a computing machine of any sort, can be accomplished by a suitably programed Turing machine.
ANA - A true analog, neural net can compute things which no Turing machine can.
ANA* - A true analog, neural net can compute things that cannot be expressed as algorithms.

Physical Symbol System Hypothesis:
SYM - If (PBP), then S* must be such that some of the propositions O0, O1, ... which are objects of S*'s occurrent deliberations (and hopes, fears, etc.--the objects of her propositional attitudes) are represented by formula <<O1>>, <<O2>>, ... of some symbol system L^T, where they can be processed according to the reasoning mechanism that is part of L^T. [Note that this is a symbol system, NOT the language of thought. This is consistent with SOAR, for example: "Symbol systems subsume particular logicist architectures.]

Relations:
R1: (ANA) -> -(CTT*)
R2: ((ANA) ^ (CTT)) -> (ANA*)
R3: (PBP) -> ((SYM) -> (PER_TUR))     ***some people claim this is true
(LEFT OFF ON PAGE 329)
---------------------------------------},
	Author = {Bringsjord, Selmer},
	Date-Added = {2011-10-11 02:29:30 -0400},
	Date-Modified = {2014-01-17 17:22:14 +0000},
	Journal = {Journal of Experimental and Theoretical AI},
	Pages = {319-349},
	Title = {{Is the Connectionist-Logicist Clash One of AI's Wonderful Red Herrings?}},
	Volume = {3.4},
	Year = {1991},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Nvbm5lY3Rpb25pc3RfbG9naWNpc3RfY2xhc2gucGRm0hcLGBlXTlMuZGF0YU8RAfoAAAAAAfoAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx9jb25uZWN0aW9uaXN0X2xvZ2ljaXMjRjBENUMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw1cyrl+gQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyrm2wQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAF5NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBjb25uZWN0aW9uaXN0X2xvZ2ljaXMjRjBENUMucGRmAA4AQgAgAGMAbwBuAG4AZQBjAHQAaQBvAG4AaQBzAHQAXwBsAG8AZwBpAGMAaQBzAHQAXwBjAGwAYQBzAGgALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAExVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Nvbm5lY3Rpb25pc3RfbG9naWNpc3RfY2xhc2gucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A2ADdAOUC4wLlAuoC9QL+AwwDEAMXAyADJQMyAzUDRwNKA08AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADUQ==}}

@article{Bringsjord1998b,
	Annote = {Leibnitz's law requires second order logic to be expressed

Goes over different types of logics. He summarizes the "wise man puzzle"'s formalized solution by Thayse (1989):

"In the late 1960s, the AI community was boiling with a debate over whether knowledge is better represented for AI purposes declaratively or procedurally. ... In 1974, Robert Kowalski showed the equivalence of a Horn-clause representation and a procedural representation of knowledge. ... Implementation decisions regarding a commitment to procedural or declarative representations, after Kowalski's work, were best viewed as issues of programming style rather than of anything more substantive" (289)

"At the core of that argument [in Bringsjord's "wonderful red herrings" paper] was a chain of mathematical equivalence holding between Turing machines, k-tape Turing machines, cellular automata, and (standard) neural nets - a chain that played a role in an argument designed to show that, at bottom, CAI and LAI are, contra Smolensky (author of the CAI manifestos Smolensky 1988a and 1988b), perfectly consistent with each other." (298)

"Honest LAIniks will concede that their systems have fared poorly in realizing the acquisition function. Pure LAI systems ... traditionally remove this function from the system itself: they have an external human designer simply populate a pre-defined ontology ... Connectionists *have* enjoyed impressive success in the acquisition, recognition and action functions." (299).

Chart comparing CAI to LAI in several categories (300) gives strength advantages to LAI in Derivation and Communication, weakness in Acquisition.

"Our conclusion is that if in the future we desire not only to *build* human-matching robots (or androids), but to *understand* them (and cognition in general) as well, then the logic-AI marriage ought to be sustained" (303)

},
	Author = {Bringsjord, Selmer and Ferrucci, David},
	Date-Added = {2011-10-04 01:05:41 -0400},
	Date-Modified = {2011-10-04 03:28:15 -0400},
	Journal = {Minds and Machines},
	Pages = {273-308},
	Title = {Logic and Artificial Intelligence: Divorced, Separated, Still Married ...?},
	Volume = {8},
	Year = {1998}}

@article{Sun2001a,
	Annote = {Discusses consciousness, makes the primary argument that it is difference in representation and ease of accesibility that makes conscious knowledge different from unconscious knowledge.

Has a definition based on how easy it is for knowledge to be given conceptual labels. "Explicitness of a representation is therefore defined as the inverse of Kolmogorov complexity of its transformation, a theoretical measure of the algorithmic complexity (Li & Vitanyi, 1997)" (5). Localist representations have lower Kolmogorov complexity compared with distributed representations, for example.

Argues that as far as mechanistic explanations of consciousness go, knowledge content, knowledge organization, and knowledge processing are all insufficient explanations--only knowledge representation remains.

"Since localist representation is a prerequisite for synergy and meta-level control, and localist representation necessarily leads to accessibility, we believe that conscious awareness is a necessary result, not a mere coincidence." (7)

A more detailed paper is in Coward & Sun 2004, which actually suggests mappings from CLARION's components on to physiological features of the brain. in it:
temporal lobe - correlated w/consciously controlled sequence learning (Keele, Ivry, Hazeltine, Mayr & Heuer, 1998)
frontal lobe - correlated with explicit recall of sequences (Posner, DiGirolamo & Fernandez-Duque, 1997). Suggests these two correspond to top level of CLARION.w},
	Author = {Sun, Ron},
	Date-Added = {2011-10-02 06:29:43 -0400},
	Date-Modified = {2014-01-29 00:24:18 +0000},
	Journal = {Journal of Cognitive Systems Research},
	Number = {4},
	Pages = {241-249},
	Title = {Computation, Reduction and Teleology of Consciousness},
	Volume = {1},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi5qY3NyMDEucGRm0hcLGBlXTlMuZGF0YU8RAbQAAAAAAbQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rw5zdW4uamNzcjAxLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxKSyq27PwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyq3zfwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAE1NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBzdW4uamNzcjAxLnBkZgAADgAeAA4AcwB1AG4ALgBqAGMAcwByADAAMQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAOlVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvc3VuLmpjc3IwMS5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDGAMsA0wKLAo0CkgKdAqYCtAK4Ar8CyALNAtoC3QLvAvIC9wAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAL5}}

@article{Helie2010,
	Annote = {Talks about their theory of reasoning, EII (Explicit-Implicit Interaction) which has 5 main principles:

1) The coexistence of and difference between explicit and implicit knowledge.
2) The simultaneous involvement of implicit and explicit processes in most tasks.
3) The redundant representation of explicit and implicit knowledge.
4) The integration of the results of explicit and implicit processing.
5) The iterative (and possibly bidirectional) processing.

This paper also discusses some alternate theories of creative problem solving, especially as they pertain to that "moment of insight".
FOK - Feeling of knowing; that "eureka" moment (995). Also in (Yaniv and Meyer 1987).
ICL - Internal confidence level, used in this theory to keep track of FOK, which is supposed to happen when ICL reaches a certain threshold "that defines what is meant by *definitive result*".(998)

		Goes through several CLARION simulations which match psychological data, all related to the insight emergence.
},
	Author = {Helie, Sebastien and Sun, Ron},
	Date-Added = {2011-09-27 20:54:58 -0400},
	Date-Modified = {2011-09-27 21:42:17 -0400},
	Journal = {Psychological Review},
	Number = {3},
	Pages = {994-1024},
	Title = {Incubation, Insight and Creative Problem Solving: A Unified Theory and a Connectionist Model},
	Volume = {117},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2hlbGllLXN1bi1wc3ljcmV2MjAxMC1mLnBkZtIXCxgZV05TLmRhdGFPEQHoAAAAAAHoAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcbaGVsaWUtc3VuLXBzeWNyZXYyMDEwLWYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8QHsqn81IAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMqoK5IAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBaTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAaGVsaWUtc3VuLXBzeWNyZXYyMDEwLWYucGRmAA4AOAAbAGgAZQBsAGkAZQAtAHMAdQBuAC0AcABzAHkAYwByAGUAdgAyADAAMQAwAC0AZgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAR1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvaGVsaWUtc3VuLXBzeWNyZXYyMDEwLWYucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOANMA2ADgAswCzgLTAt4C5wL1AvkDAAMJAw4DGwMeAzADMwM4AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAzo=}}

@book{Chapman1988,
	Annote = {Entire book is an attempt to chronicle Piaget the philosopher, rather than limiting him to child psychology. 

Tries to answer the charge that Piaget's theory was too descriptive and not explanatory. Piaget himself seemed to believe that description comes first, then a middle stage, and finally full explanation. he seemed to think it was somewhere in the middle. (339-340) So although he did apparently believe that his abstract models did "correspond to real causal mechanisms of some kind, he did not attempt for the time being to specify the nature of those mechanisms" (340). 

He talks about how Piaget's stage theory is criticized by the existence of asynchronous development among tasks presumably belonging to the same stage. But it turns out to be a bit more complicated. The "horizontal decalage" Piaget and Inhelder described is one example of this asynchrony. "Although Piaget (1941, 1950/1974a) tried to explain the occurrence of such decalages within his theory, some interpreters have argued that the existence of asynchrony across domains of content cannot be reconciled with a concept of structure that unites the domains in question." (341)

He then tries to answer a "more serious charge": that even some of the explanations and predictions of Piagetianism are apparently false. The famous charge is the one ascribing asynchrony, which is claimed to be inconsistent with the apparent synchrony of stage development. He answers this by first nothing the different types of asynchrony:
1) Content Decalages: Developmental lags between the ages at which a given structure emerges with respect to different areas or domains of content. Ex: The one "reported to exist between analogous operations applying to logico-mathematical content versus infralogical content" (341). 
2) Within Domains: Asynchrony among groupings within, but not necessarily between, domains of content. It turns out that Piaget actually specifically stated that synchronous development here should not be expected. (Pinard & Laurendeau 1969). 
3) Procedural Decalages: Different versions of the same task solved by children at different ages, particularly children who are supposed to be younger than the ages at which the necessary skills to solve such problems develop. The methode clinique doesn't rule out the possibility that children can still solve tasks procedurally, even though they may not be able to declaratively explain why or even consciously know why. 
4) Specific structural issues: Having to do with Piaget's specific hypotheses having to do with particular structures: Piaget might suggest that one structure is necessary for another, for example, therefore performance ability regarding them should emerge in the appropriate order.

Responds to them all as follows:

1) CONTENT DECALAGES:

"The idea that the concept of *structures d'ensemble* implies developmental synchrony across content areas is based on a confusion between *formal analogies* and *functional totalities*. The fact that Piaget recognized the same formal structure (e.g., one of the eight groupings) to characterize thinking in different areas of content does not imply that these areas are united in any single functional totality. ... The idea that *structures d' ensemble* imply developmental synchrony results from a confusion of Piaget's specific concept of *structures d'ensemble* as relational totalities with the notion of "structural unity" across domains of content. This latter notion he specifically denied." (346-7)

In fact, Piaget did not even believe in the existence of general stages. "In a discussion among the contributors to a 1955 symposium in Geneva on the problem of stages in child development, Piaget justified his lack of belief in general stages by denying what he called the "structural unity of the person." The latter phrase was his term for the idea that all behaviors of an individual of a given stage are manifestations of a single structure. "Nowhere have I seen structural unity, at no stage in the development of the child ... And if there is no structural unity, there are no general stages that permit fixed correspondences, verifiable in all domains and between all functions" (Piaget in Osterrieth et al., 1956, p. 58). In short, contrary to widely accepted interpretations of his theory, Piaget did not believe in general stages of development characterized by developmental synchrony across domains of content" (346-7).

"The fact that Piaget's structural-stage theory does not imply developmental synchrony across areas of content was pointed out by ... Pinard and Laurendeau (1969), Brainerd (1978a), Longeot (1978), and Gelman and Baillargeon (1983), among others." (347)
Citations:
Brainerd 1978 - Piaget's Theory of Intelligence (book)
Gelman and Baillargeon 1983 - A review of some Piagetian concepts. In P.H. Mussen (Ed), Handbook of child psychology (4th ed., vol. 3, p. 167-230).
Longeot 1978 - Las stades operatoires de Piaget et les facteurs de l' intelligence. Grenoble: Presses Universitaires de Grenoble.
Pinard and Laurendeau 1969 - "Stage" in Piaget's cognitive-developmental theory: Exegesis of a concept. In D. Elkind & J.H. Flavell (Eds.), Studies in cognitive development (p. 121-170).

2) WITHIN DOMAINS:

Piaget's conclusions in "The early growth of logic in the child" shows surprise that classification and seriation applied to similar contents developed at roughly the same time (348). "Piaget's writings contain no suggestion that all structures belonging to any developmental stage are united in a single functional totality and must therefore develop in synchrony."

3) PROCEDURAL DECALAGES: WITH DIFFERENT VERSIONS OF THE SAME TASK

He notes that we must question the assumption that the logical form of the new version of the problem is the same, which is not necessarily so easy to do. This has to do with how the subject actually goes about solving the task. Example is given with the transitive reasoning task: "Chapman (1978a) argued that whereas the "standard" Piagetian version of this task (in which comparison objects are visible only two at a time) ensures that a transitive inference can be drawn only from an *operational* composition of premise relationships, the "alternate" version (in which comparison objects are all simultaneously visible and arranged from left to right according to length) allows children to make a correct inference through the use of *functional* reasoning: When children are presented the "premise" relationships among adjacent objects in the latter version, they learn in effect that the longer of the two objects is always on the right (or left). The "transitivity" question regarding the relation in length between nonadjacent objects can be inferred as a function of their (right-left) relation in space, and the individual "premise" relationships need not be considered at all." (351)

"In [Chapman's] view, the reason why Braine (1959) found children to exhibit "transitivity" at an earlier age than in studies using typical Piagetian methods was not because he succeeded in eliminating the extraneous efects of their verbal skills but because his training procedure incidentally allowed children to generate a correct answer through single-premise inferences." (354)

"The existence of procedural decalages therefore cannot be interpreted as contradicting the structural aspects of Piagetian theory unless one can demonstrate that variations in procedures indeed produce tasks that are solved at different ages *with the same form of reasoning*." (355)

4) SPECIFIC STRUCTURAL ISSUES

He questions the methods in which specific experiments are carried out.},
	Author = {Chapman, Michael},
	Date-Added = {2011-09-21 12:14:52 -0400},
	Date-Modified = {2011-09-21 23:10:55 -0400},
	Publisher = {Cambridge Univ Press},
	Title = {Constructive Evolution: Origins and Development of Piaget's Thought},
	Year = {1988}}

@incollection{Piaget2001,
	Annote = {They had mixed up pictures, and made sure the child understood which each was. They asked the child to put the pictures in pairs, based on what seemed "to go well together." Then they would ask them to put the pairs into pairs (so 4 pictures in an analogical relationship), helping them along by suggesting things if they got stuck: "What lets the bird stay warm in the winter? Feathers." After analogies were formed, the experimented would propose some counterexamples: would a nest go as well as the fur? This would elicit justifications for their choice, or get them to submit, suggesting a weak, arbitrary choice was made initially.

STAGE 1: (5-6 yrs)
They make some mistakes that suggest they don't understand the problem. Where a typical analogy is 1:2::3:4, they relate 1 and 4 using some justification, which has nothing to do with the analogy (which in this case was correct: tiller:boat :: handlebar:bicycle). However, clearly they do get SOME analogies correct, which shows that even Piaget didn't think that analogical reasoning was impossible with children, just that they had a weak grasp of it.
Piaget: "we can say that the failure to construct relations between relations, or forms of forms, at the more primitive stages comes about because there are as yet no stable elementary relations (and we mean two-term relations here, not four-term relations). Consequently there are no simple forms that can be expressed in terms of stable classes." (143) "Still, ... in certain situations ... we can see the dawning of a momentary approximation to analogies. These analogies are not yet based on classes, but on the salience of an action scheme that is more resistant than the others. So, for instance, handlebars-bicycle and tiller-boat go together because "they're for driving" and cork-bottle goes with lid-pot because they're used to close containers" (144). 
Relations tend to be qualitative and finalistic--("it's for")--when "nondescript and arbitrary relations are first stripped away." But even the choice of general over arbitrary characteristics has very little consistency. The exceptions are particularly salient action schemes, like "steering" for the bicycle and the boat.

STAGE 2: (7-8 to 10-11)
Level IIA: Rather than relating objects to one another (intensional, qualitative meanings) they group them based on an extensional, class feature. "their common qualities correspond extensionally to a class. This may seem like a feeble advance but in reality it is considerable, for it leads to quantification, to inclusion, etc. --- in short to the constitution of concrete operations." (147) But they "still give in when confronted with counter-suggestions."
Level IIB: Main difference is they start to resist countersuggestions. But their justification for resisting doesn't seem to contain stable analogical reasoning, just vague "groping" features (nests don't have hair, etc)

STAGE 3:
They almost completely eliminate the "groping", and start rejecting counterexamples. "At Stage I children will accept any nondescript countersuggestion, because the relations that they have established are themselves nondescript; they fail to make i all of the terms in a set of four at once." (148) 

There is nothing for Stage 4, which I assume is because by this stage analogies are already a fully acquired skill.

"The construction of analogies makes an even prettier example of reflecting abstraction ... [For example, in the reactions of Level IA, they] show to what degree empirical abstraction is incompetent to attain the important characteristics of the object on its own, without activity by the subject."

"As for the passage from analogies to proportions, we previously noted with Barbel Inhelder [cites "The Growth of Logical Thinking"] that the constitution of every metric proportion (in all of the varied problems presented in that work) was preceded by its elaboration on a qualitative level. In other words, the development of a metric proportion is preceded by the understanding of the corresponding analogy, before measurements are introduced. The only difference between the relevant analogies in this case, and analogies in general, is that those that are precursors to proportions range over covariations. It is because these analogies involve covariation that they allow an interplay of compensations and the equality of cross-products, as one of us has shown for what he called "logical proportions." " (152)},
	Author = {Piaget, Jean and Montangero, Jacques and Billeter, J.B.},
	Booktitle = {Studies in Reflecting Abstraction},
	Date-Added = {2011-09-20 20:51:20 -0400},
	Date-Modified = {2014-01-29 00:22:03 +0000},
	Editor = {Campbell, Robert},
	Publisher = {Psychology Press},
	Title = {{The Formation of Analogies}},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2ltZzAwNC5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCmltZzAwNC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEHTKzN58AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKzRa8AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGltZzAwNC5wZGYAAA4AFgAKAGkAbQBnADAAMAA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9pbWcwMDQucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==}}

@incollection{Goswami2001,
	Annote = {Relational Similarity Constraint - Originally from Goswami 1992, a requirement that analogies require relational/structural and surface similarities. "In order to examine the development of "pure" analogical reasoning in children, therefore, we need to examine their understanding of the relational similarity constraint in the *absence* of surface similarity." (438) what?

Item Analogy Task - Two items A, B presented to child. Third item C is presented, child is asked to generate D. Requires relational similarity constraint. Piaget used pictorial versions. Piaget "concluded that younger children solved analogies on the basis of associations (see also Sternberg and Nigro 1980). He argued that children only became able to reason on the basis of relational similarity at around eleven to twelve years of age. ... Closer inspection of Piaget's experimental methods, however, suggest that his conclusions about analogical development were too negative (Goswami 1991)." (439)

Relational Familiarity hypothesis (Goswami 1992) - She argues that one problem was Piaget didn't check to make sure children understood what steering wheels did, etc. They were using unfamiliar items and concepts. She gave multiple choice questions with simpler, familiar concepts and they were able to perform above chance. Tested 4, 5, and 9 year olds, percentages were 59, 66, and 94 percent. Relational familiarity hypothesis is the "idea that children's analogical performance depends on their relational knowledge" (443).

Analogical Reasoning in Infants and Toddlers - For very young children, researchers have created *problem analogies* to show analogical reasoning. Similar problems are given: for the first, the solution may be modeled by a parent. Children were then able to solve the second (which was different but analogous in some way). Freeman (1996) came up with a similar technique, except it was purely mental: they gave an example of something being used to help something fly, then a similar hypothetical problem was presented.

Relational Primary hypothesis (Goswami 1992, 1996) - "the notion that relational processing may be active from early in primacy" (448).

Describes Pauen (1996)'s "force table" which is meant to show that "analogy is an important mechanism for understanding physical principles" (456). 

ANALOGIES IN PIAGETIAN TASKS

"Most neo-Piagetian theorists ... incorporate the concept of relational mapping ... However, Halford is the only neo-Piagetian who has formally proposed that analogy plays a central role in the development of logical reasoning, and who has linked analogical processes to performance in traditional Piagetian tasks." (459) Apparently it was Halford that suggested a lot of the things that are incorporated into LISA: limitations in primary memory constrain the types of analogy that children could use, which he says explains the late emergence of concrete operations. "Halford's argument was that capacity limitations prevented children from representing and mapping transitive or class inclusion relations prior to approximately five years of age." (459)

"Halford has suggested that familiar ordered structures may provide useful analogies for transitive reasoning tasks." Example: "Tom happier than Bill happier than John" might be understood with an analogy to "A higher than B higher than C", similarly to how Johnson-Laird described the emergence of transitive understanding without mental logic. Note however, that the initial statement "A higher than B higher than C" still needs to be understood somehow, and especially the generalized "if A>B and B>C then A > C", is an inferential generalization that cannot(?) be done with analogical or deductive processes. So the ability to understand and extract the generalized rule is still not explained.

They tested this hypothesis (Goswami 1995) with a height relation (Daddy Bear > Mommy Bear > Baby Bear), children were able to solve transitive ordering problems involving temperature, width, loudness, etc. (462)

"Goswami et al.'s data suggest that Halford's structure-mapping theory of how analogies might contribute to the development of logical reasoning is both powerful and plausible. However, further research is required, particularly regarding the developmental appropriateness of the notion of capacity limitation as an upper limit on children's use of analogies (see Gentner and Rattermann 1999; Goswami 1999)." (464)

Imitation "provides an early form of analogizing. Interestingly, Piaget also suggested a role for analogy in explaining imitation behavior in infants. he noted the occurrence of "motor analogies" in his own babies, in which the infants imitated certain spatial relations that they had observed in the physical world with their own bodies. For example, they imitated the opening and closing of a matchbox by opening and closing their hands and mouths. Piaget suggested that this behavior showed that the infants were trying to *understand* the mechanism of the matchbox through a motor analogy, reproducing a kinesthetic image of opening and closing. Again, the infant is suggested to be representing *relations*, and analogy is suggested as the mechanism for knowledge acquisition and for explaining events in the everyday world." (454) [No source is given for this Piaget observation, but it is corroborated in the "Constructive Evolution" book].},
	Author = {Goswami, Usha},
	Booktitle = {The Analogical Mind: Perspectives from Cognitive Science},
	Date-Added = {2011-09-20 17:27:35 -0400},
	Date-Modified = {2011-10-23 23:55:44 -0400},
	Editor = {Gentner, Dedre and Holyoak, Keith J. and Kokinov, Boicho N.},
	Publisher = {The MIT Press},
	Title = {Analogical Reasoning in Children},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDEzLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSYW5hbG9neV9jaGFwMTMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48sMuBAz8AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMuBSY8AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAYW5hbG9neV9jaGFwMTMucGRmAAAOACYAEgBhAG4AYQBsAG8AZwB5AF8AYwBoAGEAcAAxADMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2FuYWxvZ3lfY2hhcDEzLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@inproceedings{Hummel2009,
	Address = {Sofia, Bulgaria},
	Annote = {Tries to generate an explanation from LISA's figuring out the following analogy: Given that the whole population prefers Pepsi to Coke as equally as they prefer Coke to Pepsi, but ministers prefer Coke over Pepsi; what explanations are there? Some possible answers are that ministers are more conservative and perhaps Coke Corporation supports conservative causes, etc.

Proposes three kinds of flexibility in the representations and underlying processes:
Relational flexibility - Schema should be able to see multiple roles of ministers: conservative, therefore prefers conservative-supporting organizations, for example.
Semantic flexibility - Ability to exploid partial but imperfect matches between the objects and relations composing an explanandum and the objects and relations encoded in potentially relevant schemas or examples in LTM. A prior example could be used as a source analog, but only if partial matches are allowed.
Third type of flexibility (not named in the paper) - Multiple source flexibility. An analogy often requires the ability to map from more than one source in LTM to the target (minister schema, political schema, what it means for a person to agree with a corporation, etc). 

Multiple source flexibility leads to a variant of the token-type problem: How do we know if more than one representational elements (tokens) refer to the same referent (object or type in the world). This is easy with 1:1 mapping but not with multiple source flexibility.

To represent causal relations between propositions (causes(A,B)) they create a new type of node, CE (cause-effect) nodes, (represented by diamonds) which connect propositions. The algorithm is done so that it matches using these connections, and they should generate the explanation: "ministers prefer Coke because they agree with the corporation that makes Coke." They then describe the actual schema they used, and show some typical results (7), not all of which make perfect sense.},
	Author = {Hummel, John E. and Landy, David H.},
	Booktitle = {New Frontiers in Analogy Research: Proceedings of the Second International Conference on Analogy},
	Date-Added = {2011-09-15 13:58:25 -0400},
	Date-Modified = {2011-10-26 03:06:09 -0400},
	Editor = {Kokinov, B. and Holyoak, Keith J. and Gentner, D.},
	Title = {From Analogy to Explanation: Relaxing the 1:1 Mapping Constraint...Very Carefully},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0h1bW1lbF9MYW5keV8yMDA5LnBkZtIXCxgZV05TLmRhdGFPEQHQAAAAAAHQAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcVSHVtbWVsX0xhbmR5XzIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8QXMqXtO8AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMqX7S8AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBUTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoASHVtbWVsX0xhbmR5XzIwMDkucGRmAA4ALAAVAEgAdQBtAG0AZQBsAF8ATABhAG4AZAB5AF8AMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQVVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvSHVtbWVsX0xhbmR5XzIwMDkucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAM0A0gDaAq4CsAK1AsACyQLXAtsC4gLrAvAC/QMAAxIDFQMaAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAxw=}}

@article{Hummel2003a,
	Annote = {Quick overview of LISA architecture.

LISA uses a "symbolic connectionism" approach, as opposed to the symbolic propositional representation approaches of SME, ACME, ABMR, and IAM. LISA's representations try to "capture the symbolic nature of human (and other primate) cognition ... to relate models of analogy to cortical functions, particularly the role of the prefrontal cortex in relational reasoning". Specifically, LISA "codes relational structures by dynamically binding distributed representations of roles to distributed representations of their fillers". 

relational thinking is:
structure-sensitive - human relational thinking depends on the capacity to code and manipulate relational knowledge, with complex structures emerging from the systematic recombination of more primitive eements.
flexible - in how knowledge is accessed and used. People can apply old knowledge to new situations that are similar but by no means identical, somehow recognizing and exploiting useful partial matches.

Analogs contain propositions (P) at the top. Below that are SPs (Sub-proposition units) which bind relational roles to arguments or to other propositions, in nested cases. Below that are object units and predicate units, which are localist representations. All these units are local to the analogs, and are TOKENS rather than TYPES. Below the object and predicate units are the semantic units, which are TYPES and shared between all the analogs. 

The currently active analog is the driver, the current focus. The four basic types of processes are:
Memory retrieval: driver propositions are excited one at a time, which propagates down to semantic units, and that in turn excites propositions in LTM. The propositions compete and an analog gets chosen to be the receipient(s), and is put into AM (active memory).
Analogical mapping: Weights are adjusted between units referring to the same thing between driver and recipient. Both excitatory and inhibitory weights are adjusted.
Analogical inference: The weights / mappings are used to create new propositions.
Schema induction: Like analogical inference, except this is used to inductively produce rules.},
	Author = {Hummel, John E. and Holyoak, Keith J.},
	Date-Added = {2011-09-13 16:53:22 -0400},
	Date-Modified = {2014-01-17 17:22:51 +0000},
	Journal = {Cognitive Studies: Bulletin of the Japanese Cognitive Science Society},
	Pages = {58-75},
	Title = {{Relational Reasoning in a Neurally-plausible Cognitive Architecture: An Overview of the LISA Project}},
	Volume = {10},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0NvZ1N0dWRpZXNMSVNBLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSQ29nU3R1ZGllc0xJU0EucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6OqsqW540AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMqXH80AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAQ29nU3R1ZGllc0xJU0EucGRmAAAOACYAEgBDAG8AZwBTAHQAdQBkAGkAZQBzAEwASQBTAEEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0NvZ1N0dWRpZXNMSVNBLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@misc{Sun2003,
	Annote = {Appears to be longer version of the 2004 article with the same title.

"[A] cognitive architecture is the overall, essential structure and process of a domain-generic computational cognitive model, use for a broad, multiple-level, multiple-domain analysis of cognition and behavior." (4)

"...it is important that we are careful to devise only minimal <i>initial</i> learning capabilities that are capable of "bootstrapping", in accordance with whatever phenomena that we aim to model (Sun et al. 2001)" (6)


Essential characteristics:

Ecological realism - everyday activities of humans, such as: (these are also listed under "behavioral characteristics")
	reactivity - relatively fixed, automatic, quick responses that don't require detailed recomputations
	sequentiality - human activities are mostly sequential, carried out one step at a time
	routineness - human activities become routine over time, but can adapt as well
	trial-and-error adaptation - classical conditioning, law and effect, probability learning, etc.
Bio-evolutionary realism - should be reducible to animal intelligence
Cognitive realism - capture ESSENTIAL characteristics of behavior and cognitive processes, like: (also listed as "cognitive characteristics")
	Dichotomy of implicity/explicit processes
	Synergistic interaction (between implicit/implicit interaction)
	Bottom-up learning
	Modularity
Eclecticism of methodologies and techniques - he argues we should NOT hold too tightly to any specific approach, instead try to be broad (so we need to make sure we're not ahering too exclusively to neo-piagetianism)

},
	Author = {Sun, Ron},
	Date-Added = {2011-09-10 16:29:40 -0400},
	Date-Modified = {2011-09-10 18:44:57 -0400},
	Howpublished = {Website},
	Month = {September},
	Title = {Desiderata for Cognitive Architectures},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi1wcDIwMDMucGRm0hcLGBlXTlMuZGF0YU8RAbQAAAAAAbQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rw5zdW4tcHAyMDAzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxKAyo+r1gAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyo/kFgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAE1NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBzdW4tcHAyMDAzLnBkZgAADgAeAA4AcwB1AG4ALQBwAHAAMgAwADAAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAOlVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvc3VuLXBwMjAwMy5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDGAMsA0wKLAo0CkgKdAqYCtAK4Ar8CyALNAtoC3QLvAvIC9wAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAL5}}

@article{Sun2001b,
	Annote = {Early description of CLARION, talks in depth about the mindfield navigation experiment. Description of the reinforcements used to train CLARION on this task (21). Performance seemed to match that of humans.

Comparisons to other architecutres (39-40):
ACT*/ACT-R - Does not allow for bottom-up learning, and ACT does not explain differences in accessibility (from a representational viewpoint) between the two types of knowledge. CLARION can learn autonomously without a teacher.
SOAR - Also doesn't distinguish between implicit/explicit knowledge. SOAR requires a large amount of a priori knowledge about operators and their preferences.
Drescher's Piagetian Architecture - Doesn't clearly mark procedural vs declarative, and implicit vs explicit. Only deals with low-level procedural learning / motor interaction.

},
	Author = {Sun, Ron},
	Date-Added = {2011-09-10 15:32:49 -0400},
	Date-Modified = {2014-01-29 00:23:54 +0000},
	Journal = {{Cognitive Science}},
	Number = {2},
	Pages = {203-244},
	Title = {{From Implicit Skills to Explicit Knowledge: A Bottom-Up Model of Skill Learning}},
	Volume = {25},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi5DUzk5LnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMc3VuLkNTOTkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8SkMqPq9wAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMqP5BwAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAc3VuLkNTOTkucGRmAAAOABoADABzAHUAbgAuAEMAUwA5ADkALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi5DUzk5LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=}}

@book{Inhelder1958,
	Annote = {'Rog' chapter 16: Hypothesis formation prior to
                  acting is distinctly stage 4, contra Fodor!: -
                  "[C]oncrete thought remains essentially attached to
                  empirical reality. The system of concrete
                  operations-the final equilibrium attained by
                  preoperational thought--can handle only a limited
                  set of potential transofmrations. Therefore, it
                  attains no more than a concept of "what is
                  possible," which is a simple (and not very great)
                  extension of the empirical situation. ... [S]trictly
                  speaking, at the concrete level, the child does not
                  formulate any hypotheses. He begins by acting;
                  although in the course of his action he tries to
                  coordinate the sequence of recordings of the results
                  he obtains, he structures only the reality on which
                  he acts. But if the reader objects that these
                  cognitive organizations are in fact hypotheses, we
                  would answer that in any case they are hypotheses
                  that do no more than outline plans for possible
                  actions; they do not consist of imagining what the
                  real situation would be if this or that hypothetical
                  condition were fulfilled, as they do in the case of
                  the adolescent." (250-251) - [I]n formal thought
                  there is a reversal of the direction of thinking
                  between <i>reality</i> and <i>possibility</i> in the
                  subjects' method of approach. ... [It becomes the
                  case that] <i>reality</i> that is now secondary to
                  <i>possibility</i>. Henceforth, they conceive of the
                  given facts as that sector of a set of possible
                  transofmrations that has actually come about; for
                  they ar eneither explained nor even regarded as
                  facts until the subject undertakes verifying
                  procedures that pertain to the entire set of
                  possible hypotheses compatible with a given
                  situation. In other words, formal thinking is
                  essentially hypothetico-deductive. By this we mean
                  that the deduction no longer refers directly to
                  perceived realities but to hypothetical
                  statements--i.e., it refers to propositions which
                  are formulations of hypotheses or which postulate
                  facts or events independently of whether or not they
                  actually occur. Thus, the deductive process consists
                  of linking up these assumptions and drawing out the
                  necessary consequences even when their validity,
                  from the standpoint of experimental verification, is
                  only provisional. The most distinctive property of
                  formal thought is this reversal of direction between
                  <i>reality</i> and <i>possibility</i>; instead of
                  deriving a rudimentary type of theory from the
                  empirical data as is done in concrete inferences,
                  formal thought begins with a theoretical synthesis
                  implying that certain relations are necessary and
                  thus proceeds in the opposite direction. Hence,
                  conclusions are rigorously deduced from premises
                  whose truth status is regarded only as hypothetical
                  at first; only later are they empirically verified.
                  - "Thus, aside from the structural consequences it
                  implies, the most fundamental property of formal
                  thought is this reversal of direction between
                  <i>reality</i> and <i>possibility</i>. And so we
                  must use this essential difference between concrete
                  and formal thought as a starting point in accounting
                  for the form of equilibrium found at this last stage
                  in the development of thought." (255) Even they
                  acknowledge that correct reasoning might come about
                  in pre-stage 4 ages: - "[I]t is possible to get
                  correct reasoning about simple propositions as early
                  as the 7-8 year level, provided that these
                  propositions correspond to sufficiently concrete
                  representations. Even if the content of the
                  complexion problem requires nothing more than serial
                  order operations, the fact that it cannot be solved
                  in exclusively verbal terms until several years
                  after the child can solve it with the aid of
                  physical props shows us that some other factor is at
                  work here." (252) Structural possibility vs
                  instrumental possibility distinction: (260-264)
                  Instrumental Possibility - Possible operations and
                  relations in designating those which the subject
                  himself regards as possible--i.e., those which he
                  knows he is able to perform or construct, even
                  without actually trying them out. ... identical with
                  our earlier description of possibility from the
                  subject's point of view.  Structural Possibility -
                  The operations and relations that the subject would
                  be capable of performing or constructing without his
                  thinking of doing so--i.e., without the subject's
                  becoming aware of the contingency or even of his own
                  capacity with regard to it. ... it is possibility
                  defined by the observer rather than the
                  subject. (260) They continue in this chapter with
                  the comparison of equilibrium in nature (physics)
                  and in their model.  "...in a state of
                  <i>physical</i> equilibrium reality alone is causal
                  and possibility relates only to the mind of the
                  physicist who deduces this reality; in contrast, in
                  a state of <i>mental</i> equilibrium the succession
                  of mental acts is affected not only by the
                  operations actually performed but also by the entire
                  set of possible operations insofar as they orient
                  the subject's searching toward deductive
                  closure. For in this case it is the subject who
                  deduces, and the possible operations are part of the
                  same deducitve system as the real operations he
                  performs. ... Despite this difference between
                  physical and mental processes, it remains true that
                  in both cases a system is in equilibrium when all of
                  the potehtial transformations compatible with the
                  system links compensate each other. This physical
                  definition of equilibrium corresponds in the mental
                  field to the following considerations: the state of
                  fact--or reality--corresponds to the operations
                  explicitly performed by the subject, whereas the
                  potential transformations correspond to the possible
                  operations that the subject could perform and that
                  he may explicitly perform later on but which he has
                  not or has not yet performed at the moment
                  considered; the system links correspond to the
                  givens of th eproblem posed--i.e., to the content on
                  which his operations are exercised. Our problem is
                  to find the point at which it can be said that
                  equilibrium is attained for such a mental system."
                  (266-267) Equilibrium is defined in terms of
                  operations and their ability to compensate each
                  other, which is inextricably tied with the concept
                  of reversibility. "...it is because the total set of
                  possible oeprations constitutes a system of
                  potential transofmrations which compensate each
                  other--and which compensate each other insofar as
                  they conform to laws of reversibility--that the
                  system is in equilibrium. The operational
                  reversibility and the system equilibrium constitute,
                  after all, a single unified property, and it is
                  because the possible operations are reversible and
                  mobile (i.e., can be combined in all ways, but with
                  a complete liberty for a return to the initial
                  starting point) that possibility acts in a
                  continuous manner on the choice of new operations to
                  be performed." (267-268) From here, now that the
                  "solution of the problem of formal thought is to be
                  sought in an analysis of the structural integration
                  which characterizes formal operations in contrast to
                  concrete operations", they talk about specifying the
                  structural integration of operations better, and in
                  doing so must justify the use of logico-mathematical
                  methods.  Justifies use of symbolic logic and
                  structural abstraction (269-71) "But especially, and
                  this is most important for the problem at hand,
                  using symbolic logic as a means of analysis makes it
                  possible to show that these sets of operations do
                  not consist of simple series of juxtaposed elements;
                  on the contrary, these collections of elements have
                  structure as wholes. These wholes are the integrated
                  structures of formal propositional operations
                  (equivalent to the concrete <i>groupings</i> of
                  classes and relations) which it would be instructive
                  to analyze in order to resolve the psychological
                  problems posed in the present work. In this respect,
                  symbolic logic allows for an analysis which goes
                  more deeply into the heart of intelligence than
                  arithmetical or statistical calculations. Whereas
                  the latter bear either on the results of operations
                  or on "factors" which do not directly furnish
                  meaning, the qualitative analysis available to
                  symbolic logic reaches the structures themselves
                  --i.e., the operational mechanism as such and not
                  simply its results or its more or less general
                  conditions.  ...  [The equilibrium forms can be
                  analyzed from two perspectives: the genetic or
                  experimental and the theoretical.] In genetic logic,
                  empirical researh consists of determining ... which
                  operations are involved in the subject's cognitive
                  acts and how these operations are gradually
                  organized intro structures to the point where
                  certain empirically verifiable forms of equilibrium
                  are reached. On the other hand, theoretical analysis
                  describes these same structures in their general or
                  abstract aspects so as to show how the most complex
                  can be derived from the simples, and it determines
                  the system of possible operations which would permit
                  the utilization of this or that actually performed
                  operation. It is clear from the start that these two
                  types of research can be mutually reinforcing in
                  furthering our understanding of cognitive
                  equilibrium states.  ...  Moreover, ... the question
                  is a psychological one; the calculus of symbolic
                  logic is brought in as an analytical instrument
                  insofar as it is a more general algebra than the
                  elementary algebra founded on numerical
                  operations. If we may compare those sciences in the
                  process of growth with the sciences which have
                  attained full control of their methods, experimental
                  psychology can be seen as corresponding, on the
                  mental level, to experimental physics in the study
                  of matter, with pure symbolic (or axiomatic) logic
                  corresponding to mathematics. As for the discipline
                  which deals with constructing a theory of mental
                  operations by means of symbolic calculus, ... [i]t
                  would remain a branch of psychology, as mathematical
                  physics is a branch not of mathematics but of
                  physics. But it would utilize the algebra of
                  symbolic logic as an analytic instrument in the same
                  way that mathematical physics now makes use of the
                  techniques and notation of mathematics." (269-71)
                  Here we see the logicist manifesto, clearly
                  explained.
                  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                  chapter XVIII (reprinted in "The Essential Piaget"):
                  "Two observations arise out of this circular process
                  which characterizes all exchanges between the
                  nervous system and society. The first is that the
                  formal structures are neither innate a priori forms
                  of intelligence which are inscribed in advance in
                  the nervous system, nor are they collective
                  representations which exist ready-made outside and
                  above the individual. Instead, they are forms of
                  equilibrium which gradually settle on the system of
                  exchanges between individuals and the physical
                  milieu and on the system of exchanges [among]
                  individuals themselves. Moreover, in the final
                  analysis the two systems can be reduced to a singe
                  system seen from two different perspectives [...]
                  The second observation is that between the nervous
                  system and society there is individual
                  activity--i.e., the sum of the experience of an
                  individual in learning to adapt to both physical and
                  social worlds. If formal structures are laws of
                  equilibrium and if there is really a functional
                  activity specific to the individual, we would expect
                  adolescent thinking to show a series of spontaneous
                  manifestations expressing the organization of formal
                  structures as it is actually experienced [...] In
                  other words, formal development should take place in
                  a way that furthers the growth of the adolescent in
                  his daily life as he learns to fill adult roles."
                  (436, from Chap. XVIII).  Piaget goes on to describe
                  what he sees as parallels between the emergence of
                  formal thought and changes in the life of the
                  adolescent and his relation towards others.
                  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                  A list of the experiments in this book: Part I - The
                  Development of Propositional Logic Chapter 1 - The
                  Equality of Angles of Incidence and Reflection and
                  the Operations of Reciprocal Implication: billiard
                  ball game, they are asked to hit a ball, bounce it
                  off a side, and hit a target.  Chapter 2 - The Law
                  of Floating Bodies and the Elimination of
                  Contradictions: subject is asked to classify objects
                  based on whether they will float on water, explain
                  the classification chosen, actually test it, then
                  summarize observations. This is the only mention of
                  the word "analogy", but I don't see clear examples
                  of analogical reasoning here. Rather there are
                  faulty hypotheses (the subjects claim things with
                  "holes" or "air inside" will float).  Chapter 3 -
                  Flexibility and the Operations Mediating the
                  Seaparation of Variables: rod sticking out of
                  something horizontally, with a weight at the end:
                  how much will the rod bend? This depends on several
                  things: rod material, thickness, length, the weight
                  at the tip, etc. How subjects separate the variables
                  is paid close attention to in this and the following
                  experiments.  Chapter 4 - The Oscillation of a
                  Pendulum and the Operations of Exclusion: A pendulum
                  with three factors: Different weights, string
                  lengths, heights of the release point, and force of
                  the push. Only the length matters to the speed.
                  Chapter 5 - Falling Bodies on an Inclined Plane and
                  the Disjunction Operations: A ball can be rolled
                  down an incline, where it then rolls off a ramp and
                  goes into one of eight compartments, to measure
                  distance. Subjects vary height of incline and
                  compare with landing compartment.  Chapter 6 - The
                  Role of invisible Magnetization and the Sixteen
                  Binary Propositional Operations: A rotating metal
                  bar spins and points to one pair of boxes, but only
                  the pair denoted by stars has magnets. The problem
                  is to determine why the bar always ends up pointing
                  to the magnet boxes (subjects don't know there are
                  magnets initially). They can open the boxes and see
                  that they all contain wax, but the ones with stars
                  have concealed magnets.  Part II - The Operational
                  Schemata of Formal Logic: Many of these experiments
                  start by examining the known physics laws relevant
                  to the experiment, and examining how the subjects
                  gain intuitive feels for them.  Chapter 7 -
                  Combinations of Colored and Colorless Chemical
                  Bodies: Tries to force combinatorial
                  reasoning. Child is given four identical flasks with
                  identically appearing colorless, odorless liquids,
                  but they mix to create different
                  colors. Experimenter mixes diferent combinations in
                  front of subject, observes reactions. Subject is
                  asked to reproduce a certain color. Sequence of
                  mixing also matters. Interestingly, you see that
                  some stages never consider the idea of mixing two
                  elements separately (112), and there are other
                  systematic errors made with regards to incomplete
                  conceptions of combinatorics.  Chapter 8 - The
                  Conservation of Motion in a Horizontal Plane: A
                  horizontal plane along which a ball can roll is
                  connected to a ball and a spring to launch it. Ball
                  rolls, subjects must predict stopping points. This
                  experiment is interesting in that I&P argue that
                  conservation of inertia is learned even though it is
                  never observed (129).  Chapter 9 - Communicating
                  Vessels: There are three apparatus where the subject
                  can raise or lower the water level with a lever and
                  some pistons. In apparatus A, subject raises or
                  lowers the vessels by hand by adding or taking away
                  the stands on which they rest. In B, he raises or
                  lowers the two vessels with levers. In C, he can
                  only move one of the vessels, the other being
                  stationary. I'm not sure still what the apparatuses
                  look like, no pictures are shown. I'm guessing that
                  by "communicating vessels" they mean tubes of
                  varying width and height connected so that they
                  share liquid somehow. Here they first describe the
                  four general operator-level operators (operators
                  which transform particular operators into others):
                  I, N, R, and C (134).  Chapter 10 - Equilibrium in
                  the Hydraulic Press: Similar to Chap. 9 and a
                  drawing of the "communicating vessels" is actually
                  shown. Each "vessel" is a test-tube-like thing
                  except the bottom is connected to the bottom of
                  another tube by a plastic tube so that pressure
                  exerted on the piston in one tube can raise the
                  water level in the other. Subjects must balance the
                  water level.  Chapter 11: Equilibrium in the
                  Balance: A "conventional balance" with the basket on
                  each side variable in distance from the
                  center. Subjects must balance, reconciling the
                  causal effects of basket distance and weights.
                  Chapter 12: Hauling Weight on an Inclined Plane: An
                  incline with a toy truck. The truck is pulled up the
                  incline by a rope connected to a weight on the other
                  side. Variables are the incline and the amount of
                  weights.  Chapter 13: The Projection of Shadows:
                  Rings of varying diameters placed between a light
                  and a screen. The size of the shadow is dependent on
                  distance and ring size. Subjects must find two
                  shadows which cover each other exactly, using only
                  unequal rings.  Chapter 14: Centrifugal Force and
                  Compensations: Three metal balls of different
                  weights on a disc, the disc spins. The subject must
                  predict in which order they will fall off. This
                  requires a compensation problem--weighing the
                  initial distance from the center vs the weight of
                  the balls.  Chapter 15: Random Variations and
                  Correlations: The goal is to see how subjects
                  construct the correlation schema based on chance
                  fluctuations. No new experiments are used, they
                  simply use the previous experiments, since they all
                  had random fluctuations.},
	Author = {Inhelder, Barbel and Piaget, Jean},
	Date-Added = {2011-09-03 14:30:34 -0400},
	Date-Modified = {2011-12-25 18:41:52 -1000},
	Publisher = {Basic Books, Inc},
	Title = {The Growth of Logical Thinking: From Childhood to Adolescence},
	Year = {1958},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2ltZzAwMi5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCmltZzAwMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEGTKzN54AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKzRa4AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGltZzAwMi5wZGYAAA4AFgAKAGkAbQBnADAAMAAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9pbWcwMDIucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==},
	Bdsk-File-2 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BpYWdldC5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCnBpYWdldC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEQDLPgNkAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADLPkm0AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHBpYWdldC5wZGYAAA4AFgAKAHAAaQBhAGcAZQB0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9waWFnZXQucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==}}

@incollection{Nilsson2007,
	Annote = {summarized best in his own words:


"In summary, I don't think any of the four different kinds of attacks on the
PSSH diminishes the importance of symbolic processing for achieving humanlevel intelligence. The first attack is based on the erroneous claim that the PSSH
lacks symbol grounding. By all means, let's have symbol grounding when needed.
The second attack is based on the need for non-symbolic processing; let's have
that too when needed. The third attack, based on the claim that the brain is
not a computer, will vanish when people who study brains increasingly use computational concepts to understand brain function. And the fourth attack, based
on the idea that brains are mindless, will vanish when it becomes evident that
constructs best understood as being mindless achieve only mindless behavior."

The rest of it is his personal predictions on the future of physical symbol systems (PSS), just kind of skimmed past that. Anyone not from stanford who published such speculative views would have been ignored and ridiculed.},
	Author = {Nilsson, Nils},
	Booktitle = {50 Years of AI},
	Date-Added = {2011-08-31 02:23:44 -0400},
	Date-Modified = {2011-10-11 00:05:55 -0400},
	Editor = {Lungarella, Max},
	Pages = {9-17},
	Publisher = {Springer},
	Title = {The Physical Symbol System Hypothesis: Status and Prospects},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QLy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3Bzc2gucGRm0hcLGBlXTlMuZGF0YU8RAZwAAAAAAZwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rwhwc3NoLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxENyoNMcwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyoOEswAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEdNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBwc3NoLnBkZgAADgASAAgAcABzAHMAaAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIANFVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvcHNzaC5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDAAMUAzQJtAm8CdAJ/AogClgKaAqECqgKvArwCvwLRAtQC2QAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALb}}

@article{Barwise1981,
	Annote = {this paper was referenced as the one in which the "half" problem was proved to be outside of the domain of FOL.},
	Author = {Barwise, Jon and Cooper, Robin},
	Date-Added = {2011-08-30 15:23:01 -0400},
	Date-Modified = {2011-08-30 15:24:00 -0400},
	Journal = {Linguistics and Philosophy},
	Number = {2},
	Pages = {159-219},
	Title = {Generalized Quantifiers and Natural Language},
	Volume = {4},
	Year = {1981},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzE1MzM2Ni5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCjE1MzM2Ni5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPH3KgrDKAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKgukKAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6ADE1MzM2Ni5wZGYAAA4AFgAKADEANQAzADMANgA2AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy8xNTMzNjYucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==}}

@book{Anderson1976,
	Annote = {CHAPTER 7
Shows that the ACT productions are at least as expressive as FOL. He does this in a weaker sense of equivalence which only preserves logical consequence:
CRITERION FOR EQUIVALENCE: (P is a predicate calculus formula, Pt is its ACT translation under the given algorithm,  is a set of PC formulas, t is the set of their translations)
P is equivalent to Pt iff for all ,  |= P iff t |= Pt.
Algorithm essentially involves normalizing the FOL formula to a form called production normal form (PNF) and converting that into a set of ACT productions.

To show that ACT productions are more expressive than FOL, we show that ACT productions can represent natural language concepts not expressible in FOL.},
	Author = {Anderson, John R.},
	Date-Added = {2011-08-28 23:13:50 -0400},
	Date-Modified = {2011-08-28 23:44:18 -0400},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Language, Memory and Thought},
	Year = {1976}}

@webpage{Bottou2011,
	Annote = {Definition of reasoning: "algebraic manipulation of previously acquired knowledge in order to answer a new question", as opposed to going from premises to conclusion.
logical inference requires searching combinatorially large spaces, but probabilistic methods have limited expressivity ("since probabilistic inference is a mathematical construction, it is easily described using first order logic; the converse is not true.") Then he notes the problem: "Human reasoning displays neither the limitations of logical inference nor those of probabilistic inference. ... This suggests the existence of a middle layer, already a form of reasoning, but not yet formal or logical."

"This document presents an idea that results from a long maturation (Bottou, 2008). Both deep learning and multi-task learning show taht we can leverage auxiliary tasks to help solving a task of interest. This apparently simple idea can be interpreted as a rudimentary form of reasoning. Enriching this algebraic structure then leads to higher forms of reasoning. This provides a path to build reasoning abilities into machine learning systems from the ground up."

2. AUXILIARY TASKS
Summarizes a NLP system that has an auxiliary module which assigns a score to a sequence of words to detect if it's genuine or not. They report it is very fast.

3. REASONING REVISITED
"Although modular learning systems and their training algorithms have been researched extensively ..., little attention has been paid to the rules that describe how to assemble trainable modules in order to address a particular task. In fact, these composition rules play an extremely important role. [These rules] describe the algebraic manipulations that let us combine previously acquired knowledge -- in the form of models previously trained on auxiliary tasks -- in order to create a model that addresses a new task."
This highlights his definition of reasoning, which operates on composition rules and trainable modules, rather than premises / conclusions.

4. PROBABILISTIC MODELS
Says that typically, probabilistic methods  "induce an algebraic structure on the space of conditional probability distribution models describing relations between arbitrary subsets of random variables."

5. REASONING SYSTEMS
A reasoning system is one that deals with "a more complex object composed of (a) an algebraic space of models, and (b) composition rules that establish a homomorphic correspondence between the space of models and the space of questions of interest." A wide variety of possible systems meets this definition, and so rather than choose one above all others he suggests "map[ping] the universe of reasoning systems. What are the potential algebraic structures? What is their footprint in terms of expressive power, suitability for specific applications, computational requirements, and predictive abilities?"

"The following sections describe more specific ideas investigating reasoning systems suitable for [NLP] and vision tasks."


CONCLUSIONS
"Instead of trying to bridge the gap between machine learning systems and sophisticated "all-purpose" inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up. This possibility gives new ways to work around the limitations of both logical and probabilistic inference. Is this the new path to Artificial Intelligence?"},
	Author = {Bottou, Leon},
	Date-Added = {2011-08-28 16:19:46 -0400},
	Date-Modified = {2011-08-28 17:18:40 -0400},
	Journal = {arXiv.1102.1808},
	Lastchecked = {8/28/2011},
	Title = {From Machine Learning to Machine Reasoning},
	Url = {http://arxiv.org/abs/1102.1808},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3RyLTIwMTEtMDItMDgucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxF0ci0yMDExLTAyLTA4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxKhyoAmLAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyoBebAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgB0ci0yMDExLTAyLTA4LnBkZgAOACQAEQB0AHIALQAyADAAMQAxAC0AMAAyAC0AMAA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy90ci0yMDExLTAyLTA4LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI},
	Bdsk-Url-1 = {http://arxiv.org/abs/1102.1808}}

@article{Brooks1990,
	Annote = {Famous article in which Brooks attacks the symbol system hypothesis in favor of the physical grounding hypothesis.},
	Author = {Brooks, Rodney A.},
	Date-Added = {2011-08-21 20:15:58 -0400},
	Date-Modified = {2011-08-21 20:16:57 -0400},
	Journal = {Robotics and Autonomous Systems},
	Pages = {3-15},
	Title = {Elephants Don't Play Chess},
	Volume = {6},
	Year = {1990}}

@incollection{Braine1998d,
	Annote = {Whereas chapter 7's experiments focused on proving that adults perform errorlessly on simple problems using the schemas, this chapter's experiments try to further validate the schema model by showing that the intermediate steps follow the inference one would expect using this schema set, as opposed to Rips's theory or Mental Models.

"...the schemas and the direct reasoning routine often predict the order in which inferences are made. ... the condition of application of the requisite schema cannot be satisfied until these inferences have been made. This fact provides an additional way to test the theory: Finding on such problems that participants do not make the inferences in the order predicted would falsify an essential prediction of the model. Finding that they do make the inferences in the predicted order would favor the model..." (149)


Regarding mental models:

"...the mental-models theory of Johnson-Laird et al. (1992) and Johnson-Laird and Byrne (1991) accounts poorly for the protocol data reported. The suggestions for improving that theory, [which at the time Johnson-Laird was still working on] if successful, could yield a theory that would be hard to distinguish from a mental logic. Pragmatic schema theory (Cheng & Holyoak, 1985) also cannot account for participants' inferences because of the arbitrary nature of the problem content (as Cheng et al., 1986, wrote "arbitrary problems do not evoke any pragmatic schema"; p. 303). In the absence of other kinds of theories that can account for participants' responses, it seems to us that our work provides strong support for the existence of a mental logic. Our model is an advance of the prior mental-logic models of Braine (1978), Osherson (1975), and Rips (1983) in that it accounts better than they do for participants' performance on problems ... there is no reason to doubt that further work will bring convergence on an optimal mental-logic model." (192)

"We have no doubt that mental models in some form also provide a tool available to the human reasoner. ... We worry that the effort to account for ALL[italicized] reasoning with mental models has led in directions ultimately inimical to understanding how people reason with models. ... " (194)
They go on to rebut challenges to mental logic:
- criticisms that mental logic does not provide an economical account of reasoning since it allows for the existence of other reasoning mechanisms, and is thus hard to refute. They say chapter 7's discussion contain many ways to refute it, and that to test a mental logic theory you try to replicate it and compare, then tweak the theory. Either it converges to an ideal set of schemas, or it gets worse no matter what and reaches an impasse.


Regarding deontic reasoning / pragmatic schema:

"[Regarding] the various arguments against a mental logic, beginning with those of Cheng and Holyoak (1985), Cheng et al. (1986), and Holland et al. (1986) ... Although they accept that some people may sometimes use context-free inference schemas like those of our logic, they repeatedly claim that people typically make inferences based on pragmatic reasoning schemas. The most they allow is that some context-free inference schemas MAY[italicized] be available to some participants as default strategies in the event that pragmatic reasoning schemas are not engaged. We take issue with the claim of Cheng and her colleagues. First, to determine the kinds of reasoning that are typical, one would have to carry out an ecological study or otherwise obtain a sample of real-life inferences that are representative of everyday reasoning, which has not been done. Second, the reasoning scenarios on which they base their claim are variations on the Wason Selection task (Wason, 1966), which has little intuitive face validity as a typical everyday reasoning task. ... many kinds of strictly logical inferences seem to have at least a good a claim on typicality (e.g., the inference that when one of two alternatives turns out wrong, the other must be right; or that when both horns of a dilemma lead to the same result, one should expect that result no matter what ...). Thus, there is no reason to suppose that mental-logic-based inferences are any less typical than those that Cheng and her colleagues have studied." (193)

Cheng and Holland "...believe (e.g., Holland et al., 1986) that context-free schemas of a logical sort are rather rare and subject to individual differences. Thus, they posit no logic that is shared among participants. A set of schemas, some of which may be present in some participants, would account neither for the data reported her nor for those of chapters 7 and 12 and other work cited earlier. ... pragmatic theory would need to define pragmatic schemas that cover all possible context with which people are able to reason and their various possible forms. ... Thus, we see the pragmatic approach and ours as complementary rather than competitive. There is no impediment to adding pragmatic schemas to our logic ... [it] would account for a great many reasoning phenomena, including content effects and the kind of data described here." (193)

},
	Author = {Braine, Martin D.S. and O'Brien, David P. and Noveck, Ira A. and Samuels, Mark C. and Lea, R. Brooke and Fisch, Shalom M. and Yang, Yingrui},
	Booktitle = {Mental Logic},
	Chapter = {8},
	Date-Added = {2011-08-19 19:52:55 -0400},
	Date-Modified = {2011-08-20 03:39:50 -0400},
	Editor = {Braine, Martin D.S. and O'Brien, David P.},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Further Evidence for the Theory: Predicting Intermediate and Multiple Conclusions in Propositional Logic Inference Problems},
	Year = {1998}}

@incollection{Braine1998c,
	Annote = {"It has been urged that [mental models] may suffice for all deductive reasoning (Johnson-Laird, 1982, 1983). However, at the time this work was done, no mental-model theory of propositional reasoning had been proposed". (92)

"The theory allows three sources for reasoning errors." :
comprehension errors - error of construal of the premises or the conclusion, e.g. the starting information used by the subject is not that intended by the problem setter
heuristic inadequacy errors - when the subject's reasoning program fails to find a line of reasoning that solves a problem (problem is too difficult for the subject)
processing errors - lapses of attention, errors of execution, working memory inadequacy, etc.

Divided problems into indirect and direct reasoning:
Indirect reasoning: problems whose purpose is to find out whether subjects are all able to find the solutions, they may give rise to heuristic inadequacy errors.
Direct reasoning: reasoner starts with the premises, makes inference from them, and successively makes further inferences from premises + propositions already inferred, until given conclusion or contradiction is reached.

They found that when using two theory-based indices of expected problem complexity--the number of reasoning steps needed to solve a problem in their system and the sum of the difficulty weights of those steps, the indices were highly predictive of empirical measures of the difficulty of direct reasoning problems. Correlations ranged up to .95, for the joint prediction of rated difficulty from the weighted-sum index combined with problem length. (121) They then consider whether nonlogical models (specifically those based on cognitive "biases") could explain the results. They controlled for things like affirmatively phrased conclusions, but errors were still low on direct reasoning. Furthermore, biases would not have affected ratings because of the crossvalidated predicted of rated difficulty. This is all sort of brushed aside (and I don't understand the bias objection anyway). They used reasoning problems that had neural content (so that no preexisting knowledge or domain-specific skills would provide a basis for inferences). These were all inferences that should have been carried out using one step of one of the basic inferences. (See chapter 8 for more complicated inferences).

"...many simple inferences sanctioned by schemas (e.g., Schemas 2, 3, and 5) occur developmentally earlier than truth judgments and are made much more consistently than truth judgments by adults (Braine & Rumain, 1981). If the schema p, [therefore] p OR q were part of the essential meaning of or for subjects, then it should not be possible for them to reject the inference on simple problems." (128)

"Johnson-Laird's (1975) set of schemas is fairly similar to ours but lacks schemas equivalent to Schemas 5, 10, 11, and 14, and the strategy of enumeration of alternatives a priori. ... In general, it is not surprising that our system fits the evidence better than Johnson-Laird's because the present system was arrived at by starting with a set like his and successively altering the system where indicated by introspective reports or data on relative difficulties of problems." (128) [Footnote: "Johnson-Laird (1983) does not now agree with his 1975 model, but not for our reasons."]

"Merely changing the subject matter of propositions does not seem to change subjects' reasoning. ...there is good reason to believe that the theory proposed is general across subject matter." (133) 

IDEA: I wonder if these things will be affected by psychological priming, where an idea is somewhat "fresh" in the subject's mind. Assuming that schema can be primed, say that we repeat the sorts of tests done here (checking how effectively problems of varying complexity are solved) but prime certain schema beforehand. *****

IMPLICATIONS FOR "NATURAL" PROPOSITIONAL LOGIC
A set of schemas for a natural propositional logic should satisfy three conditions, they believe:
1) The schemas should be logically and psychologically valid. For the inferences the schemas define, the conclusions should follow from the premises. They go on to discuss how some of the schemas might possibly be of questionable validity (1, 2, 12, 13, and the strategy of enumeration of alternatives a priori).
2) The schemas should be psychologically elementary as well as valid.
3) The set of schemas should be psychologically complete. It should contain all the psychologically valid elementary schemas that there are.


},
	Author = {Braine, Martin D.S. and Reiser, Brian J. and Rumain, Barbara},
	Booktitle = {Mental Logic},
	Chapter = {7},
	Date-Added = {2011-08-17 23:24:20 -0400},
	Date-Modified = {2011-08-19 19:54:39 -0400},
	Editor = {Braine, Martin D.S. and O'Brien, David P.},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Evidence for the Theory: Predicting the Difficulty of Propositional Logic Inference Problems},
	Year = {1998}}

@incollection{Braine1998b,
	Annote = {Basic description of mental-propositional logic theory (which does not include innate FOL and modal logic mechanisms, it is in that sense a limited theory). 

BASIC INFERENCE SCHEMAS (see description of properties of the logical schemas described in Braine1998a):
[I will use - for negation, <=> for the triple line equality]

Core schemas:
1) --p   <=>   p
2) (p1 | ... | pn) -> q; pi    =>    q
3) p1 | ... | pn; -pi    =>    p1 | ... | pi-1 | pi+1 | ... | pn
4) -(p1 & ... & pn); pi    =>    p1 & ... & pi-1 & pi+1 & ... pn
5) p1 | ... | pn; p1 -> q; p2 -> q; ...; pn -> q    =>    q
6) p1 | ... | pn; p1 -> q1; ...; pn -> qn    =>    q1 | ... | qn
7) p -> q; p    =>    q

Principal feeder schemas:
8) p1; p2; ...; pn    =>   p1 & ... & pn
9) p1 & ... pn    =>    pi

Incompatibility schemas:
10) p; -p    =>    INCOMPATIBLE
11) p1 | ... | pn; -p1 & ... & -pn    =>    INCOMPATIBLE

Other schemas:
12) Given chain of reasoning of form "Suppose p -> ... -> q" one can conclude: IF p THEN q
13) Given chain of reasoning of form "Suppose p -> ... -> INCOMPATIBLE" one can conclude: -p
14) p & (q1 | ... | qn)    <=>    (p & q1) | ... | (p & qn)

-------------

The DRR (Direct Reasoning Routine) is claimed to be universal. Together with the inference schemas, they constitute the "primary skills", and are often called the "basic model" (79). When subjects are making inferences from information they have (without a given goal conclusion), just the inference procedure is applied. Otherwise when a conclusion is given whose truth is to be evaluated, the routine uses the following algorithm:

__________________________________________
DRR:

Premise_Set = all given premises
Matching_Conclusion = true or false, depending on if we are using DRR to match a conclusion or just to find inferences
Goal_Conclusion = only defined if Match_Conclusion==true

// preliminary procedure:
If (Matching_Conclusion):
	if (Goal_Conclusion is an if-then statement):
		add antecedent of Goal_Conclusion to Premise_Set
		Goal_Conclusion = consequent of Goal_Conclusion
	call evaluation procedure
	// we should only reach this point if evaluation procedure was indeterminate
	continue on to inference procedure

//begin inference procedure:
changes_made = false
For each of schemas 1-7, call it schema s:
	If s is applicable or if s can be applicable after applying one of the feeder schemas (8,9,14, and 1 in the right-to-left direction):
		apply s, resulting proposition is p
		if (p is NOT already in Premise_Set):
			changes_made = true
			add p to Premise_Set
			if (Matching_Conclusion == true):
				call evaluation procedure //should only move on from here if evaluation_procedure was indeterminate
			exit this for loop
		else loop again
if (changes_made):
	repeat the inference schema (this should only happen when the Premise_Set has been augmented)
else:
	exit this program, start running indirect reasoning strategies.

evaluation_procedure():
	if Goal_Conclusion is in Premise_Set or it can be inferred by applying a combination of the feeder schemas:
		respond true, exit program (since now we have reached our goal)
	else if the Goal_Conclusion, or an inference from it by schema 9, is incompatible (by Schemas 10 or 11) with something in 
	  Premise_Set, or with a proposition that can be inferred from the premise set by applying one or a combination of the feeder schemas:
		response false, exit program (since now we have found a contradiction)
	else:
		return to caller, evaluation_procedure was indeterminate
___________________________________________

SOME INDIRECT REASONING STRATEGIES (applied only when DRR fails):

Supposition-of-alternatives strategy. If the premise set contains a disjunction (or if one is obtained by applying Schema 9), and if some of the propositions of the disjunction do not occur as antecedents of conditionals in the premise set, then suppose each of these in turn and try to derive a conditional with it as antecedent, using Schema 12.

Strategies of enumeration of alternatives a priori. E.g., if the premise set contains one or more conditionals of the form "If p then ..." or "If not p then ...", add the proposition p or not p to the premise set and return to the inference procedure.

Reductio Ad Absurdum Strategy:
	Limited form: If there is a conjunction or disjunction embedded within a premise proposition or within the conclusion, then suppose the conjunction or disjunction as per Schema 13 and use the evaluation procedure to test its compatibility with the premise set; if the evaluation if "false," add the negation of the conjunction or disjunction to the premise set; use the evaluation procedure to test the conclusion against the augmented premise set, and if the evaluation is indeterminate, return to the Inference Procedure.
	Stronger form: To test the falsity of a conclusion given, or of any proposition embedded within a premise or the conclusion, add the negation of that proposition to the premise set and try to derive an incompatibility as per Schema 13, using the Inference Procedure, any available other strategies, and the Evaluation Procedure.

____________________________________________



Methinks this can be programmed (these notes were carefully put into pseudocode, since Braine's original work was procedural but somewhat messy) and compared to the programs simulating mental models. The question is, using what sort of metrics to compare the two? 

"Biases and nonlogical heuristics (cf. Evans, 1982) can affect reasoning performance at the stage of response choice or during a line of reasoning, but, we predict, will do so when a problem requires resources beyond the DRR plus readily available strategies: Then, biases and nonlogical heuristics may yield an alternative to "nothing follows" or "can't tell." "(8) He goes on to say that the pragmatic reasoning schemas of Cheng and Holyoak and the social contracts of Cosmides might be elicited at this point by certain content. It may affect the algorithm's performance by affecting the order in which certain schema are applied.},
	Author = {Braine, Martin D.S. and O'Brien, David P.},
	Booktitle = {Mental Logic},
	Date-Added = {2011-08-15 20:43:49 -0400},
	Date-Modified = {2011-08-15 22:36:48 -0400},
	Editor = {Braine, Martin D.S. and O'Brien, David P.},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {The Theory of Mental-Propositional Logic: Description and Illustration},
	Year = {1998}}

@incollection{Braine1998a,
	Annote = {3 points about mental logic, which they state are similar to Fodor's arguments on the existence of a LOT (although they explicitly mention that they don't adopt the radical innateness Fodor does; only that the "syntax of thought" is innate (48):
1) How did a mental logic evolve? Possibly for pragmatic goals (an example is given).
2) There seems to be a consensus that the mental logic consists of a set of inference schemas together with some sort of basic program for applying them.
3) A mental logic is intimately connected to the concept of a language of thought for two reasons: to represent inference schemas, some system of representation is needed; and more importantly, some sort of innate format for representing knowledge would seem to be a precondition for memory, at least for declarative memory. If there is no format for recording something, there is no way to record it.

The rest of the chapter he spends talking about some evidence from linguistics towards the existence of an innate logical mechanism.

"A natural logic based on inference schemas entails that there is a set of logically sound schemas, each of which has the following properties:" (49)
1) Each schema is psychologically valid; each can be used basically without error on "maximally simple problems that could be solved using it".
2) Each schema is psychologically elementary: The inference it defines is made in a single step
3) Each is psychologically primitive -- available early to children
4) Universal: Has properties 1-3 in all cultures and languages

},
	Author = {Braine, Martin D.S. and O'Brien, David P.},
	Booktitle = {Mental Logic},
	Chapter = {4},
	Date-Added = {2011-08-14 22:38:11 -0400},
	Date-Modified = {2011-08-15 20:44:19 -0400},
	Editor = {Braine, Martin D.S. and O'Brien, David P.},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {How to Investigate Mental Logic and the Syntax of Thought},
	Year = {1998}}

@incollection{OBrien1998,
	Annote = {rather than Piaget's original view that the "structure of concrete-operational thought corresponds to a logic of classes, and formal-operational thought is equivalent ot the 16 truth-functional operators" (27), mental logic adherents believe "reasoning proceeds through the application of sound inference schemas":
inference schemas - procedures specifying which propositions can be derived from assumed propositions of a particular form
sound schemas - assure that propositions derived from tru assumptions inherit that truth

further, they disagree about how the schemas are used. Some say they are used to verify conclusions made by other processes, some don't (28).

O'Brien's 3-part model:
a) a set of inference schemas
b) a reasoning program implementing them in a line of reasoning
c) a set of independently motivated pragmatic principles that influence interpretation of surface-structure propositions and can suggest or inhibit certain inferences and reasoning strategies. (28)

Differentiates introduction, elimination, core, feeder, and complex schemas:
- core schemas: automatic, usually simple: (p or q) and (-p) automatically infer (q)
- feeder schemas: applied when their propositional output feeds into a subsequent inference, in which case they are applied automatically. They may lead to infinite loops (p and q) to (p and p and q) to ..., for example, which people don't do. They are designated as empirical; when subjects are asked to write every inference they can from some given assumptions, they usually omit the feeder schema output even if the output of feeder schemas is required to make the core-schema inferences they give.
- complex schemas: require use of an indirect-reasoning routine. To falsify proposition p, you can assume p and find a contradiction. If one isn't found, then a negation-introduction schema allows assertion of not-p. These schemas are NOT claimed to be universally available, and depend on the effortful use of an indirect-reasoning routine.

"As yet, the reasoning program of The Model does not capture adequately when subjects look ahead [to figure out which inferences will be needed to get closer to the goal] and when they do not, but then, neither does the reasoning program proposed by Rips (1983), with its focus on goal-attaining inferences." (30)

Some evidence for the model:
"The inferences that The Model predicts should be made effortlessly and routinely were made routinely and with little apparent effort." (33)
"[P]eople seem to behave in ways that The Model predicts both on logical-reasoning problems and in text comprehension. The Model successfully predicts which problems subjects solve, the relative perceived difficulty of the solved problems, response times on simple problems, and the order in which inferences are written down. I know of no competing model that has had this sort of empirical success." (34)

A REPLY TO SOME ARGMENTS AGAINST MENTAL LOGIC
On failure to solve Wason's selection task and THOG task:
"With the exception of Piaget (see Beth & Piaget, 1966, p.181, which seems to indicate that the selection task should be solvable), none of the theories of mental logic predicts that such problems will be solved, and the basic parts of The Model, including the core and feeder schemas together with the direct-reasoning routine, are nowhere near being sufficient to solve such problems. Thus, failure to solve these complex problems does not count as evidence against The Model." (35)
He further argues that the versions of Wason that are solvable are difficult to explain without logical reasoning, and the THOG task (Wason & Brooks, 1979) requires a reasoning strategy going will [sic] beyond the basic parts of The Model.
He agrees that reasoning depends on a combination of logical and nonlogical processes (37).


COMPETING NONLOGICAL THEORIES HAVE THEIR OWN PROBLEMS
Talks briefly about the deontic theories, which ascribe reasoning to the following of permission and obligation rules, which then set goals. He "see[s] no a priori reason that evolution should provide domain-specific processes but not general processes. Species with overly specified behavioral traits are at an evolutionary disadvantage when their environmental situation changes." (40) 
He notes that with the "drinking game" version of Wason's task, the problem is structurally different. The rules are assumed true and can be used directly to draw a conclusion, making it inherently easier.

Mental models:
says it's not totally clear what a mental model is: an image is too limited, plus images are not propositional and do not contain variables.
"[T]here are many sorts of propositions that are difficult, if not impossible, to represent with a mental model. Thus, there is a clear need for some representational and inference processes other than those provided by mental models. I make no claim that people never use mental models--only that inferences from mental models would cohabit with inferences from other sources, including those of a mental logic. I do not think that [mental model theory is] an adequate account of what such mental models would be, and their introduction of propositional-like tags [which is how they chose to represent universal quantification] suggests that part of a mental-models theory should be a propositional mental logic." (42)


IRRATIONALITY AND THE MODEL
In general, the argument from the content-bound theories of Cosmides, Cheng and Holyoak, and the mental-models theory of Johnson-Laird claim that when there is support for their type of reasoning, it suggests people do not use logical inference schemas. "Such arguments against theories that rely only on formal content-free inference rules are straw-man arguments. Mental-logic theories have never claimed exclusivity. Even Piaget thought that formal-operational skills are constrained by real-world knowledge. ... Evidence for some effects of extralogical processes is not inconsistent with the claims of the mental-logic approach. That people make errors on some reasoning tasks is not a sufficient reason to proclaim the absence of any mental logic." (43)

},
	Author = {O'Brien, David P.},
	Booktitle = {Mental Logic},
	Chapter = {3},
	Date-Added = {2011-08-14 13:55:54 -0400},
	Date-Modified = {2011-08-14 22:39:27 -0400},
	Editor = {Braine, Martin D.S. and O'Brien, David P.},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Mental Logic and Irrationality: We Can Put a Man on the Moon So Why Can't We Solve Those Logical Reasoning Problems?},
	Year = {1998}}

@book{Johnson-Laird1983,
	Annote = {
--------CHAPTER 6---------------------------
explicit inference - at forefront of awareness, slow [possibly facilitated by external means: working out computations on a sheet of paper, for example]
implicit - rapid, effortless, outside of conscious awareness

"any adequate theory [...] must recognize the distinction between [implicit and explicit]" (127)

Susan needed Mary's pencil
She gave it to her (129)
Children have trouble making the implicit inference in this case regarding who "she" and "her" refer to.

Constructing inference:
1 - construct finite model satisfying first premise and another model for the second premise, taking care to use the same # of items to represent the middle term in both models
2 - form integrated model by joining the two in virtue of the items representing the middle term.
3 - formulate a conclusion true of the resulting model that interrelates the two terms.

"what about the machinery for searching for end items, destroying identities, and testing truth conditions -- does it perhaps incorporate a formal logic? Once again, the answer is negative. All that is required is the ability to construct models, to search for entities in them, and to generate descriptions of them -- in short, the basic computational power described in Chapter 1 in terms of Turing machines and recursive functions. Such functions do not in themselves constitute a logic: they can be used to model either logical or illogical processes." (133)

Externalizing and systematizing logic has obvious advantages, hence "the theory is compatible with the development of logic as an intellectual tool." (133)


TRANSITIVITY
He demonstrates that simply by knowing how to use the transitivity rule between two elements will automatically lead to the emergence of properties that logically follow. For example: There are more A's than B's; There are more B's than C's. We could say that the inferential process which leads to "There are more A's than C's" requires the FOL rule:
xRy AND yRz -> xRz
But simply by drawing a mental picture of a room with more A's than B's, and even less C's, knowing how to use the rule "more than" allows you to draw the conclusion "more A's than C's" without applying the transitive rule.
KNOWING HOW TO USE a rule can lead to the emergence, through mental models, of inferences related to that rule. But:
- how do the inductive rules become extracted from know-how?
- how does one acquire the ability to understand how to use a rule?

Argues against the idea that a transitivity schema is derived from the notion of serial order:
"Although it is true that serial orders give rise to transitivity, there are a number of transitive relations that do not depend on orderings, e.g., 'is included in', 'is an ancestor of', 'is identical to'. Their transitivity follows from their semantics, and can be readily grasped from an appropriate mental model: for instance, a model in which a is included in b and b is included in c readily yields the conclusion that a is included in c. It is accordingly a mistake to try to reduce the representation of all transitive relations to a system based on an underlying ordinal dimension." (137)

QUANTIFICATION
He shows that basically drawing mental pictures can allow for many FOL operations, like universal instantiation:
J is a Scot; All Scots are Human

step 1(a):
	s
j ==	s
	s

step 1(b):
s == h
s == h
s == h
	h
	h

step 2:
	s ==	h
j ==	s ==	h
	s ==	h
		h
		h

step 3:
therefore J is Human.

More complex relations like "Some professors attended all the meetings" can be represented with arrows.
He also gives the example that is not provable in first order logic, it requires a higher order logic which is not complete:

More than half the musicians were classically trained
More than half the musicians were in rock groups
-> Some of the musicians were both classically trained and in rock groups.

This can be easily figured out by both children AND mental models, but not possible with FOL alone (proven by Barwise and Cooper, (1981) "Generalized quantifiers and natural language", Linguistics and Philosophy).

"[T]here is no way to formalize the calculus so that all valid inferences are derivable within it. If there can be no formal logic that captures all the valid deductions, then [a fortioti [emphasized]] there can be no mental logic that does either. It is a remarkable fact that natural language contains terms with an implicit 'logic' that is so powerful that it cannot be completely encompassed by formal rules of inference. It follows, of course, that any theory that assumes that the logical properties of expressions derive directly from a mental logic cannot give an adquate account of those that call for a higher-order predicate calculus. This failure is a final and decisive blow to the doctrine of mental logic." (140-141)

Then he talks about Fodor's claim that logical rules must be innate (the expressibility / bootstrap argument we are familiar with). His first counter is the evolution one (how could such a thing have evolved?). Then:

"[T]he claim that there is no way in which the logical power of the mind could be increased by learning is ambiguous. Any computable function can be characterized in terms of the three sorts of primitive recursive functions (the zero, identity, and successor functions) and the three operations that create new functions out of old (composition, recursion, and minimization -- see Chapter 1). Hence, any computable procedure whatsoever can be constructed out of these functions." (143)
This argument basically says what I have been saying--as long as we have a certain expressibility (here defined in terms of Turing machines) it can propagate. Continues:
"We can see why it is not necessary to accept Fodor's conclusion. First, there is no need to assume that stage 1 is weaker in [computational [emphasis]] power than stage 2: in stage 1, an individual has a weaker logic than in stage 2, but does process the capacity to construct a more powerful logic. Second, one must not confuse [what [emphasis]] is learned with [how [emph]] it is learned. When Pythagoras first proved his celebrated theorem, he learned something new - a certain proposition, which he may have believed to be true, was [necessarily [emph.]] true. How Pythagoras discovered his proof may indeed have depended on all sorts of inductive procedures, but this supposition in no way infects what Pythagoras learnt. In general, it may be true, as Fodor claims, that learning must be a process of non-demonstrative inference, but it does not follow that all that can be learned is the inductive confirmation, or disconfirmation, of a belief." (143)
"The mind almost certainly has a rich set of native functions, together with specific procedures for guiding the process of constructing new functions out of old. ... The conclusion to be drawn is not that nativism should be abandoned -- there must be an innate armamentarium of data and procedures. And Fodor is right to argue that stages in inferential ability cannot possibly be associated solely with mental logics of increasing power. Where he is wrong, however, is in his stronger thesis that [in principle [emph.]] all concepts are innate and that inferential skill cannot be learned." (144)
"Because the theory of mental models has no need of mental logic, it does not have to explain the initial development of reasoning ability by way of the acquisition of rules of inference. What children learn first are the truth conditions of expressions: they learn the contribution of connectives, quantifiers, and other such terms to these truth conditions. " (144)



--------------- CHAPTER 10: MENTAL REPRESENTATION OF A WORD? ------------------

Talks about theories of words like the definitional, stereotype, etc. 
Theories that think the meanings of words are represented by expressions in a mental language don't explain "how these expressions relate to the world. [This would be ok if] a satisfactory account of how speakers understand the properties of intensions and the relations between them could be given without considering how they grasp extensions. In fact, this tacit assumption of the psychological autonomy of intensions turns out to be false. Unless the retrieval of referents is taken into account, it is impossible to explain the resolution of lexical ambiguities, the instantiation of words in context, the vagaries in the logical properties of spatial relations, and a variety of deictic phenomena. Further doubt is cast on the decompositional theory by the failure to obtain experimental support for any process of dcomposition, on the strong form of the network theory by the existence of marked within-category differences, and on the meaning postulate theory by the feasibility of definitions and the existence of mental dictionary entries." 


From chapter 11:
"Even if all the semantic properties and relations of such spatial terms as [right [emph]] and [left [emph]] could be pinned down by lexical decomposition, links in a network, or meaning postulates, which were somehow able to cope with the vagaries of transitivity, then it would still be necessary to specify how these words enter into the specifications of the truth conditions of the sentences in which they occur. The procedural theory outlined in this chapter takes that goal as its starting point. What emerges from this approach is that once truth conditions have thus been taken care of there is no need to give a separate account of the semantic properties of expressions. They are emergent properties of the truth conditions." (265)


----------------- CHAPTER 12: GRAMMAR AND PSYCHOLOGY ---------------------------
"The previous chapter outlined the theory that utterances are translated into propositional representations that can be used by a procedural semantics to construct mental models; and it illustrated the way this semantics might work by describing in detail a computer program for making inferences from spatial descriptions." (266)

Just as it is important to distinguish between meaning, the mental representation of meaning, and the process by which that representation is constructed, it is important to distinguish between grammatical structure (linguistic analysis), its mental representation, and the process by which that structure is recovered (the latter two requiring psycholinguistic investigation).

This chapter basically talks about linguistic methods to parse natural language and obtain propositional information from sentences. 

"...a useful conjecture midway between the lower bound of recursion and the upper bound of Turing machines is that grammatical structures can be adequately analysed by phrase-structure rules. The same conjecture is compatible with the hypothesis that grammatical sentences consist of a canonical form and any variations on that form can be analysed using a push-down stack to store temporally displaced constituents (Ades and Steedman, 1982)." (295)



--------------------CHAPTER 15: THE NATURE OF MENTAL MODELS-----------------------
"My goal of accounting for the process of inference, which I took to be a useful test case for cognitive science, has now been attained. Of course, I have not explained every mental process that underlies A's behaviour, but I have shown how the meanings of words can be mentally represented, how sentences can be parsed to form a propositional representation, how a propositional representation can be treated as the input to a procedural semantics that constructs mental models, how a unitary mental model of a discourse, such as the premises of the syllogism, can be formedon the basis of co-reference, and how reasoning follows the fundamental semantic principle of validity in a search for counter-examples to putative conclusions." (396)

Immediate constraints on possible mental models:
1) The principle of computability: Mental models, and the machinery for constructing and interpreting them, are computable. This ensures no more than a denumerably infinite number of possible mental models.
2) The principle of finitism: A mental model must be finite in size and cannot directly represent an infinite domain.
3) The principle of constructivism: A mental model is constructed from tokens arranged in particular structure to represent a state of affairs. The primary function of models is to represent states of affairs, and since there are an infinite number of possible models but a finite mechanism for constructing them, knowledge must have a certain structure. And this structure must then be built out of some more basic things. This is similar to the Fodorian argument for the existence of concepts (that they are the building blocks of representations).
4) The principle of economy in models: A description of a single state of affairs is represented by a single mental model even if the description is incomplete or indeterminate.
5) Mental models can directly represent indeterminacies iff their use is not computationally intractable, i.e., there is not an exponential growth in complexity.
6) The predicability principle: one predicate can apply to all the terms to which another applies, but they cannot have intersecting ranges of application. (argued in Keil, 1979)
7) The innateness principle: all conceptual primitives are innate. 
8) There is a finite set of conceptual primitive sthat give rise to a corresponding set of semantic fields, and there is a further finite set of concepts, or 'semantic operators', that occur in every semantic field serving to build up more complex concepts out ot the underlying primitives. Some examples of semantic operators are: Time, space, possibility, permissibility, causation, and intention.


HOW DO MENTAL MODELS REPRESENT THE EXTERNAL WORLD?
Reference. Bacteria and protozoa are just what he calls "Cartesian automata." An organism that makes use of a representation of the external world is a "Craikian automation" (after Kenneth Craik) which is a cartesian automata with a sensorioum that encodes impinging stimuli and the machinery to use this info to create a representation of the world, which guides its behavior.
"The essential characteristic of a model is its functional role. A model is a high-level representation in what is, from a functional point of view, an arbitrary symbolic notation." (403)
A simple robot which can detect edges, has sensors which move a piece of paper which "become[s] a model in the robot because of their function as an arbitrarily selected symbolic notation that is used to register the position of the robot in its world." (404)
I would add that the boundary between the two types of automata is not absolute, there seems to be levels. The bumblebee has some sort of representation, he talks about how it has something like a representation of the desired food source but it acts automatically, it does not use that symbolic representation as simply one factor in its intentional attitudes (405) which seems to be a level in between the two (though he says the bumblebee, described this way, is Craikian).

WHAT PROCESSES CONSTRUCT AND INTERPRET MENTAL MODELS?
"if the perception of the world is model-based, then discourse about the world must be model-based" (407)
Comprehension of discourse:
1) First is phonemic / graphemic representation, encodes sounds/letters
2) Propositional representation, close to surface form of utterance
3) Mental model, constructed on the basis of the truth conditions of the propositions expressed by the sentences in the discourse. Meaning of sentence, according to compositionality, is a function of the meanings of its words and the syntactic relations between them.

WHAT CONCEPTS ARE EMBODIED IN MENTAL MODELS?
Talks about basic and complex concepts (see requirements above, 6-8.

THE STRUCTURE OF MENTAL MODELS
},
	Author = {Johnson-Laird, Philip N.},
	Date-Added = {2011-08-10 19:03:11 -0400},
	Date-Modified = {2011-08-12 22:53:42 -0400},
	Publisher = {Harvard University Press},
	Title = {Mental Models: Towards a Cognitive Science of Language, Inference, and Consciousness},
	Year = {1983}}

@incollection{Johnson-Laird1985,
	Annote = {Seems to be an earlier account of mental models, in which he again shows that inferences like modus ponens can be made using the mental model rules, which does not require a mental logic rule to be built in. 

"...human beings, however, very often fail to examine all the possibilities--they have no logic to help them. Moreover, logic alone can never guide the reasoner to a particular conclusion--it always permits an infinite number of alternative valid conclusions from any premises whatsoever. The overwhelming majority of such conclusions are entirely trivial, consisting of such assertions as the mere conjunction or dicjunction of the premises, and so human reasoners must obviously be guided by principles entirely outside logic to the particular conclusions that they draw. The heuristic principle that people appear to follow is to build a model that establishes a connection between those items that are referred to only in separate premises." (314)

The implication here seems to be that mental models can just be the heuristic by which we make the search through conclusion-space more tractable, still leaving the door open for an underlying logical mechanism of FOL expressivity.

He also describes some work by Sylvia Scribner in which an uneducated, illiterate Kpelle subject is unable (or unwilling) to make an inference regarding a hypothetical subject "Mr. Smith" because he does not know the man personally. (314-315) Possibly the sort of evidence that was used against Piaget to demonstrate that formal operations simply doesn't develop in some cultures.},
	Author = {Johnson-Laird, Philip N.},
	Booktitle = {Thinking and Learning Skills},
	Date-Added = {2011-08-09 22:17:54 -0400},
	Date-Modified = {2011-08-09 22:25:17 -0400},
	Editor = {Chipman, Susan F. and Segal, Judish W. and Glaser, Robert},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Logical Thinking: Does it Occur in Daily Life? Can it Be Taught?},
	Volume = {2},
	Year = {1985}}

@incollection{Johnson-Laird2008,
	Annote = {"...theorists have yet to devise an algorithm for recovering the logical form of propositions." (355)

THE SIMULATION OF SPATIAL REASONING USING MENTAL MODELS
- each mental model is a possibility, something like a 3-d model of the world. A conclusion is necessary if held in all models, possible if held in at least one model, and probable if held in most models given that the models are equiprobable.
- Bara, Bucciarelli, and Lombardo (2001) wrote a program that simulated reasoning in single model-based program
- Program has a lexicon specifying the meanings of the key words in the input, which may be sentential connectives, quantifiers, causal verbs, deontic verbs, relational terms, or nouns referring to objects. (344)
- Program also has grammar of the relevant fragment of english.
- Each grammatical rule has a function that carries out the corresponding semantic interpretation. Parser uses a "shift-and-reduce" method.
- Input is a description of some physical arrangement (344 for example).
- describes how the system can construct a model step by step in which the transitivity of position holds (x is to the right of y, y is to the right of z, therefore x is to the right of z) without explicitly defining a transitivity rule. (344-345)

how to write out a mental model in the program: p. 349



"Table 12.2 summarizes the main procedures used in the program. If the human inferential system uses models, it needs such procedures, too." (345) 
THIS IS WHAT I WAS LOOKING FOR -- a procedure which should have the power of FOL or higher which Johnson-Laird admits must be necessary},
	Author = {Johnson-Laird, Philip N. and Yang, Yingrui},
	Booktitle = {Cambridge Handbook of Computational Psychology},
	Date-Added = {2011-08-08 01:30:24 -0400},
	Date-Modified = {2011-08-09 10:45:21 -0400},
	Editor = {Sun, Ron},
	Pages = {339-358},
	Publisher = {Cambridge Univ Press},
	Title = {Mental Logic, Mental Models, and Simulations of Human Deductive Reasoning},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QYy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzIwMDggTWVudGFsIExvZ2ljIE1lbnRhbCBNb2RlbHMgYW5kIFNpbXVsYXRpb25zIG9mIEh1bWFuLnBkZtIXCxgZV05TLmRhdGFPEQJOAAAAAAJOAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfMjAwOCBNZW50YWwgTG9naWMgTWVuI0UzQzg0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48hMpmwCAAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMpm+GAAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMjAwOCBNZW50YWwgTG9naWMgTWVuI0UzQzg0LnBkZgAOAHoAPAAyADAAMAA4ACAATQBlAG4AdABhAGwAIABMAG8AZwBpAGMAIABNAGUAbgB0AGEAbAAgAE0AbwBkAGUAbABzACAAYQBuAGQAIABTAGkAbQB1AGwAYQB0AGkAbwBuAHMAIABvAGYAIABIAHUAbQBhAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAGhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzIwMDggTWVudGFsIExvZ2ljIE1lbnRhbCBNb2RlbHMgYW5kIFNpbXVsYXRpb25zIG9mIEh1bWFuLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAPQA+QEBA1MDVQNaA2UDbgN8A4ADhwOQA5UDogOlA7cDugO/AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA8E=}}

@incollection{Johnson-Laird,
	Annote = {better, more up to date description of the mental models theory of reasoning. 

PRINCIPLE OF TRUTH: mental models represent clauses in the premises, affirmative or negative, only when they are true, and not when they are false (209).

One of the reasons this theory can't be completely represented symbolically is that the models themselves are constructed using background knowledge (214).

"At the heart of the model theory is the assumption that individuals who have had no training in logic are able to make deductions. The theory does not abandon logic entirely (pace, e.g., Toulmin 1958). Mental models relate to the model theory of logic, and to the logical principle that an inference is valid if there are no counterexamples to its conclusion. Individuals accordingly reason by constructing mental models of possibilities." (220)},
	Author = {Johnson-Laird, Philip N.},
	Booktitle = {Reasoning: Studies in Human Inference and Its Foundations},
	Date-Added = {2011-08-07 22:51:29 -0400},
	Date-Modified = {2013-01-30 20:46:24 -0500},
	Editor = {Rips, L. AND Adler, J.},
	Pages = {206-222},
	Publisher = {Cambridge Univ Press},
	Title = {Mental Models and Deductive Reasoning},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QVS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzIwMDggTWVudGFsIE1vZGVscyBhbmQgRGVkdWN0aXZlIFJlYXNvbmluZy5wZGbSFwsYGVdOUy5kYXRhTxECJAAAAAACJAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHHzIwMDggTWVudGFsIE1vZGVscyBhbiNFM0M4Ni5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPIbKZMdWAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKZP+WAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAXk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6ADIwMDggTWVudGFsIE1vZGVscyBhbiNFM0M4Ni5wZGYADgBeAC4AMgAwADAAOAAgAE0AZQBuAHQAYQBsACAATQBvAGQAZQBsAHMAIABhAG4AZAAgAEQAZQBkAHUAYwB0AGkAdgBlACAAUgBlAGEAcwBvAG4AaQBuAGcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFpVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzIwMDggTWVudGFsIE1vZGVscyBhbmQgRGVkdWN0aXZlIFJlYXNvbmluZy5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDmAOsA8wMbAx0DIgMtAzYDRANIA08DWANdA2oDbQN/A4IDhwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAOJ}}

@article{Johnson-Laird2010,
	Abstract = {An old view in logic going back to Aristotle is that an inference is valid in 
virtue of its logical form. Many psychologists have adopted the same point 
of view about human reasoning: the first step is to recover the logical form 
of an inference, and the second step is to apply rules of inference that match 
these forms in order to prove that the conclusion follows from the premises. 
The present paper argues against this idea. The logical form of an inference 
transcends the grammatical forms of the sentences used to express it, because logical form also depends on context. Context is not readily expressed 
in additional premises. And the recovery of logical form leads ineluctably to 
the need for infinitely many axioms to capture the logical properties of relations. An alternative theory is that reasoning depends on mental models, and 
this theory obviates the need to recover logical form.},
	Annote = {Lots of logical examples that mean to refute mental logic. This article tries to show that "previous theories based on formal rules have finessed a very difficult problem: how reasoners recover the logical form of propositions." (217)


Gave the example:
"Ann is a blood relative of Beth, Beth is a blood relative of Chris, what follows?"
People will normally infer that Ann and Chris are blood relatives, which doesn't logically follow. It seems an unstated implied transitivity of blood relation is called up. But I see some problems:
1) Why must it only be a first order logic? It seems that:
bloodRelatives(Ann,Beth) & bloodRelatives(Beth,Chris) -> isLikely(bloodRelatives(Ann,Beth))
is a perfectly fine modal logic that might produce this conclusion. 
2) Clearly the reasoning process of human beings attempts to extract logical facts not explicitly stated to fill in models to understand statements like the one given. Does Johnson-Laird deny that inferences are then performed over those resulting facts? (quotes given below) Because sure, there may be a delayed step between the process of reading and drawing inferences (which would be called the model construction stage) but nevertheless, inferences are performed, which requires logic. (I wonder what Yang's mental metalogic theory says about this).

On the need for logic to perform inferences over models:
"[ML] theories have little or nothing to say about how individuals discover that a set of assertions is inconsistent, and what they do to rectify inconsistencies. In contrast, the model theory allows for a process in which they withdraw a conclusion which conflicts with the facts - a form of so-called "nonmonotonic" reasoning (Brewka, Dix, & Konolige, 1997) - and then formulate an explanation that resolves the inconsistency (see, e.g., Johnson-Laird, et al., 2004)."
"Fortunately, you don't need logical form or meaning postulates if you reason using models. You consider the meanings of the premises, you take context and knowledge into account, and then you imagine the possibilities compatible with this information, though you prefer to work with just a single mental model, which suffices for institutions (Johnson-Laird, 1983, Ch. 6). If a conclusion holds in each of your models, you consider that the inference is valid. The transitivity of relations is an emergent property of building iconing models based on the meanings of relations ..." (216)

"Experimental evidence corroborates this account, and a computer program implementing it shows that transitivity need not depend on meaning postulates, but can emerge from the meanings of relations." (216)

Complains that it is difficult or impossible to refute mental logic completely (216) but:
"In contrast, the model theory would be refuted once and for all if it could be shown that inferences that demand the construction of multiple mental models are easier than those in the same domain that demand the construction of only a single model." (217)

Open problems with mental model:
"One major problem is the construction of models from perception ... In computer programs implementing the model theory, knowledge is represented as fully explicit models, which can be conjoined with models based on verbal premises in the process of modulation (see, e.g., Johnson-Laird, et al., 2004). ... how such models are acquired is another major puzzle for which we have no solution as yet" (218)
"mental models are sometimes erroneous, whereas logical models are impeccable. ... logic is neither a theory of what conclusions individuals tend to draw nor a theory of how they draw them [, rather] which premises in a formalized language logically imply which conclusions. It is not dispensable, but it is not the direct route to a psychological theory." (218) AGREED!},
	Author = {Johnson-Laird, Philip N.},
	Date-Added = {2011-08-06 22:27:49 -0400},
	Date-Modified = {2011-08-06 23:05:33 -0400},
	Journal = {Psychologica Belgica},
	Number = {3&4},
	Pages = {193-221},
	Title = {Against Logical Form},
	Volume = {50},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzIwMTBhZ2FpbnN0LWxvZ2ljYWwtZm9ybS5wZGbSFwsYGVdOUy5kYXRhTxEB7AAAAAAB7AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHHDIwMTBhZ2FpbnN0LWxvZ2ljYWwtZm9ybS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPIrKYc51AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKYga1AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAW01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6ADIwMTBhZ2FpbnN0LWxvZ2ljYWwtZm9ybS5wZGYAAA4AOgAcADIAMAAxADAAYQBnAGEAaQBuAHMAdAAtAGwAbwBnAGkAYwBhAGwALQBmAG8AcgBtAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBIVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy8yMDEwYWdhaW5zdC1sb2dpY2FsLWZvcm0ucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A1ADZAOEC0QLTAtgC4wLsAvoC/gMFAw4DEwMgAyMDNQM4Az0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADPw==}}

@article{Johnson-Laird2001,
	Annote = {Basic description of mental models. It seems more that the mental models theory emphasizes the role of background knowledge and depth of understanding in inferential thought (very compatible with schema and neo-piagetianism) but I still don't see how the reasoning to carry out inferences, even when done using a network of background knowledge, can be done without an innate logical mechanism (or at least one with sufficient logical expressivity). The argument against mental logic seems to be one based on the lack of applying inferential rules as such.


Three main assumptions of mental models theory:
1) Each mental model represents a possibility
2) "The Principle of Truth": Mental models represent what is true according to the premises, but by default not what it false. (People tend to ignore false facts when reasoning, as opposed to traditional inference which uses false facts to derive contradictions)
3) Deductive reasoning depends on mental models.

Predictions:
1) The fewer models required for an inference, the easier it should be. One model is better than many.
2) Reasoners sometimes fail to consider all models in multiple-model problems. They draw conclusions that are POSSIBLE rather than NECESSARY.
3) When falsity matters, fallacies occur (principle of truth discussion)
4) Content and background knowledge modulate the interpretation of assertions, and so no connectives are truth functional.
5) With experience, reasoners develop tailor-made strategies for particular sorts of problems.

With MM, something is regarded as true if a model is found that satisfies everything, and false if no models do.},
	Author = {Johnson-Laird, Philip N.},
	Date-Added = {2011-08-06 18:46:50 -0400},
	Date-Modified = {2013-01-30 20:46:13 -0500},
	Journal = {TRENDS in Cognitive Sciences},
	Number = {10},
	Title = {Mental Models and Deduction},
	Volume = {5},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xMTEuNjg3My5wZGbSFwsYGVdOUy5kYXRhTxEByAAAAAAByAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEzEwLjEuMS4xMTEuNjg3My5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPFTKYzx9AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKY3S9AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAUk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6ADEwLjEuMS4xMTEuNjg3My5wZGYADgAoABMAMQAwAC4AMQAuADEALgAxADEAMQAuADYAOAA3ADMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD9Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xMTEuNjg3My5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AywDQANgCpAKmAqsCtgK/As0C0QLYAuEC5gLzAvYDCAMLAxAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADEg==}}

@article{Mizuno2011,
	Abstract = {Personal pronouns, such as `I' and `you', require a speaker/listener to continuously re-map their reciprocal relation to their referent, depending on who is saying the pronoun. This process, called `deictic shifting', may underlie the incorrect production of these pronouns, or `pronoun reversals', such as referring to oneself with the pronoun `you', which has been reported in children with autism. The underlying neural basis of deictic shifting, however, is not understood, nor has the processing of pronouns been studied in adults with autism. The present study compared the brain activation pattern and functional connectivity (synchronization of activation across brain areas) of adults with high-functioning autism and control participants using functional magnetic resonance imaging in a linguistic perspective-taking task that required deictic shifting. The results revealed significantly diminished frontal (right anterior insula) to posterior (precuneus) functional connectivity during deictic shifting in the autism group, as well as reliably slower and less accurate behavioural responses. A comparison of two types of deictic shifting revealed that the functional connectivity between the right anterior insula and precuneus was lower in autism while answering a question that contained the pronoun `you', querying something about the participant's view, but not when answering a query about someone else's view. In addition to the functional connectivity between the right anterior insula and precuneus being lower in autism, activation in each region was atypical, suggesting over reliance on individual regions as a potential compensation for the lower level of collaborative interregional processing. These findings indicate that deictic shifting constitutes a challenge for adults with high-functioning autism, particularly when reference to one's self is involved, and that the functional collaboration of two critical nodes, right anterior insula and precuneus, may play a critical role for deictic shifting by supporting an attention shift between oneself and others.

},
	Annote = {They found decreased activity between two brain areas in autistic children when processing pronouns, might explain their inability to use them properly.},
	Author = {Mizuno, Akiko and Liu, Yanni and Williams, Diane L. and Keller, Timothy A. and Minshew, Nancy J. and Just, Marcel A.},
	Date-Added = {2011-08-03 17:41:45 -0400},
	Date-Modified = {2013-01-30 20:35:43 -0500},
	Journal = {Brain},
	Month = {July},
	Pages = {1-14},
	Title = {The Neural Basis of Deictic Shifting in Linguistic Perspective-Taking in High-Functioning Autism},
	Volume = {134},
	Year = {2011}}

@incollection{Stanovich2003,
	Annote = {didn't read the whole thing, lost interest.},
	Author = {Stanovich, Keith E. and West, Richard F.},
	Booktitle = {Evolution and the Psychology of Thinking},
	Date-Added = {2011-07-31 15:58:39 -0400},
	Date-Modified = {2013-01-30 21:02:06 -0500},
	Editor = {Over, David E.},
	Publisher = {Psychology Press},
	Title = {Evolutionary Versus Instrumental Goals: How Evolutionary Psychology Misconceives Human Rationality},
	Year = {2003}}

@incollection{Over2003,
	Annote = {EEA - Environment of Evolutionary Adaptedness, in which our ancestors evolved via natural selection

Contrasts massive modularity with dual-process mind theories (according to which there are general-purpose cognitive processes as well as content-specific modules).

Type/System 1 processes - content specific modules
Type/System 2 processes - general-purpose, content-independent mental processes

Massive modularity can be defined as saying there are no type/system 2 processes (122).
Massive modularity theoriest have been opposed to mental logic, because it is general-purpose content-independent reasoning. (123-124) Use following structure (p.124)

- X-type adaptive problems and Y-type nonadaptive problems are of the same clear logical form.
- Experiments show people can reliably solve X but not Y-type.
- Therefore people do not have a mental logic applying equally to X and Y type, rather they have an evolved module for content-specific inference about X-type.

(I) If a card has an A on one side, then it has a 4 on the other side.
(D1) If a man eats cassava root, then he must have a tattoo on his face.

Cosmides assumes these two have the same logical form. Over argues that (I) is an indicative conditional, (D1) is a deontic conditional.

(D2) If a man clears up spilt blood, then he must use rubber gloves. (126)

Whereas (D1) is a social contract, (D2) is a "conditional precaution".
"We have already noted that knowledge of deontic logical implications cannot be the result of a content-specific module. That an obligation to perform an action logically implies permission to perform it is a formal relation, not depending on the content of the action." (126)

In response to (Fiddick 2003), "[Different emotional reactions to different types of obligations and permissions] does not mean that, at the highest level, statements about both types do not have the formal property that an obligation logically implies a permission." (128)

Talks about frequency vs probability theories of mind, crticized the Cosmidez and Tooby claim that "people only understand how to perform probability inferences from beliefs or propositions having a content to do with objective relative frequencies." (128)

"Cosmides and Tooby (2000) have developed their position [...] They no longer claim that general-purpose mechanisms would have been "...grossly inefficient and easily out competed ... by content-specific mechanisms" (Tooby & Cosmides, 1992, p. 112). Mechanisms for logical thought evolved by natural selection, they now accept, and were adaptive in the EEA. They do not believe this happened merely because of social competition. They have a much more general account of why it was adaptive, having to do with the capacity of suppositional reasoning to make inferences about possibilities and cope with uncertainty and novelty in the world." (138)

"If we agree that people have a mental logic, or a primary workplace where they follow logical rules, then they should have the ability to follow these rules to solve problems of the same clear logical form. If people do not do this then perhaps the problems are not really of the same logical form, as they are not in indicative and deontic selection tasks. Another possibility is that the logical forms are not sufficiently clear, but we can sometimes correct this with some formal techniques, such as Euler circles." (141)},
	Author = {Over, David E.},
	Booktitle = {Evolution and the Psychology of Thinking},
	Date-Added = {2011-07-31 14:23:23 -0400},
	Date-Modified = {2011-07-31 14:29:26 -0400},
	Editor = {Over, David E.},
	Publisher = {Psychology Press},
	Title = {From Massive Modularity to Metarepresentation: The Evolution of Higher Cognition},
	Year = {2003}}

@incollection{Amit2003,
	Annote = {Accuses Cosmides and Tooby of saying special-purpose behavior-causing mechanisms evolved to solve one adaptive problem but not others. Instead, he argues they should be seen as evolving in a complex environment in which they must have evolved to solve multiple problems.
"The point here is not that there are or are not brain mechanisms that are specialized to solve individual adaptive problems but simply that there is no way of knowing in advance." (104)

Identifies problems with the cheater detection theory:
- Circumstantial variability. Even if we did evolve to exhibit cheater detection, it doesn't necessarily follow that the feature is a result of domain-specific mechanisms. It could instead be an emergent feature of other mechanisms.
- Historical variability. The historical conditions (specifically the way in which we lived as a society) may not necessarily map up to what is required for Cosmides to be right.

Then talks about how connectionist networks were largely successful in linguistics, and therefore it may be possible that the cheater detection features are emergent from connectionist architectures as well.},
	Author = {Almor, Amit},
	Booktitle = {Evolution and the Psychology of Thinking},
	Date-Added = {2011-07-31 13:25:55 -0400},
	Date-Modified = {2011-07-31 13:43:14 -0400},
	Editor = {Over, David E.},
	Publisher = {Psychology Press},
	Title = {Specialized Behavior without Specialized Modules},
	Year = {2003}}

@incollection{Fiddick2003,
	Annote = {Argues that variants of the Wason selection task meant to refute the theory there is a deontic reasoning module in humans don't sufficiently make their point. SCT (social contract theory) is defended here against deontic module theories.

SCT - Social Contract Theory - humans have a "look for cheaters" algorithms: "If you take the benefit, you must pay the cost." Fiddick emphasizes the point that it is not meant to be a general theory of reasoning (37), and so criticisms of it based on that assumption are misplaced. Associated with Cosmides.
Precaution theory - rule of the form "if the hazard exists, you must use protection" (as opposed to social contract rules). "the real question with precautionary rules is [...] whether people reason about social contracts and precautions using a common mental mechanism or whether these rules invoke distinct reasoning mechanisms (Fiddick, 1998)" (37).
The Deontic Alternative - Both social contracts and precautions are deontic rules (to which one is obligated or entitled to perform).

Pragmatic Reasoning Schemas Theory (PRST) - associated with Cheng & Holyoak. People reason about practical real-world problems using abstract knowledge structures, pragmatic reasoning schemas, which are compiled from personal experiences with different problem domains (38). This constructs "permission schema" with four types of production rules. (Holyoak & Cheng, 1995, p. 291) Fiddick notes that PRST predicts that precautions will elicit logically correct performance as well as social contracts, but SCT only predicts social contracts will. (38).

adaptive rules - abstract precautions and social contracts (41)
deontic rules - abstract permissions and obligations

experiment verified that social contract and precaution-formulated experiment showed much better success rates than action/situation, or permission/obligation.


EMOTIONS AS A CLUE TO INTERPRETATION
It is proposed that violations of social contracts elicit angry reactions; violations of precautions elicit fearful reactions. Fiddick tested what facial reactions subjects thought were appropriate when rules were violated. Majority of subjects selected angry face for the abstract social contract problem, and the fear face for the abstract precaution problem, which was a replication of previous findings.
PRST predicts that since permissions and obligations subsume social contracts and precautions, either people translate all rule violations into violations of social contracts and obligations, which should then generate fear and anger, or they will be confused and show random distributions.
SCT predicts sc violations -> anger, and doesn't make predictions for obligations.
Data supported SCT and Cosmides (1989) claim that people interpret abstract permission rules as social contracts.

Dominance Theory - Cummins' theory, very similar to PRST.

Cosmides,L 1989: Evolutionary psychology and the generation of culture
Fiddick 1998: The deal and the danger: An evolutionary analysis of deontic reasoning / Domains of deontic reasoning
Holyoak & Cheng, 1995: Pragmatic reasoning with a point of view},
	Author = {Fiddick, Laurence},
	Booktitle = {Evolution and the Psychology of Thinking},
	Date-Added = {2011-07-28 21:01:18 -0400},
	Date-Modified = {2013-01-30 20:22:41 -0500},
	Editor = {Over, David E.},
	Publisher = {Psychology Press},
	Title = {Is There a Faculty of Deontic Reasoning? A Critical Re-Evaluation of Abstract Deontic Versions of the Wason Selection Task},
	Year = {2003}}

@incollection{Martens2006,
	Annote = {Use an ant algorithm, "AntMiner+", to classify and generate crisp IF-THEN-ELSE rules. 

"Swarm intelligence is the property of a system whereby the collective behaviors of (unsophisticated) agents interacting locally with their environment cause coherent functional global patterns to emerge" (22).

Identifies aspects whose specification is implied by the design of an ant system:
- An environment that represents the problem domain in such a way that it lends itself to incrementally building a solution for the problem;
- A problem dependent heuristic evaluation function (eta), which represents a quality factor for the different solutions (something like a fitness function);
- Rule for pheromone updating (tau), which takes into account the evaporation and the reinforcement of the trails;
- A probabilistic transition rule based on the value of the heuristic function and on the strength of the pheromone trail that is used to iteratively construct a solution;
- A clear specification of when the algorithm converges to a solution.

Provides good list of literature overview, shows people who have applied ant algorithms to:
Clustering, Classification, Traveling Salesman, Vehicle Routing, Quadratic Assignment, Scheduling, and Telecommunications (24).

},
	Author = {Martens, David and De Backer, Manu and Haesen, Raf and Baesens, Bart and Holvoet, Tom},
	Booktitle = {Swarm Intelligence in Data Mining},
	Chapter = {2},
	Date-Added = {2011-07-28 14:18:20 -0400},
	Date-Modified = {2011-07-28 14:45:02 -0400},
	Editor = {Abraham, Ajith and Grosan, Crina and Ramos, Vitorino},
	Pages = {21-43},
	Publisher = {Springer},
	Title = {Ants Constructing Rule-Based Classifiers},
	Year = {2006}}

@book{Goertzel1994,
	Address = {233 Spring Street, New York, NY, USA},
	Annote = {A lot of the first few chapters is not impressing me, nothing particularly new. Seems to go back and forth between Neitzsche, other philosophers, the flow is confusing and the chapters are so short which would be good if there weren't such a wide topic disparity between them.
},
	Author = {Goertzel, Ben},
	Date-Added = {2011-07-27 18:02:43 -0400},
	Date-Modified = {2011-07-28 11:51:24 -0400},
	Publisher = {Plenum Press},
	Title = {Chaotic Logic : Language, Thought, and Reality from the Perspective of Complex Systems Science},
	Year = {1004}}

@unpublished{Hyotyniemi1996,
	Abstract = {Any algebraically computable function can be expressed as a recurrent neural network structure consisting of identical computing elements (or, equivalently, as a nonlinear discrete-time system of the form , where  is a simple `cut' function). A constructive proof is presented in this paper.},
	Annote = {Shows a way to implement a turing-complete system with a recurrent perceptron network. It basically encodes a program's lines of code into the neuron connections. No inputs are given, it has to be encoded as the initial state. The "program" is then run until termination (which involves all instruction nodes having zero outputs, so the state is "final"). The "variable nodes" give the final output in their output values (weights?).},
	Author = {Hyotyniemi, Heikki},
	Date-Added = {2011-07-27 16:17:12 -0400},
	Date-Modified = {2011-07-27 16:18:39 -0400},
	Lastchecked = {7/27/2011},
	Title = {Turing Machines are Recurrent Neural Networks},
	Url = {http://lipas.uwasa.fi/stes/step96/step96/hyotyniemi1/},
	Year = {1996},
	Bdsk-Url-1 = {http://lipas.uwasa.fi/stes/step96/step96/hyotyniemi1/}}

@article{Siegelmann1991,
	Abstract = {This paper shows the existence of a finite neural network, made up of sigmoidal neurons, which simulates a universal Turing machine. It is composed of less than 10 5 synchronously evolving processors, interconnected linearly. High-order connections are not required.},
	Annote = {Tries to answer the question of turing-equivalency for neural networks of finite size. Uses processor nets / recursive nets, which has N evolving "processors" which are all continuous-valued (as opposed to binary / threshold neurons), with one as the output node, and an input signal going into every processor. The state of the system at any time is a vector of N rational numbers, each one representing the activation value of a processor.

She says "[F]initely many threshold neurons cannot simulate more than finite automata behavior". This doesn't leave out NNs that increase in neural size (perhaps Shultz's is an example) and approaches that have infinite precision for the edge weights, which output information based on the state of the system rather than an output node.

Anyway, such networks are turing-equivalent. The ability to calculate functions of arbitrary length comes from the rational values (which can be arbitrarily long) of the processor activations. Seems like a bit of a cheat to me.,.},
	Author = {Siegelmann, Hava T. and Sontag, Eduardo D.},
	Date-Added = {2011-07-27 14:50:35 -0400},
	Date-Modified = {2013-04-13 20:30:31 -0400},
	Journal = {Applied Mathematics Letters},
	Pages = {77-80},
	Title = {Turing Computability with Neural Nets},
	Volume = {4},
	Year = {1991}}

@book{Namatame2006,
	Author = {Namatame, Akira},
	Date-Added = {2011-07-25 17:40:04 -0400},
	Date-Modified = {2011-07-25 17:41:32 -0400},
	Publisher = {World Scientific Publishing Co. Pte. Ltd.},
	Series = {Advances in Natural Computation},
	Title = {Adaptation and Evolution in Cognitive Systems},
	Volume = {5},
	Year = {2006}}

@book{Morra2008,
	Address = {New York, New York, USA},
	Annote = {Chapter 1 : From Piaget to the Neo-Piagetians

Good discussion on logic in Piagetianism. He divides the "logical Piaget" from the "dialectical Piaget" (which he admits, are overlapping categories) and talks about why the logical theory was overthrown, tries to save the dialectical one. Argues that the dialectical view was either ignored or misunderstood by Americans, who came from a mostly empirical tradition.
Then makes a great argument, summarizing the points that I talked about in my paper: there should be greater correspondence between informational approaches and neo-Piagetianism, since they stand to benefit from each other.

----------------------------------------

Chapter 2: The Theory of J. Pascual-Leone

Talks briefly about learning paradox (60) and claims that Pascual-Leone's proposed "metasubjective operators" avoid the problem of emergent expressibility of schema without resorting to extreme nativism. I'm not convinced, though...the expressibility comes from the operators, then?

----------------------------------------

Chapter 3 : Structuralist Approaches to Developmental Stages

"The problem posed for contemporary research is whether having abandoned formal logic as a model for the structure of thought, it is also necessary to abandon the concept of structure and the associated one of genesis; or, whether it is "only" necessary to find a more appropriate model for cognitive structure than is provided by formal logic" (90).

----------------------------------------

Chapter 7 : Cognitive Development as Change in Representations

----------------------------------------

Chapter 9 : Applications},
	Author = {Morra, Sergio and Gobbo, Camilla and Marini, Zopito and Sheese, Ronald},
	Date-Added = {2011-07-19 08:34:43 -0400},
	Date-Modified = {2011-07-19 12:35:24 -0400},
	Publisher = {Lawrence Erlbaum Associates},
	Title = {Cognitive Development : Neo-Piagetian Perspectives},
	Year = {2008}}

@article{Arkoudas2009,
	Author = {Arkoudas, Konstantine and Bringsjord, Selmer},
	Date-Added = {2011-07-16 03:50:54 -0400},
	Date-Modified = {2011-07-16 03:53:32 -0400},
	Journal = {Artificial Intelligence},
	Month = {October},
	Number = {15},
	Pages = {1367-1405},
	Title = {Vivid: A Framework for Combining Diagrammatic and Symbolic Reasoning},
	Volume = {173},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3ZpdmlkXzEyMDQwNS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEHZpdmlkXzEyMDQwNS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEqvJCYGAAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADJCcfQAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHZpdmlkXzEyMDQwNS5wZGYAAA4AIgAQAHYAaQB2AGkAZABfADEAMgAwADQAMAA1AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy92aXZpZF8xMjA0MDUucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==}}

@book{Putnam1975,
	Author = {Putnam, Hilary},
	Date-Added = {2011-07-16 03:44:26 -0400},
	Date-Modified = {2011-07-16 03:45:25 -0400},
	Publisher = {Cambridge Univ Press},
	Title = {Mind, Language and Reality : Philosophical Papers, Volume 2},
	Year = {1975},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8Qci4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1B1dG5hbSBIaWxhcnkgLSBNaW5kLCBMYW5ndWFnZSBBbmQgUmVhbGl0eSAtIFBoaWxvc29waGljYWwgUGFwZXJzIFZvbCAyLnBkZtIXCxgZV05TLmRhdGFPEQJ8AAAAAAJ8AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfUHV0bmFtIEhpbGFyeSAtIE1pbmQsI0YxMTBGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8RD8oF5h4AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMoGHl4AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAUHV0bmFtIEhpbGFyeSAtIE1pbmQsI0YxMTBGLnBkZgAOAJgASwBQAHUAdABuAGEAbQAgAEgAaQBsAGEAcgB5ACAALQAgAE0AaQBuAGQALAAgAEwAYQBuAGcAdQBhAGcAZQAgAEEAbgBkACAAUgBlAGEAbABpAHQAeQAgAC0AIABQAGgAaQBsAG8AcwBvAHAAaABpAGMAYQBsACAAUABhAHAAZQByAHMAIABWAG8AbAAgADIALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAHdVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1B1dG5hbSBIaWxhcnkgLSBNaW5kLCBMYW5ndWFnZSBBbmQgUmVhbGl0eSAtIFBoaWxvc29waGljYWwgUGFwZXJzIFZvbCAyLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgEDAQgBEAOQA5IDlwOiA6sDuQO9A8QDzQPSA98D4gP0A/cD/AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAP+}}

@article{Quartz1997,
	Author = {Quartz, Steven R and Sejnowski, Terrence J.},
	Date-Added = {2011-07-16 03:11:52 -0400},
	Date-Modified = {2011-07-16 03:15:19 -0400},
	Journal = {Behavioral and Brain Sciences},
	Pages = {537-596},
	Title = {The Neural Basis of Cognitive Development: A Constructivist Manifesto},
	Volume = {20},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xNjQuMjg5NC5wZGbSFwsYGVdOUy5kYXRhTxEByAAAAAAByAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEzEwLjEuMS4xNjQuMjg5NC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPF3JNERSAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADJNIqiAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAUk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6ADEwLjEuMS4xNjQuMjg5NC5wZGYADgAoABMAMQAwAC4AMQAuADEALgAxADYANAAuADIAOAA5ADQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD9Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xNjQuMjg5NC5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AywDQANgCpAKmAqsCtgK/As0C0QLYAuEC5gLzAvYDCAMLAxAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADEg==}}

@article{Arlin1975,
	Abstract = {Notes that recent investigation of th Piagetian stage of formal operations suggest that consistent, progressive changes in thought structures may extend beyond the level of formal operations. The present study, employing 60 female college seniors as Ss, systematically searched for new structures. It suggests a new stage to account for these structures and offers empirical evidence to support the hypothesized 5th stage. 2 formal stages are defined operationally: the problem-solving stage (traditional Piagetian formal operations stage) and the problem-finding stage. The commonly accepted criteria for a stage model are applied to justify the 2-stage hypothesis. Particular emphasis is placed on the sequencing criterion and on evidence that the problem-solving stage is the necessary but not sufficient condition for the problem-finding stage. Discussion centers on the theoretical and empirical importance of considering the 2-stage hypothesis, and further research questions are suggested. (16 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
	Author = {Arlin, Patricia K.},
	Date-Modified = {2013-01-30 20:15:09 -0500},
	Doi = {10.1037/0012-1649.11.5.602},
	Issn = {0012-1649},
	Journal = {Developmental Psychology},
	Keywords = {cognitive development,problem solving},
	Language = {English},
	Number = {5},
	Pages = {602--606},
	Title = {Cognitive development in adulthood: A fifth stage?},
	Url = {http://content.apa.org/journals/dev/11/5/602},
	Volume = {11},
	Year = {1975},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QTS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NvZ25pdGl2ZSBkZXZlbG9wbWVudCBpbiBhZHVsdGhvb2QucGRm0hcLGBlXTlMuZGF0YU8RAgwAAAAAAgwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx9jb2duaXRpdmUgZGV2ZWxvcG1lbnQjRThBQzYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADorGyQ/XoAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyRAd8AAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAF5NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBjb2duaXRpdmUgZGV2ZWxvcG1lbnQjRThBQzYucGRmAA4ATgAmAGMAbwBnAG4AaQB0AGkAdgBlACAAZABlAHYAZQBsAG8AcABtAGUAbgB0ACAAaQBuACAAYQBkAHUAbAB0AGgAbwBvAGQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFJVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NvZ25pdGl2ZSBkZXZlbG9wbWVudCBpbiBhZHVsdGhvb2QucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A3gDjAOsC+wL9AwIDDQMWAyQDKAMvAzgDPQNKA00DXwNiA2cAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADaQ==},
	Bdsk-Url-1 = {http://content.apa.org/journals/dev/11/5/602},
	Bdsk-Url-2 = {http://dx.doi.org/10.1037/0012-1649.11.5.602}}

@book{Barrouillet2011,
	Address = {New York, New York, USA},
	Author = {Barrouillet, Pierre and Gaillard, Vinciane},
	Date-Modified = {2013-01-30 20:15:02 -0500},
	Publisher = {Psychology Press},
	Title = {Cognitive Development and Working Memory : A Dialogue between Neo-Piagetian Theories and Cognitive Approaches},
	Year = {2011}}

@misc{Barwise1998a,
	Abstract = {Reasoning, problem solving, indeed the general process of acquiring knowledge, is not an isolated, homogenous affair involving a one agent using a single form of representation, but more typically a complicated, collaborative, heterogeneous activity. This paper describes an effort to expand our understanding of such reasoning and to develop tools to enable individuals and groups to use computers more effectively in practical problem-solving tasks. Natural deduction and problem solving A recent article in the New York Times reported the discovery of mass in the neutrino by a team of 120 scientists from 23 research institutions. The discovery involved the design and construction of a massive experiment involving a tank inside a deep zinc mine, filled with 12.5 million gallons of water, and equipped with specially designed light amplifiers covering the inside of the tank. Using this set-up as a neutrino detector to compare flavors of neutrinos coming directly from the atmosphere versus those coming through the earth, the scientists were able to determine that some neutrinos changed flavor in passing through the earth. The discovery also had a logical element, with mass being the only plausible explanation for the observations consistent with quantum theory that could not be ruled out in one way or another. As this example illustrates, large-scale collaborative projects involve many people reasoning toward the solution of a common problem over an extended period of time. The design and construction of a product, for example, whether a scientific apparatus, a building, or a complex hardware or software system, often involves a multi-disciplinary team of clients and engineers working toward a common goal. Such distributed reasoning projects frequently yield less than optimal...},
	Author = {Barwise, Jon and Etchemendy, John},
	Pages = {1--11},
	Publisher = {Proceedings of the Seventh Conference on Theoretical Aspects of Rationality and Knowledge},
	Title = {{A Computational Architecture for Heterogeneous Reasoning}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.5942},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3AxLWJhcndpc2UucGRm0hcLGBlXTlMuZGF0YU8RAbQAAAAAAbQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rw5wMS1iYXJ3aXNlLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxDtyQmFOAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyQnLiAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAE1NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBwMS1iYXJ3aXNlLnBkZgAADgAeAA4AcAAxAC0AYgBhAHIAdwBpAHMAZQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAOlVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvcDEtYmFyd2lzZS5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDGAMsA0wKLAo0CkgKdAqYCtAK4Ar8CyALNAtoC3QLvAvIC9wAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAL5},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.5942}}

@article{Barwise1983,
	Annote = {Goes over how they discovered that students learn and reason a lot better with diagrammatic representations rather than purely sentential propositional logic, and talks about how they thought something therefore must be missing. We neglected the diagrammatic types of reasoning in favor of the sentential, written forms, but human reasoning treats all of these as homogenous.},
	Author = {Barwise, Jon and Etchemendy, John},
	Journal = {Philosophy},
	Pages = {1--23},
	Title = {{Computers , visualization , and the nature of reasoning}},
	Year = {1983},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0NWYW5kTlIucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwtDVmFuZE5SLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw2kySvn5gAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAySwuNgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBDVmFuZE5SLnBkZgAOABgACwBDAFYAYQBuAGQATgBSAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9DVmFuZE5SLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@book{Beatty2001,
	Address = {Thousand Oaks, CA},
	Annote = {Textbook. See my notes in google notebook "Brain Notes".},
	Author = {Beatty, Jackson},
	Isbn = {0761920617},
	Keywords = {Brain,Neurons,Neuroscience},
	Mendeley-Tags = {Brain,Neurons,Neuroscience},
	Publisher = {Sage Publications, Inc.},
	Title = {{The Human Brain : Essentials of Behavioral Neuroscience}},
	Year = {2001}}

@article{Beer2004,
	Abstract = {Maturana and Varela's notion of autopoiesis has the potential to transform the conceptual foundation of biology as well as the cognitive, behavioral, and brain sciences. In order to fully realize this potential, however, the concept of autopoiesis and its many consequences require significant further theoretical and empirical development. A crucial step in this direction is the formulation and analysis of models of autopoietic systems. This article sketches the beginnings of such a project by examining a glider from Conway's game of life in autopoietic terms. Such analyses can clarify some of the key ideas underlying autopoiesis and draw attention to some of the central open issues. This article also examines the relationship between an autopoietic perspective on cognition and recent work on dynamical approaches to the behavior and cognition of situated, embodied agents.},
	Author = {Beer, Randall D},
	Doi = {10.1162/1064546041255539},
	Issn = {1064-5462},
	Journal = {Artificial life},
	Keywords = {Artificial Intelligence,Cognition,Cognition: physiology,Humans,Life,Models, Biological,Models, Neurological},
	Month = jan,
	Number = {3},
	Pages = {309--26},
	Pmid = {15245630},
	Title = {{Autopoiesis and cognition in the game of life.}},
	Url = {http://www.ncbi.nlm.nih.gov/pubmed/15245630},
	Volume = {10},
	Year = {2004},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/15245630},
	Bdsk-Url-2 = {http://dx.doi.org/10.1162/1064546041255539}}

@inproceedings{Bello2007,
	Annote = {People usually think the false belief task demonstrates the emergence of the ability to represent the beliefs of others (second order beliefs, the theory theory, etc). They show that by a relatively small change, Polyscheme can demonstrate that same change.

        
 We claim that there is nogap in conceptual or theoretical knowledge differentiating three and four year old subjects. We claim that three
year old subjects are in possession of all of the knowledge needed to pass the false belief task, but haven't yet
learned to properly re-focus their attention on the target's line-of-sight. },
	Author = {Bello, Paul and Bignoli, Perrin and Cassimatis, Nicholas},
	Booktitle = {Proceedings of ICCM 2007 - Eighth International Conference on Cognitive Modeling},
	File = {:Users/licatj/Documents/Shared/research/bello\_\_bignoli\_\_\_\_cassimatis.pdf:pdf},
	Pages = {169--174},
	Title = {{Attention and Association Explain the Emergence of Reasoning About False Beliefs in Young Children}},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2JlbGxvX19iaWdub2xpX19fX2Nhc3NpbWF0aXMucGRm0hcLGBlXTlMuZGF0YU8RAfoAAAAAAfoAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx9iZWxsb19fYmlnbm9saV9fX19jYXMjRTNDRDIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjzSykYOegAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAykZGugAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAF5NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBiZWxsb19fYmlnbm9saV9fX19jYXMjRTNDRDIucGRmAA4AQgAgAGIAZQBsAGwAbwBfAF8AYgBpAGcAbgBvAGwAaQBfAF8AXwBfAGMAYQBzAHMAaQBtAGEAdABpAHMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAExVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2JlbGxvX19iaWdub2xpX19fX2Nhc3NpbWF0aXMucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A2ADdAOUC4wLlAuoC9QL+AwwDEAMXAyADJQMyAzUDRwNKA08AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADUQ==}}

@article{Bickhard2008,
	Abstract = {A shift from a metaphysical framework of substance to one of process enables an integrated account of the emergence of normative phenomena. I show how substance assumptions block genuine ontological emergence, especially the emer- gence of normativity, and how a process framework permits a thermodynamic-based account of normative emergence. The focus is on two foundational forms of normativ- ity, that of normative function and of representation as emergent in a particular kind of function. This process model of representation, called interactivism, compels changes in many related domains. The discussion ends with brief attention to three domains in which changes are induced by the representational model: perception, learning, and language.},
	Author = {Bickhard, Mark H.},
	Date-Modified = {2013-01-30 20:29:21 -0500},
	Doi = {10.1007/s11229-008-9375-x},
	File = {:Users/licatj/Documents/Shared/research/npsB332.tmp.pdf:pdf},
	Issn = {0039-7857},
	Journal = {Synthese},
	Keywords = {an action and interaction,cummins,dretske,emergence,evolutionary epistemology,fodor,hume,interactivism,kim,language,learning,millikan,normative function,normativity,perception,process,representation,representation and cognition is,social ontology,substance,the interactivist model of},
	Month = jul,
	Number = {3},
	Pages = {547--591},
	Title = {The Interactivist Model},
	Url = {http://www.springerlink.com/index/10.1007/s11229-008-9375-x},
	Volume = {166},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL25wc0IzMzIudG1wLnBkZtIXCxgZV05TLmRhdGFPEQG4AAAAAAG4AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcPbnBzQjMzMi50bXAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Q6snWSgcAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMnWgkcAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBOTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAbnBzQjMzMi50bXAucGRmAA4AIAAPAG4AcABzAEIAMwAzADIALgB0AG0AcAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAO1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvbnBzQjMzMi50bXAucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUApACkgKXAqICqwK5Ar0CxALNAtIC3wLiAvQC9wL8AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAv4=},
	Bdsk-Url-1 = {http://www.springerlink.com/index/10.1007/s11229-008-9375-x},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/s11229-008-9375-x}}

@article{Bringsjord2001,
	Abstract = {Steven Pinker's How the mind works (HTMW) marks in my opinion an historic point in the history of humankind's attempt to understand itself. Socrates delivered his "know thyself" imperative rather long ago, and now, finally, in this behemoth of a book, published at the dawn of a new millennium, Pinker steps up to have psychology tell us what we are: computers crafted by evolution - end of story; mystery solved; and the poor philosophers, having never managed to obey Socrates' command, are left alone to wander in the labyrinth of their benighted speculation forever. Unfortunately, though HTMW is to this point the crowning attempt of psychology to make systematic sense of persons by integrating everything relevant science knows, the book fails - and it fails so fundamentally and irremediably that we would do well to wonder anew whether we should supplant the basic view it promotes with what I call the super-mind hypothesis: the view that though mere animals are evolved computers, persons are more. [ABSTRACT FROM AUTHOR]},
	Annote = {C - "straight" computationalism, the view that minds are computing machines
E - minds arose from evolution by mutation/nat. selection
C\^{}E

        
Says chomsky also rejects E? [2]

        
Tries to show that Pinker doesn't answer Wallace's Paradox (WP) well enough. First he characterizes it more rigorously by defining it in terms of a hierarchy of problems and problem-solving powers (6).

        
exaptation - a trait that evolved, but doesn't have any survival value. (propounded by Gould)
reductionism - what Bringsjord calls Pinker's response to WP. Our ancestors evolved the powers we use, but used them for different things. (8)

        
Bringsjord uses pinker's critique to take down exaptation. Then attacks reductionism:
- it is not falsifiable
- how to explain infinitary reasoning in reductionism?},
	Author = {Bringsjord, Selmer},
	Date-Modified = {2013-01-30 20:28:21 -0500},
	Doi = {10.1080/09515080120051580},
	Issn = {0951-5089},
	Journal = {Philosophical Psychology},
	Keywords = {mental work,psychology,reverse engineering},
	Month = jun,
	Number = {2},
	Pages = {227--243},
	Title = {Are We Evolved Computers?: A Critical Review of Steven Pinker's How the Mind Works},
	Url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/09515080120051580\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
	Volume = {14},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzUzOTMyODUucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rws1MzkzMjg1LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjyRyTyGcgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyTzMwgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgA1MzkzMjg1LnBkZgAOABgACwA1ADMAOQAzADIAOAA1AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy81MzkzMjg1LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq},
	Bdsk-Url-1 = {http://www.informaworld.com/openurl?genre=article%5C&doi=10.1080/09515080120051580%5C&magic=crossref%7C%7CD404A21C5BB053405B1A640AFFD44AE3},
	Bdsk-Url-2 = {http://dx.doi.org/10.1080/09515080120051580}}

@article{Bringsjord2000,
	Annote = {he seems to like Searle's way of writing, but closes with something interesting regarding Dennett's qualia eliminativism:
"[Dennett] thus seals his doom, dialectically speaking. Since Dennett's main premise is a denial of the existence of what nearly every other human on this planet thinks is what makes life worth living, until he turns this premise into a conclusion established by some argument, he will convince very, very few."},
	Author = {Bringsjord, Selmer},
	Journal = {Minds and Machines},
	Number = {3},
	Pages = {457--459},
	Title = {{Review of The Mystery of Consciousness by John Searle}},
	Volume = {10},
	Year = {2000}}

@incollection{Bringsjord2008a,
	Address = {New York, New York, USA},
	Annote = {How logic is used in computational psychology. Makes distinction between Mental Logic, Mental Models, and Mental Meta-Logic (his and Yang's theory).},
	Author = {Bringsjord, Selmer},
	Booktitle = {The Cambridge Handbook of Computational Psychology},
	Date-Modified = {2012-03-14 02:40:24 -0400},
	Editor = {Sun, Ron},
	Pages = {127--169},
	Publisher = {Cambridge Univ Press},
	Title = {{Declarative/Logic-Based Cognitive Modeling}},
	Year = {2008}}

@inproceedings{Bringsjord1998a,
	Abstract = {According to the received view in the psychology of reasoning, Piaget's view that F - Humans naturally develop a context-free deductive reasoning scheme at the level of elementary first-order logic. has been overthrown by the poor performance of educated adult subjects on specific logic problems (e.g., Wason's selection task). We propose that Piaget's F (or at least a variant) is alive and well, because the subjects in question are simply victims of a defective education. With a modicum of the right sort of logic training, humans reason deductively on logic problems well enough to vindicate Piaget.},
	Address = {Mahwah, NJ},
	Annote = {more about neo-piagetianism. A more in-depth discussion of:

        
F - Humans naturally develop a context-free deductive reasoning scheme at the level of elementary first-order logic.

        
Just because a problem only requires logic L to solve, doesn't mean we shoud ignore the other factors like how complex the word problem is as it is stated (example on p. 2).

        

      },
	Author = {Bringsjord, Selmer and Noel, Ron and Bringsjord, Elizabeth},
	Booktitle = {Proceedings of the 20th Annual Conference of the Cognitive Science Society},
	Date-Modified = {2011-10-04 03:27:17 -0400},
	File = {:Users/licatj/Documents/Shared/research/lminds.cogsci.pdf:pdf},
	Pages = {173--178},
	Publisher = {Lawrence Erlbaum Associates},
	Read = {1},
	Title = {{In Defense of Logical Minds}},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2xtaW5kcy5jb2dzY2kucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFsbWluZHMuY29nc2NpLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxCbyiQ4HQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyiRwXQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBsbWluZHMuY29nc2NpLnBkZgAOACQAEQBsAG0AaQBuAGQAcwAuAGMAbwBnAHMAYwBpAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9sbWluZHMuY29nc2NpLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@article{Bringsjord2006,
	Annote = {mentions neo-piagetian position.

        
1) We (the authors) are neo-piagetians in regard to reasoning.
2) Mental metalogic - Authors' theory of human reasoning

        
F - Humans naturally develop a context-free deductive reasoning scheme at the level of elementary FOL.

        
The Wason puzzles are credited with killing the F proposition: it seems like people "have not reached [...] formal operations. Yet they are supposed to have [done so by] the age of 12." (102)
Bringsjord's response - "The reason that subject perform poorly on problems like those give by Wason is that their education is defective; and because their education is defective, they haven't reached Piaget's stage of formal operations."
This is made compatible with the adverb "naturally" with the point that just because education, or experience, is required, it doesn't mean that it isn't natural. Then:

        
F' - If educated in logic as they are in artichmetic, humans develop a context-free deductive reasoning scheme at the level of elementary first-order logic -- a scheme that will allow for the solving of problems like those famously pressed against Piagetian[sic] by Wason, Johnson-Laird, and others, and for the solving of significantly harder problems as well.

        

        
Mental Metalogic (MML) - although some knowledge seems to be modeled in syntactic/symbolic form, some knowledge is "represented in irreducibly semantic form, or in what we call mental models" (103).
Mental Models - can be pictorial or imagistic, as opposed to semantic, linguistic

        
small part the neo-Piagetian claim that normal, suitablyeducated cognizers are masters of more than System 2 cognition at the level of
FOL (Bringsjord et al. 1998). },
	Author = {Bringsjord, Selmer and Shilliday, Andrew and Taylor, Josh and Bello, Paul and Yang, Yingrui and Arkoudas, Konstantine},
	File = {:Users/licatj/Documents/Shared/research/Bringsjord Vol2 Issue2.pdf:pdf},
	Journal = {International Journal},
	Keywords = {both formal and informal,intelligent agents,logic,of intelligent agents in,order to,our overall goal is,reasoning,superteach,that would hinder,to harness the power,what is superteaching,without descending into details},
	Pages = {88--116},
	Title = {{Harnessing Intelligent Agent Technology to `` Superteach '' Reasoning}},
	Volume = {2},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0JyaW5nc2pvcmQgVm9sMiBJc3N1ZTIucGRm0hcLGBlXTlMuZGF0YU8RAeQAAAAAAeQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxpCcmluZ3Nqb3JkIFZvbDIgSXNzdWUyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjzayiQucgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyiRmsgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFlNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBCcmluZ3Nqb3JkIFZvbDIgSXNzdWUyLnBkZgAADgA2ABoAQgByAGkAbgBnAHMAagBvAHIAZAAgAFYAbwBsADIAIABJAHMAcwB1AGUAMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIARlVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvQnJpbmdzam9yZCBWb2wyIElzc3VlMi5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDSANcA3wLHAskCzgLZAuIC8AL0AvsDBAMJAxYDGQMrAy4DMwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAM1}}

@article{Brun2011,
	Abstract = {Humor identification is a hard natural lan- guage understanding problem. We identify a subproblem --- the ``that's what she said'' problem---with two distinguishing character- istics: (1) use of nouns that are euphemisms for sexually explicit nouns and (2) structure common in the erotic domain. We address this problem in a classification approach that includes features that model those two char- acteristics. Experiments on web data demon- strate that our approach improves precision by 12\% over baseline techniques that use only word-based features.},
	Author = {Brun, Yuriy and Science, Computer},
	File = {:Users/licatj/Documents/Shared/research/P11-2016.pdf:pdf},
	Journal = {Computational Linguistics},
	Pages = {89--94},
	Title = {{That ' s What She Said : Double Entendre Identification}},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1AxMS0yMDE2LnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMUDExLTIwMTYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Q7somXvEAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMomlzEAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAUDExLTIwMTYucGRmAAAOABoADABQADEAMQAtADIAMAAxADYALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1AxMS0yMDE2LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=}}

@book{Carey2009,
	Address = {New York, New York, USA},
	Annote = {Her formulation of Fodor's paradox:

        
1. All learning mechanisms reduce to hypothesis formation and testing.
2. Hypotheses that play a role in learning new concepts must be formulated in terms of available concepts, using the machinery of compositional semantics.
3. Primitive concepts are not formulatable (definitionally or probabilistically) in terms of other concepts.
4. Therefore, primitive concepts cannot be learned, and thus must be innate.
5. Lexical concepts are primitive.
6. Therefore, lexical concepts must be innate.},
	Author = {Carey, Susan},
	Publisher = {Oxford University Press, USA},
	Title = {{The Origin of Concepts}},
	Year = {2009}}

@article{Carey2004,
	Annote = {- Describes a theory for how 'bootstrapping' works to explain how children "create a representational system with more [representational] power than any on which it is built", specifically with regard to understanding the natural numbers. 
- Bootstrapping is a process that makes "essential use of the human capacity for creating and using external symbols such as words and icons. Bootstrapping capitalizes on our ability to learn sets of symbols and the relations among them directly, independently of any meaning assigned to them in terms of antecedently interpreted mental representations. These external symbols then serve as placeholders, to be filled in with richer and richer meanings. The processes that fill the placeholders create mappings between previously separate systems of representation, drawing on the human capacity for analogical reasoning and inductive inference. The power of the resulting system of concepts derives from the combination and integration of previously distinct representational systems."
- Talks about two types of number comparisons evident in children: an analog way to compare two values that estimates their value, and a one-to-one mapping with symbols in the head with sets of size 1, 2, and 3.
- weber's law: "the discriminability of two values is a function of their ratio." Used to demonstrate an analog counting mechanism with the tapping example.
- the process happens as follows: the child first learns the counting list (one, two, three, four, etc.), just to learn the order of names. Then, children "make a wild analogy--that between the order of a particular quantity within an ordered list, and that between this quantity's order in a series of sets related by additional individuals. There are two quite different bases of ordering--but if the child recognizes this analogy, she is n the position to make the crucial induction: for ay word on the list whose quantificational meaning is known, the next word on the list refers to a set with another individual added."
- Note that we need both the ability to memorize sequeces, and an analogical reasoning. Unfortunately, this is classic HF.
- This paper is challenged by Rips, Asmuth, Bloomfield (2005)},
	Author = {Carey, Susan},
	Journal = {Daedalus},
	Number = {1},
	Title = {{Bootstrapping \& the Origin of Concepts}},
	Volume = {133},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QLi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BkZi5wZGbSFwsYGVdOUy5kYXRhTxEBmAAAAAABmAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHB3BkZi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEP3Ksw1pAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKs0WpAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIARk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHBkZi5wZGYADgAQAAcAcABkAGYALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADNVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3BkZi5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AvwDEAMwCaAJqAm8CegKDApEClQKcAqUCqgK3AroCzALPAtQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC1g==}}

@incollection{Case1992,
	Address = {New York, New York, USA},
	Annote = {
        Critiques of "classic" Piagetian system:
        
Objections from empiricists:
- difficult to test in straightforward ways
- the apparent "unevenness" of intellectual development (which is not consistent with alterations to epistemological structure)
- individual differences in order of task acquisition, which is inconsistent with idea of there being general logical structures which are insensitive to environmental/contextual factors.
Response:
The objection to the difficulty to operationalize and tie to empirical data in a hypotheticodeductive fashion is answered in two ways: (1) avoiding the use of symbolic logic (!), and (2) being more descriptive of the processes involved.

        
Objections from fellow rationalists:
absence of a detailed treatment of 
- stage transition (replacement by more powerful logical structures)
- individual differences in deveopmental process
- factors like affect or perception in influencing the direction of thought
Response:
Objection summarized is that Piagetianism was "too global" in describing development. Neo-Piagetians answer with extension postulates described below.

        
Objections from Socio-Historical investigators:
- theory doesn't explain differences in the rate or terminal level of children's performance on Piagetian tasks between Western and non-Western cultures
- Doesn't explain alternative forms of reasoning other cultures appear to apply to such tasks in adulthood (? page 165)
Response:
Neo-Piagetians emphasize role of cultural influences in structural development.

        
          
Neo-Piagetianism
        
Case says that most agree on some postulates from classical Piagetianism, add extensions, and then modify the classical system.

        
Classical Postulates:
- Importance of children's cognitive structures
- Role of child's own activity in creating such structures
- Universal sequence of structural levels: "[neo-Piagetian theories] all agree there is a preliminary stage in which sensorimotor structure predominate, followed by two or three further stages in which children's intellectual strcutures become increasingly symbolic and abstract." (167)
- Hierarchical inclusion of earlier structures in later ones.
- Characteristic ages for acquisition of structures at different levels.

        
Extension postulates:
- Development and learning distinguished. Development is transformation/accomodation of structural framework, learning is said to involve the assimilation of new content to an existing structural framework in classical piagetianism. Neo-Piagetianists extend this in some way.
- Developmental restructuring presumed local in nature: Structural transformation operates on "parts" at a time, rather than on the whole. This answers the objection that development is uneven.
- Cyclic recapitulation of structural sequences hypothesized. Existence of a cyclic recursion through substages at each general stage or level of development was mentioned by Piaget (as vertical displacement / vertical decalage), but is further developed in neo-Piagetian theories.
- Affective and cognitive structures related. The role of socioemotional functioning in the overall developmental process.

        
Modifications to classic Piagetianism:
- Cognitive structures redefined. Most neo-piagetians do not describe IN TERMS OF SYMBOLIC LOGIC. Rather, they are defined in terms of their form, complexity, and their levels of hierarchical integration, in order to argue that they apply to a broader range of behavior (motor activity, language).
- Shifting upper limit on complexity of cognitive structures postulated. If structure modification is local, why are there typical ages of developmental milestones at all? Neo-Piagetian answer is: distinction between "the general processes that constrain and potentiate development and the more specific processes of structural acquisition that operate within these general constraints and potentials." In other words, an upper limit, like working memory.
- Role of maturation in determining upper limit hypothesized. The idea that biological factors regulate this upper limit.
- Importance of individual differences stressed.
- Content of high-level structures asserted to be cultural in origin. "because children's structures are no longer defined in terms that are logical or mathematical in nature [...], the structures of Western logical and mathematical thought lose their primary in the context of neo-Piagetian theory." Consequences include the idea that western formal mathematical structures could be cultural in origin; other structures like those in social or artistic analysis could be seen as just as important to high-level Western thought as logical/mathematical ones; sociocultural processes and institutions may play a vital role in development at ALL stages; and there may be high-level intellectual structures in other cultures that are very different.  },
	Author = {Case, Robbie},
	Booktitle = {Intellectual Development},
	Chapter = {6},
	Date-Modified = {2013-01-30 20:26:36 -0500},
	Editor = {Sternberg, Robert J. and Berg, Cynthia A.},
	Pages = {161--196},
	Publisher = {Cambridge Univ Press},
	Title = {Neo-Piagetian Theories of Child Development},
	Year = {1992}}

@misc{Cassimatis2006,
	Annote = {Profusion problem: a major obstacle to intelligent systems that are at once more broadly functional and more robust is the profusion of knowledge, data structures, and algorithms that must be integrated into a system to achieve this goal. In other words, humans must draw on a shitload of info, the integration of which is difficult to model computationally.


"There are techniques for combining existing learning methods {\ldots} but these do not create new algorithms altogether; they only learn to delegate among existing algorithms. Thus, existing machine-learning methods by themselves are not sufficient to solve the procedural profusion problem. {\ldots} Merely encapsulating this machinery into [message-passing modules] does not allow for the internal operation of one algorithm to be influenced by another." (5)
	- this is related to profusion problem


        
Cognitive Substrate Hypothesis - There is a relatively small set of computational problems such that once the problems of artificial intelligence are solved for these (a machine called a "cognitive substrate" can effectively solve them) then the rest of human-level intelligence can be achieved by the relatively simpler problem of adapting the cognitive substrate to solve other problems. Progress on these smaller problems would be progress towards human-level intelligence. Also, they are based on the SAME or SIMILAR mechanisms, making them easier to integrate. 

Guesses to what it might be:
- reasoning about things related to social / physical reasoning: temporal intervals, causal relations, identities between objects and events, ontologies, beliefs, desires.

"{\ldots}the research presented here is based on the hypothesis that a fully successful implementation of a substrate will require that the benefits of each specific class of AI methods must somehow be integrated into one system (Minsky 1986)" (47)

        
Arguments for:
 - evolution: we must have evolved to solve some social, etc problems.
 - implicit in AI: many architectures have success with just one simple underlying idea, or they believe that most or all AI problems can be solved with one method
 - nonspatial or physical thought often involves mechanisms the brain uses for spatial / physical thought. Supports hypothesis that a relatively small set of computational mechanisms can underly a wide variety of cognition.

        

        

        },
	Author = {Cassimatis, Nicholas},
	Booktitle = {AI Magazine},
	Date-Modified = {2012-03-20 13:55:04 -0400},
	File = {:Users/licatj/Documents/Shared/research/AIMag06.pdf:pdf},
	Pages = {45--56},
	Title = {{A Cognitive Substrate for Achieving Human-Level Intelligence}},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0FJTWFnMDYucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwtBSU1hZzA2LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjyiykX4SgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAykYwigAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBBSU1hZzA2LnBkZgAOABgACwBBAEkATQBhAGcAMAA2AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9BSU1hZzA2LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@inproceedings{Chaput2003,
	Abstract = {-- Constructivist learning is a hierarchical part-towhole learning system used by humans and desirable for use by robots. Current implementations are too resourceintensive to be used for anything but simple environments. In this paper, we reimplement one such system, the Schema Mechanism, using a hierarchy of self-organizing maps. The result is an efficient system for learning perceptual and action schemas that can be used in real-world applications},
	Annote = {UT-Austin students directly implemented Drescher's work using neural network, and replicate his results.},
	Author = {Chaput, Harold H. and Kuipers, Benjamin and Miikkulainen, Risto},
	Date-Modified = {2013-01-30 20:26:25 -0500},
	Publisher = {In Proceedings of the Workshop on Sel fOrganizing Maps (WSOM03)},
	Title = {Constructivist Learning: A Neural Implementation of the Schema Mechanism},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.107.1526},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QVC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL25ldXJhbCBpbXBsZW1lbnRhdGlvbiBvZiBzY2hlbWEgbWVjaGFuaXNtLnBkZtIXCxgZV05TLmRhdGFPEQIiAAAAAAIiAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfbmV1cmFsIGltcGxlbWVudGF0aW9uI0YxMEU5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Q6ckPxOgAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMkQCzgAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAbmV1cmFsIGltcGxlbWVudGF0aW9uI0YxMEU5LnBkZgAOAFwALQBuAGUAdQByAGEAbAAgAGkAbQBwAGwAZQBtAGUAbgB0AGEAdABpAG8AbgAgAG8AZgAgAHMAYwBoAGUAbQBhACAAbQBlAGMAaABhAG4AaQBzAG0ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL25ldXJhbCBpbXBsZW1lbnRhdGlvbiBvZiBzY2hlbWEgbWVjaGFuaXNtLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDlAOoA8gMYAxoDHwMqAzMDQQNFA0wDVQNaA2cDagN8A38DhAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAOG},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.107.1526}}

@incollection{Chater2008,
	Address = {New York, New York, USA},
	Annote = {Chomsky argued associationist models are only DFA equivalent (477) - analogous to discussions on expressivity, but recall drescher's objection

        
Symbolic Computational Frameworks:
  Psycholinguistic theories
  - focus on generative tradition
  - usually assume structural, rather than probabilistic, features of language are central (479)

        
Connectionist Psycholinguistics:
  - typically provide "bottom-up" models of learning
  - "soft" regularities are better captured by connectionist rather than rule-based methods (fuzzy borders around concepts)

        
Probabilistic:
  - says the problem is not merely to find any derivation, but to find the most probable derivation(s) of logicical rules constructed from grammatical rules to a string of words generated from the application of those rules (481).
  - Bayesian methods
  - as with connectionist vs symbolic, probabilistic vs symbolic can be either complementary or competitive.

        

        
E.M. Gold (1967) proved that under certain assumptions, learners provably cannot converge on a language even "in the limit" as the corpus becomes indefinitely large, supporting the poverty of the stimulus argument. (491) But probabilistic approaches make learning look less tractable.},
	Author = {Chater, Nick and Christiansen, Morten H.},
	Booktitle = {The Cambridge Handbook of Computational Psychology},
	Chapter = {17},
	Date-Modified = {2011-07-16 02:59:07 -0400},
	Editor = {Sun, Ron},
	Pages = {477--504},
	Publisher = {Cambridge Univ Press},
	Title = {{Computational Models of Psycholinguistics}},
	Year = {2008}}

@article{Chisholm1990,
	Annote = {Addresses some confusing conclusions and "paradoxes" that can arise from not taking into account the temporal dimension of properties, when understanding what propositional attitudes refer to. (Does Chisholm support something like Fodor's referentialism?)},
	Author = {Chisholm, Roderick M},
	Journal = {Philosophical Perspectives},
	Pages = {545--556},
	Title = {{Referring to Things That No Longer Exist}},
	Volume = {4},
	Year = {1990}}

@article{Chisholm1991,
	Annote = {Argues that the soul (aka a person), is the only such substance that can have qualitative mental properties (the definition of qualitative is carefully set forth here). Then -- "Anything that has a qualitative property, then, is a substance that is capable of thinking" (174). 

        
He then gives five arguments which strongly suggest (but he says, do not prove) the simplicity of the soul (that we are substances but not compounds of substances; the soul can not be broken up into parts), by mereological essentialism.},
	Author = {Chisholm, Roderick M},
	Journal = {Philosophical Perspectives},
	Pages = {167--181},
	Title = {{On the Simplicity of the Soul}},
	Volume = {5},
	Year = {1991}}

@article{Chiu2004,
	Author = {Chiu, Catherine},
	Journal = {Minerva},
	Title = {{The Bryn Mawr Tour Guide Robot}},
	Year = {2004}}

@article{Chomsky2010,
	Annote = {Chomsky first criticizes skinner's definitions of things like operant, conditioning, reinforcement, etc. His approach is to look at what explanatory powers the terms have over other more 'popular' terms like belief, desire, intention, etc. He concludes that they have none different, and are basically renames of the popular terms. So it seems his entire strategy is:
- find out what experimentally verifiable consequences a theory will have, compared to current and alternate theories
- criticize on that basis: either they have none different, or their unique consequences can and have been experimentally proven/disproven.

I find it somewhat ironic then, that the behaviorist philosophy, which focused only on the observable and experimentally verifiable, should have been taken down by someone whose approach was so intimately dependent on the experimentally verifiable.

Chomsky then goes to the terms Skinner developed specifically for describing verbal behavior, which he dismisses as also as hopelessly vague as his regular behaviorist terms. He then claims that any terms similarly defined will fail.

Closes with a brief discussion of the argument from productivity of language, poverty of the stimulus, and summarizes the main claim against behaviorism: that the ignoring of the contribution from internal properties of the speaker (in this case an internal grammar which would account for productivity) will severely handicap any study of language and make it so they'll never understand it.},
	Author = {Chomsky, Noam and Jakobovits, In Leon A and Miron, Murray S},
	Date-Modified = {2011-07-17 12:26:26 -0400},
	Journal = {Philosophy},
	Pages = {1--29},
	Title = {{A Review of B . F . Skinner ' s Verbal Behavior}},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0EgUmV2aWV3IG9mIEIucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFBIFJldmlldyBvZiBCLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjydySx6zAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAySzBHAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBBIFJldmlldyBvZiBCLnBkZgAOACQAEQBBACAAUgBlAHYAaQBlAHcAIABvAGYAIABCAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9BIFJldmlldyBvZiBCLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@article{Connolly2007,
	Annote = {I want to learn exactly what their conception of stereotypes is. This article is the most recent one in which he talks about stereotypes (as of 5/2011). 

        
a system of representations is                                                 
        
          compositional iff
        
                                                        : (a) it contains both syntactically primitive and syntactically complex symbols; and (b) the syntax and content of the complex symbols is exhaustively determined by the syntax and content of their primitive constituents. (3)

        
"If this selection process among prototypical values of inherited features can be made good in general, using prototypical representations, then the prototype theory will have accomplished just what is wanted: complex prototype representations that satisfy the compositionality constraint" (6).

        
Any successful prototype model with conceptual combination must explain DS:
the less familiar a complex concept (the less background information, exemplar memories one has), the more one would assume the prototypical values of its constituents. "component properties not specified by or semantically incompatible with the particular combination are inherited as is."
- the default to the (compositional) stereotype strategy (=DS) applies only where composition is not superceded by prior knowledge and experience (8).
- another formulation: "Barring information to the contrary, assume that the typical AN satisfies (inter alia) the N stereotype. (8)

        
Arguments that DS does not satisfy compositionality:
-(3.1.1) DS is a bad strategy a priori. 
-(3.1.2) Experimental evidence they claim challenges idea DS is what people use to interpret complex concepts.d
  -claim: One's confidence that an arbitrary AN is a stereotypic N should be no less than one's confidence that an arbitrary N is a stereotypic N, same for AAN and AN, etc to (A\^{}n)N.
  -experiment: 40 undergraduates

        
their general findings: "The more concepts enter into novel combinations, the less certain one is about the stereotypic properties of the [typical] instances of the combined concept." (13)

        
Then, "the choice, then, is between two two-stage models":
- classical view: minimal concepts/combinatorics, followed by knowledge-driven inferential stage.
- prototype view: knowledge relevant to deriving interpretations of combinations is built into concepts themselves, providing an automatic mechanism through the automatic inheritance of features.},
	Author = {Connolly, Andrew C and Fodor, Jerry A and Gleitmana, Lila R and Gleitman, Henry},
	Date-Modified = {2013-01-30 20:25:29 -0500},
	File = {:Users/licatj/Documents/Shared/research/sdarticle.pdf:pdf},
	Journal = {Cognition},
	Number = {1},
	Pages = {1--22},
	Title = {Why Stereotypes Don't Even Make Good Defaults},
	Volume = {103},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NkYXJ0aWNsZS5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDXNkYXJ0aWNsZS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEkvKA2PuAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKA5wuAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHNkYXJ0aWNsZS5wZGYADgAcAA0AcwBkAGEAcgB0AGkAYwBsAGUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NkYXJ0aWNsZS5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==}}

@misc{Cowie1997,
	Abstract = {Arguments from the `Logical Problem of Language Acquisition' suggest that since linguistic experience provides few negative data that would falsify overgeneral grammatical hypotheses, innate knowledge of the principles of Universal Grammar must constrain learners' hypothesis formulation. Although this argument indicates a need for domain-specific constraints, it does not support their innateness. Learning from mostly positive data proceeds unproblematically in virtually all domains. Since not every domain can plausibly be accorded its own special faculty, the probative value of the argument in the linguistic case is dubious. In ignoring the holistic and probablistic nature of theory construction, the argument underestimates the extent to which positive data can supply negative evidence and hence overestimates the intractability of language learning in the absence of a dedicated faculty. While nativism about language remains compelling, the alleged `Logical Problem' contributes nothing to its plausibility and the emphasis on the Problem in the recent acquisition literature has been a mistake.},
	Author = {Cowie, Fiona},
	Booktitle = {Synthese},
	Date-Modified = {2013-01-30 20:25:20 -0500},
	Doi = {10.1023/A:1004975305820},
	File = {:Users/licatj/Documents/Shared/research/cowie.pdf:pdf},
	Issn = {0039-7857},
	Keywords = {Humanities,Social Sciences and Law},
	Number = {1},
	Pages = {17--51--51},
	Publisher = {Springer Netherlands},
	Title = {THE LOGICAL PROBLEM OF LANGUAGE ACQUISITION},
	Url = {http://www.springerlink.com/content/m167tw6642378256/},
	Volume = {111},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Nvd2llLnBkZtIXCxgZV05TLmRhdGFPEQGgAAAAAAGgAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcJY293aWUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8NnMo2cZ0AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMo2qd0AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBITWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAY293aWUucGRmAA4AFAAJAGMAbwB3AGkAZQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIANVVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvY293aWUucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMEAxgDOAnICdAJ5AoQCjQKbAp8CpgKvArQCwQLEAtYC2QLeAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAuA=},
	Bdsk-Url-1 = {http://www.springerlink.com/content/m167tw6642378256/},
	Bdsk-Url-2 = {http://dx.doi.org/10.1023/A:1004975305820}}

@article{DelCul2009,
	Abstract = {What neural mechanisms support our conscious perception of briefly presented stimuli? Some theories of conscious access postulate a key role of top-down amplification loops involving prefrontal cortex (PFC). To test this issue, we measured the visual backward masking threshold in patients with focal prefrontal lesions, using both objective and subjective measures while controlling for putative attention deficits. In all conditions of temporal or spatial attention cueing, the threshold for access to consciousness was systematically shifted in patients, particular after a lesion of the left anterior PFC. The deficit affected subjective reports more than objective performance, and objective performance conditioned on subjective visibility was essentially normal. We conclude that PFC makes a causal contribution to conscious visual perception of masked stimuli, and outline a dual-route signal detection theory of objective and subjective decision making.},
	Author = {Del Cul, a and Dehaene, S and Reyes, P and Bravo, E and Slachevsky, A},
	Date-Modified = {2013-01-30 20:25:13 -0500},
	Doi = {10.1093/brain/awp111},
	Issn = {1460-2156},
	Journal = {Brain : a journal of neurology},
	Keywords = {Adult,Algorithms,Attention,Attention: physiology,Brain Damage,Brain Mapping,Brain Mapping: methods,Chronic,Chronic: pathology,Chronic: physiopathology,Chronic: psychology,Consciousness,Consciousness: physiology,Cues,Female,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Middle Aged,Neuropsychological Tests,Pattern Recognition,Perceptual Masking,Perceptual Masking: physiology,Photic Stimulation,Photic Stimulation: methods,Prefrontal Cortex,Prefrontal Cortex: pathology,Prefrontal Cortex: physiopathology,Sensory Thresholds,Sensory Thresholds: physiology,Visual,Visual: physiology},
	Month = sep,
	Number = {Pt 9},
	Pages = {2531--40},
	Pmid = {19433438},
	Title = {Causal role of prefrontal cortex in the threshold for access to consciousness.},
	Url = {http://www.ncbi.nlm.nih.gov/pubmed/19433438},
	Volume = {132},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2RlbGN1bF9jYXVzYWxyb2xlX2JyYWluMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEB+AAAAAAB+AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHH2RlbGN1bF9jYXVzYWxyb2xlX2JyYWluMjAwOS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDbHJa27yAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADJa7VCAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAXk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGRlbGN1bF9jYXVzYWxyb2xlX2JyYWluMjAwOS5wZGYADgBAAB8AZABlAGwAYwB1AGwAXwBjAGEAdQBzAGEAbAByAG8AbABlAF8AYgByAGEAaQBuADIAMAAwADkALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAEtVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2RlbGN1bF9jYXVzYWxyb2xlX2JyYWluMjAwOS5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A1wDcAOQC4ALiAucC8gL7AwkDDQMUAx0DIgMvAzIDRANHA0wAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADTg==},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/19433438},
	Bdsk-Url-2 = {http://dx.doi.org/10.1093/brain/awp111}}

@article{Demetriou2000,
	Author = {Demetriou, Andreas},
	Date-Modified = {2013-01-30 20:25:03 -0500},
	Journal = {Behavioral and Brain Sciences},
	Pages = {781--792},
	Title = {Continuing Commentary},
	Year = {2000}}

@book{Demetriou2004,
	Address = {Cambridge, UK},
	Date-Modified = {2013-01-30 20:25:00 -0500},
	Editor = {Demetriou, Andreas and Raftopoulos, Athanassios},
	Publisher = {Cambridge Univ Press},
	Title = {Cognitive Developmental Change : Theories, Models and Measurement},
	Year = {2004}}

@book{Drescher1991,
	Annote = {Fodor is mentioned in 38-39, 86, 87

Brief highlights of his system:
- it only has 10 primitive built-in actions, and it can achieve a "practical elaboration of the spatial relationship among the various visual-field items and proprioceptive items. ... [It builts schemas which] chain together in networks that tell the mechanism how to move the hand from one body-relative position to another by a series of motions between adjacent positions, or how to direct the gaze to a given orientation, or change the gaze to shift an image to a given part of the visual field" (12).
- "the schema mechanism builds synthetic items that begin to designate objects, as distinct from their current perceptions."

SCHEMAS
- three main parts: a context, an action, and a result. e.g.: p~qr/a/xy means (p, r, and not q must be true, then if action 'a' is taken, x and y will be true).
- schemas cannot be 'partially satisfied', the contexts must be fully met; however actions can be taken without the context conditions being satisfied
- schemas aren't rules saying action must be taken, they only specify possible courses of action
- activation can be explicit (schema is selected and its action initiated) or implicit (schema may have its action initiated as a result of sharing an action with an explicitly activated schema).
- reliability (probability with which the schema succeeds when activated) vs. correlation measures (ratio of probability an activated schema achieves result state vs times when the result state occurs but the schema was not activated)

ITEMS
- primitive vs. synthetic items; synthetic items are created by the system by abstracting schemas themselves. 
- synthetic items are constructed "to reify the validity conditions of an unreliable schema. That is, a new synthetic item is defined to represent whatever unknown aspect of the world governs the schema's validity" (82). E.g. the child discovers that moving its hand from position x,y to x,y-5 causes it to touch something. This is unreliable; it "only succeeds when there happens to be an object at that position". But it is "locally consistent, meaning that if it happens to succeed when activated on some occasion, it is likely to succeed again if activated again within, say, the next several seconds." So if "a schema is found to be unreliable but locally consistent, the mechanism constructs a new synthetic item, called that schema's *reifier*; the schema is the new item's *host schema.* The host schema's reifier designates whatever condition makes the schema valid---in this case, roughly the condition that a palpable object is present at body-relative position" (x,y-5).

ACTIONS
- primitive (built-in) and composite (constructed) actions. 

SIMULATION
- there is a 2d simulation with a robot and a single hand that can be moved to a range of positions relative to the face. The hand came move in a 3x3 unit region relative to the body position (imagine a 3x3 square in which the hand can move. The body is directly below the middle cell on the bottom row.)
- There are visual, tactile, and proprioceptive (direct perception of the positions of the limbs or eyes through muscle tension or the like) sensors that can be "On" or "Off" based on whether the hand is in the relevant position.
- There is one coarse tactile item for each of the four sides of the hand (to simulate "touching" something", and the left side (with the "fingers") as four tactile detail items that detect textural properties. These are just four variables (text0,...,text3) that denote arbitrary textural details of an object "touching the fingers." Similarly, the body has four tactile items for contact, one on each side, and the front of the body (where the "head" and "mouth" are) has four items designating arbitrary, unspecified aspects of an object's taste.
- the robot has a visual system with foveal regions so it can learn how to look at/for things. This visual system gives it a top (birds-eye) view. The visual field can center anywhere in a 3x3 region relative to the body. The visual field can be no more than 6 units away from the body. So there is a 7x7 "potentially visible body-relative" region, and a 5x5 "visual field" that represents what the object is looking at. Within the 5x5 visual field, there are foveal regions (basically distinguished cells near the center of the visual field) 
- there are 25 coarse visual items, one for each of the 5x5 visual field regions, which can be on (if an object's image appears at the corresponding region). These report only the presence or absence of an object; no detail on appearance is provided.
- For objects appearing in the *foveal* regions (special cells near the visual field's center), there are 16 visual detail items, which are meant to be analogous to shape, texture, color, etc. 
- he shows the development of things like the ability to pick up by grasping (grasping itself is a built-in action), the elaboration of proprioception, etc.
- Built-in actions:
	- handf,handb,handr,handl: move the hand incrementally forward, backward, right, or left
	- eyef, eyeb, eyer, eyel: shifts the glance orientation one cell
	- grasp: closes the hand, grasping any object touching the hand's "fingers" unless the hand was already closed.
	- ungrasp: opens hand
- "Beginnings of the persistent-object concept" (135):
	- Schemas can be unreliable (a touch schema might only work if an object is at a certain position) but locally consistent---"if it succeeds on some occasion, it probably will succeed again if activated again soon". This is what designates persistent objects. It can also happen with visual synthetic items: "a manifestation of a visual object---seeing it at visual-field region (1,4)---by the probing action of glancing at a particular body-relative position. The reifying synthetic item... designates a persistent visible object at that position." (136)
	- Inverse action pairs---such as when a child touches and withdraws from an object, done repeatedly, catalyzes the construction of a synthetic item. This, he claims, "functions not only as a special case of recognizing persistence, but also as a precursor of a less limited version of persistence recognition." (137) Recall that synthetic items are built on top of existing schemas. 
	- synthetic items develop that "might be called *inversely indexed* representations of persistent objects---for example, [hp33] and [vp23]. The standardly indexed representations may be thought of as posing the question *What is at this position?*, and answering: an object. In contrast, the inversely indexed representation asks *Where is the object?*, and answers: at this position." A persistent object, then, is reflected by the subject being able to answer questions involving it. 
	- eventually, a "more complete object concept must include a coordination of both indexing schemes---knowing that a given position now harbors a particular object, and knowing that a given object is now to be found at a particular position." His system doesn't discover the correspondence between visual and tactile objects, "it does learn of the effective synonimity between among [sic] some similar items." So the coordination of cross-modal schemata happens to a very limited degree.

COMPARISONS
- acknowledges that the schemas resemble production rules in that they are a "kind of qualitative, symbolic construct" but they differ because they have: (1) three main parts rather than two, which he argues is crucial "for purposes of learning such rules in the first place". For example, it allows the agent to discover what "would happen" if something were done. (2) situation-action learning is intrinsically, infeasibly slow. In contrast, context-action-result structures allow "various islands of the state-space can be learned as soon as they are encountered, with no forseen applicability to any goal, then quickly chained through to reach a goal when the necessary pieces have been assembled." (3) The number of situation-action rules that have to b elearned is proportionate to the product of the size of the state-space and the number of goal indications. In contrast, each piece of a schema-implemented state-space network says what the result of some action would be, and is acquired independently of the system's goals. (4) "for purposes of learning, the context and action cannot combine to form an undifferentiated antecedent of a two-part rule; the marginal attribution machinery, needed to solve the context-result chicken-and-egg problem [of the role the context plays in bringing about the result, or whether the result brought about the context?] must compare what happens with vs. without the action ... and thus requires an explicit distinction between context and action. Hence, a three-part structure is warranted."
- schemas are qualitative, symbolic but not connectionist systems. The schema mechanism's main architecture if connectionist, however, so he argues "a schema's extended context is essentially a connectionist network solving a classifier problem. The schema mechanism might be viewed as a kind of hybrid system..."
- Chunking. He discusses a chunking method that would resemble chunking in SOAR, "which, like other explanation-based learning mechanisms, identifies and records the dependencies in a search process, and abbreviates subsequent searches by recording what follows from those dependencies, so taht the search need not be recapitulated." But it's not implemented currently in his system.

THE CHICKEN AND EGG PROBLEM OF EMPIRICAL LEARNING
- p.5: "A given action may have a variety of different results in difference circumstances; for example, moving one's hand incrementally backward can result in a tactile sensation on the chin, the shoulder, or elsewhere, depending on where the hand started. Even if a particular result follows a given action reliably under certain circumstances, that result may occur only rarely in general. Moreover, causes other than the given action may also give rise to the result; and even when that action does cause the result, the result may be buried among many unrelated events. Thus, even the most reliable results can be hard to notice as such, until the corresponding circumstances have been identified; but those, in turn, cannot be sought without first knowing what result they correspond to. That is the chicken-and-egg problem."
- He solves it using the "marginal attribution facility" which distinguishes the "relevance of a result from its reliability. A result is relevant to an action is the result occurs more often when the action is taken than when not, however infrequent the result may be even when the action is taken." Reliability is the probability the schema succeeds when it's been activated.
- "empirical learning poses the chicken-and-egg problem of identifying an action's results before knowing the corresponding context conditions; the solution is to distinguish relevance from reliability, and to use an exhaustive crossbar to look for relevance."

(SUGGESTED) FUTURE WORK AND EVALUATING PERFORMANCE
- Subactivation - to allow the mechanism to learn from thought experiments and observed physical events. 
- Connectionist contexts - detect context through connectionist means
- Clustering of items
- Combinatorics and garbage collection
- says that it "faces combinatorial problems that threaten its ability to scale up to more advanced abilities."},
	Author = {Drescher, Gary L.},
	Date-Modified = {2014-06-25 02:39:26 +0000},
	File = {:Users/licatj/Documents/Shared/research/Made-Up Minds A constructivist Approach to Artificial Intelligence.pdf:pdf},
	Isbn = {0262041200},
	Publisher = {The MIT Press},
	Title = {Made-Up Minds: A Constructivist Approach to Artificial Intelligence},
	Year = {1991},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QbS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL01hZGUtVXAgTWluZHMgQSBjb25zdHJ1Y3RpdmlzdCBBcHByb2FjaCB0byBBcnRpZmljaWFsIEludGVsbGlnZW5jZS5wZGbSFwsYGVdOUy5kYXRhTxECbAAAAAACbAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHH01hZGUtVXAgTWluZHMgQSBjb25zdCNGMTBBNi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEKbKF4X+AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKF74+AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAXk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AE1hZGUtVXAgTWluZHMgQSBjb25zdCNGMTBBNi5wZGYADgCOAEYATQBhAGQAZQAtAFUAcAAgAE0AaQBuAGQAcwAgAEEAIABjAG8AbgBzAHQAcgB1AGMAdABpAHYAaQBzAHQAIABBAHAAcAByAG8AYQBjAGgAIAB0AG8AIABBAHIAdABpAGYAaQBjAGkAYQBsACAASQBuAHQAZQBsAGwAaQBnAGUAbgBjAGUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAHJVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL01hZGUtVXAgTWluZHMgQSBjb25zdHJ1Y3RpdmlzdCBBcHByb2FjaCB0byBBcnRpZmljaWFsIEludGVsbGlnZW5jZS5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgD+AQMBCwN7A30DggONA5YDpAOoA68DuAO9A8oDzQPfA+ID5wAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAPp}}

@article{Edwards2009,
	Abstract = {This paper identifies and criticizes a line of reasoning that has played a substantial role in the widespread rejection of the view that Fodor has dubbed ``Concept Atomism''. The line of reasoning is not only fallacious, but its application in the present case rests on a misconception about the explanatory potential of Concept Atomism. This diagnosis suggests the possibility of a new polemical strategy in support of Concept Atomism. The new strategy is more comprehensive than that which defenders of the view, namely Fodor, have employed.},
	Annote = {Claims a major mistake with many conceptual theories is they assume that what a concept DOES (function) instantly says what concepts ARE (constitution). He organizes the landscape of conceptual theories a little:

        
CRole - Conceptual Role theories, a concept is [at least partially] constituted by its inferential role(s), aka Pragmatism
  Functionalism
  Prototype Theories
  "Hidden Structure" theories
  Concept empiricism - the view that most concepts are constructions out of more basic perceptual representations
CRef - Concept referentialism (that concepts are individuated referentially)
  Concept Atomism

        
CRole theories would be those who are confusing "does" with "are". So what's wrong with the "is-from-does" line of reasoning?
He admits it does have "some intuitive pull".
He means to argue only that advocates of CRef have [... a] neutral strategy for explaining the relevant aspects of conceptual role. In other words, that it doesn't explain concepts any better than atomism does.
- publicity requirement (299): if functional role plays a big part in conceptual constitution and concepts are thus very rich,  it makes it harder to explain how concepts can be shared.
- doesn't the compositionality requirement as stated by fodor also make this same "mistake"?

        
Good quotes: 
- "while the advocate of CRef denies that a concept's role is concept constitutive, they can, and I think they should, embrace the claim that various facts about conceptual role play an important--albeint contingent--part in a broader story about what implements the reference relation." (299)
- "...my suspicion is that most opponents of Concept Atomism would, if caught in a moment of honesty, admit to having much more confidence in the failure of Concept Atomism than in their own attempts to evade Fodor's critical arguments." (303)

      },
	Author = {Edwards, Kevan},
	Date-Modified = {2013-01-30 20:23:33 -0500},
	Doi = {10.1007/s11229-009-9584-y},
	File = {:Users/licatj/Documents/Shared/research/fulltext (1).pdf:pdf},
	Issn = {0039-7857},
	Journal = {Synthese},
	Month = jul,
	Number = {2},
	Pages = {289--310},
	Title = {What Concepts Do},
	Url = {http://www.springerlink.com/index/10.1007/s11229-009-9584-y},
	Volume = {170},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICgxKS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGZ1bGx0ZXh0ICgxKS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDxDKCc5qAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKCgaqAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZ1bGx0ZXh0ICgxKS5wZGYAAA4AIgAQAGYAdQBsAGwAdABlAHgAdAAgACgAMQApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoMSkucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==},
	Bdsk-Url-1 = {http://www.springerlink.com/index/10.1007/s11229-009-9584-y},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/s11229-009-9584-y}}

@misc{Ehman2006,
	Annote = {Based on production rules, which are "triggered".

        
They believe:
BEHAVIOR = ARCHITECTURE + CONTENT
(I note this leaves out context)

        
"A particular architecture, that is, a particular fixed set of mechanisms and structures, stands as a theory of what is common among much of the behavior at the level above it. Using this idea, we can        
        
           define a cognitive architecture as a theory of the fixed mechanisms and structures that underlie human cognition
        
                 [emphasis added]" (4)

        
Soar's theory believes behavior:
- is goal oriented
- takes place in a rich, complex, detailed environment
- requires a large amount of knowledge
- requires the use of symbols and abstractions
- is flexible and a function of the environment
- requires learning from the environment and experience

        
they use the "principle of rationality": "if an agent has knowledge that an operator application will lead to one of its goals then the agent will select that operator" (Newell, 1982)

        
they have working memory and explicitly refer to it (14)

        
LEARNING
Uses four learning mechanisms: Chunking, Reinforcement learning, Semantic learning, Episodic learning.
Chunking - process that creates new rules from learning. "Chunking is essentially a deductive, compositional learning mechanism; that is, the preference for a curve ball represents a kind of deduction from prior knowledge, and the new rule is composed from a "then" part containing the deduction, and an "if" part containing the knowledge that contributed to the deduction. [...] As a theory, Soar says that chunking happens all the time -- it is a ubiquitous mechanism that requires no intention to learn on the part of the agent." (27)
Reinforcement Learning - creates "only operator selection rules and the basis for creating them is statistical regularities in rewards as opposed to the results of internal reasoning." They mention that Soar must first figure out what the rules are before determining expected rewards for each rule (28).
Episodic Memory - records events and history embedded in experience. "a passive learning mechanism that does not do any generalization."
Semantic Memory - Declarative structures, what you "know" disassociated from the place and time when they are learned (29).},
	Author = {Ehman, Jill Fain and Laird, John and Rosenbloom, Paul},
	Date-Modified = {2013-01-30 20:23:27 -0500},
	File = {:Users/licatj/Documents/Shared/research/GentleIntroduction-2006.pdf:pdf},
	Number = {0413013},
	Title = {A Gentle Introduction to Soar, an Architecture for Human Cognition: 2006 Update},
	Url = {http://ai.eecs.umich.edu/soar/sitemaker/docs/misc/GentleIntroduction-2006.pdf},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0dlbnRsZUludHJvZHVjdGlvbi0yMDA2LnBkZtIXCxgZV05TLmRhdGFPEQHoAAAAAAHoAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcbR2VudGxlSW50cm9kdWN0aW9uLTIwMDYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Plcoxd4oAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMoxr8oAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBaTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAR2VudGxlSW50cm9kdWN0aW9uLTIwMDYucGRmAA4AOAAbAEcAZQBuAHQAbABlAEkAbgB0AHIAbwBkAHUAYwB0AGkAbwBuAC0AMgAwADAANgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAR1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvR2VudGxlSW50cm9kdWN0aW9uLTIwMDYucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOANMA2ADgAswCzgLTAt4C5wL1AvkDAAMJAw4DGwMeAzADMwM4AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAzo=},
	Bdsk-Url-1 = {http://ai.eecs.umich.edu/soar/sitemaker/docs/misc/GentleIntroduction-2006.pdf}}

@book{Everitt2007,
	Address = {New York, New York, USA},
	Author = {Everitt, Katherine M. and Harada, Susumu and Bilmes, Jeff and Landay, James A.},
	Booktitle = {Proceedings of the ninth international conference on Multimodal interfaces - ICMI '07},
	Date-Modified = {2013-01-30 20:23:17 -0500},
	Doi = {10.1145/1322192.1322235},
	Isbn = {9781595938176},
	Keywords = {context,exercise,fitness,speech recognition},
	Pages = {247},
	Publisher = {ACM Press},
	Title = {Disambiguating Speech Commands Using Physical Context},
	Url = {http://portal.acm.org/citation.cfm?doid=1322192.1322235},
	Year = {2007},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1322192.1322235},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1322192.1322235}}

@article{Fodor2005,
	Annote = {I'm not seeing any really substantial things here, mostly defensive moves. Denies Pinker's accusation that Fodor sees the mind as having a Turing architecture.

        
"Aside from that, Pinker's description of the current situation in cog. sci. actually doesn't differ from mine: we both think Classical architectures very likely can't model cognitive processing in general; and we both think that nobody know what to replace them with. The difference is that Pinker is relentlessly cheerful in face of all this bad news. Denial works!" (27)

        
"The notorious problem with constraint satisfaction is
that, insofar as it is able to achieve globality, it does so at the price of holism. Holistic models of thought lack all sorts of properties that are strikingly characteristic of human cognition (see, for example the discussion of `transportability' in TMD). The puzzle par excellence about our cognition is that it manages, somehow, to be global but not holistic. I wish I knew how it does that, but I don't. Nor does Pinker. Nor does anybody else."
          
Note: Global is contrasted with the local reference constraint on Turing Machines, where they can only look at one symbol at a time.
        

        
Response to modularity:
Calls out the massively modular hypothesis (note that he doesn't necessarily reject modularity in general) and asks how it would explain things like "phoning your optometrist to make an appointment for some time early next week." (28)
"(1) How could such anarchitecture be sensitive to global properties of belief systems (see above); and (2)
Who puts all the module's outputs together to produce integrated beliefs?"

        
Defines massive modularity:
"the claim that cognitive processes are effected, more or less exhaustively, by encapsulated, domain specific mechanisms" (29).

        
Identifies a confusion between believing cognitive mechanisms are modular vs functionally individuated. (29) },
	Author = {Fodor, Jerry},
	Date-Modified = {2013-01-30 20:21:20 -0500},
	Doi = {10.1111/j.0268-1064.2005.00275.x},
	Issn = {0268-1064},
	Journal = {Mind and Language},
	Month = feb,
	Number = {1},
	Pages = {25--32},
	Title = {Reply to Steven Pinker 'So How Does The Mind Work?'},
	Url = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00275.x},
	Volume = {20},
	Year = {2005},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00275.x},
	Bdsk-Url-2 = {http://dx.doi.org/10.1111/j.0268-1064.2005.00275.x}}

@book{Fodor1998,
	Address = {New York, New York, USA},
	Annote = {FINALLY, Stereotypes and prototypes in Fodor's usage defined:
"Terminological conventions with respect to the topics this chapter covers are unsettled. I'll use 'stereotype' and 'prototype' interchangeably, to refer to mental representations of certain kinds of properties. So, 'the dog stereotype' and 'the dog prototype' designate some such (complex) concept as: BEING A DOMESTIC ANIMAL WHICH BARKS, HAS A TAIL WHICH IT WAGS WHEN IT IS PLEASED, ... etc. I'll use 'exemplar' for the mental representation of a kind, or of an individual, that instantiates a prototype; so 'sparrows are the exemplars of birds' and 'bambi is Smith's exemplar of a deer' are both well-formed. 'Sparrows are stereotypic birds' (/'Bambi is a prototypic deer') are also OK; they mean that a certain kind (/individual) exhibits certain stereotypic (/prototypic) properties to a marked degree." (Footnote on page 88)

        
Concepts and everything else defined:

        
Concepts: "Very roughly, concepts are constituents of mental states. Thus, for example, believing that cats are animals is a paradigmatic mental state, and the concept ANIMAL is a constituent of the belief that cats are animals (and of the belief that animals sometimes bite; etc. I'm leaving it open whether the concept ANIMAL is likewise a constituent of the belief that some cats bite; we'll raise that question presently). So the natural home of a theory of concepts i as part of a theory of mental states. I shall suppose throughout this book that RTM is the right theory of (cognitive) mental states." (6)

        
Concept Atomism: "I'm going to argue for a very strong version of psychological atomism; one according to which what concepts you have is conceptually and metaphysically independent of what epistemic capacities you have. If this is so, then patently concepts couldn't be epistemic capacities." (6) *Note that epistemic capacities refers to the type of theory where you build your representation of concepts from experience or experience-related primitives (like sensorimotor capacities. So if concepts can't be broken into epistemic capacities, concepts are like atoms (hence the name). Fodor goes on to say: "I do agree that if there is a knock-down, a priori argument that concepts are logical constructs out of capacities, then my view about their ontology can't be right and I shall have to give up my kind of cognitive science. Oh, well. If there's a knock-down, a priori argument that cats are logical constructs out of sensations, then my views about their ontology can't be right either, and I shall have to give up my kind of biology. Neither possibility actually worries me a lot." (6)

        
Inferential Role Semantics - The concepts one has is determined, at least in part, by what inferences one is prepared to draw or to accept. Any sort of theory that says that coextension of concepts is not sufficient for their synonymy. So one can have the concept WATER, but not H2O, if they do not have inferences linking the two (like (contains H20)->(contains H)).  Fodor argues against this as part of his RTM (12-13), as it violates concept atomism (since if primitive concepts are composed of at least in part by inferential role, then they are not atomic). Note that complex concepts CAN be constituted at least in part by their inferential relations, because compositionality requires it (BROWN COW is a complex concept which requires the inferential role that comes from joining the two together). (35) 

        
Representational Theory of Mind: He says that it "lacks a canonical formulation" and for now is a "loose confederation of theses":
1) "Psychological explanation is typicall nomic and is intentional through and through. The laws that psychological explanations invoke typically express causal relations among mental states that are specified under intentional description; viz. among mental states that are picked out by reference to their contents. Laws about causal relations among beliefs, desires, and actions are the paradigms." (7) Note that the arguments against the nonexistence of mental states, intentional states, and concepts are handled in objections to this thesis.
2) "'Mental representations' are the primitive bearers of intentional content." Both ontologically and in order of explanation, the intentionality of mental representations is prior to the intentionality of propositional attitudes, which is prior to the intentionality of natural languages. "for purposes of building intuitions, think of mental representations on the model of what Empiricist philosophers sometimes called 'Ideas'. That is, think of them as mental particulars endowed with causal powers and susceptible of semantic evaluation. [... the DOG idea] is satisfied by all and only dogs, and it has associative-cum-causal relations to, for example, the Idea CAT. So DOG has conditions of semantic evaluation and it has causal powers, as Ideas are required to do." (7) There is no "believing-that-P episode without a corresponding tokening-of-a-mental-representation episode" (7). So RTM says that everytime you believe that P, it "activates" a corresponding mental representation P' in your "belief box" (to use Stephen Schiffer's term).
3) Thinking is computation. Fodor notes that one must come first: computations defined over symbols or symbols that are in part defined by the computations which can act on them. Both cannot presuppose the other (although again he says that while it may be possible, he just doesn't see any way). 
4) Meaning is, more or less, information (Informational Semantics. This is replaced in LOT2 with Referential semantics). "A representation R expresses the property P in virtue of its being a law that things that are P cause tokenings of R (in, say, some still-to-be-specified circumstances C)." So IRS (inferential role semantics) cannot be right because it undermines conceptual atomism. If IRS were true, and the inferential role is what makes the difference between content and reference, then every concept must have an inferential role. But you need more than one concept to draw an inference, so if IRS is true, conceptual atomism isn't. (14) According to IS, since water is H20 and two is prime, but they are not mutually constitutive (it's not true that one requires either both concepts or none) it is possible to have the concept WATER but not HYDROGEN, and TWO but not PRIME. "It's perfectly consistent to claim that concepts are individuated by the properties they denote, and that the properties are individuated by their necessary relations to one another, but to deny that knowing about the necessary relations among the properties is a condition for having the concept." (74)
5) Whatever distinguishes coextensive concepts is ipso facto 'in the head'.  He goes into a discussion challenging the Frege architecture and MOPs (methods of presentation).

        
Since to know what individuates something is the same as knowing what it means to possess something, Fodor argues that it doesn't matter whether we start with a theory of concept individuation or possession: knowing one determines the other.

        
Chapter 2

        
Lists 5 non-negotiable conditions on any theory of concepts:
1) Concepts are mental particulars; specifically, they satisfy whatever ontological conditions have to be met by things that function as mental causes and effects.
2) Concepts are categories and routinely employed as such. They apply to things in the world, and those things 'fall under' them.
3) Compositionality: concepts are the constituents of thoughts, and in indefinitely many cases, of one another. Mental representations inherit their contents from the contents of their constituents.
4) Quite a lot of concepts must turn out to be learned. 
5) (publicity requirement) Concepts are PUBLIC; they're the sorts of things that lots of people can, and do, share. If I believe that the current president has the properties: 46 years old, X1, X2, ..., XN and you believe he is 47 years old, and X1, X2, ..., XN, then we have measurably similar beliefs about him, but not the same belief. But what about the shared beliefs themselves (the Xi), are they or aren't they literally "shared"? This poses "a dilemma for the similarity theorist that is, as far as I can see, unavoidable. If he says that our agreed upon beliefs [...] [are shared,] then he hasn't managed to do what he promised; vix. introduce a notion of similarity of content that dispenses with a robust notion of publicity. But if he says that the agreed beliefs aren't literally shared (viz. that they are only required to be similar), then his account of content similarity begs the very question it was supposed to answer: his way of saying what is it for concepts to have similar but not indentical contents presupposes a prior notion of beliefs with similar but not identical contents." (31-32) So any theory that allows for similar beliefs, must at some level break down to have the same beliefs (how can two things be similar if they cannot be compared to each other?) If you suppose concepts are positions in a multi-dimensional vector space, to compare two spaces they must have the same dimensions, and those dimensions are then public.

        

      },
	Author = {Fodor, Jerry},
	Date-Modified = {2013-01-30 20:21:25 -0500},
	Isbn = {0198236379},
	Publisher = {Oxford University Press, Inc. New York, NY, USA},
	Title = {Concepts : Where Cognitive Science Went Wrong},
	Year = {1998}}

@book{Fodor1980,
	Address = {Cambridge, Massachusetts},
	Annote = {Piaget: 87-95, 175-176

        
"I am, in fact, strongly inclined to doubt the very intelligibility of the suggestion that there is a stage at which cognitive processes are carried out in a medium which is fundamentally nondiscursive. I am not, of course, denying the empirical possibility that children may use images more than adults do, or that their concepts may be, in some interesting sense, more concrete than adult concepts. What I do deny, however, is that the difference could be qualitative in the kind of way that Bruner seems to require." (177)

        
"Now, if I read it correctly, a good part of the psychology of cognitive development, especially as it has been influenced by Vygotsky, Bruner, and, above all, Piaget, has been concerned with defending three interrelated hypotheses about such processes.
1) The development of the child's cognitive capacities exhibits a reasonably ordered decomposition into stages.
2) These stages, though they are in the first instance characterized by reference to specific behavioral abilities that the child exhibits, are fundamentally expressions of the kinds of concepts it has available, with weaker conceptual systems corresponding to earlier stages.
3) Learning mediates the developmental progression from stage to stage.
[...] the view under discussion is that the child's developing intellectual capacities reflect changes in competence rather than (mere) changes in performance. [...] the difference is intrinsic to the expressive power of the conceptual systems available at the various developmental stages." (87)

        
Talks about Piaget's belief of increasing logics (88)

        
"What the arguments do show is just that if there are stages and they are determined by the expressive power of the underlying conceptual system, then the mechanism of cognitive development cannot, in point of logic, be concept learning." (95)},
	Author = {Fodor, Jerry A},
	Date-Modified = {2013-01-30 20:21:29 -0500},
	Edition = {2},
	File = {:Users/licatj/Documents/Shared/research/the\_language\_of\_thought.pdf:pdf},
	Isbn = {0674510305},
	Publisher = {Harvard University Press},
	Title = {The Language of Thought},
	Year = {1980},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3RoZV9sYW5ndWFnZV9vZl90aG91Z2h0LnBkZtIXCxgZV05TLmRhdGFPEQHoAAAAAAHoAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcbdGhlX2xhbmd1YWdlX29mX3Rob3VnaHQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Sn8oY22wAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMoZE6wAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBaTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAdGhlX2xhbmd1YWdlX29mX3Rob3VnaHQucGRmAA4AOAAbAHQAaABlAF8AbABhAG4AZwB1AGEAZwBlAF8AbwBmAF8AdABoAG8AdQBnAGgAdAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAR1VzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvdGhlX2xhbmd1YWdlX29mX3Rob3VnaHQucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOANMA2ADgAswCzgLTAt4C5wL1AvkDAAMJAw4DGwMeAzADMwM4AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAzo=}}

@book{Fodor2008,
	Annote = {Main theses:
- Pragmatism is the pervasive opponent of cartesian realism, which is correct
- Most of what we know about concepts follows from the compositionality of thoughts (190)
- ALL concepts are innate

        
Association is different from composition - if concept C is associated with A but composed of B, then retrieving C retrieves A based on the strength of the association, but always retrieves B. (1038)

        

        
        
          Chapter 5
        
        
        
No concept, complex or otherwise, can be learned (1275), but stereotypes CAN (1497). What are other differences between stereotypes and concepts?
- concepts can be complex and defined in terms of other concepts, stereotypes cannot
- concepts can combine to form other concepts, stereotypes cannot combine (this and previous point I could not find in this book, it is sourced elsewhere)
- in the boat analogy, stereotypes are like the boats, always moving based on experience, and concepts are the immovable, innate attractors / whirlpools that stereotypes can be closer to or further from.

        
stereotypes are defined as "statistical representations of experience". (1497)

        

        
        
          Chapter 6 - Preconceptual Representation
        
        
        
          

        Defines "iconic" representations as nonconceptual and different from "discursive" representations (1577), but leaves it open that there may be other types. What separates the two is that discursive representations have "canonical decompositions" (1596) while iconic representations do not.

        
          
Picture Principle: If P is a picture of X, then parts of P are pictures of parts of X.

        
This all sounds very pictorialist, and with pictorialist assumptions and the picture principle, it follows that iconic representations do not directly correspond to discursive representations and vice versa (1617).

        
He argues that iconic representations "lack many of the characteristic features of conceptualized representations" (1599). So you can't do the same kind of reasoning with iconic representations. You may be able to extract predicates from images, but "even though a picture contains information about giraffes, only an interpreter who has the concept GIRAFFE can see that it does" (1664). You can store the image containing giraffes even if you don't have a concept of what a giraffe is (he calls this "registering"), but extracting information from and reasoning about that image's giraffes requires that you have the giraffe concept (called "perceiving").},
	Author = {Fodor, Jerry A},
	Date-Modified = {2014-01-29 00:21:12 +0000},
	Publisher = {Oxford Univ. Press},
	Title = {{LOT 2: The Language of Thought Revisited}},
	Year = {2008}}

@book{Fodor2000,
	Annote = {Available through RPI Library website
The following chapters I have the pdfs for:

        
        
          
            
Chapter 4: There Are No Recognitional Concepts - Not Even RED

          
        
        
        
A concept is recognitional iff:
1- It is at least partially constituted by its possession conditions; and
2- Among its possession conditions is the ability to recognize at least some things that fall under the concept AS things that fall under the concept.
Fodor aims here to prove that there are no such things as recognitional concepts.

        
Satisfier - a concept's states, capacities, dispositions, etc. in virtue of which one meets the possession condition(s) for the concept. (footnote 1). 
Premise P (The "compositionality condition") - S is a satisfier for concept C iff C inherits S from the satisfiers for its constituent concepts. Fodor proves this based on concept productivity.
Fodor argues that since "there are no concepts among whose satisfiers are recognitional capacities, hence that there are no recognitional concepts." (36)
If concepts are at least partially their stereotypes, then knowing a concept's stereotype is a satisfier for those concepts. (38) But by Premise P, if you know the stereotypes for the constituents of a complex concept, you should know the stereotype for that concept. (the compositionality condition). But in the example of PET FISH, or MALE NURSE, Fodor says it doesn't compose. Therefore stereotypes cannot be concept-constitutive.

        
Further, he argues that there can be no recognitional concepts. Using a similar argument, the ability to recognize good instances of a concept doesn't compose. (He repeats that someone who can recognize that trouts are fish and puppies are pets is not therefore good at recognizing that goldfish are pet fish.) "The capacity for recognizing pet fish as such is not conceptually, or linguistically, or semantically connected to capacities for recognizing pets as such or fish as such." (39) But this is hard to accept, the example doesn't "click" with me.

        
He closes with a good FAQ section.                                
        
          
            

            
Chapter 5: There Are No Recognitional Concepts - Not Even RED, Part 2: The Plot Thickens

          
        
        
        
derp                                
        
          
            

            
Chapter 8: Review of Paul Churchland's 
        
        
        
        
        
          
        
        
          
            The Engine of Reason, The Seat of the Soul

            
          
        
        
          
        
        
        
        
derp                                
        
          
            

            
Chapter 9: Connectionism and the Problem of Systematicity: Why Smolensky's Solution Doesn't Work

          
        
        
        
derp                                
        
          
            

            
Chapter 10: Connectionism and the Problem of Systematicity (Continued): Why Smolensky's Solution Still Doesn't Work

          
        
        
        
derp},
	Author = {Fodor, Jerry A},
	Booktitle = {Philosophy},
	Date-Modified = {2013-01-30 20:18:36 -0500},
	File = {:Users/licatj/Documents/Shared/research/chap9\_InCriticalCondition.pdf:pdf;:Users/licatj/Documents/Shared/research/chap10\_InCriticalCondition.pdf:pdf;:Users/licatj/Documents/Shared/research/chap4\_ICC.pdf:pdf;:Users/licatj/Documents/Shared/research/chap8\_ICC.pdf:pdf;:Users/licatj/Documents/Shared/research/chap5\_ICC.pdf:pdf},
	Isbn = {9780262061988},
	Issn = {00318191},
	Publisher = {MIT Press},
	Series = {Representation and mind},
	Title = {In Critical Condition : Polemical Essays on Cognitive Science and the Philosophy of Mind},
	Url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:In+Critical+Condition\#2},
	Year = {2000},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NoYXA0X0lDQy5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDWNoYXA0X0lDQy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOP7DKBClMAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKBGGMAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGNoYXA0X0lDQy5wZGYADgAcAA0AYwBoAGEAcAA0AF8ASQBDAEMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NoYXA0X0lDQy5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==},
	Bdsk-File-2 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NoYXA1X0lDQy5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDWNoYXA1X0lDQy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOQFbKBbt+AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKBfO+AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGNoYXA1X0lDQy5wZGYADgAcAA0AYwBoAGEAcAA1AF8ASQBDAEMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NoYXA1X0lDQy5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==},
	Bdsk-File-3 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NoYXA4X0lDQy5wZGbSFwsYGVdOUy5kYXRhTxEBsAAAAAABsAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHDWNoYXA4X0lDQy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAORFPKBClEAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKBGGEAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIATE1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGNoYXA4X0lDQy5wZGYADgAcAA0AYwBoAGEAcAA4AF8ASQBDAEMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADlVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NoYXA4X0lDQy5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AxQDKANIChgKIAo0CmAKhAq8CswK6AsMCyALVAtgC6gLtAvIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC9A==},
	Bdsk-File-4 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NoYXA5X0luQ3JpdGljYWxDb25kaXRpb24ucGRm0hcLGBlXTlMuZGF0YU8RAfAAAAAAAfAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx1jaGFwOV9JbkNyaXRpY2FsQ29uZGl0aW9uLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADlbaygQo3wAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAygRhHwAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFxNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBjaGFwOV9JbkNyaXRpY2FsQ29uZGl0aW9uLnBkZgAOADwAHQBjAGgAYQBwADkAXwBJAG4AQwByAGkAdABpAGMAYQBsAEMAbwBuAGQAaQB0AGkAbwBuAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBJVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9jaGFwOV9JbkNyaXRpY2FsQ29uZGl0aW9uLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDVANoA4gLWAtgC3QLoAvEC/wMDAwoDEwMYAyUDKAM6Az0DQgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANE},
	Bdsk-File-5 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NoYXAxMF9JbkNyaXRpY2FsQ29uZGl0aW9uLnBkZtIXCxgZV05TLmRhdGFPEQH0AAAAAAH0AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEceY2hhcDEwX0luQ3JpdGljYWxDb25kaXRpb24ucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4/BMoEKOcAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMoEYScAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBdTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAY2hhcDEwX0luQ3JpdGljYWxDb25kaXRpb24ucGRmAAAOAD4AHgBjAGgAYQBwADEAMABfAEkAbgBDAHIAaQB0AGkAYwBhAGwAQwBvAG4AZABpAHQAaQBvAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAEpVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NoYXAxMF9JbkNyaXRpY2FsQ29uZGl0aW9uLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOANYA2wDjAtsC3QLiAu0C9gMEAwgDDwMYAx0DKgMtAz8DQgNHAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA0k=},
	Bdsk-Url-1 = {http://scholar.google.com/scholar?hl=en%5C&btnG=Search%5C&q=intitle:In+Critical+Condition%5C#2}}

@misc{Frank,
	Abstract = {Introduces Fodor's Informational Atomism as defined in fodor's book "Concepts", and argues that IA "fails to live up to its promise as a generalized theory of representation. In particular, I will examine how it fails to account for data provided by a classical task in the psychological problem solving literature, the candle task. By showing how all plausible construals of the Fodor theory fail to account for laboratory data, I hope to suggest that the theory has serious shortcomings, especially in its treatment of inferential knowledge about concepts."},
	Annote = {Summary says IA is defined by:
- for a mind to have a concept is for that mind to be in some sort of relationship to the world
- conceptual atomism: primitive (and most) concepts have no internal structure

        
"[Primitive concepts] have what Fodor calls "causal properties"-properties that govern the way they influence our behavior."

        
concept individuation = tokening? (3)

        
"[in f]unctional fixedness tasks [...] subjects are presented with a situation that requires them to use a familiar object to perform a novel function in order to solve a particular task. [...] In the candle task, participants are given a candle, a book of matches, and a box of tacks. They are asked to use these materials to mount the candle on a wall so that it burns normally and does not drip wax onto the floor. [... This] is known as a functional fixedness task because when subjects achieve the optimal solution, they do it by finding a novel function for the box: they use it as a support, rather than a container. On the other hand, when they fail it is because they do not find this novel function, leading psychologists to speculate that its function is already "fixed" by its presentation with the tacks inside it."
But presenting it differently (putting the box by itself) nearly everyone gets the optimal solution.

        

        

        
Argues that the "representation space" (the space in which the concepts used to represent the items provided) of the solvers' were different than that of the non-solvers, which conceptual atomists would argue, since conceptual atomism is inflexible. "there is only one way that an object can be represented, thus the theory has no way of accounting for the verbal undifferentiation of the box. On the conceptual atomist account, either the box is present or it is absent." 

        
- is it correct to assume that the process used to solve problems has these limitations? Should we assume that just because one possesses the concepts, they will automatically find the correct combination of the present concepts to solve the problem? Perhaps the problem-solving "filters" live in the non-constituent conceptual space--that is the parts of the conceptual world that are not constitutive of the core of the concepts: things like associations between concepts, inferential roles, etc.

        
He then goes on to consider the possibility that knowledge exists in the solvers that doesn't exist in the non-solvers, which is unlikely since we can drastically increase the amount of solvers by changing the items' "mode of presentation".

        

        

        

        
I'm not convinced. His "representation space" holds both concepts and inferential rules regarding those concepts. It still seems plausible to me that inferential rules regarding concepts are learned, and some of them can be made more "active" than others by things like recent memory (think psychological priming) or modes of presentation. And associations as well, think about the fact that WATSON won Jeopardy.},
	Author = {Frank, Michael C.},
	Doi = {10.1016/S1364-6613(98)01236-4},
	File = {:Users/licatj/Documents/Shared/research/frank.pdf:pdf},
	Issn = {13646613},
	Number = {2},
	Title = {{Against Informational Atomism}},
	Url = {http://philosophy.stanford.edu/apps/stanfordphilosophy/files/wysiwyg\_images/frank.pdf},
	Volume = {3},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2ZyYW5rLnBkZtIXCxgZV05TLmRhdGFPEQGgAAAAAAGgAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcJZnJhbmsucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8PDsoIeGsAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMoIsKsAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBITWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAZnJhbmsucGRmAA4AFAAJAGYAcgBhAG4AawAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIANVVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvZnJhbmsucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMEAxgDOAnICdAJ5AoQCjQKbAp8CpgKvArQCwQLEAtYC2QLeAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAuA=},
	Bdsk-Url-1 = {http://philosophy.stanford.edu/apps/stanfordphilosophy/files/wysiwyg%5C_images/frank.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/S1364-6613(98)01236-4}}

@article{Gentner1983,
	Author = {Gentner, D},
	Date-Modified = {2013-01-30 21:23:37 -0500},
	File = {:Users/licatj/Documents/Shared/research/Gentner.pdf:pdf},
	Journal = {{Cognitive Science}},
	Pages = {155--170},
	Title = {{Structure-Mapping: A Theoretical Framework for Analogy}},
	Volume = {7},
	Year = {1983},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0dlbnRuZXIucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwtHZW50bmVyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw+by+Ek9gAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAy+FdNgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBHZW50bmVyLnBkZgAOABgACwBHAGUAbgB0AG4AZQByAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9HZW50bmVyLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@article{Grabner2010,
	Author = {Grabner, Roland H. and Ansari, Daniel and Smedt, Bert and Hannula, Minna M.},
	Date-Modified = {2013-01-30 20:55:40 -0500},
	Doi = {10.1007/s11858-010-0277-2},
	File = {:Users/licatj/Documents/Shared/research/glossaryCogNeu.pdf:pdf},
	Issn = {1863-9690},
	Journal = {Zdm},
	Month = sep,
	Number = {6},
	Pages = {661--663},
	Title = {Glossary of Technical Terms in Cognitive Neuroscience},
	Url = {http://www.springerlink.com/index/10.1007/s11858-010-0277-2},
	Volume = {42},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2dsb3NzYXJ5Q29nTmV1LnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSZ2xvc3NhcnlDb2dOZXUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8P6Moe3EUAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMofFIUAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAZ2xvc3NhcnlDb2dOZXUucGRmAAAOACYAEgBnAGwAbwBzAHMAYQByAHkAQwBvAGcATgBlAHUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2dsb3NzYXJ5Q29nTmV1LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=},
	Bdsk-Url-1 = {http://www.springerlink.com/index/10.1007/s11858-010-0277-2},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/s11858-010-0277-2}}

@article{Grady,
	Author = {Grady, William O},
	Journal = {To appear in C. Doughty \& M. Long (eds.), The Handbook of Second Language Acquisition},
	Pages = {1--19},
	Title = {{The Radical Middle: Nativism without Universal Grammar}},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3JhZGljYWxtaWRkbGUucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFyYWRpY2FsbWlkZGxlLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxHmyQzl4gAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyQ0sMgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgByYWRpY2FsbWlkZGxlLnBkZgAOACQAEQByAGEAZABpAGMAYQBsAG0AaQBkAGQAbABlAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9yYWRpY2FsbWlkZGxlLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@book{Green1971,
	Abstract = {This book is a collection of papers presented at the symposium, "Conference on Ordinal Scales of Cognitive Development, sponsored by the California Test Bureau. Papers include: "The Theory of Stages in Cognitive Development" (J. Piaget); "Two Approaches to Intelligence: Piagetian and Psychometric" (D. Elkind); "An Implicit Metric for Ordinal Scales: Implications for Assessment of Cognitive Growth" (P. M. Bentler); "Theoretical Regularities and Individual Idiosyncrasies" (R. D. Tuddenham); "Some Problems Associated with Formal Thought and Its Assessment" (K. Lovell); "The Role of Experience in the Rate and Sequence of Cognitive Development" (M. L. Goldschmid); "Does the Piagetian Approach Imply Instruction?" (S. E. Englemann); "Developmental Theory and Diagnostic Procedures" (B. Inhelder); "Developmental Stages and Developmental Processes" (H. Beilin); "The Uses of Verbal Behavior in Assessing Children's Cognitive Abilities" (J. H. Flavell); "Closing Remarks" (B. Inhelder and J. Piaget). The following papers were not read at the conference, but were presented in written and outline form respectively: "Montonicity Analysis: An Alternative to Linear Factor and Test Analysis" (P. M. Bentler); "Assessing Cognitive Development via Measures of Optimal Performance" (J. D. Ayers). Comments and open floor discussions on each paper are included. (MS)},
	Address = {New York, New York, USA},
	Annote = {
        David Elkind, "Two Approaches to Intelligence : Piagetian and Psychometric"

        
        
Similarities: both agree that genetics have a role, although small, both don't use the experimental method, relying more on correlational studies, and both define intelligence as rationality.
Differences:
psychometrics are quantitative while piaget is qualitative,
source of genetic causality: psychometrics see it as intra-species variability, piaget focuses on nonrandom factors that cause the strict ordering of stages, each building on the last
course of mental growth. Psychometrics have one type, the child is measured using the same questions asked to 17 year olds (quantitative), piaget says that children differ fundamentally in how they think (qualitative).
relative contributions of nature and nurture. (?) Piaget sees the intelligent as able to be independent from both environmental and internal regulation.
His conclusion - the qualitative nature of piaget doesn't make it a suitable replacement for psychometrics in measuring intelligence.},
	Author = {Green, Donald Ross and Others},
	File = {:Users/licatj/Documents/Shared/research/Measurement and Piaget.pdf:pdf},
	Publisher = {McGraw-Hill Book Co.},
	Title = {{Measurement and Piaget}},
	Year = {1971},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL01lYXN1cmVtZW50IGFuZCBQaWFnZXQucGRm0hcLGBlXTlMuZGF0YU8RAeQAAAAAAeQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxpNZWFzdXJlbWVudCBhbmQgUGlhZ2V0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxDGyg1K5gAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyg2DJgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFlNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBNZWFzdXJlbWVudCBhbmQgUGlhZ2V0LnBkZgAADgA2ABoATQBlAGEAcwB1AHIAZQBtAGUAbgB0ACAAYQBuAGQAIABQAGkAYQBnAGUAdAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIARlVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvTWVhc3VyZW1lbnQgYW5kIFBpYWdldC5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDSANcA3wLHAskCzgLZAuIC8AL0AvsDBAMJAxYDGQMrAy4DMwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAM1}}

@article{Harzem2004,
	Author = {Harzem, Peter},
	Journal = {Archives},
	Keywords = {and strict behaviorism in,are,are so preposterously silly,behaviorism,class of theories which,cognitive psychology,consciousness,instances of the numerous,introspection,particular,reductive materialism in general,science of psychology,that,titchener,watson,wittgenstein},
	Number = {February 2002},
	Pages = {5--12},
	Title = {{BEHAVIORISM FOR NEW PSYCHOLOGY : WHAT WAS WRONG WITH BEHAVIORISM AND WHAT IS WRONG WITH IT NOW}},
	Volume = {12},
	Year = {2004}}

@article{Jylkka2008,
	Author = {Jylkk\"{a}, Jussi},
	Doi = {10.1007/s11023-008-9118-2},
	Issn = {09246495},
	Journal = {Minds and Machines},
	Keywords = {atomism \'{a},informational semantics \'{a} conceptual,sustaining mechanisms \'{a} deference,\'{a} psychological essentialism \'{a}},
	Number = {1},
	Pages = {25--46},
	Title = {{Why Fodor's Theory of Concepts Fails}},
	Url = {http://www.springerlink.com/index/10.1007/s11023-008-9118-2},
	Volume = {19},
	Year = {2008},
	Bdsk-Url-1 = {http://www.springerlink.com/index/10.1007/s11023-008-9118-2},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/s11023-008-9118-2}}

@misc{Kuhl,
	Abstract = {TED Talk},
	Annote = {She says that babies have a critical period for learning language, and they start out very early with the ability to distinguish sounds from all languages, which they lose quickly after exposure to their native language. Interestingly, this is socially activated: if they listen to sounds on tv it doesn't affect them, only when they hear a human speaking it.},
	Author = {Kuhl, Patricia},
	Date-Modified = {2013-01-30 20:44:33 -0500},
	Title = {The Linguistic Genius of Babies (Patricia Kuhl)},
	Url = {http://www.ted.com/talks/patricia\_kuhl\_the\_linguistic\_genius\_of\_babies.html},
	Bdsk-Url-1 = {http://www.ted.com/talks/patricia%5C_kuhl%5C_the%5C_linguistic%5C_genius%5C_of%5C_babies.html}}

@inproceedings{Langley2006,
	Address = {Boston, MA},
	Annote = {describes ICARUS architecture, which is similar to ACT-R and SOAR, but has a built-in conceptual inference module utilized for its most basic activities. },
	Author = {Langley, Pat and Choi, Dongkyu},
	Booktitle = {Proceedings of the Twenty-First National Conference on Artificial Intelligence},
	File = {:Users/licatj/Documents/Shared/research/10.1.1.74.7031.pdf:pdf},
	Publisher = {AAAI Press},
	Title = {{A Unified Cognitive Architecture for Physical Agents}},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS43NC43MDMxLnBkZtIXCxgZV05TLmRhdGFPEQHEAAAAAAHEAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcSMTAuMS4xLjc0LjcwMzEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48bcpGH6MAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMpGV+MAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBRTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTAuMS4xLjc0LjcwMzEucGRmAAAOACYAEgAxADAALgAxAC4AMQAuADcANAAuADcAMAAzADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS43NC43MDMxLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAp8CoQKmArECugLIAswC0wLcAuEC7gLxAwMDBgMLAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAw0=}}

@article{Larkin1987,
	Author = {Larkin, J.H. and Simon, H.A.},
	Date-Modified = {2013-01-30 20:43:54 -0500},
	File = {:Users/licatj/Documents/Shared/research/Larkin.pdf:pdf},
	Journal = {Cognitive Science},
	Pages = {65--99},
	Title = {Why a Diagram is (Sometimes) Worth 10,000 Words},
	Volume = {11},
	Year = {1987},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0xhcmtpbi5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCkxhcmtpbi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEJLJ4IiXAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADJ4MDXAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AExhcmtpbi5wZGYAAA4AFgAKAEwAYQByAGsAaQBuAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9MYXJraW4ucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==}}

@article{Levine1999,
	Abstract = {In keeping with other recent efforts, Fodor's CONCEPTS focuses on the metaphysics of conceptual content, bracketing such epistemological questions as, "How can we know the contents of our concepts?" Fodor's metaphysical account of concepts, called "informational atomism," stipulates that the contents of a subject's concepts are fixed by the nomological lockings between the subject and the world. After sketching Fodor's "what else?" argument in support of his view, we offer a number of related criticisms. All point to the same conclusion: Fodor is ultimately not merely bracketing the epistemology of conceptual content; his theory makes answers to the epistemological questions impossible.},
	Annote = {Published in 1999, well before LOT2, but offers insight into the development of ideas that led Fodor to LOT2. Author summarizes Fodor's arguments in his book "Concepts". 
- Attacks IA (informational atomism)
- Attacks an older version of concept possession, using a "Dumb Detector" argument (if molecules can recognize dopamine receptors, do they have the concept DOPAMINE?), this is outdated by Fodor's LOT2 clarification of concept possession.},
	Author = {Levine, Alex and Bickhard, Mark H.},
	Date-Modified = {2013-01-30 20:43:36 -0500},
	File = {:Users/licatj/Documents/Shared/research/1743067.pdf:pdf},
	Journal = {Philosophical Psychology},
	Number = {1},
	Pages = {5--23},
	Title = {{Concepts : Where Fodor Went Wrong}},
	Volume = {12},
	Year = {1999},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzE3NDMwNjcucGRm0hcLGBlXTlMuZGF0YU8RAagAAAAAAagAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RwsxNzQzMDY3LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADjyCydZKCQAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAydaCSQAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEpNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgAxNzQzMDY3LnBkZgAOABgACwAxADcANAAzADAANgA3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA3VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy8xNzQzMDY3LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDDAMgA0AJ8An4CgwKOApcCpQKpArACuQK+AssCzgLgAuMC6AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALq}}

@article{Ludwig2008,
	Author = {Ludwig, Kirk and Schneider, Susan},
	Journal = {Mind \& Language},
	Number = {1},
	Pages = {123--143},
	Title = {{Fodor ' s Challenge to the Classical Computational Theory of Mind}},
	Volume = {23},
	Year = {2008}}

@book{Margolis1999,
	Abstract = {(from the cover) This book provides a collection of the important classic and contemporary works on the nature of concepts in the field of cognitive science. The papers, written by philosophers, psychologists and linguists, address the key philosophical and psychological issues involved in the nature of concepts and their acquisition. Unselected chapters are journal reprints, chapter reprints and excerpts from authored books, all covered by PsycINFO. ((c) 1999 APA/PsycINFO, all rights reserved).},
	Annote = {definition for prototype:
"roughly, a description of the best examples or central tendency of a concept." (355, chapter by Smith, Osherson, Rips, and Keane)
a prototype can also refer to the "best example" of an instance of a category, like used in Chapter 18 by George Lakoff.

        

        
In LOT2, Fodor refers to this book (p. 140, Fodor2008) as being something that incorrectly cites atomism, referentialism as being necessary assumptions to conclude innatism.},
	Booktitle = {Knowledge Creation Diffusion Utilization},
	Chapter = {Against De},
	Editor = {Margolis, Eric and Laurence, Stephen},
	Isbn = {0262631938},
	Pages = {x, 652 pp.},
	Publisher = {MIT Press},
	Title = {{Concepts: Core Readings}},
	Url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=sj1gczQ-7K8C\&amp;oi=fnd\&amp;pg=PR9\&amp;dq=Concepts:+Core+Readings\&amp;ots=NnpkDmvY2A\&amp;sig=68d8zNR04ba71uE426XtYdnRbrc},
	Year = {1999},
	Bdsk-Url-1 = {http://books.google.com/books?hl=en%5C&amp;lr=%5C&amp;id=sj1gczQ-7K8C%5C&amp;oi=fnd%5C&amp;pg=PR9%5C&amp;dq=Concepts:+Core+Readings%5C&amp;ots=NnpkDmvY2A%5C&amp;sig=68d8zNR04ba71uE426XtYdnRbrc}}

@article{McLaughlin2009,
	Abstract = {One of the main challenges that Jerry Fodor and Zenon Pylyshyn (Cognition 28:3--71, 1988) posed for any connectionist theory of cognitive architecture is to explain the systematicity of thought without implementing a Language of Thought (LOT) architecture. The systematicity challenge presents a dilemma: if connectionism cannot explain the systematicity of thought, then it fails to offer an adequate theory of cognitive architecture; and if it explains the systematicity of thought by implementing a LOT architecture, then it fails to offer an alternative to the LOT hypothesis. Given that thought is systematic, connectionism can offer an adequate alternative to the LOT hypothesis only if it can meet the challenge. Although some critics tried to meet the challenge, others argued that it need not be met since thought is not in fact systematic; and some claimed not to even understand the claim that thought is systematic. I do not here examine attempts to answer the challenge. Instead, I defend the challenge itself by explicating the notion of systematicity in a way that I hope makes clear that thought is indeed systematic, and so that to offer an adequate alternative to the LOT hypothesis, connectionism must meet the challenge.},
	Annote = {formulates concise statement of the systematicity requirement, talks about why connectionism misses it

        
"Ceteris paribus, anyone able tomentally represent that aRb is able tomentally represent that bRa." The challenge is (for connectionists who believe that mental states can be reduced to a connectionist architecture, rather than for the connectionists that are eliminativist about mental states) to explain systematicity without resorting to a language of thought.},
	Author = {McLaughlin, Brian P},
	File = {:Users/licatj/Documents/Shared/research/systematicity.pdf:pdf},
	Journal = {Synthese},
	Number = {2},
	Pages = {251--274},
	Title = {{Systematicity Redux}},
	Volume = {170},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N5c3RlbWF0aWNpdHkucGRm0hcLGBlXTlMuZGF0YU8RAcAAAAAAAcAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48RxFzeXN0ZW1hdGljaXR5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxKaygnLaAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAygoDqAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFBNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBzeXN0ZW1hdGljaXR5LnBkZgAOACQAEQBzAHkAcwB0AGUAbQBhAHQAaQBjAGkAdAB5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9zeXN0ZW1hdGljaXR5LnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDJAM4A1gKaApwCoQKsArUCwwLHAs4C1wLcAukC7AL+AwEDBgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMI}}

@book{Meadows2006,
	Address = {New York, New York, USA},
	Annote = {
        Chapter 2: Descriptive studies of children's cognitive skills and knowledge
        
Evidence that children seem to learn and use "basic-level" categories easier than "superordinate-level":
- Work done by Rosch et al. 1976: 
- Then what was Fodor talking about? "To the contrary, it appears that the most accessible concepts, both in perceptual classification and in ontogeny, are `middle level' ones (Rosch 1973). In fact, it appears that children generally learn sensory concepts relatively late, whether the criterion of learning is the ability to sort or the ability to name. Likewise, a dog is, I suppose, a kind of animal; but subjects are faster at classifying a dog as a dog than in classifying the same dog as an animal. "Rosch, E. (1973), `On the internal structure of perceptual and semantic categories', in T. Moore (ed.), Cognitive Development and the Acquisition of Lanqua\~{}e (New York: Academic). 

        
Evidence that Piaget, Inhelder, Vygotsky were wrong about how the cognitive abilities of children were limited:- page 156, and she says "much of the rest of this shows [that it has come under a successful attack since 1970s]"- "None of this can be taken as suggesting that infants can categorise like adults, but these and similar studies [...] do show classification in infants; infants are also quite demonstrably capable of recognising a new instance of an important and familiar category, such as feeding bottles, and treating it as similar to previous encountered instances."
- Sugarman (1981, 1983)
- Fivush 1987; Mandler2004a
- Clark 1983, Gelman and Baillargeon 1983, Smith 1989b, Hespos and Spelke 2004
- (p. 164) "Thus the current state of opinion seems to be that Piaget was right when he insisted that knowledge and thinking are based on processes that are 'functional invariants' throughout life, but wrong or at least oversimplifying when he described qualitatively different structures of knowledge at different ages. Later conceptual structures are bigger, more flexible and more easily accessed and reflected on than earlier ones, but not unambiguously different in their organisation and certainly not generalised into a uniform level of competence across different ages. Our concepts are embedded in our theories, and differences in world knowledge interact with differences in levels of explanation (Johnson et al. 2004) [...] Developmental changes seem to be a matter of differentiation, elaboration and perhaps integration of knowledge systems rather than qualitative changes in the whole basis of conceptualisation (though there are clearly microlevel changes in limited areas [...])" (164).

        
Rosch, E.H., et al (1976) Basic objects in natural categories. Cognitive Psychology 8, 342-439.
Sugarman, S. (1981) The cognitive basis of classification in very young children : an analysis of object ordering trends. Child Development 52, 1172-1178.
Sugarman, S. (1983) Children's Early Thought: Developments in Classification. Cambridge, UK: Cambridge University Press
Fivush 1987: Scripts and Categories: interrelationships in development. In Concepts and Conceptual Development. 
Mandler 2004a:
Clark, E.V. 1983: Meaning and Concepts. In "Handbook of Child Psychology", vol. 3
Gelman and Baillargeon 1983:
Smith 1989b:
Hespose and Spelke 2004:
Johnson et al 2004: What are theories for? Concept use throughout the continuum of dinosaur experience. Journal of Experimental Child Psychology 87, 171-200.

        

        
Neo-piagetianism

      },
	Author = {Meadows, Sara},
	Edition = {2},
	Publisher = {Routledge},
	Title = {{The Child as Thinker}},
	Year = {2006}}

@book{Mitchell1993,
	Address = {Cambridge, Massachusetts},
	Annote = {"The long-term goal of the Copycat project (and related projects) is to use computer models to help provide such a scientific basis for concepts." (231)

Definitions
Codelets
"small special-purpose pieces of code that act independently to build up hierarchical gloms from an initially unconnected set of jumbled letters." (32) (for Jumbo)
"codelets play the role of enzymes, randomly encountering letters and gloms (molecules) in the program's 'cytoplasm' and attempting to join them together to form ever-larger structures. Complex structures are built up gradually by chains of codelets." (32)
Temperature - "measures the amount of perceptual organization in the system (low temperature meaning a high degree of organization) and which, on the basis of this value, controls the degree of randomness used in making decisions" (36)

Slipnet - where concepts reside. Uses nodes, allows slippages and associations. Concepts are "identified not with a single node but rather with a region in the Slipnet, centered on a particular node and having blurry rather than sharp boundaries" (39). They had to include each letter of the alphabet as a node, with "successor" and "predecessor" edges hard-coded in (47). Also, the types of descriptions were hard-coded in (p. 48: length, letter-category, etc). Five types of slipnet links:
Category links- links possible descriptor category nodes to nodes (letter "a" to "letter-category")
Instance links - inverse of category links
Property links - links node to its properties ("A" to "first" and "Z" to "last")
Slip links - potential slippages, like leftmost <-> rightmost, first <-> last, etc.
Lateral links - non-hierarchical semantic relationships among nodes. Successor and predecessor, etc. (49-50)
Workspace - where "perceptual structures are built hierarchically on top of the 'raw' input" (40)

Coderack - "can be viewed as representing various pressures in a given problem." (42) Holds pending codelets.


The five target problems are:
abc => abd; ijk => ?
abc => abd; iijjkk => ?
abc => abd; kji => ?
abc => abd; ace => ?
abc => abd; mrrjjj => ?

Related Work
Dedre Gentner's "structure-mapping" theory "perhaps the best-known work in cognitive science on analogy" (201). SME (Structure Mapping Engine)
Keither Holyoak and Paul Thagard's ACME (Analogical Constraint Mapping Engine)
Thomas Evans' ANALOGY program

Problems Copycat cannot solve (245-246)
abc => abd
	ace => ?
	aababc => ?
	pxqxrxsx => ?
	aaabbbcck => ?
	bcdacdabd => ?
abcd => abcde
	ijklm => ?
	ijxlm => ?
	mlkji => ?
	iiii => ?
	iiiijjjj => ?
mmmkooeeeeefqxx => kfq
	riipppppplooyg => ?
rrccmmkppbb => k
	ljooooosrezv => ?
abcde => xxxxx
	pqr => ?
xxj => fgh
	pxxx => ?
pqrxxxx => pqrstuv
	efghmm => ?
amcmemg => abcdefg
	wxyx => ?
eeeeqee => eeeeree
	sosss => ?
eeeqee => qqqeqq
	sabsss => ?
eqe => qeq
	abcdcba => ?
abcdde => abcde
	pqstu => ?
abced => abcde
	ppqqrrs => ?
a => z
	b => ?
pqr => rqb
	a => ?
discussion is given for these problems and explanations for why it may be having trouble with these.},
	Author = {Mitchell, Melanie},
	Date-Modified = {2013-09-13 16:24:12 -0400},
	Publisher = {The MIT Press},
	Title = {Analogy-Making as Perception : A Computer Model},
	Year = {1993}}

@article{Patterson2005,
	Abstract = {In recent articles Fodor and Lepore have argued that not only do considerations of learnability dictate that meaning must be compositional in the well-known sense that the meanings of all sentences are determined by the meanings of a finite number of primitive expressions and a finite number of operations on them, but also that meaning must be`reverse compositional' as well, in the sense that the meanings of the primitive expressions of which a complex expression is composed must be determined by the meaning of that complex expression plus the manner of its composition. I argue against the requirement of reverse compositionality and against the claim that learnability requires it. I consider some objections and close the paper by arguing against the related claim that concepts are reverse compositional. [ABSTRACT FROM AUTHOR]},
	Annote = {Argues that the "reverse compositionality" that Fodor requires is unnecessary. This is a good read because it might help clarify the concept vs stereotype confusion.},
	Author = {Patterson, Douglas},
	Doi = {10.1111/j.0268-1064.2005.00288.x},
	Issn = {0268-1064},
	Journal = {Mind and Language},
	Keywords = {compositionality (linguistics),fodor,information theory,language \& languages,learning,semantics,stereotypes},
	Mendeley-Tags = {fodor,learning,stereotypes},
	Month = jun,
	Number = {3},
	Pages = {326--352},
	Title = {{Learnability and Compositionality}},
	Url = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00288.x},
	Volume = {20},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzE3MTY4MTQ0LnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMMTcxNjgxNDQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48gckItsoAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMkI/RoAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMTcxNjgxNDQucGRmAAAOABoADAAxADcAMQA2ADgAMQA0ADQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzE3MTY4MTQ0LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00288.x},
	Bdsk-Url-2 = {http://dx.doi.org/10.1111/j.0268-1064.2005.00288.x}}

@book{Piaget1977,
	Address = {New York, New York, USA},
	Annote = {Chapter 25: "The Growth of Logical Thinking from Childhood to Adolescence" (from "The Growth of Logical Thinking")
"Two observations arise out of this circular process which characterizes all exchanges between the nervous system and society. The first is that the formal structures are neither innate a priori forms of intelligence which are inscribed in advance in the nervous system, nor are they collective representations which exist ready-made outside and above the individual. Instead, they are forms of equilibrium which gradually settle on the system of exchanges between individuals and the physical milieu and on the system of exchanges [among] individuals themselves. Moreover, in the final analysis the two systems can be reduced to a singe system seen from two different perspectives [...] The second observation is that between the nervous system and society there is individual activity--i.e., the sum of the experience of an individual in learning to adapt to both physical and social worlds. If formal structures are laws of equilibrium and if there is really a functional activity specific to the individual, we would expect adolescent thinking to show a series of spontaneous manifestations expressing the organization of formal structures as it is actually experienced [...] In other words, formal development should take place in a way that furthers the growth of the adolescent in his daily life as he learns to fill adult roles." (436, from Chap. XVIII). 
Piaget goes on to describe what he sees as parallels between the emergence of formal thought and changes in the life of the adolescent and his relation towards others.        
        
          
            

            

            
Chapter 26: Logic and Psychology
        
        
        
fdj},
	Author = {Piaget, Jean},
	Editor = {Gruber, Howard E. and Voneche, J. Jacques},
	Publisher = {Basic Books, Inc},
	Title = {{The Essential Piaget}},
	Year = {1977}}

@book{Piaget1958,
	Address = {New York, New York, USA},
	Annote = {chapter XVIII (reprinted in "The Essential Piaget"):
"Two observations arise out of this circular process which characterizes all exchanges between the nervous system and society. The first is that the formal structures are neither innate a priori forms of intelligence which are inscribed in advance in the nervous system, nor are they collective representations which exist ready-made outside and above the individual. Instead, they are forms of equilibrium which gradually settle on the system of exchanges between individuals and the physical milieu and on the system of exchanges [among] individuals themselves. Moreover, in the final analysis the two systems can be reduced to a singe system seen from two different perspectives [...] The second observation is that between the nervous system and society there is individual activity--i.e., the sum of the experience of an individual in learning to adapt to both physical and social worlds. If formal structures are laws of equilibrium and if there is really a functional activity specific to the individual, we would expect adolescent thinking to show a series of spontaneous manifestations expressing the organization of formal structures as it is actually experienced [...] In other words, formal development should take place in a way that furthers the growth of the adolescent in his daily life as he learns to fill adult roles." (436, from Chap. XVIII). 
Piaget goes on to describe what he sees as parallels between the emergence of formal thought and changes in the life of the adolescent and his relation towards others.        
      },
	Author = {Piaget, Jean and Inhelder, Barbel},
	Pages = {chapter XVIII},
	Publisher = {Basic Books, Inc},
	Title = {{The Growth of Logical Thinking}},
	Year = {1958}}

@book{Piattelli-Palmarini1980,
	Address = {Cambridge, Massachusetts},
	Editor = {Piattelli-Palmarini, Massimo},
	Publisher = {Harvard University Press},
	Title = {{Language and Learning : The Debate between Jean Piaget and Noam Chomsky}},
	Year = {1980}}

@article{Pinker2005a,
	Annote = {Repeatedly states that Fodor does not answer his criticisms in "So How Does the Mind Work?" However, he recaps the disagreement between him and Fodor on whether or not the mind searches for truth or simply for beliefs that are produce action (?? read Fodor again for clarification on this disagreement):

        
"Fodor defends his conviction that `the proper function of cognition is the fixation of true beliefs' by claiming that systematic error in cognition can always be explained in terms of an interaction between a knowledge system that aims at true beliefs and a decision system that applies them to generate overt behavior. ... This ignores an obvious third possibility: that the mind indeed contains separate belief and decision systems, but the belief system is prone to systematic error in circumstances where fixing true beliefs leads to lower fitness than satisficing or self-deceiving with false beliefs." (36)},
	Author = {Pinker, Steven},
	Doi = {10.1111/j.0268-1064.2005.00276.x},
	Issn = {0268-1064},
	Journal = {Mind and Language},
	Month = feb,
	Number = {1},
	Pages = {33--38},
	Title = {{A Reply to Jerry Fodor on How the Mind Works}},
	Url = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00276.x},
	Volume = {20},
	Year = {2005},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00276.x},
	Bdsk-Url-2 = {http://dx.doi.org/10.1111/j.0268-1064.2005.00276.x}}

@incollection{Pinker2007,
	Address = {New York, New York, USA},
	Annote = {Fodor is cited "not as a player in the nature-nurture debate but as a player in the debate over how the meanings of words are represented in people's minds." (90)
Pinker tries to push forward theory of conceptual semantics by opposing it with:
Extreme Nativism (term for Fodor's belief)
Radical Pragmatics ("the idea that the mind does not contain fixed representations of the meanings of words. Words are fluid, and can mean very different things in different circumstances. We give them a meaning only on the fly, in the context of the current conversation or text. What we draw upon in memory is not a lexicon of definitions but a network of associations among words and the kinds of events and actors they typically convey." (91) )
Linguistic Determinism - "upends" conceptual semantics. "Rather than language being a window into human thought, which is couched in a richer and more abstract format, our native language is the language of thought, and so determines the kinds of thoughts we can think." (91-92)

        
He shows evidence that there are in fact concepts that can be decomposed. (102-106)

        
"A definition (which admittedly is always incomplete) is not the same thing as a semantic representation." (100)},
	Author = {Pinker, Steven},
	Booktitle = {The Stuff Of Thought : Language as a Window into Human Nature},
	Chapter = {3},
	Date-Modified = {2011-07-16 02:59:02 -0400},
	Isbn = {9780143114246},
	Pages = {89--152},
	Publisher = {Penguin Group Inc.},
	Title = {{Fifty Thousand Innate Concepts (and Other Radical Theories of Language and Thought)}},
	Year = {2007}}

@article{Pinker2005,
	Abstract = {In my bookHow the Mind Works, I defended the theory that the human mind is a naturally selected system of organs of computation. Jerry Fodor claims that`the mind doesn't work that way'(in a book with that title) because(1) Turing Machines cannot duplicate humans' ability to perform abduction(inference to the best explanation);(2) though a massively modular system could succeed at abduction, such a system is implausible on other grounds; and(3) evolution adds nothing to our understanding of the mind. In this review I show that these arguments are flawed. First, my claim that the mind is a computational system is different from the claim Fodor attacks(that the mind has the architecture of a Turing Machine); therefore the practical limitations of Turing Machines are irrelevant. Second, Fodor identifies abduction with the cumulative accomplishments of the scientific community over millennia. This is very different from the accomplishments of human common sense, so the supposed gap between human cognition and computational models may be illusory. Third, my claim about biological specialization, as seen in organ systems, is distinct from Fodor's own notion of encapsulated modules, so the limitations of the latter are irrelevant. Fourth, Fodor's arguments dismissing of the relevance of evolution to psychology are unsound. [ABSTRACT FROM AUTHOR]},
	Annote = {- says Fodor's view of CTM is that the mind isn't only Turing-equivalent, but that it has a TM architecture (6), which is preposterous
- but the version of CTM that the mind is Turing-equivalent is not defensible either (7) because we cannot do everything a TM can (perfect recall of an almost infinite set of rules and calculations that take an almost infinite amount of time).
Goes through some inconsistencies with Fodor's critiques of CTM (until p.9).

        
Says Fodor claims "abduction" is impossible for computational systems to do.
          
Abduction - The ability to bring up relevant information when solving a problem, or to be sensitive to inconsistencies in belief systems. (9) AKA globality, the frame problem, or 'inference to the best explanation.' (9)
Pinker shows that the gap between this supposed ability and the abilities of computational systems is not as wide as Fodor thinks. For example, what about constraint satisfaction networks? What about symbolic-connectionist hybrids? (11-13)
Fodor also says that even if heuristics cause what looks like abduction, it doesn't explain the abduction used to come up with those heuristics in the first place. Pinker's reply is basically that there's not enough evidence for this (15).

        
Fodor says that massive modularity could explain abduction, but nobody can explain how the brain knows which modular unit to activate at the right time. Pinker says yes we do (17).

        
Finally, Pinker answers Fodor's criticisms of the contribution of evolutionary psychology, which are not worth getting into based on Fodor's misunderstandings of evolution.},
	Author = {Pinker, Steven},
	Doi = {10.1111/j.0268-1064.2005.00274.x},
	Issn = {0268-1064},
	Journal = {Mind and Language},
	Keywords = {brain,computational learning theory,machine theory,turing machines},
	Month = feb,
	Number = {1},
	Pages = {1--24},
	Title = {{So How Does the Mind Work?}},
	Url = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00274.x},
	Volume = {20},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QRC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3NvIGhvdyBkb2VzIHRoZSBtaW5kIHdvcmsucGRm0hcLGBlXTlMuZGF0YU8RAfAAAAAAAfAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx1zbyBob3cgZG9lcyB0aGUgbWluZCB3b3JrLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxJryQjTUgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyQkZogAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFxNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBzbyBob3cgZG9lcyB0aGUgbWluZCB3b3JrLnBkZgAOADwAHQBzAG8AIABoAG8AdwAgAGQAbwBlAHMAIAB0AGgAZQAgAG0AaQBuAGQAIAB3AG8AcgBrAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBJVXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9zbyBob3cgZG9lcyB0aGUgbWluZCB3b3JrLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDVANoA4gLWAtgC3QLoAvEC/wMDAwoDEwMYAyUDKAM6Az0DQgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANE},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00274.x},
	Bdsk-Url-2 = {http://dx.doi.org/10.1111/j.0268-1064.2005.00274.x}}

@book{Prinz2002,
	Annote = {Referred to by Fodor in "Atomism, Pluralism, and Conceptual Content".

        
Prinz's "proxytypes" are what concepts are. They are "perceptually derived representations [in long-term memory networks] that can be recruited by working memory to represent a category".

        
Strategies used to respond to the (hypothetical) emergent property DANGEROUS coming in BROWN COW:
1) deny that BROWN COW is compound (GRAY MATTER, DUMB WAITER, (BETWEEN JOBS?))
2) argue DANGEROUS actually comes from one of the constituents of BROWN COW
3) argue it is a permissible exception to the compositionality requirement

        
"[The argument that prototypes are not compositional and cannot be concepts] actually misconstrues the modality of the compositionality requirement. [...] [I]t is one thing to say that concepts must be compositional, and another to say that they must be capable of compositional combination. I submit that only the latter is required." (291)

        
"We should derive the prototypes of phrasal concepts in a purely compositional way only when relevant background knowledge and exemplar memories are unavailable. When these things are available, we should use them. It is simply bad cognitive policy to limit ourselves to the information contained in the constituents of our phrasal concepts when we have other relevant information at our disposal." (291)
Prinz here offers us a testable hypothesis: In phrasal concepts where background knowledge \& exemplar memories are unavailable (very rare cases), do their prototypes generate emergent features? Think "COWS BELONGING TO PEOPLE WHOSE NAMES BEGIN WITH 'W'".

        
Additionally, why does Fodor assume that concepts combine in the same way? Shouldn't novel phrasal concepts have the same features for different people? An experiment that asks people to consider multiple concepts may show different emergent features, can it be then argued that this supports the idea that atomic concept compositionality is not the only thing people use to produce thoughts

        
Prinz's 3-stage model of concept (prototype) combination:
1) Retrieval Stage - check if information regarding a compound concept already exists.
2) Composition stage - if (1) doesn't work, try to join concepts using combination rules (some compositional, some not). 
3) Analysis stage - check new collection of features, see if it makes sense (fill in gaps, draw inferences, resolve inconsistencies, etc)
Also known as RCA model (see figure 11.1 on p.308)

      },
	Author = {Prinz, Jesse},
	Booktitle = {Mind},
	Date-Modified = {2013-01-30 21:05:35 -0500},
	File = {:Users/licatj/Documents/Shared/research/chap11.pdf:pdf},
	Isbn = {9780262162074},
	Publisher = {MIT Press},
	Title = {Furnishing the Mind : Concepts and their Perceptual Basis},
	Url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=Gp5A85NQzJMC\&amp;oi=fnd\&amp;pg=PR9\&amp;dq=Furnishing+the+Mind\&amp;ots=85B1OvQxTS\&amp;sig=Wt7JpmCwXHROKsKKCP\_gtJBsN4A},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2NoYXAxMS5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCmNoYXAxMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOP67KCe3WAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKCiYWAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGNoYXAxMS5wZGYAAA4AFgAKAGMAaABhAHAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9jaGFwMTEucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==},
	Bdsk-Url-1 = {http://books.google.com/books?hl=en%5C&amp;lr=%5C&amp;id=Gp5A85NQzJMC%5C&amp;oi=fnd%5C&amp;pg=PR9%5C&amp;dq=Furnishing+the+Mind%5C&amp;ots=85B1OvQxTS%5C&amp;sig=Wt7JpmCwXHROKsKKCP%5C_gtJBsN4A}}

@article{Putnam,
	Annote = {identifies IH (innateness hypothesis) as "hopelessly vague".

        
Questions the idea that first language learning is really that easy compared to second language learning, when we look at how many habits need to be unlearned by the adult, and time the adult spends on learning the new language.

        
Horribly outdated in terms of what it thinks AI is capable of, it doesn't believe that using experimentation, a computer can learn how to beat the peg game (10).

        
Good quote on page 10:
"Invoking innateness only postpones the problem of learning; it does not solve it. Until we understand the strategies which make general learning possible - and vague talk of 'classes of hypotheses' - and 'weighting functions' is utterly useless here - no discussion on the limits of learning can even begin."},
	Author = {Putnam, Hilary},
	Date-Modified = {2013-01-30 21:05:22 -0500},
	Journal = {Linguistics},
	Keywords = {chomsky,innate idea,language,n},
	Number = {12-22},
	Title = {The 'Innateness Hypothesis' and Explanatory Models in Linguistics},
	Url = {http://philpapers.org/rec/PUTTIH},
	Volume = {17},
	Year = {1967},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0LnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMZnVsbHRleHQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8PickM+qoAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMkNQPoAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAZnVsbHRleHQucGRmAAAOABoADABmAHUAbABsAHQAZQB4AHQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=},
	Bdsk-Url-1 = {http://philpapers.org/rec/PUTTIH}}

@article{Quartz2003,
	Annote = {Carefully goes through several iterations until he defines what "strong" innateness is:

        
Innateness Proposal V: a neural function f is innate iff (1) the devel- opment of the neural architecture G containing f is regulated exclu- sively by genetic and intrinsic epigenetic mechanisms and processes and permissive somatic interaction processes, (2) f is fixed from F by genetic and intrinsic epigenetic mechanisms and processes and somatic interaction processes, and (3) phylogenetic interactions external to the organism evaluate f according to some fitness metric. (18)

        
Then gives the:

        
Neural Constructivist Proposal: a neural function f is not strongly innate iff (1) the development of the neural architecture G containing f is regulated exclusively by genetic and intrinsic epigenetic mechan- isms and processes and instructivist somatic interaction processes, (2) f is fixed from F by genetic and intrinsic epigenetic mechanisms and processes and somatic interaction processes, and (3) phylogenetic inter- actions external to the organism evaluate f according to some fitness metric. (19)

      },
	Author = {Quartz, Steven R},
	Journal = {Biology and Philosophy},
	Keywords = {computational learning theory,empiricism,innatness,nativism,neural con-},
	Pages = {13--40},
	Title = {{Innateness and the Brain}},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QLy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3Rlc3QucGRm0hcLGBlXTlMuZGF0YU8RAZwAAAAAAZwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rwh0ZXN0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxKcyTXrWAAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyTYxqAAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAEdNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgB0ZXN0LnBkZgAADgASAAgAdABlAHMAdAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIANFVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvdGVzdC5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDAAMUAzQJtAm8CdAJ/AogClgKaAqECqgKvArwCvwLRAtQC2QAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALb}}

@misc{Quartz1993,
	Abstract = {Recent interest in PDP (parallel distributed processing) models is due in part to the widely held belief that they challenge many of the assumptions of classical cognitive science. In the domain of language acquisition, for example, there has been much interest in the claim that PDP models might undermine nativism. Related argu-ments based on PDP learning have also been given against Fodor's anti-construc-tivist position- a position that has contributed to the widespread dismissal of constructivism. A limitation of many of the claims regarding PDP learning, however, is that the principles underlying this learning have not been rigorously characterized. In this paper, I examine PDP models from within the framework of Valiant's PAC (probably approximately correct) model of learning, now the dominant model in machine learning, and which applies naturally to neural network learning. From this perspective, I evaluate the implications of PDP models for nativism and Fodor's influential anti-constructivist position. In particular, I demonstrate that, contrary to a number of claims, PDP models are nativist in a robust sense. I also demonstrate that PDP models actually serve as a good illustration of Fodor's anti-constructivist position. While these results may at first suggest that neural network models in general are incapable of the sort of concept acquisition that is required to refute Fodor's anti-constructivist position, I suggest},
	Annote = {Says Fodor is right, and the solution to his paradox is to increase representational power as a PART of learning. Cited by Shultz.

        
Advances idea that "non-stationary" systems, which are those that change (increase?) their initial hypothesis space as a result of normal learning.},
	Author = {Quartz, Steven R.},
	Pages = {223--242},
	Publisher = {Cognition},
	Title = {{Neural networks, nativism, and the plausibility of constructivism}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.116.1914},
	Volume = {48},
	Year = {1993},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xMTYuMTkxNC5wZGbSFwsYGVdOUy5kYXRhTxEByAAAAAAByAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEzEwLjEuMS4xMTYuMTkxNC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPFbJD8MqAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADJEAl6AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAUk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6ADEwLjEuMS4xMTYuMTkxNC5wZGYADgAoABMAMQAwAC4AMQAuADEALgAxADEANgAuADEAOQAxADQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD9Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzEwLjEuMS4xMTYuMTkxNC5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AywDQANgCpAKmAqsCtgK/As0C0QLYAuEC5gLzAvYDCAMLAxAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADEg==},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.116.1914}}

@book{Ratey2002,
	Annote = {Textbook. See my notes in google notebook "Brain Notes".},
	Author = {Ratey, John J.},
	Isbn = {0679453091},
	Keywords = {Brain,Neurons,Neuropsychology,Neuroscience},
	Mendeley-Tags = {Brain,Neurons,Neuroscience},
	Publisher = {Vintage Books},
	Title = {{A User's Guide to the Brain : Perception, Attention, and the Four Theaters of the Brain}},
	Year = {2002}}

@book{Ridley1995,
	Abstract = {(Audible.com audiobook edition)},
	Annote = {Good summary:
http://www.mcgoodwin.net/pages/otherbooks/mr\_redqueen.html

        
Describes the red queen hypothesis (as time passes, we have to "run faster" just to keep up with other species), which can explain how features evolved so quickly. (Also explains why we don't "turn back into monkeys"). Talks about many mechanisms supporting this.

        
Describes sexual selection theories: two dominant ones are Fisherean ("sexy son", we select the genes that would produce a son that could breed well) and Good-gene (we look for signs of healthy genes). Both support Ornaments, signs of what we're looking for.

        
FINAL CHAPTER

        
Although he admits the last two chapters put forth what is probably the most tenuous evolution theory in the book, it is the most interesting to me.

        
Book concludes: 
        
          Sexual selection made us look for pedomorphic / neotonic features. Skulls are larger in children in ape-like creatures, so we selected for that. That allowed the brain to expand, accelerated by a red queen effect. Language and higher level cognitive functions are byproducts of this, not the causes.
        
         For humans, wit and displays of intelligence are sexy and are our "peacock feathers". It is our species' feature, and the one which led to our accelerated intelligence.
- Another factor that may have encouraged neoteny is that since our species looked like kids longer, men stuck around more, increasing probability of survival and further selecting men who stuck around.
- The "we use it to form alliances", toolmaker, and machiavellian (for deception) theories of why our minds evolved are lacking
- Objection: Why don't other species evolve this? well why do peacocks have exaggerated feathers and we don't? Almost all species have an exaggerated "peacock feather," red queen explains how just a small change, when successful, can take off in an accelerated pace.
- Objection: The smart don't breed more. That's not necessarily true. Maybe in modern society yes, but throughout history those in power have bred MUCH more (think genghis khan).},
	Author = {Ridley, Matt},
	Pages = {Audiobook},
	Title = {{The Red Queen: Sex and the Evolution of Human Nature}},
	Year = {1995}}

@article{Rips2006,
	Abstract = {According to one theory about how children learn the concept of natural numbers, they first determine that ``one'', ``two'', and ``three'' denote the size of sets containing the relevant number of items. They then make the following inductive inference (the Bootstrap): The next number word in the counting series denotes the size of the sets you get by adding one more object to the sets denoted by the previous number word. For example, if ``three'' refers to the size of sets containing three items, then ``four'' (the next word after ``three'') must refer to the size of sets containing three plus one items. We argue, however, that the Bootstrap cannot pick out the natural number sequence from other nonequivalent sequences and thus cannot convey to children the concept of the natural numbers. This is not just a result of the usual difficulties with induction but is specific to the Bootstrap. In order to work properly, the Bootstrap must somehow restrict the concept of ``next number'' in a way that conforms to the structure of the natural numbers. But with these restrictions, the Bootstrap is unnecessary.},
	Annote = {Argues against Carey's (2004) suggestion that the natural number concept can be learned using a bootstrapping mechanism (abstract explains it). Basically, the definition of next(i) (the inductive step which allows for the bootstrap jump to understand the natural numbers) is underspecified in Carey's account, to the degree that it does not disambiguate between the standard natural number order and a limited one that only counts modulo 10.},
	Author = {Rips, Lance J. and Asmuth, Jennifer and Bloomfield, Amber},
	Date-Modified = {2013-01-30 21:04:38 -0500},
	Journal = {Cognition},
	Number = {3},
	Pages = {B51--B60},
	Title = {Giving the Boot to the Bootstrap: How Not to Learn the Natural Numbers},
	Volume = {101},
	Year = {2006}}

@article{Rives2009,
	Abstract = {This Article does not have an abstract.},
	Author = {Rives, Bradley},
	Doi = {10.1080/09515080903157916},
	Issn = {0951-5089},
	Journal = {Philosophical Psychology},
	Month = aug,
	Number = {4},
	Pages = {525--529},
	Publisher = {Routledge},
	Title = {{LOT 2: The Language of Thought Revisited (Review)}},
	Url = {http://www.informaworld.com/10.1080/09515080903157916},
	Volume = {22},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0xPVDJSZXZpZXcucGRm0hcLGBlXTlMuZGF0YU8RAbQAAAAAAbQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rw5MT1QyUmV2aWV3LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxClyUy9LgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyU0DfgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAE1NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBMT1QyUmV2aWV3LnBkZgAADgAeAA4ATABPAFQAMgBSAGUAdgBpAGUAdwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAOlVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvTE9UMlJldmlldy5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDGAMsA0wKLAo0CkgKdAqYCtAK4Ar8CyALNAtoC3QLvAvIC9wAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAL5},
	Bdsk-Url-1 = {http://www.informaworld.com/10.1080/09515080903157916},
	Bdsk-Url-2 = {http://dx.doi.org/10.1080/09515080903157916}}

@article{Robbins2002,
	Abstract = {Concepts semantically compose just in case they combine in such a way that the content of a complex concept is exhaustively determined by the contents of its constituents plus syntax. Compositionality is a standard constraint on theories of concepts, but one which statistical theories of concepts, such as prototype theory and theory theory, apparently fail to meet. I argue that, once the constraint is properly formulated, it emerges that this failure may be merely apparent.},
	Annote = {Classifies concept theories using three binary choices:
1) Atomists vs Atatomists
2) Classical Anatomism - concepts are definitional, encodes conditions that are necessary and sufficient for membership in category
vs
Nonclassical anatomism / Statisticalism - looser structure, more fuzzy membership (dominant in modern psychology)
3) Prototype theory - concepts are structured like probabilistically weighted feature lists
vs
Theory theory - essence of conceptual structure is an explanatorily coherent network of basic principles - a mini-theory of the target category.

        
Compositionality constraint: The content of a complex (NON-LEXICAL) concept is exhaustively determined by the contents of its constituent concepts and the rules governing the combination of those constituents.
The Compositionality Constraint \~{}CC! is usually advertised as a high-levelempirical hypothesis. It stems from an inference to the best explanation of two striking features of our mental life:
* Concepts are productive: there is no finite upper bound on the number of distinct concepts a thinker can potentially host.
* Concepts are systematic: the capacity to host certain concepts \~{}e.g. my mice-loving cat! entails the capacity to host other concepts with a sim- ilar structure \~{}my cat-loving mouse, my cat-loving cat, etc.!.

        
He states very concisely the compositionality challenge and its premises:
(P1) Concepts semantically compose.
(P2) According to statistical theories of concepts, the content of a concept corresponds to a statistical structure, such as a prototype or mini-theory.(P3) Statistical structures---prototypes, mini-theories, and the like---do not compose. 
(P4) If P1 and P3 are true, then statistical structures are not conceptual contents.
(C) Statistical theories of concepts are false.

        
Ways to read P1:
P1u: Conceptual contents always compose. 
P1fe: Conceptual contents compose in all but at most finitely many cases. 
P1i: Conceptual contents compose in indefinitely many cases.

        
"...weak compositionality will suffice. Consider productivity. If concepts are weakly compositional, then any thinker will be able to build up an open-ended set of them from a finite base, simply by combinatorial operations. [...] Likewise, mutatis mutandis, with the explanation of systematicity." (318-319)

        
Minimal Compositionality Constraint. The content of indefinitely many complex concepts is exhaustively determined by the contents of their con- stituents and the rules governing the combination of those constituents.

        
Ways to read P3 that emphasize the negation:
P3uw: It is not the case that statistical structures always compose
P3few: It is not the case that statistical structures compose in all but at most finitely many cases.
P3iw: It is not the case that statistical structures compose in indefinitely many cases.
P3in: (ambiguous with P3i) In indefinitely many cases, statistical structures do not compose.

        
SMM - Selective Modification Model (Smith et al. 1988). Had a high correlation between "observed and predicted typicality judgments", but has two limitations:
- the 'missing slots' problem: Apple didn't have an [orientation] slot, which makes it so UPSIDE-DOWN APPLE could not be generated by selective modification.
- the 'multiple effects' problem: modifying APPLE with SHRIVELED affects several attributes (shape, taste, etc). This shows that the attributes are not independent.

        
Why do we assume that the emergence of features is a result of concept combination? "...studies conducted by James Hampton support the hypothesis that subjects forming novel conjoint concepts regularly default to the assumption that membership in each constituent category is probabilistically independent of the other [...] it is hard to square with the claim that featural emergence is characteristic of concept combination in general." (324-5)

        
Two-factor theories of concepts: (Block) 
Concepts have two parts: Wide content (a content's reference) and narrow content (a way of thinking about the reference). Then a complex concept is:
-Wide Compositional iff its wide content is exhaustively determined by the wide contents of its constituents plus syntax.
-Totally Compositional iff its content simpliciter is exhaustively determined by the contents simpliciter of its constituents plus syntax. (does this imply wide compositionality?)

        

      },
	Author = {Robbins, Philip},
	Doi = {10.1111/1468-0068.00373},
	File = {:Users/licatj/Documents/Shared/research/1468-0068.00373.pdf:pdf},
	Issn = {00294624},
	Journal = {No\^{u}s},
	Number = {2},
	Pages = {313--334},
	Title = {{How to Blunt the Sword of Compositionality}},
	Url = {http://www.blackwell-synergy.com/links/doi/10.1111/1468-0068.00373},
	Volume = {36},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzE0NjgtMDA2OC4wMDM3My5wZGbSFwsYGVdOUy5kYXRhTxEByAAAAAAByAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEzE0NjgtMDA2OC4wMDM3My5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPHvKCe5WAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKCiaWAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAUk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6ADE0NjgtMDA2OC4wMDM3My5wZGYADgAoABMAMQA0ADYAOAAtADAAMAA2ADgALgAwADAAMwA3ADMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAD9Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzE0NjgtMDA2OC4wMDM3My5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AywDQANgCpAKmAqsCtgK/As0C0QLYAuEC5gLzAvYDCAMLAxAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADEg==},
	Bdsk-Url-1 = {http://www.blackwell-synergy.com/links/doi/10.1111/1468-0068.00373},
	Bdsk-Url-2 = {http://dx.doi.org/10.1111/1468-0068.00373}}

@inproceedings{Shilliday2010,
	Annote = {PBSI - provability-based semantic interoperability, a logic based approach to information sharing and joint reasoning
          
Syntactic interoperability - shared protocols for communication and information exchange
          
Semantic interoperability - shared meaning. Note difference from and similarity to syntactic interoperability. Understanding, consequences of information are preserved between systems; very hard to do

        
Two goals of PBSI:
Meaningful information sharing - ability to take information expressed in one ontology's language, and re-express it in another's. Doesn't necessarily imply it can be translated in the other direction.
Joint reasoning - Ability to reason over knowledge in multiple systems while preserving semantic consequences between them.

Provability-based queries - queries where the response is accompanied by a justification

Previous attempts at semantic interoperability:
Schema matchings - when ontologies are similar, you presume that vocabularies from each are the same. (lastName vs surname)
Schema morphisms - actually mapping expressions (not just vocabulary) from one ontology to another
Both do not allow semantic consequence to be transferred when translation is impossible. They are also both non-logical, syntactic manipulations.

        
          
Translation Graph - visual trace of incremental construction and interrelation of ontology signatures (7)

Ontologies:
Pair <E,P> where:
E = <o,p> = signature in many-sorted logic
o = partition of the language's universe of discourse, with its cells being the sorts belonging to E
p = set of functors
P = set of sentences in the language of E.

},
	Author = {Shilliday, Andrew and Taylor, Josh and Clark, Micah and Bringsjord, Selmer},
	Booktitle = {Proceedings of the 2010 conference on Ontologies and Semantic Technologies for Intelligence, Frontiers in Artificial Intelligence and Applications},
	Date-Modified = {2012-03-02 00:48:37 -0500},
	Keywords = {logic,ontologies,provability-based semantic interoperability,translation graphs,unmanned aerial vehicles},
	Publisher = {IOS Press},
	Title = {Provability-Based Semantic Interoperability for Information Sharing and Joint Reasoning},
	Url = {http://www.cs.rpi.edu/~clarkm5/chapters/PBSI4OICpreprint.pdf},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2pvc2h1YSB0YXlsb3IgcGJzaWlzanIucGRm0hcLGBlXTlMuZGF0YU8RAeQAAAAAAeQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rxpqb3NodWEgdGF5bG9yIHBic2lpc2pyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxCAyKNDfgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyKN7vgAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAFlNYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBqb3NodWEgdGF5bG9yIHBic2lpc2pyLnBkZgAADgA2ABoAagBvAHMAaAB1AGEAIAB0AGEAeQBsAG8AcgAgAHAAYgBzAGkAaQBzAGoAcgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIARlVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvam9zaHVhIHRheWxvciBwYnNpaXNqci5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDSANcA3wLHAskCzgLZAuIC8AL0AvsDBAMJAxYDGQMrAy4DMwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAM1},
	Bdsk-Url-1 = {http://www.cs.rpi.edu/~clarkm5/chapters/PBSI4OICpreprint.pdf}}

@book{Shultz2003,
	Address = {Cambridge, Massachusetts},
	Author = {Shultz, Thomas R.},
	Date-Modified = {2012-02-29 06:49:59 -0500},
	Isbn = {026219483},
	Publisher = {The MIT Press},
	Title = {{Computational Developmental Psychology}},
	Year = {2003}}

@incollection{Shultz2008,
	Address = {New York, New York, USA},
	Annote = {Published a little later than his 2004 book, and does an in depth comparison of symbolic and connectionist architectures as they attempt to represent different developmental phenomena. Makes more of the same arguments of CC (Cascade correlation) vs. BP (Back propagation) neural networks, as the former has dynamic structure that changes qualitatively while the latter is static. Makes some other arguments in favor of connectionist models' advantages for modeling developmental psychology (466).},
	Author = {Shultz, Thomas R. and Sirois, Sylvain},
	Booktitle = {The Cambridge Handbook of Computational Psychology},
	Chapter = {16},
	Date-Modified = {2011-07-16 02:57:46 -0400},
	Editor = {Sun, Ron},
	Pages = {451--476},
	Publisher = {Cambridge Univ Press},
	Title = {{Computational Models of Developmental Psychology}},
	Year = {2008}}

@book{Siagian2007,
	Author = {Siagian, Christian and Itti, Laurent},
	Booktitle = {2007 IEEE/RSJ International Conference on Intelligent Robots and Systems},
	Date-Modified = {2013-01-30 21:03:24 -0500},
	Doi = {10.1109/IROS.2007.4399349},
	Isbn = {978-1-4244-0911-2},
	Month = oct,
	Pages = {1723--1730},
	Publisher = {IEEE},
	Title = {Biologically-Inspired Robotics Vision Monte-Carlo Localization in the Outdoor Environment},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4399349},
	Year = {2007},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4399349},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/IROS.2007.4399349}}

@article{Stavy2010,
	Author = {Stavy, Ruth and Babai, Reuven},
	Date-Modified = {2013-01-30 21:01:48 -0500},
	Doi = {10.1007/s11858-010-0251-z},
	File = {:Users/licatj/Documents/Shared/research/fulltext (2).pdf:pdf},
	Issn = {1863-9690},
	Journal = {Zdm},
	Keywords = {1 general introduction,brain imaging \'{a} control,difficulties,intuitive interference \'{a} intuitive,it is well known,mechanisms \'{a},reasoning \'{a} geometry,that many students encounter},
	Month = apr,
	Number = {6},
	Pages = {621--633},
	Title = {Overcoming Intuitive Interference in Mathematics: Insights from Behavioral, Brain Imaging and Intervention Studies},
	Url = {http://www.springerlink.com/index/10.1007/s11858-010-0251-z},
	Volume = {42},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICgyKS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGZ1bGx0ZXh0ICgyKS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDzTKHuEuAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKHxluAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZ1bGx0ZXh0ICgyKS5wZGYAAA4AIgAQAGYAdQBsAGwAdABlAHgAdAAgACgAMgApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoMikucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==},
	Bdsk-Url-1 = {http://www.springerlink.com/index/10.1007/s11858-010-0251-z},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/s11858-010-0251-z}}

@article{Stojanov,
	Abstract = {In the present paper we describe several autonomous agent architectures developed in the last 5 years, and inspired by mostly by Piaget's genetic epistemology. In the introduction part we give an overview of the developments in AI and robotics after the behaviorist turn in the mid `80s and propose a tentative taxonomy of the approaches that followed according to their treatment of representation.},
	Annote = {references heavily Drescher's work and is almost exclusively an extension of it.},
	Author = {Stojanov, Georgi},
	Journal = {Electrical Engineering},
	Title = {{Petitag\'{e} : A Case Study in Developmental Robotics}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.8507},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3Blcml0YWdlLnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMcGVyaXRhZ2UucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8Q/8kPwOgAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMkQBzgAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAcGVyaXRhZ2UucGRmAAAOABoADABwAGUAcgBpAHQAYQBnAGUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3Blcml0YWdlLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.8507}}

@article{Strumbelj2010,
	Author = {Strumbelj, Erik and Kononenko, Igor},
	Journal = {Journal of Machine Learning Research},
	Keywords = {classification,data postprocessing,explanation,visualization},
	Pages = {1--18},
	Title = {{An Efficient Explanation of Individual Classifications using Game Theory}},
	Volume = {11},
	Year = {2010}}

@article{Sukardi2007,
	Annote = {Undergrad paper. Good summary on Quartz (1997) and the connectionist response to Fodor and innatism in general.},
	Author = {Sukardi, Hendrick and Luo, J.},
	Number = {March},
	Title = {{On Prerepresentation}},
	Url = {http://www.rebelandking.com/hs/papers/UNI302 - On Prerepresentations.pdf},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QSS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1VOSTMwMiAtIE9uIFByZXJlcHJlc2VudGF0aW9ucy5wZGbSFwsYGVdOUy5kYXRhTxECAAAAAAACAAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHH1VOSTMwMiAtIE9uIFByZXJlcHJlcyNGMTJBQS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEqrJNeMmAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADJNil2AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAXk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AFVOSTMwMiAtIE9uIFByZXJlcHJlcyNGMTJBQS5wZGYADgBGACIAVQBOAEkAMwAwADIAIAAtACAATwBuACAAUAByAGUAcgBlAHAAcgBlAHMAZQBuAHQAYQB0AGkAbwBuAHMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAE5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL1VOSTMwMiAtIE9uIFByZXJlcHJlc2VudGF0aW9ucy5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDaAN8A5wLrAu0C8gL9AwYDFAMYAx8DKAMtAzoDPQNPA1IDVwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANZ},
	Bdsk-Url-1 = {http://www.rebelandking.com/hs/papers/UNI302%20-%20On%20Prerepresentations.pdf}}

@book{Sun2002,
	Annote = {Describes some theoretical justifications for CLARION, and has some good thorough philosophy of mind stuff. 

        

        Chapter 2

          
- Talks about explicit vs implicit knowledge, two levels of knowledge that can co-exist. They each have different learning models. 
- Top-Down learning (explicit to implicit) is implemented in other systems, while Clarion demonstrates Bottom-Up learning, which allows extracting of explicit knowledge from implicit. Explicit knowledge has been shown to be parallel to, and lag behind, the development of implicit knowledge (23). Studies such as the artificial grammar (where arbitrary strings generated with some secret grammar as opposed to those which were random were distinguishable by people, even when they couldn't explain why) show this.
- Both the top (explicit) and bottom (implicit) levels have knowledge that can be split up into action-centered and non-action-centered.
- We are introduced to the two most important new ideas of CLARION: dual processes, and bottom-up learning.

        
          
Chapter 6 : Symbol Grounding and Situated Cognition
        

        
- symbol grounding is "connecting symbols to lower-level sensory-motor processes and thus rooting the abstract in the concrete" (133)
- quotes Pierce (1955) who distinguished between signs and symbols (137) using the interpretant (the effect of a sign on someone who reads or comprehends it):
  A sign is either an icon, index, or symbol, depending on which distinguishes that icon:
    icon - a sign which would possess the character which renders it significant even if its object didn't exist (a lead-pencil streak representing a geometric line). An icon has something in common with its object (a physical similarity or a sounds-like relationship) that remains with the icon even if the object changes.
    index - a sign which would lose the character which makes it a sign if its object were removed, but would not lose that character if there were no interpretant (a bullet-hole as the sign of a shot). This is a more "real" connection between the object and sign than an icon has. 
    symbol - a sign which would lose the character which makes it a sign if there were no interpretant (any utterance of speech which signifies what it does only by virtue of its being understood to have that signification). Symbols only represent because they have been determined and created to do so.
Semiotics and Pierce's writings contain much more detailed descriptions of this.

        
- modern cog-sci definitions of what a symbol is:
          
Physical Symbol System Hypothesis - Newell and Simon (1976), essentially that "A physical symbol system has the necessary and sufficient means for general intelligent action". General intelligent action is the full range of human intelligent behavior. A physical system here is a "set of entities, called symbols, which are physical patterns that can occur as components of another type of entity called an expression (symbol structure). Thus a symbol structure is composed of a number of instances (or tokens) of symbols related in some physical way" (135). A symbol is a physical part of a compositional system that can arbitrarily refer to something.
          
Modified Physical Symbol System Hypothesis - A physical system is built from a set of elements (symbols) which can be formed into symbolic structures through relations, and interacts with its environment in two ways: (1) receives sensory stimuli which it converts into symbols, and (2) acts on the environment based on symbol structures it produces. 
Sun opts for the older physical symbol system hypothesis, and argues that some form of symbol processing is needed, even with a connectionist system.

      },
	Author = {Sun, Ron},
	Date-Modified = {2011-09-09 19:25:17 -0400},
	Publisher = {Lawrence Erlbaum Associates, Mah- wah, NJ},
	Title = {{Duality of the Mind: A Bottom Up Approach Toward Cognition}},
	Year = {2002}}

@article{Sun2004a,
	Annote = {NEWELL, A. (1990). Unified theories of cognition. Cambridge, MA: Harvard University Press

        
VERE, S.A. (1992). A cognitive process shell. Behavioral and Brain Sciences, 15, 460--461.

        

        
DESIDERATA
Ecological realism - everyday activities of humans, such as:
	reactivity
	sequentiality
	routineness
	trial-and-error adaptation
Bio-evolutionary realism - should be reducible to animal intelligence
Cognitive realism - capture ESSENTIAL characteristics of behavior and cognitive processes, like:
	Dichotomy of implicity/explicit processes
	Synergistic interaction (between implicit/implicit interaction)
	Bottom-up learning
	Modularity
Eclecticism of methodologies and techniques - he argues we should NOT hold too tightly to any specific approach, instead try to be broad (so we need to make sure we're not ahering too exclusively to neo-piagetianism)

      },
	Author = {Sun, Ron},
	Date-Modified = {2013-01-30 21:01:00 -0500},
	Doi = {10.1080/0951508042000286721},
	File = {:Users/licatj/Documents/Shared/research/sun-pp2003-f.pdf:pdf},
	Issn = {0951-5089},
	Journal = {Philosophical Psychology},
	Month = sep,
	Number = {3},
	Pages = {341--373},
	Title = {Desiderata for Cognitive Architectures},
	Url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/0951508042000286721\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
	Volume = {17},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3N1bi1wcDIwMDMtZi5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEHN1bi1wcDIwMDMtZi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEn3KN86SAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKOAbSAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHN1bi1wcDIwMDMtZi5wZGYAAA4AIgAQAHMAdQBuAC0AcABwADIAMAAwADMALQBmAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9zdW4tcHAyMDAzLWYucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==},
	Bdsk-Url-1 = {http://www.informaworld.com/openurl?genre=article%5C&doi=10.1080/0951508042000286721%5C&magic=crossref%7C%7CD404A21C5BB053405B1A640AFFD44AE3},
	Bdsk-Url-2 = {http://dx.doi.org/10.1080/0951508042000286721}}

@article{Thomas2010,
	Abstract = {Using traditional educational research methods, it is difficult to assess students' understanding of mathe- matical concepts, even though qualitative methods such as task observation and interviews provide some useful information. It has now become possible to use functional magnetic resonance imaging (fMRI) to observe brain activity whilst students think about mathematics, although much of this work has concentrated on number. In this study, we used fMRI to examine brain activity whilst ten university students translatedbetweengraphical andalgebraic formatsof both linear and quadratic mathematical functions. Consistent with previous studies on the representation of number, this task elicited activity in the intra-parietal sulcus, as well as in the inferior frontal gyrus.Wealso analysed qualitative data on participants' introspection of strategies employed when rea- soning about function. Expert participants focused more on key properties of functions when translating between formats than did novices. Implications for the teaching and learning of functions are discussed, including the relationship of function properties to difficulties in conversion from algebraic to graphical representation systems and vice versa, the desir- ability of teachers focusing attention on function properties, and the importance of integrating graphical and algebraic function instruction.},
	Author = {Thomas, Michael O. J. and Wilson, Anna J. and Corballis, Michael C. and Lim, Vanessa K. and Yoon, Caroline},
	Date-Modified = {2013-01-30 21:00:24 -0500},
	Doi = {10.1007/s11858-010-0272-7},
	File = {:Users/licatj/Documents/Shared/research/fulltext (4).pdf:pdf},
	Issn = {1863-9690},
	Journal = {Zdm},
	Keywords = {fmri \'{a} versatility \'{a},function \'{a},mathematical cognition \'{a} algebra,representation \'{a} conversion \'{a},\'{a}},
	Month = jul,
	Number = {6},
	Pages = {607--619},
	Title = {Evidence from Cognitive Neuroscience for the Role of Graphical and Algebraic Representations in Understanding Function},
	Url = {http://www.springerlink.com/index/10.1007/s11858-010-0272-7},
	Volume = {42},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICg0KS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGZ1bGx0ZXh0ICg0KS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPD0XKHuFVAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKHxmVAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZ1bGx0ZXh0ICg0KS5wZGYAAA4AIgAQAGYAdQBsAGwAdABlAHgAdAAgACgANAApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoNCkucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==},
	Bdsk-Url-1 = {http://www.springerlink.com/index/10.1007/s11858-010-0272-7},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/s11858-010-0272-7}}

@article{Viger2005,
	Abstract = {Jerry Fodor's argument for an innate language of thought continues to be a hurdle for researchers arguing that natural languages provide us with richer conceptual systems than our innate cognitive resources. I argue that because the logical/formal terms of natural languages are given a use-theory of meaning, unlike predicates, logical/formal terms might be learned without a mediating internal representation. In that case, our innate representational system might have less logical structure than a natural language, making it possible that we augment our innate representational system and improve our ability to think by learning a natural language. [ABSTRACT FROM AUTHOR]},
	Annote = {offers another alternate solution to fodor's paradox? This one is based on language learning as a way to increase the expressive power of a concept.

        
He is saying that some things (the logical terms in natural languages) can be learned without having a preexisting direct mental representation if they are learned indirectly, through their uses.
- Examine this more carefully. Wouldn't we then need a way to represent that group of uses in order to reason about it? Is this one of those cases Fodor complained about where HF is working in the background unbeknownst to the author?

        
the interesting thing about this thesis is that language has been suggested as the major factor in explaining how human cognitive ability increased so rapidly in evolutionary terms

        
1) Logical concepts need not have innate corresponding representations like predicates do
2) Anything expressible in mentalese is innate.
3) Natural language can express logical concepts, even if the underlying mentalese can not
4) Therefore natural languages are more expressive than mentalese, and concepts can be learned that are not innate by the definition in (2)},
	Author = {Viger, Christopher},
	Doi = {10.1111/j.0268-1064.2005.00287.x},
	Issn = {0268-1064},
	Journal = {Mind and Language},
	Keywords = {innateness hypothesis (linguistics),language \& languages,learning,theory},
	Month = jun,
	Number = {3},
	Pages = {313--325},
	Title = {{Learning to Think: A Response to the Language of Thought Argument for Innateness}},
	Url = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00287.x},
	Volume = {20},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPC4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2xlYXJuaW5nIHRvIHRoaW5rLnBkZtIXCxgZV05TLmRhdGFPEQHQAAAAAAHQAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcVbGVhcm5pbmcgdG8gdGhpbmsucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8QlckI0r4AAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMkJGQ4AAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBUTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAbGVhcm5pbmcgdG8gdGhpbmsucGRmAA4ALAAVAGwAZQBhAHIAbgBpAG4AZwAgAHQAbwAgAHQAaABpAG4AawAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQVVzZXJzL2pvaG4vRG9jdW1lbnRzL1NoYXJlZC9yZXNlYXJjaC9QYXBlcnMvbGVhcm5pbmcgdG8gdGhpbmsucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAM0A0gDaAq4CsAK1AsACyQLXAtsC4gLrAvAC/QMAAxIDFQMaAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAxw=},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00287.x},
	Bdsk-Url-2 = {http://dx.doi.org/10.1111/j.0268-1064.2005.00287.x}}

@article{Vogiatzis2008,
	Address = {New York, New York, USA},
	Author = {Vogiatzis, Dimitrios and Karkaletsis, Vangelis},
	Date-Modified = {2013-01-30 20:59:12 -0500},
	Doi = {10.1145/1389586.1389598},
	Isbn = {9781605580678},
	Journal = {Proceedings of the 1st ACM international conference on PErvasive Technologies Related to Assistive Environments - PETRA '08},
	Pages = {1},
	Publisher = {ACM Press},
	Title = {A Framework for Human-Robot Interaction},
	Url = {http://portal.acm.org/citation.cfm?doid=1389586.1389598},
	Year = {2008},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1389586.1389598},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1389586.1389598}}

@article{Weiskopf2007,
	Abstract = {Certain of our concepts are innate, but many others are learned. Despite the plausibility of this claim, some have argued that the very idea of concept learning is incoherent. I present a conception of learning that sidesteps the argu- ments against the possibility of concept learning, and sketch several mechanisms that result in the generation of new primitive concepts. Given the rational consid- erations that motivate their deployment, I argue that these deserve to be called learning mechanisms. I conclude by replying to the objections that these mecha- nisms cannot produce genuinely new content and cannot be part of genuinely cognitive explanations.},
	Annote = {"I don't take a stand here on how rich the initially specified set of triggered concepts is, or even on what sorts of concepts make it up. Rather, I've argued that the common notion of a fixed conceptual lexicon is a mistaken one." (23)

        
He claims that by broadening the definition of learning we can solve the acquisition problem. More specifically, we can describe a method by which new concepts are entered into one's conceptual repertoire as a result of experience. Basically in this paper he seems to be saying that we can give names to complex concepts in order to make them simple concepts, which then increases the possible concepts over which we can reason.
          

          
Compositionalists - those that believe concepts have an internal structure, and can be decomposed "into features that contribute to their semantic content and psychological role." (2)
          
Atomists - contrasts with compositionalists. Atomists believe that a concept's associative links / semantic content are small and that they have nothing to do with a concept's "possession or individuation conditions." (3) Fodor seems to support this.

        
Conceptions of learning
Inductivist - Fodor's (5)
Adaptionist - Learning is long-lasting adaptive change (6)

        
learning skills - learning to be better at DDR can't be described propositionally (how can a proposition explain how to be faster at hitting the right arrow?)

        
He says both compositionalists and atomists need to solve the acquisition problem (which is the problem of how we acquire primitive concepts). (3) Is this really true for the atomists? Certainly Fodor doesn't agree.

        
He talks about Fodor's definition of learning and then contrasts it with "perceptual learning", which has four conditions:
- it is a psychological process
- driven by and appropriately sensitive to environmental causes
- causes relatively long-lasting change in perceptual/congnitive systems
- it is adaptive (6)
Why does he integrate perceptual learning with inductive learning? Is it because they have the same word? Why should we assume that they are different aspects of the same process?
But he does say that adaptionist and inductivist learning don't completely overlap. (think example of getting better at DDR) Not all that is learned by adaptionist definition needs to be propositional.

        
Coining - basically naming something that was only indirectly represented before.},
	Author = {Weiskopf, Daniel a.},
	Date-Modified = {2013-01-30 20:58:49 -0500},
	Doi = {10.1007/s11098-007-9150-8},
	Issn = {0031-8116},
	Journal = {Philosophical Studies},
	Keywords = {acquisition \'{a} nativism \'{a},concepts \'{a} learning \'{a},innateness \'{a}},
	Month = sep,
	Number = {3},
	Pages = {359--384},
	Title = {The Origins of Concepts},
	Url = {http://www.springerlink.com/index/10.1007/s11098-007-9150-8},
	Volume = {140},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Zkc2tqbC5wZGbSFwsYGVdOUy5kYXRhTxEBpAAAAAABpAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHCmZkc2tqbC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDhTJSCqkAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADJSHD0AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIASU1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZkc2tqbC5wZGYAAA4AFgAKAGYAZABzAGsAagBsAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA2VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mZHNramwucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AwgDHAM8CdwJ5An4CiQKSAqACpAKrArQCuQLGAskC2wLeAuMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC5Q==},
	Bdsk-Url-1 = {http://www.springerlink.com/index/10.1007/s11098-007-9150-8},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/s11098-007-9150-8}}

@article{Weiskopf2009,
	Abstract = {Conceptual atomists argue that most of our concepts are primitive. I take up three arguments that have been thought to support atomism and show that they are inconclusive. The evidence that allegedly backs atomism is equally compatible with a localist position on which concepts are structured representations with complex semantic content. I lay out such a localist position and argue that the appropriate position for a non-atomist to adopt is a pluralist view of conceptual structure. I show several ways in which conceptual pluralism provides an advantage in satisfying the empirical and philosophical demands on a theory of conceptual structure and content.},
	Annote = {inserts two requirements of theories of concepts:
localist - some but not all of a concept's relations to other concepts are constitutive. His argument to support this essentially says that since many highly explanatory conceptual models have localist structure, we should take them at least as provisional support for the plausibility of localist concept structure (which presumably Fodor argues we don't have). Further, that which determines which of these inter-concept relations are constitutive of the structure "must be that the inclusion or exclusion of particular features is just a matter of how the conceptual system is geared towards acquiring, retrieving, modifying, and constructing representations of categories." (9) What about compositionality? He thinks the answer has already "been given by Prinz (2002, Ch. 11) and Robbins (2002). In essence, both point out that compositionality is a modal property: it concerns whether concepts can combine in a certain (non-emergent) way, not whether they always do. The fact that many complex phrasal concepts contain emergent features does not cast doubt on whether they can do this." (11)

        
pluralistic - People typically have multiple concepts available for representing each possible referential content they can conceive of. (referents->concepts is a multiple to one mapping)

        
Formulation of atomism:
(Atomism) A [lexical] concept's identity is not even partially constituted by its relations to any other concepts. [neither mereological nor inferential]
  corollary - a concept maintains its identity no matter what concepts it enters into combination with: COW is the same whether in BROWN COW or DANGEROUS COW.

        
Alternate formulations:
(Ref) Conceptual content is just reference.
 (Indiv) Concepts are individuated solely by their content and their formal/syntactic properties.
 (Inf Sem) Conceptual content is determined solely by information-carrying causal relations between concepts and their referents.3

        
"Strongest" form of atomism is the Strong Independence Principle:
(SIP): Possessing a concept does not require possessing any other concepts whatsoever.

        
Pages circa 23 or so describe the "subtraction strategy" and techniques used by people like Margolis to defend atomism, and from there distinguishes between strong independence and weak independence of concept atomism.
But subtraction strategy leads to the "intersubjectively pluralist" requirement of concepts: it should allow different subjects to possess concepts sharing their [referential]-Content but possibly differing in their [Conceptual]-content.},
	Author = {Weiskopf, Daniel a.},
	Doi = {10.1111/j.1933-1592.2009.00269.x},
	File = {:Users/licatj/Documents/Shared/research/atomism-vs-pluralism.pdf:pdf},
	Issn = {00318205},
	Journal = {Philosophy and Phenomenological Research},
	Month = jul,
	Number = {1},
	Pages = {131--163},
	Title = {{Atomism, Pluralism, and Conceptual Content}},
	Url = {http://doi.wiley.com/10.1111/j.1933-1592.2009.00269.x},
	Volume = {79},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QPy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2F0b21pc20tdnMtcGx1cmFsaXNtLnBkZtIXCxgZV05TLmRhdGFPEQHcAAAAAAHcAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcYYXRvbWlzbS12cy1wbHVyYWxpc20ucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA480MoIl6gAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMoIz+gAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBXTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAYXRvbWlzbS12cy1wbHVyYWxpc20ucGRmAAAOADIAGABhAHQAbwBtAGkAcwBtAC0AdgBzAC0AcABsAHUAcgBhAGwAaQBzAG0ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAERVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2F0b21pc20tdnMtcGx1cmFsaXNtLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOANAA1QDdAr0CvwLEAs8C2ALmAuoC8QL6Av8DDAMPAyEDJAMpAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAys=},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1111/j.1933-1592.2009.00269.x},
	Bdsk-Url-2 = {http://dx.doi.org/10.1111/j.1933-1592.2009.00269.x}}

@article{Weiskopf2008,
	Abstract = {Jean Mandler proposes an original and richly detailed theory of how concepts relate to sensory and motor capacities. I focus on her claims about conceptual representations and the processes that produce them. In her view, concepts are declarative representations of object kind information. First, I argue that since sensorimotor representations may be declarative, there is no bar to percepts being constituents of concepts. Second, I suggest that concepts track kinds and other categories not by representing kind information per se, but rather by being subject to the appropriate sort of inferential dispositions. These dispositions themselves may apply equally to perceptual and nonperceptual representations. Third, I argue that Mandler's proposed redescriptive mechanism for producing conceptual primitives can be viewed as a kind of Fodorian triggering device. Hence, there may be less distance between her view and Fodor's than either one has supposed. I suggest that redescription needs to be supplemented with several other kinds of more flexible and open-ended concept learning mechanisms. Finally, I briefly sketch the view of conceptual development that results from adopting these proposals and contrast it with Mandler's. [ABSTRACT FROM AUTHOR]},
	Annote = {seems to fully support Fodor's concept of concept "activation" and tries to use Jean Mandler's work as filling in the gaps of Fodor's description of the activation process

      },
	Author = {Weiskopf, Daniel a.},
	Doi = {10.1080/09515080801980211},
	Issn = {0951-5089},
	Journal = {Philosophical Psychology},
	Keywords = {cognitive development,empiricism,learning,nativism (psychology),psychology of,social sciences -- study \& teaching},
	Month = apr,
	Number = {2},
	Pages = {251--268},
	Title = {{First Thoughts}},
	Url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/09515080801980211\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
	Volume = {21},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QMy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzMxNjU3MDM0LnBkZtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcMMzE2NTcwMzQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA48jskItHQAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMkI+sQAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAMzE2NTcwMzQucGRmAAAOABoADAAzADEANgA1ADcAMAAzADQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADhVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzMxNjU3MDM0LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMQAyQDRAoECgwKIApMCnAKqAq4CtQK+AsMC0ALTAuUC6ALtAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAu8=},
	Bdsk-Url-1 = {http://www.informaworld.com/openurl?genre=article%5C&doi=10.1080/09515080801980211%5C&magic=crossref%7C%7CD404A21C5BB053405B1A640AFFD44AE3},
	Bdsk-Url-2 = {http://dx.doi.org/10.1080/09515080801980211}}

@article{Weiskopf2004,
	Annote = {Argues against fodor paradox using a philosophical argument, which identifies the two areas in which Fodor claims there is circular logic and disputes those claims.

        
"The locus of the debate, then, is ... between two views about how to understand what it takes to be able to think about things." (2)

        
Two objections from circularity are addressed:

        
          
The Sorting Objection
        
"(1) Having concept C depends on being able to sort Cs;and (2) Being able to sort Cs depends on having concept C (or something conceptually equivalent to it)." (2)
Concepts can be coextensional but defined differently, thus be separate concepts. (DOGS vs BARKERS).
He separates intentional sorting (I-sorting) from sorting that can be done mechanically, without intentional states (M-sorting). 

        
Fodor's circularity regarding sorting only applies to I-sorting, which requires an intentional state with regard to the concept being sorted. With two coextensional concepts S and S', if someone "possesses" concept S they can M-sort S, thus simultaneously M-sorting S' without necessarily possessing S'. Thus since statement (1) refers to M-sorting and statement (2) refers to I-sorting, the argument no longer makes sense, destroying its circularity. The BCP theorist merely needs to explain how the ability to M-sort S' can lead to possession of concept S'.},
	Author = {Weiskopf, Daniel a. and Bechtel, William},
	Doi = {10.1111/j.1468-0017.2004.00246.x},
	File = {:Users/licatj/Documents/Shared/research/remarksonfodoronhavingconcepts.pdf:pdf},
	Issn = {0268-1064},
	Journal = {Mind and Language},
	Month = feb,
	Number = {1},
	Pages = {48--56},
	Title = {{Remarks on Fodor on Having Concepts}},
	Url = {http://doi.wiley.com/10.1111/j.1468-0017.2004.00246.x},
	Volume = {19},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QSS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3JlbWFya3NvbmZvZG9yb25oYXZpbmdjb25jZXB0cy5wZGbSFwsYGVdOUy5kYXRhTxECAAAAAAACAAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHH3JlbWFya3NvbmZvZG9yb25oYXZpbiNGMTFFRi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEe/JNi7mAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADJNnU2AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAXk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AHJlbWFya3NvbmZvZG9yb25oYXZpbiNGMTFFRi5wZGYADgBGACIAcgBlAG0AYQByAGsAcwBvAG4AZgBvAGQAbwByAG8AbgBoAGEAdgBpAG4AZwBjAG8AbgBjAGUAcAB0AHMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAE5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL3JlbWFya3NvbmZvZG9yb25oYXZpbmdjb25jZXB0cy5wZGYAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDaAN8A5wLrAu0C8gL9AwYDFAMYAx8DKAMtAzoDPQNPA1IDVwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAANZ},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1111/j.1468-0017.2004.00246.x},
	Bdsk-Url-2 = {http://dx.doi.org/10.1111/j.1468-0017.2004.00246.x}}

@article{Wiggins2007,
	Author = {Wiggins, G. a.},
	Doi = {10.1093/llc/fqm025},
	Issn = {0268-1145},
	Journal = {Literary and Linguistic Computing},
	Month = dec,
	Number = {1},
	Pages = {109--116},
	Title = {{Computer Models of Musical Creativity: A Review of Computer Models of Musical Creativity by David Cope}},
	Url = {http://llc.oxfordjournals.org/cgi/doi/10.1093/llc/fqm025},
	Volume = {23},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QWS4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0NvbXB1dGVyIE1vZGVscyBvZiBNdXNpY2FsIENyZWF0aXZpdHkgQ2hhcCAxLTYucGRm0hcLGBlXTlMuZGF0YU8RAjAAAAAAAjAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM6Xc4NIKwAAAA48Rx9Db21wdXRlciBNb2RlbHMgb2YgTXUjRUEwNzcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADqB3yL6akgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGUGFwZXJzABAACAAAzperwwAAABEACAAAyL7S0gAAAAEAGAAOPEcAC/D6AAvEcwAI+kEACPpAAAJkjgACAF5NYWNpbnRvc2ggSEQ6VXNlcnM6AGpvaG46AERvY3VtZW50czoAU2hhcmVkOgByZXNlYXJjaDoAUGFwZXJzOgBDb21wdXRlciBNb2RlbHMgb2YgTXUjRUEwNzcucGRmAA4AZgAyAEMAbwBtAHAAdQB0AGUAcgAgAE0AbwBkAGUAbABzACAAbwBmACAATQB1AHMAaQBjAGEAbAAgAEMAcgBlAGEAdABpAHYAaQB0AHkAIABDAGgAYQBwACAAMQAtADYALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAF5Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0NvbXB1dGVyIE1vZGVscyBvZiBNdXNpY2FsIENyZWF0aXZpdHkgQ2hhcCAxLTYucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A6gDvAPcDKwMtAzIDPQNGA1QDWANfA2gDbQN6A30DjwOSA5cAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADmQ==},
	Bdsk-File-2 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QWi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0NvbXB1dGVyIE1vZGVscyBvZiBNdXNpY2FsIENyZWF0aXZpdHkgQ2hhcCA3LTEyLnBkZtIXCxgZV05TLmRhdGFPEQI0AAAAAAI0AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADOl3ODSCsAAAAOPEcfQ29tcHV0ZXIgTW9kZWxzIG9mIE11I0YwQzJDLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8MLMi+mZoAAAAAAAAAAAACAAUAAAkgAAAAAAAAAAAAAAAAAAAABlBhcGVycwAQAAgAAM6Xq8MAAAARAAgAAMi+0doAAAABABgADjxHAAvw+gALxHMACPpBAAj6QAACZI4AAgBeTWFjaW50b3NoIEhEOlVzZXJzOgBqb2huOgBEb2N1bWVudHM6AFNoYXJlZDoAcmVzZWFyY2g6AFBhcGVyczoAQ29tcHV0ZXIgTW9kZWxzIG9mIE11I0YwQzJDLnBkZgAOAGgAMwBDAG8AbQBwAHUAdABlAHIAIABNAG8AZABlAGwAcwAgAG8AZgAgAE0AdQBzAGkAYwBhAGwAIABDAHIAZQBhAHQAaQB2AGkAdAB5ACAAQwBoAGEAcAAgADcALQAxADIALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAF9Vc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL0NvbXB1dGVyIE1vZGVscyBvZiBNdXNpY2FsIENyZWF0aXZpdHkgQ2hhcCA3LTEyLnBkZgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDrAPAA+AMwAzIDNwNCA0sDWQNdA2QDbQNyA38DggOUA5cDnAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAOe},
	Bdsk-Url-1 = {http://llc.oxfordjournals.org/cgi/doi/10.1093/llc/fqm025},
	Bdsk-Url-2 = {http://dx.doi.org/10.1093/llc/fqm025}}

@inproceedings{Yang2003,
	Author = {Yang, Yingrui and Bringsjord, Selmer},
	Booktitle = {Proceedings of the Annual Conference of the Cognitive Science Society},
	Date-Modified = {2013-01-30 20:58:33 -0500},
	File = {:Users/licatj/Documents/Shared/research/239.pdf:pdf},
	Pages = {1275--1280},
	Title = {Mental Metalogic and its Empirical Justifications : The Case of Reasoning with Quantifiers and Predicates},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QLi4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzIzOS5wZGbSFwsYGVdOUy5kYXRhTxEBmAAAAAABmAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHBzIzOS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOPIzKPnGkAAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKPqnkAAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIARk1hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6ADIzOS5wZGYADgAQAAcAMgAzADkALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADNVc2Vycy9qb2huL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzLzIzOS5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AvwDEAMwCaAJqAm8CegKDApEClQKcAqUCqgK3AroCzALPAtQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC1g==}}

@article{Zago2010,
	Author = {Zago, Laure and Petit, Laurent and Mellet, Emmanuel and Joliot, Marc and Mazoyer, Bernard and Tzourio-Mazoyer, Nathalie},
	Date-Modified = {2013-01-30 20:58:14 -0500},
	Doi = {10.1007/s11858-010-0254-9},
	File = {:Users/licatj/Documents/Shared/research/fulltext (3).pdf:pdf},
	Issn = {1863-9690},
	Journal = {Zdm},
	Keywords = {enumeration \'{a} inferior parietal,gyrus \'{a},intraparietal sulcus \'{a} attention,\'{a} language},
	Month = may,
	Number = {6},
	Pages = {569--577},
	Title = {Neural Correlates of Counting Large Numerosity},
	Url = {http://www.springerlink.com/index/10.1007/s11858-010-0254-9},
	Volume = {42},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNy4uLy4uL0RvY3VtZW50cy9TaGFyZWQvcmVzZWFyY2gvUGFwZXJzL2Z1bGx0ZXh0ICgzKS5wZGbSFwsYGVdOUy5kYXRhTxEBvAAAAAABvAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpdzg0grAAAADjxHEGZ1bGx0ZXh0ICgzKS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDznKHuE8AAAAAAAAAAAAAgAFAAAJIAAAAAAAAAAAAAAAAAAAAAZQYXBlcnMAEAAIAADOl6vDAAAAEQAIAADKHxl8AAAAAQAYAA48RwAL8PoAC8RzAAj6QQAI+kAAAmSOAAIAT01hY2ludG9zaCBIRDpVc2VyczoAam9objoARG9jdW1lbnRzOgBTaGFyZWQ6AHJlc2VhcmNoOgBQYXBlcnM6AGZ1bGx0ZXh0ICgzKS5wZGYAAA4AIgAQAGYAdQBsAGwAdABlAHgAdAAgACgAMwApAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA8VXNlcnMvam9obi9Eb2N1bWVudHMvU2hhcmVkL3Jlc2VhcmNoL1BhcGVycy9mdWxsdGV4dCAoMykucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyADNANUClQKXApwCpwKwAr4CwgLJAtIC1wLkAucC+QL8AwEAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADAw==},
	Bdsk-Url-1 = {http://www.springerlink.com/index/10.1007/s11858-010-0254-9},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/s11858-010-0254-9}}

@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>Action Recognition</string>
		<key>keys</key>
		<string>Roemmele2014,Ovchinnikova2013,Weinland2011</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Analogical Reasoning</string>
		<key>keys</key>
		<string>Holyoak1987,Guhe2009,Owen1990,Mitchell1993,Finke1990,Klenk2011,Bartha2010,Melis1993,Keane2001,Lee2009,Halford1998,Melis2006,Turney2013,Melis1994,Gust2003,Shelley2002,AboulHosn2006,Jurgens2012,Lovett2010,Thagard2012,Finke1992,Melis1995,Klenk2009,Dunbar1999,Gust2006,Schlimm2008,Weinreb2005,Melis1996,Wilson2001,Foster2013,Krumnack2007,Vattam2013,Schwering2009,Falkenhainer1989,Gentner1986,Norton2011,Gentner2003,Riesbeck1989,Jamnik1999,Govindarajulu2013,Burstein1989,Friedman2010,Goswami1990b,Thagard1990,Forbus2007,Goldman1982,French2002,Raad2014,Shelley2002b,Gentner1997a,Law1994,Guarini2004,Holyoak1989,Thibaut2010,Robere2012,Lovett2009,Forbus2012,Sternberg1980,Colhoun2009,Rattermann1998,Yan2003,Bundy1988,Chi1981,Forbus1989,Krumnack2008,Piaget2001,Hummel2009,Schmidt2014,Holyoak2001,Lee2008,Macagno2009,Salvucci2001,Emruli2013,Friedman2011,Volle2010,Doumas2008,Hofstadter2001,Halford2002,Seifert1994,Christie2010,Trench2013,Reynolds2004,Gentner1997b,Hummel2014,Guarini2010,Forbus1995,Holyoak1995,Mitchell1995,Gentner1993,Licato2012,Eliasmith2001,Doumas2013,Gentner1983,Gentner2006,Gentner2010,Dosen2012,Cunningham2009,Licato2013a,Goswami2001,Morrison2010,Pickett2013,Forbus2009a,Markman1993,Murdock2011,Zhila2013,Spellman1992,Dietrich2010,Schauer2008,Huang1992,Hummel2003a,Dehghani2011,Hofstadter2013,Kerber1989,Forbus2002,Bringsjord2012,Gentner2011,Gentner2001,Friedman2012,Sun2004b,Turney2011,Licato2013b,Forbus1998,Hummel1997,Schwering2007,Hofstadter1995,Forbus2009b,Goswami1990a,Hummel2002,Marshall2006,Sowa2003,Jones2010,Hofstadter1984,Ross1989,Hummel2003b,Indurkhya1997</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Analogy - Vector Based Approaches</string>
		<key>keys</key>
		<string>Jurgens2012,Eliasmith2001,Pickett2013,Emruli2013,Turney2011,Zhila2013,Turney2013,Trench2013</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Automated Theorem Proving</string>
		<key>keys</key>
		<string>Owen1990,Melis1994,Ontanon2012,Melis1995,Gust2006,Huang1992,Jamnik1999,Bundy2005,Bundy1988,Krumnack2007,Melis1996,AboulHosn2006,Melis1993,Jones2010,Gust2003,Sieg2005,Alekhnovich2001,Conkey2011</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Balance Beam Task</string>
		<key>keys</key>
		<string>Wilkening1982,Klahr1999,Langley1987,vanderMaas2009,Schmidt1996,Shultz2003,Ferretti1986,Siegler1981,Shultz1994,Siegler1976,Sage1983,Jansen1997,vanRijn2003,McClelland1989,McClelland1995,Normandeau1989</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Brain / Neuro</string>
		<key>keys</key>
		<string>Prado2011,Roy2010,Ratey2002,Roy2012,Craddock2012,Zago2010,Quartz1993,DelCul2009,Mizuno2011,Grabner2010,Quartz1997,Volle2010,Stavy2010,Beatty2001</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Bringsjord / Chisholm</string>
		<key>keys</key>
		<string>Licato2012,Bringsjord2008a,Bringsjord2012,Govindarajulu2013,Arkoudas2009,Bringsjord1998,Chisholm1991,Chisholm1990,Chapin2011,Bringsjord2008b,Bringsjord2004,Licato2013b,Licato2013a,Bringsjord1998a,Bringsjord2001,Arkoudas2005,Bringsjord2011,Bringsjord2001b,Bringsjord2008c,Arkoudas2009b,Bringsjord2006,Bringsjord1998b,Bringsjord2003,Bringsjord1991,Bringsjord2011a,Bringsjord2000,Shilliday2010,Bringsjord2003b</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Case-based reasoning</string>
		<key>keys</key>
		<string>Cunningham2009,Seifert1994,Nugent2009,Mantaras2005,Aamodt1994,Ashley2010,Riesbeck1989,Watson1994,Burstein1989,Dodson2011,Ashley1990,Ashley1988</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Cognitive Systems / Architectures</string>
		<key>keys</key>
		<string>Hummel2003a,Gobet2001,Langley2006,Sun2001a,Friedman2010,Sun2001b,Shultz2003,Johnson-Laird2008,Anderson1976,Shastri1990,Sun1992a,Shultz2012,Sun1992b,Sun2004a,Sun2004b,Tversky1977,Rachkovskij2013,Cassimatis2006,Friedman2011,Sun2012a,Johnson-Laird1983,Sun2012b,Sun2002,Quartz1997,Sun2003,Licato2014a,Sun2012,Sun2005,Drescher1991,Sun2006,Sun2007,Sun1995a,Bringsjord2008a,Stanovich1999,Sun1995b,Shultz2008,Bello2011,Bennis2010,Evans2008,Sun2006b,Helie2010,Bello2012,Garcez2006,Friedman2012,Weber1998,Pynadath2013,Bello2007,Sun1991,Chaput2003,Ehman2006,Stewart2012,Doumas2013,Hummel2002,Morrison2010,Chater2008,Bottou2011</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Connectionism / Distr. vs Localist representation</string>
		<key>keys</key>
		<string>Heider1944,Roy2010,Browne2001,Chaput2003,Evans2008,Hinton1986,Drescher1991,McClelland2010,Siegelmann1991,Roy2012,Garcez2006,Sun1995,Sun2012,Rachkovskij2013,Stewart2012,Shultz2003,Hyotyniemi1996,Bringsjord1991,Elman1989,Emruli2013,Sun2002,Eliasmith2001,Mitchell1995,Shastri1990</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Deep learning / Deep NN</string>
		<key>keys</key>
		<string>Socher2010,Socher2013,Ng2011,Socher2011</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>dunno man</string>
		<key>keys</key>
		<string>Boden2009</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Ecigs</string>
		<key>keys</key>
		<string>Burstyn2013</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Emergence</string>
		<key>keys</key>
		<string>Over2003,Namatame2006,Fiddick2003,Marshall2006,Heider1944,Martens2006,Amit2003,Stanovich2003,Morrison2010,Goertzel1994</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Evolution</string>
		<key>keys</key>
		<string>Ridley1995,Bringsjord2001,Amit2003,Beer2004,Fiddick2003</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Explanations</string>
		<key>keys</key>
		<string>Friedman2012,Chi1994,Nugent2009,Hempel1965,Wellman2004,Hummel2009,Brewer2000,Keil2000,Thagard2012,Siegler1995,Dodson2011,Cummins2000,Hummel2014,Simon2000,Kitcher1989,Friedman2010,Friedman2011,Chi1989</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Fodor / Concepts</string>
		<key>keys</key>
		<string>Jylkka2008,Robbins2002,Viger2005,Fodor2008,Weiskopf2007,Pinker2005a,Quartz2003,Sun2002,Fodor2000,Ludwig2008,Fodor2005,Prinz2002,Margolis1999,Fodor1998,Pinker2007,Weiskopf2009,Edwards2009,Sukardi2007,Rives2009,Bickhard2008,Carey2004,Putnam1975,Pinker2005,Frank,Cowie1997,Levine1999,Patterson2005,Carey2009,Rips2006,Fodor1980,McLaughlin2009,Weiskopf2008,Connolly2007,Weiskopf2004</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Godel / Incompleteness / Tarski Undefinability</string>
		<key>keys</key>
		<string>Conkey2011,Bringsjord1998,Bringsjord2004,Smullyan1987,Ray2005,Mauldin,Sieg2005,Anderson2005,Murawski1998,Licato2013a,Arkoudas2005,Anderson2007</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Graph Matching</string>
		<key>keys</key>
		<string>Sammoud2005,Kuhn1955,Ontanon2012,Zaslavskiy2009,Gao2010,Leordeanu2009,Ullmann1976,Raad2014,Bunke2009,Gold1996,Munkres1957,Justice2006,Duchenne2009,Riesen2009,ZaslavskiyCode</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Law, Precedence, Legal Reasoning</string>
		<key>keys</key>
		<string>Alberti2012,Macagno2009,Franklin2012,Ashley1988,Prakken2012b,Dunne2012,Schauer2008,Indurkhya1997,Bench-Capon2012,Prakken2012,Ashley2010,Dimiskovska2013,Feteris2011,Bench-Capon2009,Bartha2010,Ashley1990,Weinreb2005,Guarini2004,Governati2008</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Licato</string>
		<key>keys</key>
		<string>Licato2014b,Licato2013a,Licato2012,Licato2011,Govindarajulu2013,Licato2014a,Bringsjord2012,LicatoUnpublished,Smith2010,Licato2013b</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Linguistics</string>
		<key>keys</key>
		<string>Everitt2007,Klein2003,Kuhl,Chomsky2010,Cowie1997,Patterson2005,Chomsky2,Chater2008,Piattelli-Palmarini1980,Putnam,Grady,McLaughlin2009</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Logic / Metareasoning / Category theory</string>
		<key>keys</key>
		<string>Smith2007,Bringsjord2008a,Smullyan1987,Anderson2005,Ray2005,Arkoudas2009,Dosen2012,Arkoudas_omega,Wang1995,Bringsjord2004,Barwise1998a,Bringsjord1998a,Zee2009,Arkoudas2005,Bringsjord2008c,Bringsjord2006,Bartha2010,Larkin1987,Arkoudas_alpha,Mauldin,Bringsjord1991,Shilliday2010,Johnson2001,Barwise1983,Anderson2007,Barwise1981</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Machine Learning</string>
		<key>keys</key>
		<string>Dorigo2005,Gao2010,Burges1998,Ng2011,Wiggins2007,Socher2013,Martens2006,Fletcher2009,Gentner1983,Bottou2011,Gold1996,Brun2011,Kulkarni2012,ZaslavskiyCode,Strumbelj2010,Umeyama1988,Kuhn1955,Le2014,Riesen2009,Marneffe2006,Klein2003,Munkres1957,Zaslavskiy2009</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Mental Logic/Models / Model-based reasoning</string>
		<key>keys</key>
		<string>Wang1995,OBrien1998,Johnson-Laird2010,Yang2003,Bringsjord1998,Braine1998a,Johnson-Laird2008,Johnson-Laird1985,Braine1998c,Braine1998b,Braine1998d,Johnson-Laird2001,Johnson-Laird,Johnson-Laird1983,Nersessian1999,Dunbar1999</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Moral Reasoning / Computational Ethics</string>
		<key>keys</key>
		<string>Dehghani2011,Sun2012a,Guarini2011,Bringsjord2011b,Guarini2005,Shore2012,McLaren2011,Mikhail,Guarini2010</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Other AI</string>
		<key>keys</key>
		<string>Mitchell1993,Boden1995,Emruli2013,Barwise1983,Luger2008,Nilsson2007,Wiggins2007,Jagannathan1989,Boden2009,Laird2001,Brooks1990</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Other Psychology / Developmental psych</string>
		<key>keys</key>
		<string>Harzem2004,Stanovich1999,Heider1944,Anderson1976,Sternberg1980,Arnon2013,Meadows2006,Bruce2010,Almas2010,Dubinsky2002,Rattermann1998,Drescher1991,Shure1968,Carey2004,Goldman1982,Zago2010,Stavy2010,Lungarella2003,Asada2009,Rips2006,DasGupta1989,Pegg2005,Marcus2009,Guerin2011,Arlin1975,Chomsky2010,Doumas2013,Gobet2001</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Phil of Mind / Symbol Grounding / Chinese Rm</string>
		<key>keys</key>
		<string>Dennett1989,Norvig2011,Turing1950,Bringsjord1991,Harnad1990,Bringsjord2001b,Bringsjord2011a,Brooks1990,Bringsjord2000,Chisholm1990,Nilsson2007,Bringsjord2003,Chisholm1991,Taddeo2012a</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Piaget / Constructivism / Schemas</string>
		<key>keys</key>
		<string>Pegg2005,Halford2002,Shultz1994,Inhelder1958,Wavering2011,Inhelder1990,Piaget2001b,Piaget2001,Quartz1993,Shultz2003,Dubinsky1991,Aksoy2013,Montangero1997,Stojanov,Green1971,Gallagher1978,DasGupta1989,Bringsjord2006,Shultz2012,Chapman1988,Piaget1979a,Arlin1975,Lungarella2003,Kofsky1999,Dubinsky2002,Quartz2003,Voyat1980,Piaget1970,Quartz1997,Demetriou2000,Platt2006,Barrouillet2011,Piaget1979b,Drescher1991,Piaget2006,vonGlasersfeld1991,Demetriou2004,Klahr1999,Shultz2008,Goldman1982,Guerin2011,Arnon2013,Jansen2002,Sternberg1980,Piaget1980,Halford1998,Piaget1977b,Bello2007,Piaget1974,Beth1966,Cohen2007,Chaput2003,Gallagher2002,Sun1995,Case1992,Piattelli-Palmarini1980,Turner2002,Piaget1991,Piaget1977,Arbib1992</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Psychometric AI</string>
		<key>keys</key>
		<string>Besold2013,Bringsjord2003b,Dowe2012,Kunda2010,Klenk2011,Chapin2011,Bringsjord2012,Lovett2010,Licato2013b,Turney2011</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Robotics</string>
		<key>keys</key>
		<string>Lungarella2003,Ivaldi2014,Siagian2007,Chiu2004,Asada2009,Drumwright2010,Vogiatzis2008,Cohen2007,Platt2006,Hernandez-Belmonte2011,Stojanov,Staranowicz2011,Mattingly2012,Aksoy2013,Kramer2007</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Semantic Databases</string>
		<key>keys</key>
		<string>Pantel2005,DiFranzo2011,Matuszek2006,Vrandecic2010,Bollacker2008,Auer2007</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Tree Matching / Applications</string>
		<key>keys</key>
		<string>Bille2005,Kilpelainen1995,Klein2003,Akutsu2010,Zhang1996,Gust2006,Ouangraoua2009,Heumann2009,Ferrara2011,Krumnack2007,Socher2013,Marneffe2006,Akutsu2011,Zhang1994,Akutsu2013,Tai1979</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Turing machines / complexity theory</string>
		<key>keys</key>
		<string>Siegelmann1991,Bringsjord2004,Turing1950,Bringsjord1991,Hyotyniemi1996</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Turing Test Alternatives</string>
		<key>keys</key>
		<string>Cohen2006,Besold2013,Levesque2012,Heider1944</string>
	</dict>
</array>
</plist>
}}
